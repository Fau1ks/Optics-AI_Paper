{
    "update_time": "2026-01-28 10:36:56",
    "word_filename": "Optical_Papers_260128.docx",
    "total_count": 279,
    "data": [
        {
            "id": "https://doi.org/10.1364/oe.587678",
            "title": "Thermal wavelength tunable all-polarization-maintaining thulium-doped NALM fiber laser",
            "link": "https://doi.org/10.1364/oe.587678",
            "published": "2026-01-21",
            "author": "Timothy Lim, Shutao Xu, Lachlan Hooper, Maria Davey, Urmi Talukder, Michelle Y. Sander",
            "summary": "<jats:p>A wavelength tunable polarization-maintaining all-fiber thulium-doped source based on a nonlinear amplifying loop mirror (NALM) is demonstrated for dissipative soliton and stretched pulse operation. Transform-limited pulse durations down to 163 fs and 134 fs are supported for dissipative soliton and stretched pulse operation, respectively. The magnitude and center wavelength shift direction of the fiber-based tunable Lyot filter can be adjusted by heating different fiber sections and lengths. Due to the versatile nature of the fiber-based Lyot filter, the strength of the temperature shift coefficient and free spectral range can be optimized through the corresponding filter design.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "热波长可调谐全保偏掺铥NALM光纤激光器",
            "abstract_cn": "<jats:p>基于非线性放大环镜 (NALM) 的波长可调谐保偏全光纤掺铥源被证明可用于耗散孤子和展宽脉冲操作。耗散孤子和展宽脉冲操作分别支持低至 163 fs 和 134 fs 的变换限制脉冲持续时间。基于光纤的可调谐Lyot滤波器的大小和中心波长偏移方向可以通过加热不同的光纤截面和长度来调节。由于基于光纤的Lyot滤波器的多功能性，可以通过相应的滤波器设计来优化温度漂移系数的强度和自由光谱范围。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1038/s41377-025-02134-z",
            "title": "Ultrahigh-radiance TTA-based OLED with 13 kA cm−2 current injection",
            "link": "https://doi.org/10.1038/s41377-025-02134-z",
            "published": "2026-01-27",
            "author": "Jichen Zhao, Yu Mao, Wansheng Liu, Zengyi Peng, Xu Wang, Jianhua Zou, Jianbin Wang, Dan Chen, Dongge Ma, Hongbin Wu, Bin Hu, Junbiao Peng",
            "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Organic semiconductors have been widely utilized in displays, solar cells, detectors, and other fields due to their tunable optoelectronic properties and simple fabrication processes. However, fabricating organic electrically pumped lasers remains an unresolved challenge. The low mobility of organic molecules struggles to sustain the current injection required for electrically pumped lasing, and the free carriers and triplets generated under high current density also quench the gain characteristics. In device fabrication, high-conductivity electrodes and resonant cavities are inevitably accompanied by optical losses, which decrease the quality factor of the resonator and further elevate the threshold current density for electrical pumping. Here, we fabricated an organic light-emitting diode (OLED) with triplet-triplet annihilation (TTA) characteristics and excellent electrical performance, capable of injecting a current density of 13 kA cm\n                    <jats:sup>−</jats:sup>\n                    <jats:sup>2</jats:sup>\n                    under 15-ns electrical pulse driving. By leveraging short-pulse driving to mitigate triplet accumulation and utilizing the TTA effect to suppress singlet-triplet annihilation (STA), the device can still remain nearly 1% external quantum efficiency (EQE) with 1 kA cm\n                    <jats:sup>−</jats:sup>\n                    <jats:sup>2</jats:sup>\n                    current injection and achieved a record-high output power of 56 W cm\n                    <jats:sup>−</jats:sup>\n                    <jats:sup>2</jats:sup>\n                    , which can sustain population inversion. The OLED was integrated into a high-quality distributed Bragg reflector (DBR) microcavity with ultrathin electrodes, realizing narrow-band light emission with a spectral linewidth of 5.5 nm under 13 kA cm\n                    <jats:sup>−</jats:sup>\n                    <jats:sup>2</jats:sup>\n                    current injection. This work paves the way for future fabrication of organic electrically pumped lasers with gain characteristics.\n                  </jats:p>",
            "journal": "Light: Science & Applications",
            "title_cn": "基于 TTA 的超高亮度 OLED，具有 13 kA cm−2 电流注入",
            "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    有机半导体由于其可调谐的光电特性和简单的制造工艺而被广泛应用于显示器、太阳能电池、探测器等领域。然而，制造有机电泵浦激光器仍然是一个尚未解决的挑战。有机分子的低迁移率难以维持电泵激激光所需的电流注入，高电流密度下产生的自由载流子和三重态也会淬灭增益特性。在器件制造中，高电导率电极和谐振腔不可避免地伴随着光学损耗，这降低了谐振器的品质因数，并进一步提高了电泵浦的阈值电流密度。在这里，我们制造了一种具有三线态-三线态湮没（TTA）特性和优异电性能的有机发光二极管（OLED），能够注入13kAcm的电流密度\n                    <jats:sup>−</jats:sup>\n                    <贾茨：sup>2</贾茨：sup>\n                    在15纳秒电脉冲驱动下。通过利用短脉冲驱动减轻三重态积累，并利用TTA效应抑制单重态-三重态湮没（STA），该器件在1 kA cm的电流下仍能保持近1%的外量子效率（EQE）\n                    <jats:sup>−</jats:sup>\n                    <贾茨：sup>2</贾茨：sup>\n                    电流注入并实现了创纪录的56 W cm输出功率\n                    <jats:sup>−</jats:sup>\n                    <贾茨：sup>2</贾茨：sup>\n                    ，可以维持种群反转。该OLED集成在具有超薄电极的高质量分布式布拉格反射器（DBR）微腔中，在13kAcm下实现光谱线宽为5.5nm的窄带发光\n                    <jats:sup>−</jats:sup>\n                    <贾茨：sup>2</贾茨：sup>\n                    电流注入。这项工作为未来制造具有增益特性的有机电泵浦激光器铺平了道路。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.584767",
            "title": "Dispersive VP-EP conformal mesh algorithm in FDTD for a CCPR model",
            "link": "https://doi.org/10.1364/oe.584767",
            "published": "2026-01-15",
            "author": "Yuan Fan, Yuhao Zhou, Yanan Liu, Han Liu, Liuge Du, Xiao Xu, Fanmin Kong, Jia Zhao",
            "summary": "<jats:p>A dispersive volume-average polarized effective permittivity (D-VP-EP) algorithm is introduced for the analysis of arbitrarily shaped three-dimensional dispersive materials, utilizing the complex-conjugate pole-residue (CCPR) model within the finite-difference time-domain (FDTD) method. The D-VP-EP employs the fitting algorithm as the preprocessor in the frequency domain, followed by an interpolation algorithm in the spatial domain, to avoid conformal-induced changes in the form of the constitutive equations during subsequent conformal mesh generation. The D-VP-EP algorithm maintains the iterative formulation of conventional CCPR-FDTD while enabling conformal meshing between 2 dispersive materials with an arbitrary number of poles. In scattering simulations of metal-dielectric dispersive bilayer nanosphere and transmission spectrum simulations of a dispersive micro-ring, the D-VP-EP effectively reduces mesh mismatch errors at curved interfaces when compared to volume-averaged or staircase, and only needs 1/16 of the computing resources of the comparison group to achieve the same accuracy.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "CCPR 模型的 FDTD 中色散 VP-EP 共形网格算法",
            "abstract_cn": "<jats:p>引入了色散体积平均极化有效介电常数 (D-VP-EP) 算法，利用时域有限差分 (FDTD) 方法中的复共轭极残差 (CCPR) 模型来分析任意形状的三维色散材料。 D-VP-EP采用频域中的拟合算法作为预处理器，然后是空间域中的插值算法，以避免在随后的共形网格生成过程中由共形引起的本构方程形式的变化。 D-VP-EP 算法保持了传统 CCPR-FDTD 的迭代公式，同时能够在具有任意数量极点的 2 种色散材料之间进行共形网格划分。在金属-介电色散双层纳米球的散射模拟和色散微环的透射谱模拟中，与体积平均或阶梯计算相比，D-VP-EP有效降低了弯曲界面处的网格失配误差，并且仅需要对照组1/16的计算资源即可达到相同的精度。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.586392",
            "title": "Dynamically programmable GST-based metasurface for multi-channel holography and optical encryption",
            "link": "https://doi.org/10.1364/oe.586392",
            "published": "2026-01-14",
            "author": "Mochi Guo, Qi Wang, Rongbo Bi, Ruijin Hong, Chenliang Chang, Dawei Zhang",
            "summary": "<jats:p>This study demonstrates a dynamically programmable metasurface leveraging germanium-antimony-tellurium (GST) for multi-channel holographic and optical encryption. By integrating a GST thin film with gallium arsenide nanostructures, non-volatile switching between near-field reflection and far-field diffraction modes is achieved via reversible GST phase transitions. Under y-polarized illumination in the crystalline state, the metasurface produces near-field amplitude-encoded images (“A”, “B”, “C”) at wavelengths of 400 nm, 600 nm, and 800 nm. Conversely, under x-polarized illumination in the amorphous state, it projects far-field phase-modulated holograms (“X”, “Y”, “Z”) at 1064 nm, 1450 nm, and 1550 nm. By leveraging wavelength, polarization, and GST phase state, a nested encryption architecture is established that dynamically associates code-chips to map plaintext to ciphertext, thereby substantially enhancing security. This work offers a promising strategy for high-capacity, reconfigurable optical encryption with potential in secure communications and dynamic displays.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "基于 GST 的动态可编程超表面，用于多通道全息术和光学加密",
            "abstract_cn": "<jats:p>这项研究展示了一种利用锗锑碲 (GST) 进行多通道全息和光学加密的动态可编程超表面。通过将 GST 薄膜与砷化镓纳米结构集成，通过可逆 GST 相变实现近场反射和远场衍射模式之间的非易失性切换。在结晶状态下的 y 偏振照明下，超表面会产生波长为 400 nm、600 nm 和 800 nm 的近场幅度编码图像（“A”、“B”、“C”）。相反，在非晶态的 x 偏振照明下，它可以投射 1064nm、1450nm 和 1550nm 的远场相位调制全息图（“X”、“Y”、“Z”）。通过利用波长、偏振和GST相状态，建立了嵌套加密架构，动态关联码片以将明文映射到密文，从而大大增强安全性。这项工作为高容量、可重构光学加密提供了一种有前途的策略，在安全通信和动态显示方面具有潜力。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.584239",
            "title": "Reinforcement learning-enabled robust phase control for OAM beam generation in coherent beam combining systems",
            "link": "https://doi.org/10.1364/oe.584239",
            "published": "2026-01-16",
            "author": "Wenjun Jiang, Guiyuan Tan, Mengmeng Zhang, Junzhe Gao, Wusheng Zhu, Jiazhen Dou, Ju Tang, Jianglei Di, Yuwen Qin",
            "summary": "<jats:p>Orbital angular momentum (OAM) beams play a vital role across diverse scientific and technological frontiers. However, in high-power regimes, intra-cavity generation is constrained by mode competition, while extra-cavity conversion suffers from low damage thresholds. Coherent beam combination (CBC) provides a promising pathway by combining multiple lasers into structured beams, yet achieving intelligent, label-free, and high-precision phase control remains a formidable challenge. Here we present a reinforcement learning-based phase control framework tailored to generate OAM beams in CBC systems, featuring a physically informed reward function and a vector-quantized (VQ) module embedded in both the actor and critic networks. The proposed framework enables rapid and robust single-stage generation of ±1 and ±2 OAM beams in a 12-channel CBC system, achieving mode purities exceeding 0.99 in noisy environments. Remarkably, it surpasses the stochastic parallel gradient descent (SPGD) algorithm in control stability, despite operating at a much lower control frequency. This work advances the development of RL-based phase control in CBC and establishes a scalable and physically grounded paradigm for intelligent optical field modulation.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "用于相干光束组合系统中 OAM 光束生成的强化学习鲁棒相位控制",
            "abstract_cn": "<jats:p>轨道角动量 (OAM) 光束在不同的科学和技术前沿发挥着至关重要的作用。然而，在高功率状态下，腔内发电受到模式竞争的限制，而腔外转换则受到低损伤阈值的影响。相干光束组合（CBC）通过将多个激光器组合成结构化光束提供了一条有前途的途径，但实现智能、无标记和高精度相位控制仍然是一个艰巨的挑战。在这里，我们提出了一种基于强化学习的相位控制框架，专门用于在 CBC 系统中生成 OAM 光束，该框架具有物理通知奖励函数和嵌入到参与者和批评者网络中的矢量量化（VQ）模块。所提出的框架能够在 12 通道 CBC 系统中快速、鲁棒地单级生成 ±1 和 ±2 OAM 光束，在噪声环境中实现超过 0.99 的模式纯度。值得注意的是，尽管其控制频率​​要低得多，但它在控制稳定性方面优于随机并行梯度下降（SPGD）算法。这项工作推动了 CBC 中基于 RL 的相位控制的发展，并为智能光场调制建立了可扩展且物理基础的范例。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.580575",
            "title": "Thermo-optically tuned parametric wavelength conversion in integrated Bragg gratings",
            "link": "https://doi.org/10.1364/oe.580575",
            "published": "2026-01-16",
            "author": "X. Wang, J. W. Choi, G. F. R. Chen, H. Gao, D. K. T. Ng, B. J. Eggleton, D. T. H. Tan",
            "summary": "<jats:p>We demonstrate thermo-optic tuning of parametric wavelength conversion in integrated Bragg gratings— an approach that enables dynamic control of nonlinear optical processes on-chip. Bragg gratings offer enhanced phase matching through sharp dispersion near the photonic stopband, enabling significantly improved four-wave mixing efficiency compared to uniform photonic waveguides. Leveraging this grating-induced dispersion, we achieve continuous-wave four-wave mixing with a 20 dB enhancement in on/off conversion efficiency relative to a reference waveguide of the same length. Crucially, we show that thermal tuning from 25 °C to 75 °C yields up to a 5 dB modulation in conversion efficiency and induces a 5 nm spectral shift in the stopband—representing a level of control not attainable in conventional waveguides. Experimental results show good agreement with theoretical predictions. These results establish integrated Bragg gratings as a powerful and reconfigurable platform for actively tunable nonlinear photonic devices.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "集成布拉格光栅中的热光调谐参量波长转换",
            "abstract_cn": "<jats:p>我们演示了集成布拉格光栅中参数波长转换的热光调谐——一种能够动态控制片上非线性光学过程的方法。布拉格光栅通过光子阻带附近的锐色散提供增强的相位匹配，与均匀光子波导相比，能够显着提高四波混频效率。利用这种光栅引起的色散，我们实现了连续波四波混频，相对于相同长度的参考波导，开/关转换效率提高了 20dB。至关重要的是，我们表明，从 25°C 到 75°C 的热调谐可产生高达 5dB 的转换效率调制，并在阻带中引起 5nm 的光谱偏移，这代表了传统波导无法达到的控制水平。实验结果与理论预测吻合良好。这些结果确立了集成布拉格光栅作为主动可调谐非线性光子器件的强大且可重新配置的平台。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.582360",
            "title": "Microcrystalline Ge interlayer-bonded InGaAs/Si avalanche photodiode with ultrahigh responsivity of 135 A/W and gain of 190",
            "link": "https://doi.org/10.1364/oe.582360",
            "published": "2026-01-20",
            "author": "Menghui Guo, Xiaolong Jiang, Jie Wang, Junfeng Yang, Zikai Lin, Yiyuan Fan, Songyan Chen, Shaoying Ke",
            "summary": "<jats:p>This paper reports a high-performance InGaAs/Si avalanche photodiode (APD) utilizing a microcrystalline germanium (μc-Ge) interlayer bonding technique. This technique enables the formation of a high-quality InGaAs/Si heterojunction with a void-free, high-strength, and oxide-free bonded interface, effectively suppressing dislocation formation and elemental interdiffusion. The device demonstrates high responsivities of 68 A/W and 135 A/W at wavelengths of 1310 nm and 1550 nm, respectively, with avalanche gains of 106.25 and 190, respectively, significantly outperforming previously reported Ge/Si and various InGaAs-based APDs. Further observation shows that the punch-through voltage increases with rising optical power, attributed to the space charge effect caused by the hole potential well at the μc-Ge bonded interface. Additionally, a defect-assisted tunneling mechanism for interfacial carrier transport is revealed. This work presents an effective technological pathway for the development of high-performance, low-noise III-V/Si integrated photodetectors.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "微晶Ge层间键合InGaAs/Si雪崩光电二极管，具有135 A/W的超高响应度和190的增益",
            "abstract_cn": "<jats:p>本文报道了一种利用微晶锗 (μc-Ge) 层间键合技术的高性能 InGaAs/Si 雪崩光电二极管 (APD)。该技术能够形成具有无空隙、高强度、无氧化物键合界面的高质量InGaAs/Si异质结，有效抑制位错形成和元素相互扩散。该器件在 1310 nm 和 1550 nm 波长下分别表现出 68 A/W 和 135 A/W 的高响应度，雪崩增益分别为 106.25 和 190，显着优于之前报道的 Ge/Si 和各种基于 InGaAs 的 APD。进一步观察表明，击穿电压随着光功率的增加而增加，这归因于μc-Ge键合界面空穴势阱引起的空间电荷效应。此外，还揭示了用于界面载流子传输的缺陷辅助隧道机制。该工作为开发高性能、低噪声III-V/Si集成光电探测器提供了一条有效的技术途径。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.583806",
            "title": "Non-uniform bit-manipulation 3D probabilistic shaping method over hollow-core fiber transmission",
            "link": "https://doi.org/10.1364/oe.583806",
            "published": "2026-01-20",
            "author": "Na Li, Bo Liu, Jianxin Ren, Yaya Mao, Shuaidong Chen, Xiantao Yang, Jianye Zhao, Rahat Ullan, Xiumin Song, Ying Li, Mingqian Liu, Huili Ji",
            "summary": "<jats:p>\n                    This paper proposes a three-dimensional (3D) probabilistic shaping (PS) method based on non-uniform bit manipulation (NUBM) for hollow-core fiber transmission. The proposed NUBM involves bit-level preprocessing to achieve a non-uniform manipulation of ‘0's and ‘1's in the amplitude bits. Subsequently, Gray mapping is employed to generate PAM4 symbols, resulting in a higher probability for the two inner PAM4 signal levels. This effectively lowers the average transmission power and moves the system nearer to the channel capacity limit. Three such probabilistically shaped PAM4 (PS-PAM4) signals are then combined and mapped into a 3D-64QAM constellation with shaping gain. The scheme was experimentally validated over a 1.5 km hollow-core fiber link, achieving a 15.75 Gb/s signal transmission. Under the condition of maintaining the same net data rate, the experimental results show that at the 7% hard-decision forward error correction (HD-FEC) threshold (BER = 3.8 × 10\n                    <jats:sup>−3</jats:sup>\n                    ), the proposed 3D-PS-64QAM scheme gains receiver sensitivity improvements of 1.7 dB and 3.2 dB compared to conventional uniform 3D-64QAM and 2D-PS-64QAM, respectively. This study validates the effectiveness of the described 3D non-uniform bit manipulation in a hollow-core fiber environment, offering a high-performance transmission solution for next-generation high-speed optical communication systems.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "空心光纤传输上的非均匀位操作3D概率整形方法",
            "abstract_cn": "<贾茨：p>\n                    本文提出了一种基于非均匀位操作（NUBM）的空心光纤传输三维（3D）概率整形（PS）方法。所提出的 NUBM 涉及位级预处理，以实现幅度位中“0”和“1”的非均匀操作。随后，采用格雷映射来生成 PAM4 符号，从而导致两个内部 PAM4 信号电平的概率更高。这有效地降低了平均传输功率并使系统更接近信道容量极限。然后将三个这样的概率整形 PAM4 (PS-PAM4) 信号组合起来并映射到具有整形增益的 3D-64QAM 星座中。该方案在1.5公里空心光纤链路上进行了实验验证，实现了15.75 Gb/s的信号传输。在保持相同净数据速率的情况下，实验结果表明，在7%硬判决前向纠错（HD-FEC）阈值下（BER = 3.8 × 10\n                    <jats:sup>−3</jats:sup>\n                    ），与传统的均匀 3D-64QAM 和 2D-PS-64QAM 相比，所提出的 3D-PS-64QAM 方案的接收器灵敏度分别提高了 1.7 dB 和 3.2 dB。这项研究验证了空心光纤环境中所描述的 3D 非均匀位操作的有效性，为下一代高速光通信系统提供高性能传输解决方案。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.585712",
            "title": "FMCW LiDAR with a GaN-based distributed feedback laser diode at 466 nm",
            "link": "https://doi.org/10.1364/oe.585712",
            "published": "2026-01-21",
            "author": "Wataru Kokuyama, Hidemi Tsuchida, Yoshiaki Nakajima",
            "summary": "<jats:p>Frequency-modulated continuous-wave (FMCW) LiDAR requires a visible narrow-linewidth laser capable of a wide linear chirp for operations in underwater environments. To this end, we evaluated a GaN-based 466 nm distributed feedback laser diode (DFB-LD) using a delayed self-heterodyne interferometer, measuring its modulation waveform. The chirp span reached a 12.2 GHz peak-to-peak value (Fourier-limited theoretical resolution: 0.92 cm in the water). The modulation nonlinearity was 9% full scale, and the coherence length was 14 m (β-separation linewidth: 1.9 MHz). Using the proposed LD, we demonstrated free-space FMCW LiDAR at ∼3 m without predistortion. Although the resolution degraded to ∼2 m due to nonlinearity and frequency noise, this work represents, to our knowledge, the first experimental demonstration of FMCW LiDAR using a visible DFB-LD, showing its potential for visible coherent sensing.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "具有基于 GaN 的分布式反馈激光二极管的 466 nm FMCW LiDAR",
            "abstract_cn": "<jats:p>调频连续波 (FMCW) LiDAR 需要具有宽线性调频的可见窄线宽激光器，才能在水下环境中运行。为此，我们使用延迟自外差干涉仪评估了基于 GaN 的 466 nm 分布式反馈激光二极管 (DFB-LD)，测量了其调制波形。线性调频跨度达到 12.2 GHz 峰峰值（傅立叶极限理论分辨率：水中为 0.92 cm）。调制非线性为满量程的 9%，相干长度为 14 m（β 分离线宽：1.9 MHz）。使用所提出的 LD，我们在 ∼3 m 处演示了无预失真的自由空间 FMCW LiDAR。尽管由于非线性和频率噪声，分辨率降低至 ∼2 m，但据我们所知，这项工作代表了使用可见光 DFB-LD 的 FMCW LiDAR 的首次实验演示，显示了其可见光相干传感的潜力。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.582311",
            "title": "Generation of 125-GHz millijoule-level ultrashort pulse-train from a Yb:YAG regenerative amplifier and PMF-polarization-mode-based pulse division",
            "link": "https://doi.org/10.1364/oe.582311",
            "published": "2026-01-22",
            "author": "Yuxi Pang, Yu Wang, Xinyu Hu, Longwang Xiu, Yanfei Liu, Xiangdong Cao",
            "summary": "<jats:p>\n                    This paper presents an ultrafast laser pulse train that delivers millijoule-class energy in 125 GHz train repetition rate, achieved mainly through a Yb:YAG regenerative amplifier (RA) combined with a polarization-maintaining fiber (PMF)-based pulse division scheme. The RA operates at a 5 kHz repetition rate in a mode-symmetrically distributed standing-wave resonant cavity incorporating a Yb:YAG crystal. The PMF-based pulse divider exploits the birefringence properties of PMF to realize pulse division at train repetition rates reaching the hundred-gigahertz or even terahertz regime, providing in a simple, stable, and cost-effective solution. Based on the integration of the RA and the pulse divider, the generation and evolution of satellite pulses induced by the Kerr nonlinear optical effect during the amplification of 125 GHz pulse trains are systematically investigated. Both numerical calculations and the experimental results confirm the temporal smoothing effect produced by a large sub-pulse number of pulse trains and its suppression effect on satellite pulse formation, and ultimately yielding a pulse train output with\n                    <jats:italic>N</jats:italic>\n                     = 32, an average power of 5.12 W, pulse energy of 1.024 mJ, and pulse duration of 2 ps.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "从 Yb:YAG 再生放大器和基于 PMF 偏振模式的脉冲划分生成 125 GHz 毫焦耳级超短脉冲序列",
            "abstract_cn": "<贾茨：p>\n                    本文提出了一种超快激光脉冲序列，可在 125 GHz 序列重复率下提供毫焦级能量，主要通过 Yb:YAG 再生放大器 (RA) 与基于保偏光纤 (PMF) 的脉冲分割方案相结合来实现。 RA 在采用 Yb:YAG 晶体的模式对称分布驻波谐振腔中以 5 kHz 重复率运行。基于 PMF 的脉冲分配器利用 PMF 的双折射特性，以达到百吉赫甚至太赫兹的序列重复率实现脉冲分配，提供简单、稳定且经济高效的解决方案。基于RA和脉冲分配器的集成，系统地研究了125GHz脉冲串放大过程中克尔非线性光学效应引起的卫星脉冲的产生和演化。数值计算和实验结果均证实了大量子脉冲数脉冲串产生的时间平滑效应及其对卫星脉冲形成的抑制作用，最终产生了\n                    <jats:斜体>N</jats:斜体>\n                     = 32，平均功率为5.12 W，脉冲能量为1.024 mJ，脉冲持续时间为2 ps。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.583426",
            "title": "Optimized image fusion rule based on targeted image evaluation metrics for vehicle imaging systems",
            "link": "https://doi.org/10.1364/oe.583426",
            "published": "2026-01-23",
            "author": "Junrong Zhou, Yupeng Chen, Guoliang Li, Baixuan Zhao, Haitao Nie, Kaifeng Zheng, Yingze Zhao, Weibiao Wang, Yuxin Qin, Jingqiu Liang, Jinguang Lv",
            "summary": "<jats:p>Vehicle assistance systems suffer from perception degradation in complex environments like haze. To address this, we develop an integrated visible polarization and infrared dual-band imaging system and propose an innovative image fusion rule based on target image evaluation metrics. Experimental results demonstrate that our method significantly enhances texture details and target discrimination in fused images. The proposed rule also shows strong versatility, supporting various fusion frameworks and multimodal imaging applications. This work provides valuable solutions for assisted driving and other fields like remote sensing and military reconnaissance.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "基于车辆成像系统目标图像评估指标的优化图像融合规则",
            "abstract_cn": "<jats:p>车辆辅助系统在雾霾等复杂环境中会遭受感知退化的影响。为了解决这个问题，我们开发了一种集成的可见光偏振和红外双波段成像系统，并提出了一种基于目标图像评估指标的创新图像融合规则。实验结果表明，我们的方法显着增强了融合图像中的纹理细节和目标辨别力。所提出的规则还显示出很强的通用性，支持各种融合框架和多模态成像应用。这项工作为辅助驾驶以及遥感和军事侦察等其他领域提供了有价值的解决方案。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.583744",
            "title": "Unified ray-wave model for end-to-end imaging in refractive–diffractive hybrid optics",
            "link": "https://doi.org/10.1364/oe.583744",
            "published": "2026-01-16",
            "author": "Jintao Shi, Desheng Li, Jingang Zhang, Xiaoxiao Wei, Yunfeng Nie",
            "summary": "<jats:p>\n                    End-to-end optical design has emerged as a promising paradigm in computational imaging, emphasizing the joint optimization of optical elements and computational algorithms. However, existing models struggle to simultaneously achieve efficiency, accuracy, and differentiability, which limits the development of refractive–diffractive hybrid systems. To address this challenge, we propose a unified ray-wave (UniRW) differentiable modeling framework that couples generalized Snell’s law with wave propagation. By unifying geometric ray tracing and wave optics, the framework enables accurate and efficient simulation of arbitrary hybrid optical systems, and can be naturally embedded into end-to-end optimization pipelines to support joint learning of optical parameters and image reconstruction networks. We validate the proposed framework on aberration correction and extended depth-of-field (EDOF) tasks. In aberration correction, the proposed hybrid lens achieves improved image reconstruction quality enabled by more accurate PSF modeling and end-to-end optimization. Quantitative results show that UniRW improves the reconstructed image peak signal-to-noise ratio (PSNR) by approximately 3.4 dB. In the EDOF setting, the proposed framework achieves high-quality image reconstruction with a PSNR of approximately 31.9 dB across an extended axial defocus range of ±500\n                    <jats:italic>µm</jats:italic>\n                    . These results demonstrate that the proposed approach bridges physical modeling and deep learning optimization, providing an efficient, accurate, and general paradigm for hybrid optical design.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "折射-衍射混合光学中端到端成像的统一射线波模型",
            "abstract_cn": "<贾茨：p>\n                    端到端光学设计已成为计算成像领域有前途的范例，强调光学元件和计算算法的联合优化。然而，现有模型难以同时实现效率、准确性和可微分性，这限制了折射-衍射混合系统的发展。为了应对这一挑战，我们提出了一个统一射线波（UniRW）可微分建模框架，将广义斯涅尔定律与波传播结合起来。通过统一几何光线追踪和波动光学，该框架能够准确高效地模拟任意混合光学系统，并且可以自然地嵌入到端到端优化管道中，以支持光学参数和图像重建网络的联合学习。我们验证了所提出的像差校正和扩展景深（EDOF）任务框架。在像差校正中，所提出的混合镜头通过更准确的 PSF 建模和端到端优化实现了更高的图像重建质量。定量结果表明，UniRW 将重建图像峰值信噪比 (PSNR) 提高了约 3.4 dB。在 EDOF 设置中，所提出的框架在 ±500 的扩展轴向散焦范围内实现了高质量图像重建，PSNR 约为 31.9 dB\n                    <jats:斜体>微米</jats:斜体>\n                    。这些结果表明，所提出的方法连接了物理建模和深度学习优化，为混合光学设计提供了高效、准确和通用的范例。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.584282",
            "title": "Rapidly tunable synthetic wavelength ranging with an RFSoC",
            "link": "https://doi.org/10.1364/oe.584282",
            "published": "2026-01-15",
            "author": "Shawn M. P. McSorley, Benjamin P. Dix-Matthews, Andrew M. Lance, David R. Gozzard, Sascha W. Schediwy",
            "summary": "<jats:p>\n                    Measurements of optical range and time-of-flight are crucial for a variety of high-precision technologies. Competitive optical measurement techniques have been developed that balance precision with accuracy and system complexity. Here, we present a continuous-wave synthetic wavelength interferometry technique that employs digitally tunable electro-optic frequency combs. With a software-defined radio, our approach can dynamically sweep the synthetic wavelength and measure absolute optical range. We demonstrate this digital approach over a free-space optical delay line of 1 m and over a 40 km fiber link. The best obtained precision over the delay line is better than 60 nm (0.2 fs). Through a 40 km fiber spool, this precision degrades to 15 µm (50 fs), which is a fractional error on the order of 2 × 10\n                    <jats:sup>−10</jats:sup>\n                    m/m. Our design is simple to implement and only relies on continuous-wave interference, decreasing system complexity.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "使用 RFSoC 快速调节合成波长范围",
            "abstract_cn": "<贾茨：p>\n                    光学范围和飞行时间的测量对于各种高精度技术至关重要。已经开发出具有竞争力的光学测量技术，可以在精度与准确度和系统复杂性之间取得平衡。在这里，我们提出了一种采用数字可调谐电光频率梳的连续波合成波长干涉测量技术。通过软件定义的无线电，我们的方法可以动态扫描合成波长并测量绝对光学范围。我们通过 1 m 的自由空间光延迟线和 40 km 的光纤链路演示了这种数字方法。延迟线上获得的最佳精度优于 60 nm (0.2 fs)。通过 40 km 光纤线轴，该精度会降低至 15 µm (50 fs)，这是 2 × 10 数量级的分数误差\n                    <jats:sup>−10</jats:sup>\n                    米/米。我们的设计易于实现，仅依赖于连续波干扰，降低了系统复杂性。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.582474",
            "title": "Frequency domain side channel on lithium niobate phase modulator in high-rate quantum key distribution system",
            "link": "https://doi.org/10.1364/oe.582474",
            "published": "2026-01-16",
            "author": "Siying Huang, Jindong Wang, Qincheng Hou, Naida Mo, Shaoke Huang, Pan Li, Xinyi Wang, Zhengjun Wei, Tianming Zhao, Yafei Yu, Zhiming Zhang",
            "summary": "<jats:p>\n                    Constructing high-rate quantum key distribution (QKD) systems is an effective way to increase secure key rates. However, in such systems, modulation strengthens the correlation between signaling and non-signaling states, allowing an eavesdropper to extract information from the latter. While frequency-domain side-channel leakage from light sources has been recognized, leakage arising from modulation in high-rate QKD systems has not yet been reported. In this paper, we first constructed BB84 phase and polarization coding units and observed frequency-domain variations in increasing rates of lithium niobate (LN) modulation. Using an information-theoretic model, we evaluated the correlation between frequency and coded bits, finding side-channel mutual information of 2.44 × 10\n                    <jats:sup>−2</jats:sup>\n                    and 8.81 × 10\n                    <jats:sup>−3</jats:sup>\n                    bits/pulse at 594 MHz and 668 MHz for phase and polarization units, respectively. Information leakage increased with higher modulation rate and voltage, and potential defense schemes are briefly discussed.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "高速量子密钥分配系统中铌酸锂相位调制器的频域侧信道",
            "abstract_cn": "<贾茨：p>\n                    构建高速量子密钥分发（QKD）系统是提高安全密钥速率的有效途径。然而，在此类系统中，调制增强了信令和非信令状态之间的相关性，从而允许窃听者从后者中提取信息。虽然来自光源的频域侧信道泄漏已经被认识到，但高速 QKD 系统中的调制引起的泄漏尚未有报道。在本文中，我们首先构建了 BB84 相位和偏振编码单元，并观察了铌酸锂 (LN) 调制速率增加的频域变化。使用信息论模型，我们评估了频率和编码比特之间的相关性，发现边信道互信息为 2.44 × 10\n                    <jats:sup>−2</jats:sup>\n                    和 8.81 × 10\n                    <jats:sup>−3</jats:sup>\n                    相位和极化单位分别为 594 MHz 和 668 MHz 的比特/脉冲。信息泄漏随着调制速率和电压的升高而增加，并简要讨论了潜在的防御方案。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.584499",
            "title": "Co-design framework for the joint optimization of astronomical optical systems and deep learning algorithms",
            "link": "https://doi.org/10.1364/oe.584499",
            "published": "2026-01-15",
            "author": "Wennan Xiang, Peng Jia, Zhengyang Li, Zeyu Bai, Jiameng Lv",
            "summary": "<jats:p>We present an optical system optimization framework that directly bridges astronomy, computational imaging, and optical engineering. Traditionally, optical systems of telescopes are optimized using classical image quality metrics (e.g., RMS spot radius), which are often decoupled from the performance of modern, deep learning-based object detection algorithms. This paper introduces an end-to-end, interdisciplinary optimization framework where the optical system is optimized directly for the detection performance of its subsequent deep learning algorithm. Our method integrates an optical system simulator—which models specific optical designs, hardware, and observation modes—with a deep learning-based detection algorithm. In this joint optimization scheme, the detection accuracy of a pre-trained, weight-fixed network on simulated imagery serves as the primary evaluation signal. By combining this signal with classical optical merit functions, we facilitate a closed-loop, iterative refinement of optical design parameters. To validate this co-design approach, we optimized both a Primary-Focus and a Ritchey-Chrétien telescope for a wide-field astronomical survey scenario. The resulting systems demonstrated gains in celestial object detection efficiency and accuracy, proving the value of our method. This work provides an innovative pathway for jointly optimizing optical systems and their bespoke algorithms for specific scientific tasks.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "天文光学系统与深度学习算法联合优化的协同设计框架",
            "abstract_cn": "<jats:p>我们提出了一个直接连接天文学、计算成像和光学工程的光学系统优化框架。传统上，望远镜的光学系统使用经典的图像质量指标（例如 RMS 光斑半径）进行优化，这些指标通常与现代基于深度学习的物体检测算法的性能脱钩。本文介绍了一种端到端、跨学科的优化框架，其中光学系统直接针对其后续深度学习算法的检测性能进行优化。我们的方法将光学系统模拟器（对特定光学设计、硬件和观察模式进行建模）与基于深度学习的检测算法集成在一起。在这种联合优化方案中，预训练的、权重固定的网络在模拟图像上的检测精度作为主要评估信号。通过将该信号与经典光学评价函数相结合，我们促进了光学设计参数的闭环、迭代细化。为了验证这种协同设计方法，我们针对宽视场天文观测场景优化了主焦点望远镜和里奇-克雷蒂安望远镜。由此产生的系统证明了天体检测效率和准确性的提高，证明了我们方法的价值。这项工作为联合优化光学系统及其针对特定科学任务的定制算法提供了一条创新途径。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1002/lpor.70909",
            "title": "Correction to “Nonlinear Distortion Equalization in Multi‐Span Optical Links Via a Feed‐Forward Photonic Neural Network”",
            "link": "https://doi.org/10.1002/lpor.70909",
            "published": "2026-01-26",
            "author": "Emiliano Staffoli, Elisabetta Ferri, Stefano Gretter, Lorenzo Pavesi",
            "summary": "Abstract not available.",
            "journal": "Laser & Photonics Reviews",
            "title_cn": "对“通过前馈光子神经网络实现多跨光链路非线性失真均衡”的修正",
            "abstract_cn": "（摘要暂缺，等待官方补全）"
        },
        {
            "id": "https://doi.org/10.1002/lpor.202502761",
            "title": "A Self‐Powered Optical Fiber Tactile Sensor with Crosstalk‐Free Imaging and Human‐Level Sensitivity",
            "link": "https://doi.org/10.1002/lpor.202502761",
            "published": "2026-01-26",
            "author": "Hongyan Zheng, Yuexi Lu, Yao Xiao, Anping Yang, Haojun Liu, Yongcheng He, Hongyou Zhou, Luyan Liu, Puxian Xiong, Enhai Song, Qianyi Guo, Dengfeng Peng, Zhijun Ma, Zhongmin Yang, Jiulin Gan",
            "summary": "<jats:title>ABSTRACT</jats:title>\n                  <jats:p>Artificial tactile sensors aim to mimic human touch with high sensitivity, fine spatial resolution, low detection thresholds, and fast response. However, developing a human‐like haptic system that integrates crosstalk‐free large‐scale arrays, ultra‐low power consumption, and efficient signal transmission and interpretation remains a formidable challenge. Inspired by human skin's layered structure and neural pathways, we developed a skin‐like optical fiber tactile sensor. A finger‐like multilayer composite is integrated onto the endsurface of a dense optical fiber array. Using self‐powered mechanoluminescent (ML) materials, this tactile photonic skin visualizes mechanical stimuli in real time, bridging tactile sensing and visual perception. Each optical fiber independently transmits localized luminescent signals, ensuring crosstalk‐free, high‐fidelity spatial encoding. Coupled with an area‐array CMOS imager and vision‐based signal processing algorithms, the system achieves human‐fingertip‐level performance: 7 kPa detection threshold, 0.4 mm spatial resolution, 86 ms response time, and high durability. Demonstrations include optical recognition of alphabetic patterns and screw threads, as well as accurate palpation‐based discrimination of material stiffness and localization of nodular anomalies in simulated biological tissues. This power‐free optical interface offers an energy‐efficient platform with real‐time visual feedback for advanced haptic applications in prosthetics, medical robotics, and human‐machine interaction.</jats:p>",
            "journal": "Laser & Photonics Reviews",
            "title_cn": "具有无串扰成像和人类水平灵敏度的自供电光纤触觉传感器",
            "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>人造触觉传感器旨在模仿人类触摸，具有高灵敏度、精细的空间分辨率、低检测阈值和快速响应。然而，开发一种集成无串扰大规模阵列、超低功耗以及高效信号传输和解释的类人触觉系统仍然是一个艰巨的挑战。受人类皮肤分层结构和神经通路的启发，我们开发了一种类皮肤光纤触觉传感器。手指状多层复合材料被集成到密集光纤阵列的端面上。这种触觉光子皮肤使用自供电机械发光（ML）材料，实时可视化机械刺激，连接触觉感知和视觉感知。每根光纤独立传输局部发光信号，确保无串扰、高保真空间编码。与面阵 CMOS 成像仪和基于视觉的信号处理算法相结合，该系统实现了人类指尖级的性能：7 kPa 检测阈值、0.4 mm 空间分辨率、86 ms 响应时间和高耐用性。演示包括对字母图案和螺纹的光学识别，以及基于触诊的材料硬度的精确辨别和模拟生物组织中结节异常的定位。这种无电源光学接口为假肢、医疗机器人和人机交互中的高级触觉应用提供了具有实时视觉反馈的节能平台。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1002/lpor.202502794",
            "title": "Breaking the Absorption‐Efficiency Paradigm: 270% EQE Gain in Cr\n                    <sup>3+</sup>\n                    ‐Doped Phosphors via Crystal Field Engineering",
            "link": "https://doi.org/10.1002/lpor.202502794",
            "published": "2026-01-26",
            "author": "Mingkai Wei, Yanjun Hao, Xuejie Zhang, Wei Li, Haoran Zhang, Bingfu Lei",
            "summary": "<jats:title>ABSTRACT</jats:title>\n                  <jats:p>\n                    Near‐infrared (NIR) phosphor‐converted LEDs (pc‐LEDs) are critical for smart agriculture and night vision, but their efficiency is limited by low external quantum efficiency (EQE) of phosphors. Herein, the introduction of Al\n                    <jats:sup>3+</jats:sup>\n                    ions via chemical substitution increased the EQE of the GdGa\n                    <jats:sub>2.85</jats:sub>\n                    (BO\n                    <jats:sub>3</jats:sub>\n                    )\n                    <jats:sub>4</jats:sub>\n                    :0.15Cr\n                    <jats:sup>3+</jats:sup>\n                    NIR phosphor from 8.3% to 30.7% (a relative increase of 270%). Importantly, an “absorption‐efficiency decoupling” paradigm is identified: while the Al\n                    <jats:sup>3+</jats:sup>\n                    substitution reduces the absorbance, confirmed by Density Functional Theory, diffuse reflectance spectra, and X‐ray photoelectron spectroscopy, the quantum efficiency is significantly increased. Theoretical analyses and spectroscopic evidence suggest that the superior EQE gain stems from Al\n                    <jats:sup>3+</jats:sup>\n                    ‐induced crystal field enhancement and subsequent energy level remodeling. This remodeling optimizes the Cr\n                    <jats:sup>3+</jats:sup>\n                    excited state dynamics by suppressing the non‐radiative transitions pathway and increasing the radiative transitions, thus overcoming the detrimental effects of absorption reduction. The optimized phosphor, combined with a blue LED chip, produced an NIR pc‐LED achieving 41.7 mW output power and 15.7% photoelectric efficiency at 100 mA. The device successfully demonstrated potential for precision agriculture and night vision. This work provides novel insight into “absorption‐efficiency decoupling” and offers a new design strategy for efficient Cr\n                    <jats:sup>3+</jats:sup>\n                    ‐doped NIR phosphors.\n                  </jats:p>",
            "journal": "Laser & Photonics Reviews",
            "title_cn": "打破吸收效率范式：通过晶体场工程在 Cr <sup>3+</sup> 掺杂荧光粉中获得 270% EQE",
            "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    近红外 (NIR) 荧光粉转换 LED (pc-LED) 对于智能农业和夜视至关重要，但其效率受到荧光粉低外量子效率 (EQE) 的限制。在此，引入Al\n                    <贾茨：sup>3+</贾茨：sup>\n                    通过化学取代的离子增加了 GdGa 的 EQE\n                    <贾茨：子>2.85</贾茨：子>\n                    （博\n                    <贾茨：子>3</贾茨：子>\n                    ）\n                    <贾茨：子>4</贾茨：子>\n                    ：0.15Cr\n                    <贾茨：sup>3+</贾茨：sup>\n                    近红外荧光粉从8.3%增加到30.7%（相对增加270%）。重要的是，确定了“吸收效率解耦”范式：而铝\n                    <贾茨：sup>3+</贾茨：sup>\n                    取代降低了吸光度，经密度泛函理论、漫反射光谱和X射线光电子能谱证实，量子效率显着提高。理论分析和光谱证据表明，优异的 EQE 增益源于 Al\n                    <贾茨：sup>3+</贾茨：sup>\n                    诱导晶体场增强和随后的能级重塑。此次改造优化了 Cr\n                    <贾茨：sup>3+</贾茨：sup>\n                    通过抑制非辐射跃迁途径并增加辐射跃迁来激发态动力学，从而克服吸收减少的有害影响。优化的荧光粉与蓝色 LED 芯片相结合，产生了 NIR pc-LED，在 100 mA 电流下实现了 41.7 mW 的输出功率和 15.7% 的光电效率。该设备成功展示了精准农业和夜视的潜力。这项工作提供了对“吸收效率解耦”的新颖见解，并为高效 Cr 提供了新的设计策略\n                    <贾茨：sup>3+</贾茨：sup>\n                    ‐掺杂近红外荧光粉。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1002/lpor.202502775",
            "title": "Non‐Contact Vitality Monitoring Enabled by Interface‐Modified Photomultiplication Organic Photodetectors",
            "link": "https://doi.org/10.1002/lpor.202502775",
            "published": "2026-01-26",
            "author": "Muyi Fu, Yazhong Wang, Yunhao Cao, Songtao Liu, Shuaiqi Li, Zhaohong Tan, Yuejia Dou, Sheng Dong, Xiye Yang, Kai Zhang, Fei Huang",
            "summary": "<jats:title>ABSTRACT</jats:title>\n                  <jats:p>\n                    Photomultiplication‐type organic photodetectors (PM‐OPDs) enable external quantum efficiencies (EQE) exceeding 100%, providing intrinsic signal amplification and simplified circuit integration. Such high sensitivity is essential for non‐contact physiological monitoring, where weak optical signals must be precisely detected over a distance. However, their practical use remains challenged by high dark current and sluggish response. Here, we introduce interface engineering using conjugated electrolytes (PFN‐Br, NDI‐Br) to simultaneously suppress dark current and tailor trap state distribution at the ZnO cathode interface. The champion ZnO/NDI‐Br device achieved a peak EQE of 6780% and a specific detectivity of 5.3 × 10\n                    <jats:sup>12</jats:sup>\n                    Jones at −20 V, along with ultrafast rise and fall times of 0.05/0.02 ms. These improvements originate from enhanced electron mobility and reduced interfacial traps, enabling efficient electron trapping and hole tunneling injections. Leveraging these advances, we demonstrated a non‐contact vital‐sign monitoring system capable of high‐fidelity heart rate detection at 50 cm and accurate blood oxygen saturation (SpO\n                    <jats:sub>2</jats:sub>\n                    ) measurement at 20 cm. This work establishes interface‐engineered PM‐OPDs as a promising platform for next‐generation remote medical sensing and long‐range optical detection.\n                  </jats:p>",
            "journal": "Laser & Photonics Reviews",
            "title_cn": "通过界面改进的光电倍增有机光电探测器实现非接触式活力监测",
            "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    光电倍增型有机光电探测器 (PM-OPD) 使外部量子效率 (EQE) 超过 100%，提供固有信号放大和简化的电路集成。如此高的灵敏度对于非接触式生理监测至关重要，因为必须远距离精确检测微弱的光信号。然而，它们的实际使用仍然受到高暗电流和缓慢响应的挑战。在这里，我们引入了使用共轭电解质（PFN-Br、NDI-Br）的界面工程，以同时抑制暗电流并定制 ZnO 阴极界面的陷阱态分布。冠军 ZnO/NDI-Br 器件的峰值 EQE 为 6780%，比探测率为 5.3 × 10\n                    <贾茨：sup>12</贾茨：sup>\n                    Jones 电压为 −20 V，具有 0.05/0.02 ms 的超快上升和下降时间。这些改进源于增强的电子迁移率和减少的界面陷阱，从而实现高效的电子捕获和空穴隧道注入。利用这些进步，我们展示了一种非接触式生命体征监测系统，能够在 50 厘米处进行高保真心率检测和准确的血氧饱和度 (SpO\n                    <贾茨：子>2</贾茨：子>\n                    ）在 20 厘米处测量。这项工作将接口设计的 PM-OPD 建立为下一代远程医疗传感和远程光学检测的有前途的平台。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1002/lpor.202502889",
            "title": "Tailored Tight‐Binding Couplings in Photonic Crystals",
            "link": "https://doi.org/10.1002/lpor.202502889",
            "published": "2026-01-26",
            "author": "Junrong Zheng, Jingwen Ma, Zhong‐Qun Tian, Jun Yi",
            "summary": "<jats:title>ABSTRACT</jats:title>\n                  <jats:p>The tight‐binding (TB) model offers a versatile framework for exploring novel photonic phenomena. Its faithful implementation in photonic crystals (PCs), however, requires not only suppressed long‐range couplings but also systematic and scalable control over both the magnitude and the sign of inter‐site couplings. Here, it is demonstrated periodic defect arrays embedded in a photonic band‐gap host as a PCs platform for programmable engineering of TB couplings. The localized defect modes provide an accurate TB description, and by adjusting either the number or the detuning of spacer sites, it is achieved flexible control of the coupling strength together with a robust, parity‐protected reversal of its sign without modifying the defect sites themselves. Numerical simulations confirm that this strategy reproduces the target TB Hamiltonian with high fidelity and greatly expands the accessible design space beyond that of conventional PCs. As proof of concept, a 2D Su–Schrieffer–Heeger lattice that undergoes the predicted topological transition and a nonsymmorphic structure supporting Möbius edge states are implemented. This work provides a versatile and scalable route to TB‐inspired phenomena in PCs.</jats:p>",
            "journal": "Laser & Photonics Reviews",
            "title_cn": "光子晶体中的定制紧束缚耦合",
            "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>紧束缚（TB）模型为探索新颖的光子现象提供了一个通用框架。然而，它在光子晶体（PC）中的忠实实现不仅需要抑制长程耦合，还需要对位点间耦合的幅度和符号进行系统且可扩展的控制。在这里，展示了嵌入光子带隙主机中的周期性缺陷阵列，作为用于 TB 耦合可编程工程的 PC 平台。局部缺陷模式提供了准确的 TB 描述，并且通过调整间隔位点的数量或失谐，可以实现耦合强度的灵活控制以及其符号的稳健、受奇偶校验保护的反转，而无需修改缺陷位点本身。数值模拟证实，该策略以高保真度再现了目标 TB 哈密顿量，并大大扩展了可访问的设计空间，超出了传统 PC 的范围。作为概念证明，实现了经历预测的拓扑转变的 2D Su-Schrieffer-Heeger 晶格和支持莫比乌斯边缘态的非对称结构。这项工作为 PC 中受结核病启发的现象提供了一种通用且可扩展的途径。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1002/lpor.202502571",
            "title": "Engineering Localized Surface Plasmon Resonance of Nanoparticles in Transparent Materials for Advanced Optical Applications",
            "link": "https://doi.org/10.1002/lpor.202502571",
            "published": "2026-01-26",
            "author": "Chi Pang, Rang Li, Xia Wang, Weijin Kong, Feng Chen",
            "summary": "<jats:title>ABSTRACT</jats:title>\n                  <jats:p>Localized surface plasmon resonance (LSPR) of nanoparticles embedded in transparent solid‐state materials provides a robust platform for integrated photonic and optoelectronic devices requiring precise spectral positioning, strong field localization, and long‐term stability. This review links fundamentals to engineering strategies and applications for plasmonic nanostructures in transparent hosts. We summarize the formation and evolution of metallic species in solids and the resulting optical properties across size regimes, covering both linear and nonlinear responses. We identify three energy‐transduction mechanisms that connect nanostructure properties to device functionality: (i) near‐field enhancement, (ii) hot‐carrier processes, and (iii) photothermal effects. Building on these foundations, we emphasize post‐fabrication morphology reconfiguration of pre‐embedded nanostructures as a primary route to programmable LSPR control, and organize representative approaches by actuation mode (thermal, electric‐field–driven, and chemistry‐based) and stimulus modality (photons, electrons, ions, or external fields). We then review applications in nonlinear and integrated photonics and optoelectronic energy conversion, highlighting how embedded plasmonic resonances improve device performance. Finally, we discuss practical challenges and emerging opportunities toward scalable, spatially programmable plasmonics, including control of buried interfaces and reproducible processing enabled by coordinated beam/laser/thermal/chemical routes.</jats:p>",
            "journal": "Laser & Photonics Reviews",
            "title_cn": "用于先进光学应用的透明材料中纳米颗粒的工程局域表面等离子体共振",
            "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>嵌入透明固态材料中的纳米粒子的局域表面等离子体共振 (LSPR) 为需要精确光谱定位、强场定位和长期稳定性的集成光子和光电器件提供了强大的平台。这篇综述将透明主体中等离子体纳米结构的基础知识与工程策略和应用联系起来。我们总结了固体中金属物质的形成和演化，以及由此产生的跨尺寸范围的光学特性，涵盖线性和非线性响应。我们确定了将纳米结构特性与器件功能联系起来的三种能量转换机制：（i）近场增强，（ii）热载流子过程，以及（iii）光热效应。在此基础上，我们强调预嵌入纳米结构的制造后形态重构作为可编程局域表面等离子体共振控制的主要途径，并通过驱动模式（热、电场驱动和化学）和刺激模式（光子、电子、离子或外部场）组织代表性方法。然后，我们回顾了非线性和集成光子学和光电能量转换中的应用，重点介绍了嵌入式等离子体共振如何提高设备性能。最后，我们讨论了可扩展、空间可编程等离子体激元的实际挑战和新兴机遇，包括通过协调光束/激光/热/化学路线实现的掩埋界面控制和可重复处理。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1109/tvcg.2026.3657654",
            "title": "How Scale Breaks “Normalized Stress” and KL Divergence: Rethinking Quality Metrics",
            "link": "https://doi.org/10.1109/tvcg.2026.3657654",
            "published": "2026",
            "author": "Kiran Smelser, Kaviru Gunaratne, Jacob Miller, Stephen Kobourov",
            "summary": "Complex, high-dimensional data is ubiquitous across many scientific disciplines, including machine learning, biology, and the social sciences. One of the primary methods of visualizing these datasets is with two-dimensional scatter plots that visually capture some properties of the data. Because visually determining the accuracy of these plots is challenging, researchers often use quality metrics to measure the projection's accuracy and faithfulness to the original data. One of the most commonly employed metrics, normalized stress, is sensitive to uniform scaling (stretching, shrinking) of the projection, despite this act not meaningfully changing anything about the projection. Another quality metric, the Kullback–Leibler (KL) divergence used in the popular t-Distributed Stochastic Neighbor Embedding (t-SNE) technique, is also susceptible to this scale sensitivity. We investigate the effect of scaling on stress and KL divergence analytically and empirically by showing just how much the values change and how this affects dimension reduction technique evaluations. We introduce a simple technique to make both metrics scale-invariant and show that it accurately captures expected behavior on a small benchmark.",
            "journal": "IEEE Trans. Vis. Comput. Graph",
            "title_cn": "规模如何打破“标准化压力”和 KL 分歧：重新思考质量指标",
            "abstract_cn": "复杂的高维数据在许多科学学科中普遍存在，包括机器学习、生物学和社会科学。可视化这些数据集的主要方法之一是使用二维散点图，直观地捕获数据的某些属性。由于直观地确定这些图的准确性具有挑战性，因此研究人员经常使用质量指标来衡量投影的准确性和对原始数据的忠实度。最常用的指标之一，标准化压力，对投影的均匀缩放（拉伸、收缩）敏感，尽管这种行为不会对投影产生任何有意义的改变。另一个质量指标，即流行的 t 分布随机邻域嵌入 (t-SNE) 技术中使用的 Kullback-Leibler (KL) 散度，也容易受到这种尺度敏感性的影响。我们通过分析和实证研究缩放对应力和 KL 散度的影响，通过显示值的变化量以及这如何影响降维技术评估。我们引入了一种简单的技术来使两个指标都具有尺度不变性，并表明它可以准确地捕获小基准上的预期行为。"
        },
        {
            "id": "https://doi.org/10.1109/tvcg.2026.3658325",
            "title": "Unlearning Comparator: a Visual Analytics System for Comparative Evaluation of Machine Unlearning Methods",
            "link": "https://doi.org/10.1109/tvcg.2026.3658325",
            "published": "2026",
            "author": "Jaeung Lee, Suhyeon Yu, Yurim Jang, Simon S. Woo, Jaemin Jo",
            "summary": "Machine Unlearning (MU) aims to remove target training data from a trained model so that the removed data no longer influences the model's behavior, fulfilling\"right to be forgotten\"obligations under data privacy laws. Yet, we observe that researchers in this rapidly emerging field face challenges in analyzing and understanding the behavior of different MU methods, especially in terms of three fundamental principles in MU: accuracy, efficiency, and privacy. Consequently, they often rely on aggregate metrics and ad-hoc evaluations, making it difficult to accurately assess the trade-offs between methods. To fill this gap, we introduce a visual analytics system, Unlearning Comparator, designed to facilitate the systematic evaluation of MU methods. Our system supports two important tasks in the evaluation process: model comparison and attack simulation. First, it allows the user to compare the behaviors of two models, such as a model generated by a certain method and a retrained baseline, at class-, instance-, and layer-levels to better understand the changes made after unlearning. Second, our system simulates membership inference attacks (MIAs) to evaluate the privacy of a method, where an attacker attempts to determine whether specific data samples were part of the original training set. We evaluate our system through a case study visually analyzing prominent MU methods and demonstrate that it helps the user not only understand model behaviors but also gain insights that can inform the improvement of MU methods. The source code is publicly available at https://github.com/gnueaj/Machine-Unlearning-Comparator.",
            "journal": "IEEE Trans. Vis. Comput. Graph",
            "title_cn": "忘却比较器：用于比较评估机器忘却方法的视觉分析系统",
            "abstract_cn": "机器取消学习（MU）旨在从训练好的模型中删除目标训练数据，使删除的数据不再影响模型的行为，履行数据隐私法下的“被遗忘权”义务。然而，我们观察到，这个快速新兴领域的研究人员在分析和理解不同 MU 方法的行为方面面临挑战，特别是在 MU 的三个基本原则方面：准确性、效率和隐私。因此，他们通常依赖于总体指标和临时评估，从而很难准确评估方法之间的权衡。为了填补这一空白，我们引入了可视化分析系统 Unlearning Comparator，旨在促进 MU 方法的系统评估。我们的系统支持评估过程中的两个重要任务：模型比较和攻击模拟。首先，它允许用户在类、实例和层级别上比较两个模型的行为，例如通过某种方法生成的模型和重新训练的基线，以更好地理解取消学习后所做的更改。其次，我们的系统模拟成员推理攻击（MIA）来评估方法的隐私性，其中攻击者试图确定特定数据样本是否是原始训练集的一部分。我们通过案例研究对著名的 MU 方法进行可视化分析来评估我们的系统，并证明它不仅可以帮助用户理解模型行为，还可以获得可以指导 MU 方法改进的见解。源代码可在 https://github.com/gnueaj/Machine-Unlearning-Comparator 上公开获取。"
        },
        {
            "id": "https://doi.org/10.1109/tvcg.2026.3657593",
            "title": "Sketch2Avatar: Geometry-Guided 3D Full-Body Human Generation in 360° from Hand-Drawn Sketches",
            "link": "https://doi.org/10.1109/tvcg.2026.3657593",
            "published": "2026",
            "author": "Ziwei Chen, Qiang Li, Jie Zhang, Anthony Kong, Ping Li",
            "summary": "Generating full-body humans in 360° has broad applications in digital entertainment, online education and art design. Existing works primarily rely on coarse conditions such as body pose to guide the generation, lacking detailed control over the synthesized results. Regarding this limitation, sketches offer a promising alternative as an expressive condition that enables more explicit and precise control. However, current sketch-based generation methods focus on faces or common objects, how to transfer sketches into 360° full-body humans remains unexplored. We first propose two straightforward strategies: adapting sketch-based 3D face generation to full-body human or lifting sketch-based 2D human generation to 3D format through a two-stage approach. Unfortunately, both methods result in unsatisfactory degradation of generation quality. To bridge this gap, in this work, we propose Sketch2Avatar, the first generative model to achieve 3D full-body human generation from hand-drawn sketches. Our model is capable of synthesizing sketch-aligned and 360°-consistent full-body human images by leveraging the geometry information extracted from sketches to guide the 3D representation generation and neural rendering. Specifically, we propose sketch-guided 3D representation generation to model the 3D human and maintain the alignment between input sketches and generated humans. Our transformer-based generator incorporates spatial feature guidance and latent modulation derived from sketches to produce high-quality 3D representations. Additionally, our designed body aware neural rendering utilizes 3D human body priors from sketches, simplifying the learning of articulated body poses and complex body shapes. To train and evaluate our model, we construct a large-scale dataset comprising approximately 19K 2D full-body human images and their corresponding sketches in a hand-drawn style. Experimental results demonstrate that our Sketch2Avatar can transfer hand-drawn sketches into photo-realistic 360° full-body human images with precise sketch-human alignment. Ablation studies further validate the effectiveness of our design choices. Our project is publicly available at: https://richardchen20.github.io/Sketch2Avatar",
            "journal": "IEEE Trans. Vis. Comput. Graph",
            "title_cn": "Sketch2Avatar：根据手绘草图生成 360° 几何引导的 3D 全身人体",
            "abstract_cn": "生成 360° 全身人体在数字娱乐、在线教育和艺术设计中具有广泛的应用。现有的作品主要依靠身体姿势等粗略条件来指导生成，缺乏对合成结果的详细控制。关于这一限制，草图提供了一种有前途的替代方案，作为一种表达条件，可以实现更明确和精确的控制。然而，目前基于草图的生成方法主要集中在人脸或常见物体上，如何将草图转换为 360° 全身人体仍有待探索。我们首先提出两种简单的策略：将基于草图的 3D 人脸生成应用于全身人体，或通过两阶段方法将基于草图的 2D 人体生成提升为 3D 格式。不幸的是，这两种方法都会导致发电质量下降得令人不满意。为了弥补这一差距，在这项工作中，我们提出了 Sketch2Avatar，这是第一个通过手绘草图实现 3D 全身人体生成的生成模型。我们的模型能够利用从草图提取的几何信息来指导 3D 表示生成和神经渲染，从而合成草图对齐且 360° 一致的全身人体图像。具体来说，我们提出草图引导的 3D 表示生成来对 3D 人体进行建模，并保持输入草图和生成的人体之间的对齐。我们基于变压器的生成器结合了空间特征引导和源自草图的潜在调制，以生成高质量的 3D 表示。此外，我们设计的身体感知神经渲染利用草图中的 3D 人体先验，简化了关节式身体姿势和复杂身体形状的学习。为了训练和评估我们的模型，我们构建了一个大型数据集，其中包含大约 19K 2D 全身人体图像及其相应的手绘风格草图。实验结果表明，我们的 Sketch2Avatar 可以将手绘草图转换为逼真的 360° 全身人体图像，并具有精确的草图与人体对齐。消融研究进一步验证了我们设计选择的有效性。我们的项目公开于：https://richardchen20.github.io/Sketch2Avatar"
        },
        {
            "id": "https://doi.org/10.1109/tvcg.2026.3657634",
            "title": "Modulating Effort Sensations in virtual reality: A Parameter-Based Haptic Feedback Approach",
            "link": "https://doi.org/10.1109/tvcg.2026.3657634",
            "published": "2026",
            "author": "Yann Glémarec, Tom Roy, Quentin Galvane, Gurvan Lécuyer, Anatole Lécuyer, Ferran Argelaguet",
            "summary": "Virtual reality is becoming increasingly popular, and modern haptic equipment, such as vibrotactile suits, haptic gloves, and force-feedback controllers, offers new means of interaction within virtual environments, significantly enhancing user experience. When interacting with virtual objects, combined visual and haptic feedback simulates the physical sensations of grasping, lifting, or moving real objects. This sensorimotor feedback is essential for inducing a sense of presence and agency, yet it remains challenging to reproduce in the absence of reliable haptic cues. In this study, we design and evaluate several haptic metaphors using combinations of vibrotactile design parameters to simulate the lifting effort associated with light to heavy objects. These parameters include primitive signals, intensity, spatial density, propagation, and temporal density. Our contribution is threefold. First, we propose a method for modulating perceived physical effort by extending signal intensity with spatial and temporal density, which together reflect the effort required to lift an object. Second, we present a user study in which participants compared haptic effects and ranked them according to perceived lifting effort, comfort, and confidence, allowing us to assess the influence of each parameter. Third, we report the results of a second study in which participants evaluated vibrotactile effects when lifting different virtual objects. The findings confirm the importance of intensity and spatial density, as well as the influence of graphical representation on perceived effort. This research provides practical insights for designing haptic-enabled virtual reality systems and offers guidance for developers seeking to create more expressive and believable vibrotactile interactions.",
            "journal": "IEEE Trans. Vis. Comput. Graph",
            "title_cn": "调节虚拟现实中的力度感觉：基于参数的触觉反馈方法",
            "abstract_cn": "虚拟现实变得越来越流行，现代触觉设备，例如振动触觉服、触觉手套和力反馈控制器，提供了虚拟环境中的新交互方式，显着增强了用户体验。当与虚拟对象交互时，视觉和触觉反馈相结合，模拟抓握、举起或移动真实对象的物理感觉。这种感觉运动反馈对于诱导存在感和代理感至关重要，但在缺乏可靠触觉提示的情况下再现仍然具有挑战性。在本研究中，我们使用振动触觉设计参数的组合来设计和评估几种触觉隐喻，以模拟与轻到重物体相关的举升力。这些参数包括原始信号、强度、空间密度、传播和时间密度。我们的贡献是三重的。首先，我们提出了一种通过空间和时间密度扩展信号强度来调节感知体力的方法，这些信号强度共同反映了举起物体所需的力。其次，我们提出了一项用户研究，参与者比较了触觉效果，并根据感知的提升力、舒适度和信心对它们进行了排名，从而使我们能够评估每个参数的影响。第三，我们报告了第二项研究的结果，其中参与者评估了举起不同虚拟物体时的振动触觉效果。研究结果证实了强度和空间密度的重要性，以及图形表示对感知努力的影响。这项研究为设计支持触觉的虚拟现实系统提供了实用的见解，并为寻求创建更具表现力和可信的振动触觉交互的开发人员提供了指导。"
        },
        {
            "id": "https://doi.org/10.1109/tvcg.2026.3657658",
            "title": "CoreEditor: Correspondence-constrained Diffusion for Consistent 3D Editing",
            "link": "https://doi.org/10.1109/tvcg.2026.3657658",
            "published": "2026",
            "author": "Zhe Zhu, Honghua Chen, Peng Li, Mingqiang Wei",
            "summary": "Text-driven 3D editing is an emerging task that focuses on modifying scenes based on text prompts. Current methods often adapt pre-trained 2D image editors to multi-view observations, using specific strategies to combine information across views. However, these approaches still struggle with ensuring consistency across views, as they lack precise control over the sharing of information, resulting in edits with insufficient visual changes and blurry details. In this paper, we propose CoreEditor, a novel framework for consistent text-to-3D editing. At the core of our approach is a novel correspondence-constrained attention mechanism, which enforces structured interactions between corresponding pixels that are expected to remain visually consistent during the diffusion denoising process. Unlike conventional wisdom that relies solely on scene geometry, we enhance the correspondence by incorporating semantic similarity derived from the diffusion denoising process. This combined support from both geometry and semantics ensures a robust multi-view editing process. Additionally, we introduce a selective editing pipeline that enables users to choose their preferred edits from multiple candidates, creating a more flexible and user-centered 3D editing process. Extensive experiments demonstrate the effectiveness of CoreEditor, showing its ability to generate high-quality 3D edits, significantly outperforming existing methods.",
            "journal": "IEEE Trans. Vis. Comput. Graph",
            "title_cn": "CoreEditor：用于一致 3D 编辑的对应约束扩散",
            "abstract_cn": "文本驱动的 3D 编辑是一项新兴任务，重点是根据文本提示修改场景。当前的方法通常使预先训练的 2D 图像编辑器适应多视图观察，使用特定的策略来组合跨视图的信息。然而，这些方法仍然难以确保视图之间的一致性，因为它们缺乏对信息共享的精确控制，导致编辑时视觉变化不足和细节模糊。在本文中，我们提出了 CoreEditor，这是一种用于一致文本到 3D 编辑的新颖框架。我们方法的核心是一种新颖的对应约束注意机制，它强制对应像素之间的结构化交互，这些像素预计在扩散去噪过程中保持视觉一致。与仅依赖于场景几何的传统智慧不同，我们通过结合从扩散去噪过程中得出的语义相似性来增强对应性。几何和语义的结合支持确保了强大的多视图编辑过程。此外，我们还引入了选择性编辑管道，使用户能够从多个候选内容中选择自己喜欢的编辑，从而创建更灵活且以用户为中心的 3D 编辑流程。大量实验证明了 CoreEditor 的有效性，显示了其生成高质量 3D 编辑的能力，显着优于现有方法。"
        },
        {
            "id": "https://doi.org/10.1021/acsphotonics.5c02007",
            "title": "Ultraviolet GaN-Based Superluminescent Diodes with Inclined Facets",
            "link": "https://doi.org/10.1021/acsphotonics.5c02007",
            "published": "2026-01-26",
            "author": "Huabin Yu, Yuanpeng Wu, Yifu Guo, Danhao Wang, Jiangnan Liu, David He, Shubham Mondal, Yixin Xiao, Md Mehedi Hasan Tanim, Di Liang, Zetian Mi",
            "summary": "Abstract not available.",
            "journal": "ACS Photonics",
            "title_cn": "具有斜面的紫外 GaN 基超辐射发光二极管",
            "abstract_cn": "（摘要暂缺，等待官方补全）"
        },
        {
            "id": "https://doi.org/10.1109/tci.2026.3657289",
            "title": "Spatiotemporal Maps for Dynamic MRI Reconstruction",
            "link": "https://doi.org/10.1109/tci.2026.3657289",
            "published": "2026",
            "author": "Rodrigo A. Lobos, Xiaokai Wang, Rex T. L. Fung, Yongli He, David Frey, Dinank Gupta, Zhongming Liu, Jeffrey A. Fessler, Douglas C. Noll",
            "summary": "The partially separable functions (PSF) model is commonly adopted in dynamic MRI reconstruction, as is the underlying signal model in many reconstruction methods including the ones relying on low-rank assumptions. Even though the PSF model offers a parsimonious representation of the dynamic MRI signal in several applications, its representation capabilities tend to decrease in scenarios where voxels present different temporal/spectral characteristics at different spatial locations. In this work we account for this limitation by proposing a new model, called spatiotemporal maps (STMs), that leverages autoregressive properties of (k, t)-space. The STM model decomposes the spatiotemporal MRI signal into a sum of components, each one consisting of a product between a spatial function and a temporal function that depends on the spatial location. The proposed model can be interpreted as an extension of the PSF model whose temporal functions are independent of the spatial location. We show that spatiotemporal maps can be efficiently computed from autocalibration data by using advanced signal processing and randomized linear algebra techniques, enabling STMs to be used as part of many reconstruction frameworks for accelerated dynamic MRI. As proof-of-concept illustrations, we show that STMs can be used to reconstruct both 2D single-channel animal gastrointestinal MRI data and 3D multichannel human functional MRI data.",
            "journal": "IEEE Trans. Comp. Imaging",
            "title_cn": "用于动态 MRI 重建的时空图",
            "abstract_cn": "部分可分离函数 (PSF) 模型通常用于动态 MRI 重建，这也是许多重建方法（包括依赖低秩假设的重建方法）中的基础信号模型。尽管 PSF 模型在多种应用中提供了动态 MRI 信号的简约表示，但在体素在不同空间位置呈现不同时间/频谱特征的情况下，其表示能力往往会下降。在这项工作中，我们通过提出一种称为时空图（STM）的新模型来解释这一限制，该模型利用（k，t）空间的自回归特性。 STM 模型将时空 MRI 信号分解为一组分量之和，每个分量由空间函数和取决于空间位置的时间函数之间的乘积组成。所提出的模型可以解释为 PSF 模型的扩展，其时间函数与空间位置无关。我们证明，通过使用先进的信号处理和随机线性代数技术，可以根据自动校准数据有效地计算时空图，从而使 STM 能够用作加速动态 MRI 的许多重建框架的一部分。作为概念验证插图，我们表明 STM 可用于重建 2D 单通道动物胃肠道 MRI 数据和 3D 多通道人体功能 MRI 数据。"
        },
        {
            "id": "https://doi.org/10.1109/tpami.2026.3657578",
            "title": "Adversarial Imitation Learning with General Function Approximation: Theoretical Analysis and Practical Algorithms",
            "link": "https://doi.org/10.1109/tpami.2026.3657578",
            "published": "2026",
            "author": "Tian Xu, Zhilong Zhang, Zexuan Chen, Ruishuo Chen, Yihao Sun, Yang Yu",
            "summary": "Adversarial imitation learning (AIL), a prominent approach in imitation learning, has achieved significant practical success powered by neural network approximation. However, existing theoretical analyses of AIL are primarily confined to simplified settings—such as tabular and linear function approximation—and involve complex algorithmic designs that impede practical implementation. This creates a substantial gap between theory and practice. This paper bridges this gap by exploring the theoretical underpinnings of online AIL with general function approximation. We introduce a novel framework called optimization-based AIL (OPT-AIL), which performs online optimization for reward learning coupled with optimism-regularized optimization for policy learning. Within this framework, we develop two concrete methods: model-free OPT-AIL and model-based OPT-AIL. Our theoretical analysis demonstrates that both variants achieve polynomial expert sample complexity and interaction complexity for learning near-expert policies. To the best of our knowledge, they represent the first provably efficient AIL methods under general function approximation. From a practical standpoint, OPT-AIL requires only the approximate optimization of two objectives, thereby facilitating practical implementation. Empirical studies demonstrate that OPT-AIL outperforms previous state-of-the-art deep AIL methods across several challenging tasks.",
            "journal": "IEEE Trans. Pattern Anal. Mach. Intell.",
            "title_cn": "具有一般函数逼近的对抗性模仿学习：理论分析和实用算法",
            "abstract_cn": "对抗性模仿学习（AIL）是模仿学习中的一种重要方法，在神经网络近似的支持下取得了巨大的实际成功。然而，现有的 AIL 理论分析主要局限于简化的设置——例如表格和线性函数逼近——并且涉及阻碍实际实现的复杂算法设计。这造成了理论与实践之间的巨大差距。本文通过探索具有一般函数逼近的在线 AIL 的理论基础来弥补这一差距。我们引入了一种称为基于优化的 AIL (OPT-AIL) 的新颖框架，它执行奖励学习的在线优化以及策略学习的乐观正则化优化。在此框架内，我们开发了两种具体方法：无模型 OPT-AIL 和基于模型的 OPT-AIL。我们的理论分析表明，两种变体都实现了多项式专家样本复杂性和交互复杂性，以学习接近专家的策略。据我们所知，它们代表了第一个在一般函数逼近下可证明有效的 AIL 方法。从实用角度来看，OPT-AIL只需要对两个目标进行近似优化，从而便于实际实施。实证研究表明，OPT-AIL 在几个具有挑战性的任务中优于以前最先进的深度 AIL 方法。"
        },
        {
            "id": "https://doi.org/10.1109/tpami.2026.3657354",
            "title": "Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment",
            "link": "https://doi.org/10.1109/tpami.2026.3657354",
            "published": "2026",
            "author": "Lingling Xu, Haoran Xie, S. Joe Qin, Xiaohui Tao, Fu Lee Wang",
            "summary": "With the continuous growth in the number of parameters of the Transformer-based pretrained language models (PLMs), particularly the emergence of large language models (LLMs) with billions of parameters, many natural language processing (NLP) tasks have demonstrated remarkable success. However, the enormous size and computational demands of these models pose significant challenges for adapting them to specific downstream tasks, especially in environments with limited computational resources. Parameter-Efficient Fine-Tuning (PEFT) offers an effective solution by reducing the number of fine-tuning parameters and memory usage while achieving comparable performance to full fine-tuning. The demands for fine-tuning PLMs, especially LLMs, have led to a surge in the development of PEFT methods, as depicted in Fig. 1. In this paper, we present a comprehensive and systematic review of PEFT methods for PLMs. We summarize these PEFT methods, discuss their applications, and outline future directions. Furthermore, extensive experiments are conducted using several representative PEFT methods to better understand their effectiveness in parameter efficiency and memory efficiency. By offering insights into the latest advancements and practical applications, this survey serves as an invaluable resource for researchers and practitioners seeking to navigate the challenges and opportunities presented by PEFT in the context of PLMs.",
            "journal": "IEEE Trans. Pattern Anal. Mach. Intell.",
            "title_cn": "预训练语言模型的参数高效微调方法：批判性审查和评估",
            "abstract_cn": "随着基于Transformer的预训练语言模型（PLM）参数数量的不断增长，特别是具有数十亿参数的大型语言模型（LLM）的出现，许多自然语言处理（NLP）任务都取得了显着的成功。然而，这些模型的巨大规模和计算需求给使其适应特定下游任务带来了巨大挑战，特别是在计算资源有限的环境中。参数高效微调 (PEFT) 提供了一种有效的解决方案，通过减少微调参数的数量和内存使用量，同时实现与完全微调相当的性能。对 PLM（尤其是 LLM）进行微调的需求导致了 PEFT 方法的发展激增，如图 1 所示。在本文中，我们对 PLM 的 PEFT 方法进行了全面、系统的回顾。我们总结了这些 PEFT 方法，讨论了它们的应用，并概述了未来的方向。此外，使用几种代表性的 PEFT 方法进行了大量的实验，以更好地了解它们在参数效率和内存效率方面的有效性。通过提供对最新进展和实际应用的见解，该调查为寻求应对 PLM 背景下 PEFT 带来的挑战和机遇的研究人员和从业人员提供了宝贵的资源。"
        },
        {
            "id": "https://doi.org/10.1109/tpami.2026.3653415",
            "title": "TextMonkey: an OCR-Free Large Multimodal Model for Understanding Document",
            "link": "https://doi.org/10.1109/tpami.2026.3653415",
            "published": "2026",
            "author": "Yuliang Liu, Biao Yang, Qiang Liu, Zhang Li, Zhiyin Ma, Shuo Zhang, Xiang Bai",
            "summary": "We present TextMonkey, a large multimodal model (LMM) tailored for text-centric tasks. Our approach introduces enhancement across several dimensions: By adopting Shifted Window Attention layer, we achieve cross-window connectivity at higher input resolutions and stabilize early training; We hypothesize that images may contain redundant tokens, and by using similarity to filter out significant tokens, we can not only streamline the token length but also enhance the model's performance. Moreover, by expanding our model's capabilities to encompass text spotting and grounding, and incorporating positional information into responses, we enhance interpretability. Evaluation on 12 benchmarks shows notable improvements: 5.2% in Scene Text-Centric tasks (including STVQA, TextVQA, and OCRVQA), 6.9% in Document-Oriented tasks (such as DocVQA, InfoVQA, ChartVQA, DeepForm, Kleister Charity, and WikiTableQuestions), and 2.8% in Key Information Extraction tasks (comprising FUNSD, SROIE, and POIE). It outperforms in scene text spotting with a 10.9% increase and sets a new standard on OCRBench, a comprehensive benchmark consisting of 29 OCR-related assessments, with a score of 561, surpassing previous open-sourced large multimodal models for document understanding. Code is released at https://github.com/Yuliang-Liu/Monkey.",
            "journal": "IEEE Trans. Pattern Anal. Mach. Intell.",
            "title_cn": "TextMonkey：用于理解文档的无 OCR 大型多模态模型",
            "abstract_cn": "我们推出了 TextMonkey，这是一个专为以文本为中心的任务而定制的大型多模态模型 (LMM)。我们的方法引入了多个维度的增强：通过采用转移窗口注意力层，我们在更高的输入分辨率下实现了跨窗口连接并稳定了早期训练；我们假设图像可能包含冗余标记，通过使用相似性过滤掉重要标记，我们不仅可以简化标记长度，还可以提高模型的性能。此外，通过扩展模型的功能以涵盖文本识别和基础，并将位置信息纳入响应中，我们增强了可解释性。对 12 个基准的评估显示出显着的改进：以场景文本为中心的任务（包括 STVQA、TextVQA 和 OCRVQA）提高了 5.2%，面向文档的任务（如 DocVQA、InfoVQA、ChartVQA、DeepForm、Kleister Charity 和 WikiTableQuestions）提高了 6.9%，关键信息提取任务（包括 FUNSD、SROIE 和 POIE）提高了 2.8%。它在场景文本识别方面表现出色，提升了 10.9%，并在 OCRBench 上树立了新标准。 OCRBench 是一个由 29 个 OCR 相关评估组成的综合基准，得分为 561，超过了之前用于文档理解的开源大型多模态模型。代码发布于https://github.com/Yuliang-Liu/Monkey。"
        },
        {
            "id": "https://doi.org/10.1109/tpami.2026.3657778",
            "title": "Goal-oriented Dynamic Weight Optimization for Multi-Object Navigation",
            "link": "https://doi.org/10.1109/tpami.2026.3657778",
            "published": "2026",
            "author": "Haitao Zeng, Xinhang Song, Shuqiang Jiang",
            "summary": "Multi-object navigation (MON) tasks involve sequentially locating multiple targets in an unknown environment, requiring global long-term planning under incomplete information. This necessitates that the agent dynamically balance immediate actions and long-term rewards while considering both local adaptability and global foresight. However, current methods overly focus on local path optimization, which leads to slower convergence in sparse reward settings and increases the risk of deadlocks or trap states. The core challenge of MON lies in the deformation of the shared decision space, where independent optimization leads to redundant and overlapping paths. Thus, path planning requires dynamic, cross-task optimization rather than simple subtask aggregation. To minimize overall effort, the optimization process should adaptively balance task contributions through weight adjustment. Thus, we propose the Goal-oriented Dynamic Weight Optimization (GDWO) algorithm. GDWO integrates target-specific value loss functions into a unified optimization framework and dynamically adjusts weights through gradient-based updates. To prevent over-optimization, weights are normalized during training according to navigation success rates, prioritizing more challenging targets. This adaptive mechanism effectively addresses the challenge of sparse rewards and improves convergence efficiency. By leveraging this mechanism, GDWO unifies multiple objectives within a unified decision space, achieving efficient optimization and balancing short-term gains with long-term goals. Additionally, we introduce two auxiliary modules: prior knowledge-based navigation and frontier-aware exploration to further enhance GDWO's performance. Experimental results on the Gibson and Matterport3D datasets demonstrate that GDWO achieves improvements in key metrics for MON tasks. It optimizes path planning, reduces exploration costs, and enhances navigation efficiency, enabling the agent to perform tasks more effectively in complex environments.",
            "journal": "IEEE Trans. Pattern Anal. Mach. Intell.",
            "title_cn": "面向目标的多目标导航动态权重优化",
            "abstract_cn": "多目标导航（MON）任务涉及在未知环境中顺序定位多个目标，需要在不完整信息下进行全局长期规划。这需要代理动态平衡即时行动和长期奖励，同时考虑局部适应性和全局远见。然而，当前的方法过度关注局部路径优化，这导致稀疏奖励设置中收敛速度变慢，并增加了死锁或陷阱状态的风险。 MON 的核心挑战在于共享决策空间的变形，其中独立优化导致冗余和重叠的路径。因此，路径规划需要动态的跨任务优化，而不是简单的子任务聚合。为了最小化总体工作量，优化过程应通过权重调整自适应地平衡任务贡献。因此，我们提出了面向目标的动态权重优化（GDWO）算法。 GDWO将特定于目标的价值损失函数集成到统一的优化框架中，并通过基于梯度的更新动态调整权重。为了防止过度优化，在训练期间根据导航成功率对权重进行标准化，优先考虑更具挑战性的目标。这种自适应机制有效地解决了稀疏奖励的挑战并提高了收敛效率。通过利用这一机制，GDWO将多个目标统一在统一的决策空间内，实现高效优化并平衡短期收益与长期目标。此外，我们引入了两个辅助模块：基于先验知识的导航和前沿感知探索，以进一步增强 GDWO 的性能。 Gibson 和 Matterport3D 数据集上的实验结果表明，GDWO 在 MON 任务的关键指标上取得了改进。它优化路径规划，降低探索成本，提高导航效率，使智能体能够在复杂环境中更有效地执行任务。"
        },
        {
            "id": "https://doi.org/10.1016/j.optlastec.2026.114781",
            "title": "A high performance deep learning based single-pixel image reconstruction framework integrating the U-Net structure with improved Mamba modules",
            "link": "https://doi.org/10.1016/j.optlastec.2026.114781",
            "published": "2026-05-01",
            "author": "Shaowei Feng, Lieshan Zhang, Yang Yang, Qinhao Xu, Yuanchao Hu",
            "summary": "Abstract not available.",
            "journal": "Optics and Laser Technology",
            "title_cn": "基于高性能深度学习的单像素图​​像重建框架，将 U-Net 结构与改进的 Mamba 模块相结合",
            "abstract_cn": "（摘要暂缺，等待官方补全）"
        },
        {
            "id": "https://doi.org/10.1016/j.optlastec.2026.114810",
            "title": "Multi-parameter optical fiber sensor based on the combination of double SPR and MZl for magnetic field, temperature, and salinity",
            "link": "https://doi.org/10.1016/j.optlastec.2026.114810",
            "published": "2026-05-01",
            "author": "Yu Wang, Yong Zhao, Riqing Lv, Lufeng Wang, Pengqi Gong, Zhenye Guo, Hongkun Zheng",
            "summary": "Abstract not available.",
            "journal": "Optics and Laser Technology",
            "title_cn": "基于双SPR和MZl组合的磁场、温度、盐度多参数光纤传感器",
            "abstract_cn": "（摘要暂缺，等待官方补全）"
        },
        {
            "id": "https://doi.org/10.1016/j.optlastec.2026.114795",
            "title": "Real-UDPM: real-time underwater image enhancement based on fast conditional denoising diffusion probabilistic model",
            "link": "https://doi.org/10.1016/j.optlastec.2026.114795",
            "published": "2026-05-01",
            "author": "Baizhong Chen, Chonglei Wang, Chunyu Guo, Yumin Su",
            "summary": "Abstract not available.",
            "journal": "Optics and Laser Technology",
            "title_cn": "Real-UDPM：基于快速条件去噪扩散概率模型的实时水下图像增强",
            "abstract_cn": "（摘要暂缺，等待官方补全）"
        },
        {
            "id": "https://doi.org/10.1016/j.optlastec.2026.114776",
            "title": "Photonic biointerfaces: A new paradigm for seamless integration with living systems based on flexible optical fibers",
            "link": "https://doi.org/10.1016/j.optlastec.2026.114776",
            "published": "2026-05-01",
            "author": "Kun Xiao, Shihao Zhou, Heng Wang, Xiaoli Li, Rui Min, Zhuo Wang",
            "summary": "Abstract not available.",
            "journal": "Optics and Laser Technology",
            "title_cn": "光子生物界面：基于柔性光纤与生命系统无缝集成的新范例",
            "abstract_cn": "（摘要暂缺，等待官方补全）"
        },
        {
            "id": "https://doi.org/10.1016/j.optlaseng.2026.109641",
            "title": "CerDef-Detector: automated detection of surface defects in buzzer ceramic discs based on deep learning and machine vision",
            "link": "https://doi.org/10.1016/j.optlaseng.2026.109641",
            "published": "2026-06-01",
            "author": "Fan Zhang, Xiangfeng Zhang, Hong Jiang, Zhiyi Fan, Kaige Sun, Hongxia Shi, Yefeng Li",
            "summary": "Abstract not available.",
            "journal": "Optics and Lasers in Engineering",
            "title_cn": "CerDef-Detector：基于深度学习和机器视觉自动检测蜂鸣器陶瓷盘表面缺陷",
            "abstract_cn": "（摘要暂缺，等待官方补全）"
        },
        {
            "id": "https://doi.org/10.1016/j.optcom.2025.132779",
            "title": "Corrigendum to “Coherent fading suppression method in the COTDR system based on multi-band filtering” [Opt. Commun. 583 (2025) 131696]",
            "link": "https://doi.org/10.1016/j.optcom.2025.132779",
            "published": "2026-06-01",
            "author": "Xiang Sui, Ying Shang, Sheng Huang, Wenan Zhao, Xiaohan Qiao, Guangqiang Liu, Chunmei Yao, Shouling Liu, Na Wan, Xianggui Kong, Hong Zhao, Fengming Mou, Zhengying Li, Weitao Wang, Chen Wang, Gangding Peng",
            "summary": "Abstract not available.",
            "journal": "Optics Communications",
            "title_cn": "“基于多频带滤波的COTDR系统相干衰落抑制方法”的勘误[选项2]交流。 [583(2025)131696]",
            "abstract_cn": "（摘要暂缺，等待官方补全）"
        },
        {
            "id": "https://doi.org/10.1364/oe.582380",
            "title": "Telescope-based scanning LiDAR system for eye-safe long-range UAV localization and tracking",
            "link": "https://doi.org/10.1364/oe.582380",
            "published": "2026-01-26",
            "author": "Christopher Naverschnigg, Andreas Sinn, Daniil Zelinskyi, Denis Ojdanić, Georg Schitter",
            "summary": "<jats:p>This paper presents the design and experimental evaluation of a telescope-based scanning light detection and ranging (LiDAR) system for eye-safe long-range localization and tracking of small uncrewed aerial vehicles (UAVs). A prototype with an eye-safe custom-built laser transmitter module, a one-dimensional APD detector array, a telescope, and a telescope mount is implemented to verify the system design. Experiments from a laboratory environment demonstrate robust static and dynamic localization of a DJI Phantom 3 UAV at a range of 300 m. Field tests confirm the system’s capabilities, successfully demonstrating distance measurements to a DJI Matrice 30 at ranges up to 50 m, and the feasibility of hybrid target tracking at velocities up to 15 m/s at distances of 300 m, where horizontal tracking is achieved using LiDAR data and applying a spatio-temporal filter with a DBSCAN-based algorithm. In contrast, vertical tracking is performed based on image-based processing.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "基于望远镜的扫描激光雷达系统，用于人眼安全的远程无人机定位和跟踪",
            "abstract_cn": "<jats:p>本文介绍了基于望远镜的扫描光探测和测距 (LiDAR) 系统的设计和实验评估，该系统用于小型无人飞行器 (UAV) 的人眼安全远程定位和跟踪。采用具有人眼安全定制激光发射器模块、一维 APD 探测器阵列、望远镜和望远镜支架的原型来验证系统设计。实验室环境中的实验证明了 DJI Phantom 3 无人机在 300 米范围内具有强大的静态和动态定位功能。现场测试证实了该系统的功能，成功展示了 DJI Matrice 30 在 50 m 范围内的距离测量，以及在 300 m 距离上以高达 15 m/s 的速度进行混合目标跟踪的可行性，其中水平跟踪是使用 LiDAR 数据并应用基于 DBSCAN 算法的时空滤波器来实现的。相比之下，垂直跟踪是基于基于图像的处理来执行的。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.587572",
            "title": "Growth, spectral, and efficient multiple wavelength laser operation of Nd:LuScO\n                    <sub>3</sub>\n                    crystal",
            "link": "https://doi.org/10.1364/oe.587572",
            "published": "2026-01-09",
            "author": "Fangyan Wang, Huichen Si, Dazhi Lu, Fei Liang",
            "summary": "<jats:p>\n                    A high-quality Nd:LuScO\n                    <jats:sub>3</jats:sub>\n                    crystal was grown using the optical floating zone (OFZ) method. The fundamental spectroscopic properties, including the absorption and emission cross sections, fluorescence lifetimes, and Judd-Ofelt intensity parameters, were systematically analyzed. Under the laser diode pumping, five distinct laser emissions were achieved. For the\n                    <jats:sup>4</jats:sup>\n                    F\n                    <jats:sub>3/2</jats:sub>\n                    →\n                    <jats:sup>4</jats:sup>\n                    I\n                    <jats:sub>11/2</jats:sub>\n                    transition channel, a maximum output power of 1.37 W with a slope efficiency of 24.9% was obtained, alongside simultaneous emissions at 1079 nm and 1086 nm. Additionally, output powers of 1.28 W and 0.40 W were achieved at 1116 nm and 1144 nm, respectively. Notably, emission at 1144 nm represents, to the best of our knowledge, the longest wavelength reported for the\n                    <jats:sup>4</jats:sup>\n                    F\n                    <jats:sub>3/2</jats:sub>\n                    →\n                    <jats:sup>4</jats:sup>\n                    I\n                    <jats:sub>11/2</jats:sub>\n                    transition in Nd\n                    <jats:sup>3+</jats:sup>\n                    -doped materials. For the\n                    <jats:sup>4</jats:sup>\n                    F\n                    <jats:sub>3/2</jats:sub>\n                    →\n                    <jats:sup>4</jats:sup>\n                    I\n                    <jats:sub>13/2</jats:sub>\n                    channel, continuous-wave output at 1465.6 nm reached 395 mW with 10.1% slope efficiency. These results demonstrate the significant potential of Nd:LuScO\n                    <jats:sub>3</jats:sub>\n                    for multi-wavelength laser applications.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "Nd:LuScO <sub>3</sub> 晶体的生长、光谱和高效多波长激光操作",
            "abstract_cn": "<贾茨：p>\n                    高品质 Nd:LuScO\n                    <贾茨：子>3</贾茨：子>\n                    使用光学浮区（OFZ）方法生长晶体。系统地分析了基本光谱特性，包括吸收和发射截面、荧光寿命和贾德-奥菲尔特强度参数。在激光二极管泵浦下，实现了五种不同的激光发射。对于\n                    <贾茨：sup>4</贾茨：sup>\n                    F\n                    <贾茨：子>3/2</贾茨：子>\n                    →\n                    <贾茨：sup>4</贾茨：sup>\n                    我\n                    <贾茨：子>11/2</贾茨：子>\n                    过渡通道的最大输出功率为 1.37 W，斜率效率为 24.9%，同时在 1079 nm 和 1086 nm 处发射。此外，在 1116nm 和 1144nm 处分别实现了 1.28W 和 0.40W 的输出功率。值得注意的是，据我们所知，1144nm 处的发射代表了报道的最长波长。\n                    <贾茨：sup>4</贾茨：sup>\n                    F\n                    <贾茨：子>3/2</贾茨：子>\n                    →\n                    <贾茨：sup>4</贾茨：sup>\n                    我\n                    <贾茨：子>11/2</贾茨：子>\n                    Nd 跃迁\n                    <贾茨：sup>3+</贾茨：sup>\n                    -掺杂材料。对于\n                    <贾茨：sup>4</贾茨：sup>\n                    F\n                    <贾茨：子>3/2</贾茨：子>\n                    →\n                    <贾茨：sup>4</贾茨：sup>\n                    我\n                    <贾茨：子>13/2</贾茨：子>\n                    通道中，1465.6 nm 处的连续波输出达到 395 mW，斜率效率为 10.1%。这些结果证明了 Nd:LuScO 的巨大潜力\n                    <贾茨：子>3</贾茨：子>\n                    适用于多波长激光应用。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.585479",
            "title": "Rational design of Yb-doped fluorophosphate fiber for narrow-linewidth single-frequency fiber laser at 1013 nm",
            "link": "https://doi.org/10.1364/oe.585479",
            "published": "2026-01-12",
            "author": "Taiyu Duan, Yuhang Deng, Xin Zhang, Yao Ji, Qinyuan Zhang",
            "summary": "<jats:p>\n                    The development of Yb\n                    <jats:sup>3+</jats:sup>\n                    -doped fiber lasers operating at short wavelength (&lt;1030 nm) is crucial for applications in quantum science and precision metrology, but is hindered by the low gain and severe reabsorption of conventional host materials in this spectral region. Exploring high-gain fibers tailored for this band offers a material-based solution. Here, we propose a rational design strategy for developing a multi-component fluorophosphate (FP) glass fiber, aiming at addressing the challenges of devitrification and spectral property modulation. The methodology begins with selecting a highly stable host matrix from the glass-forming region, followed by engineering the rare-earth local environment using modifier cations, guided by molecular dynamics simulations and Raman spectroscopy. The custom-designed Yb\n                    <jats:sup>3+</jats:sup>\n                    -doped FP glass exhibits a blueshifted emission peak at 1013 nm, a broad effective linewidth of 86.1 nm, a prolonged fluorescence lifetime of 2.38 ms, and a large Stark splitting of 812 cm\n                    <jats:sup>-1</jats:sup>\n                    , which results in high gain (6.56 dB/cm at 1064 nm and 9.09 dB/cm at 1013 nm). To validate its performance, a single-frequency fiber laser (SFFL) was constructed using only a 9 mm segment of this active fiber, achieving single-longitudinal-mode operation at 1013.4 nm with a narrow linewidth of 4.5 kHz, a low pump threshold of 8.3 mW, and exceptional stability (RMS instability&lt;0.8% over 1.5 hours). This work presents a high-gain medium for narrow-linewidth, short-wavelength SFFLs and demonstrates a generalizable design-to-device pipeline for other high-gain fibers targeting specific operational wavelengths.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "1013 nm窄线宽单频光纤激光器掺镱氟磷酸盐光纤的合理设计",
            "abstract_cn": "<贾茨：p>\n                    镱的发展\n                    <贾茨：sup>3+</贾茨：sup>\n                    在短波长（<1030 nm）下工作的掺杂光纤激光器对于量子科学和精密计量学的应用至关重要，但受到该光谱区域传统主体材料的低增益和严重重吸收的阻碍。探索专为该频段定制的高增益光纤提供了一种基于材料的解决方案。在这里，我们提出了开发多组分氟磷酸盐（FP）玻璃纤维的合理设计策略，旨在解决失透和光谱特性调制的挑战。该方法首先从玻璃形成区域选择高度稳定的主体基质，然后在分子动力学模拟和拉曼光谱的指导下，使用改性剂阳离子设计稀土局部环境。定制设计的 Yb\n                    <贾茨：sup>3+</贾茨：sup>\n                    掺杂 FP 玻璃在 1013 nm 处呈现蓝移发射峰、86.1 nm 的宽有效线宽、2.38 ms 的长荧光寿命以及 812 cm 的大斯塔克分裂\n                    <贾茨：sup>-1</贾茨：sup>\n                    ，从而产生高增益（1064 nm 处为 6.56 dB/cm，1013 nm 处为 9.09 dB/cm）。为了验证其性能，仅使用该有源光纤的 9 mm 段构建了单频光纤激光器 (SFFL)，实现了 1013.4 nm 的单纵模操作，具有 4.5 kHz 的窄线宽、8.3 mW 的低泵浦阈值和出色的稳定性（1.5 小时内 RMS 不稳定性 <0.8%）。这项工作提出了一种用于窄线宽、短波长 SFFL 的高增益介质，并展示了针对特定工作波长的其他高增益光纤的通用设计到器件管道。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.586230",
            "title": "Indirect detection of hydrogen based on light-induced thermoelastic spectroscopy",
            "link": "https://doi.org/10.1364/oe.586230",
            "published": "2026-01-14",
            "author": "Chuanning Li, Ying He, Shunda Qiao, Yufei Ma",
            "summary": "<jats:p>\n                    Hydrogen (H\n                    <jats:sub>2</jats:sub>\n                    ), as a low-density and high-efficiency clean energy source, is widely used in the H\n                    <jats:sub>2</jats:sub>\n                    energy sector. However, its colorless, odorless nature and wide explosive concentration range (4–75%) demand rapid and accurate detection techniques. Conventional H\n                    <jats:sub>2</jats:sub>\n                    detection methods based on quartz tuning forks (QTFs) suffer from time-consuming full-frequency scanning, complex data processing, and frequency errors caused by parasitic capacitance. In this study, an indirect H\n                    <jats:sub>2</jats:sub>\n                    detection method based on light-induced thermoelastic spectroscopy (LITES) is proposed for the first time. A universal pump gas is innovatively employed, allowing H\n                    <jats:sub>2</jats:sub>\n                    concentration information to be obtained solely through the excitation of a LITES signal. Two demodulation schemes are developed: a frequency-tracking demodulation that establishes a linear relationship between QTF resonant frequency and H\n                    <jats:sub>2</jats:sub>\n                    concentration, and a fixed-frequency demodulation that divides the demodulation frequency into three characteristic blocks, enabling H\n                    <jats:sub>2</jats:sub>\n                    concentration retrieval without full-frequency scanning. Experimental results demonstrate that the LITES system exhibits excellent linearity with respect to the pump gas concentration. The QTF resonant frequency shows a linear response to H\n                    <jats:sub>2</jats:sub>\n                    concentration with a sensitivity of 6.8845 mHz/% and a minimum detection limit of 0.36%. The proposed method effectively eliminates frequency errors caused by parasitic capacitance and features high sensitivity, fast response, and simplified data processing, offering a reliable approach for H\n                    <jats:sub>2</jats:sub>\n                    safety monitoring.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "基于光致热弹性光谱的氢间接检测",
            "abstract_cn": "<贾茨：p>\n                    氢气（H\n                    <贾茨：子>2</贾茨：子>\n                    ）作为一种低密度、高效的清洁能源，广泛应用于H\n                    <贾茨：子>2</贾茨：子>\n                    能源部门。然而，其无色、无味的性质和广泛的爆炸浓度范围（4-75%）需要快速、准确的检测技术。常规H\n                    <贾茨：子>2</贾茨：子>\n                    基于石英音叉（QTF）的检测方法存在全频扫描耗时、数据处理复杂以及寄生电容引起的频率误差等问题。在本研究中，间接 H\n                    <贾茨：子>2</贾茨：子>\n                    首次提出了基于光诱导热弹性光谱（LITES）的检测方法。创新性地采用了通用泵气体，使 H\n                    <贾茨：子>2</贾茨：子>\n                    仅通过 LITES 信号的激发即可获得浓度信息。开发了两种解调方案：频率跟踪解调，在 QTF 谐振频率和 H 之间建立线性关系。\n                    <贾茨：子>2</贾茨：子>\n                    集中，以及将解调频率分为三个特征块的固定频率解调，使 H\n                    <贾茨：子>2</贾茨：子>\n                    无需全频扫描即可进行浓度检索。实验结果表明，LITES 系统对于泵气浓度表现出出色的线性度。 QTF 谐振频率显示出对 H 的线性响应\n                    <贾茨：子>2</贾茨：子>\n                    浓度的灵敏度为 6.8845 mHz/%，最低检测限为 0.36%。该方法有效消除了寄生电容引起的频率误差，具有灵敏度高、响应速度快、简化数据处理等特点，为H\n                    <贾茨：子>2</贾茨：子>\n                    安全监控。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.580837",
            "title": "Multi-pass optical delay configuration using a retroreflector pair for Fourier transform interferometers",
            "link": "https://doi.org/10.1364/oe.580837",
            "published": "2026-01-07",
            "author": "Muqian Wen",
            "summary": "<jats:p>Corner cube retroreflectors can be used in Fourier transform interferometers to create multi-pass optical delay configurations to increase the resolution of the interferometer. This paper will present a multi-pass optical delay design using two identical retroreflectors and it will prove that this design will be the theoretically most efficient design to achieve as many passes as possible using two identical retroreflectors. A formula will be derived to calculate the relation between beam diameter, retroreflector position and the number of passes. An experiment was conducted to demonstrate this design which achieves 24 passes and the resulting interferometer has a scanning range of about 7.2 m.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "使用傅立叶变换干涉仪的后向反射器对的多通道光学延迟配置",
            "abstract_cn": "<jats:p>角立方体后向反射器可用于傅里叶变换干涉仪，以创建多通道光学延迟配置，以提高干涉仪的分辨率。本文将提出使用两个相同的后向反射器的多通道光学延迟设计，并将证明该设计将是理论上最有效的设计，可以使用两个相同的后向反射器实现尽可能多的通道。将推导出一个公式来计算光束直径、后向反射器位置和通过次数之间的关系。通过实验验证了这种设计，可实现 24 次通过，所得干涉仪的扫描范围约为 7.2 m。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.576117",
            "title": "Joint millimeter-wave communication and optical multipath interference localization for RoF mobile fronthaul",
            "link": "https://doi.org/10.1364/oe.576117",
            "published": "2026-01-12",
            "author": "Chuanming Huang, Rui Xue, Mengfan Cheng, Qi Yang, Deming Liu, Lei Deng",
            "summary": "<jats:p>Millimeter-wave (mm-wave) radio-over-fiber (RoF) technology is a promising solution for next-generation mobile networks. However, its practical implementation faces two critical challenges: the high cost and bandwidth requirements of optoelectronic components for mm-wave signal generation, and vulnerability to optical multipath interference (MPI) caused by reflections at dirty fiber connectors in large-scale mobile fronthaul networks. To address these challenges, we propose and demonstrate a joint mm-wave communication and MPI localization scheme for high-capacity mm-wave RoF links based on a novel linear frequency modulation single sideband (LFM-SSB) waveform, which is generated by combining a virtual-carrier-aided SSB signal with a digital LFM carrier. In the LFM-SSB waveform, the virtual-carrier-aided SSB signal enables photonic-aided mm-wave up-conversion, while the LFM carrier achieves MPI localization. The LFM carrier in the LFM-SSB waveform is eliminated after self-heterodyne detection in the absence of MPI, resulting in a negligible impact on transmission performance. Simulation results demonstrate that the proposed scheme achieves sub-decimeter (5 cm) MPI localization accuracy while maintaining robustness against large linewidth lasers. With lasers having linewidths below 2 MHz, both high-precision MPI localization and robust communication performance are achieved. It indicates that the proposed scheme offers the advantage of low-cost, large-linewidth lasers without compromising on high accuracy and large capacity. Experimental validation demonstrates the transmission of a 2 Gbaud 16QAM mm-wave signal at 30 GHz, with successful localization of a single MPI reflection path at 107.46 m. Additionally, an MPI localization resolution of 9.78 cm is achieved at a chirp rate of 200 THz/s. The experimental system supports a maximum of 6 Gbaud 16QAM mm-wave signals and successfully locates two MPI reflection paths.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "RoF移动前传的联合毫米波通信和光多径干扰定位",
            "abstract_cn": "<jats:p>毫米波 (mm-wave) 光纤无线电 (RoF) 技术是下一代移动网络的一种有前途的解决方案。然而，其实际实施面临两个关键挑战：产生毫米波信号的光电元件的高成本和带宽要求，以及大规模移动前传网络中脏光纤连接器反射引起的光多径干扰（MPI）的脆弱性。为了应对这些挑战，我们提出并演示了一种用于高容量毫米波 RoF 链路的毫米波通信和 MPI 联合定位方案，该方案基于新型线性调频单边带 (LFM-SSB) 波形，该波形是通过将虚拟载波辅助的 SSB 信号与数字 LFM 载波相结合而生成的。在LFM-SSB波形中，虚拟载波辅助的SSB信号实现光子辅助毫米波上变频，而LFM载波实现MPI定位。在没有MPI的情况下，LFM-SSB波形中的LFM载波经过自外差检测后被消除，对传输性能的影响可以忽略不计。仿真结果表明，所提出的方案实现了亚分米 (5 cm) MPI 定位精度，同时保持了对大线宽激光的鲁棒性。使用线宽低于 2 MHz 的激光器，可以实现高精度 MPI 定位和强大的通信性能。这表明所提出的方案提供了低成本、大线宽激光器的优势，同时又不影响高精度和大容量。实验验证表明可以在 30 GHz 传输 2 Gbaud 16QAM 毫米波信号，并成功定位 107.46 m 处的单个 MPI 反射路径。此外，在 200 THz/s 的啁啾速率下实现了 9.78 cm 的 MPI 定位分辨率。实验系统最大支持6 Gbaud 16QAM毫米波信号，并成功定位两条MPI反射路径。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.584007",
            "title": "Time-multiplexed method for expanding the view window of head-mounted light field displays",
            "link": "https://doi.org/10.1364/oe.584007",
            "published": "2026-01-13",
            "author": "Cheng-Ting Huang, Hong Hua",
            "summary": "<jats:p>Integral imaging-based head-mounted light field display (InI-LF-HMD) systems offer the ability to render a 3D scene with accommodation cues to alleviate vergence-accommodation conflicts. Conventional methods for designing InI-LF-HMD systems, however, are subject to several key challenges, one of which is the limited size and location of the view window where the eye of an observer can be placed to view crosstalk-free light field rendering. In this work, we characterized the analytical relationships between the size and location of the view window and the optical parameters of the system design. Based on the analytical tradeoffs, we proposed a time-multiplexed method for view window expansion by utilizing a digitally programmable shutter array. A time-multiplexed InI-based display prototype was built, through which we experimentally demonstrated that a four-phase time multiplexing enabled the expansion of the view window four times compared to a conventional rendering without compromising optical resolution and view density.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "扩展头戴式光场显示器视窗的时分复用方法",
            "abstract_cn": "<jats:p>基于集成成像的头戴式光场显示 (InI-LF-HMD) 系统能够渲染具有调节提示的 3D 场景，以缓解聚散调节冲突。然而，设计 InI-LF-HMD 系统的传统方法面临几个关键挑战，其中之一是观察者的眼睛可以放置以查看无串扰光场渲染的观察窗的尺寸和位置有限。在这项工作中，我们描述了观察窗的尺寸和位置与系统设计的光学参数之间的分析关系。基于分析权衡，我们提出了一种利用数字可编程快门阵列来扩展视图窗口的时分复用方法。构建了基于 InI 的时分复用显示原型，通过该原型，我们通过实验证明，与传统渲染相比，四相时分复用能够将视图窗口扩展四倍，而不会影响光学分辨率和视图密度。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.585727",
            "title": "Geometry-aware multimodal fusion for large-scale 3D scene understanding",
            "link": "https://doi.org/10.1364/oe.585727",
            "published": "2026-01-23",
            "author": "Yuhao Wang, Yong Zuo, Yi Tang, Xiaobin Hong, Jian Wu, Ziyu Bian",
            "summary": "<jats:p>Multimodal 3D semantic segmentation plays a crucial role in engineering applications such as autonomous driving, robotics, and 3D image acquisition and display systems. However, the complex geometry of real scenes, varying object scales, and the inherent sparsity and non-uniform sampling of LiDAR-based acquisition still present significant challenges. To address these issues, we propose an adaptive geometry fusion method for robust and efficient multimodal 3D understanding. The method adopts a dual-path 3D feature extractor: one path captures spatial structural relationships through position-based encoding, while the other integrates a geometry-aware adaptive aggregation module that models local structures using learnable kernel positions and hybrid distance–appearance weighting. Complementary image features from passive optical imaging are fused with LiDAR features to enhance semantic discrimination in regions with sparse or ambiguous 3D measurements. The overall framework remains lightweight, containing only 5.2M parameters, and achieves real-time inference at 25 ms per sample, enabling deployment in resource-constrained sensing and visualization platforms. Experiments on Semantic3D, SemanticKITTI (71.2% mIoU, surpassing the lightweight baseline RandLA-Net by 15.3%), and nuScenes demonstrate competitive performance and strong generalization. Furthermore, evaluations on real-world colored point clouds acquired from a LiDAR–camera system validate the effectiveness of the proposed method in outdoor environments, providing semantically structured 3D representations suitable for downstream 3D display and visualization applications.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "用于大规模 3D 场景理解的几何感知多模态融合",
            "abstract_cn": "<jats:p>多模态 3D 语义分割在自动驾驶、机器人、3D 图像采集和显示系统等工程应用中发挥着至关重要的作用。然而，真实场景的复杂几何形状、不同的物体尺度以及基于激光雷达的采集固有的稀疏性和不均匀采样仍然提出了重大挑战。为了解决这些问题，我们提出了一种自适应几何融合方法，以实现稳健且高效的多模态 3D 理解。该方法采用双路径 3D 特征提取器：一条路径通过基于位置的编码捕获空间结构关系，而另一条路径集成几何感知自适应聚合模块，该模块使用可学习的内核位置和混合距离-外观加权对局部结构进行建模。来自被动光学成像的补充图像特征与 LiDAR 特征融合，以增强 3D 测量稀疏或模糊区域的语义辨别能力。整体框架保持轻量级，仅包含 520 万个参数，并实现每个样本 25 毫秒的实时推理，从而能够部署在资源受限的传感和可视化平台中。在 Semantic3D、SemanticKITTI（71.2% mIoU，超过轻量级基线 RandLA-Net 15.3%）和 nuScenes 上的实验展示了具有竞争力的性能和强大的泛化能力。此外，对从 LiDAR 相机系统获取的真实世界彩色点云的评估验证了所提出的方法在室外环境中的有效性，提供适合下游 3D 显示和可视化应用的语义结构化 3D 表示。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.583765",
            "title": "Fading-suppressed Φ-OTDR with high spatial-resolution based on a chirped electro-optic frequency comb",
            "link": "https://doi.org/10.1364/oe.583765",
            "published": "2026-01-12",
            "author": "Desheng Li, Zhiyong Zhao, Xun Guan, Xiang Li, Tianye Huang, Faisal Nadeem Khan",
            "summary": "<jats:p>We propose a fading-suppressed phase-sensitive optical time-domain reflectometer (φ-OTDR) sensing system based on a chirped electro-optic frequency comb (CEOFC), which achieves high spatial resolution and simultaneously enhances the potential for long-distance sensing. A dual-parallel Mach–Zehnder modulator and a phase modulator are employed to generate multiple parallel chirped probe channels from a single carrier electrical waveform, enabling simultaneous wideband interrogation. After matched filtering, each comb line preserves the full spatial resolution determined solely by the electrical chirp bandwidth, while the combination of multi-channel Rayleigh traces effectively suppresses the fading. In a 10.84-km sensing experiment, the proposed system achieves a 50-cm spatial resolution, improving the average normalized intensity signal-to-noise ratio (SNR) by 12.92 dB, reducing the fading rate by 54%, and enhancing the phase SNR by 22.36 dB compared with the conventional chirped-pulse φ-OTDR. Two remote vibration events are accurately recovered with high fidelity. The results prove that the CEOFC-based φ-OTDR offers high spatial resolution, strong fading robustness, and a great potential for long-distance distributed acoustic sensing applications.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "基于啁啾电光频率梳的高空间分辨率衰落抑制 Φ-OTDR",
            "abstract_cn": "<jats:p>我们提出了一种基于啁啾电光频率梳 (CEOFC) 的衰落抑制相敏光时域反射计 (φ-OTDR) 传感系统，该系统实现了高空间分辨率，同时增强了长距离传感的潜力。采用双并行马赫-曾德调制器和相位调制器从单载波电波形生成多个并行啁啾探测通道，从而实现同时宽带询问。经过匹配滤波后，每条梳状线保留了仅由电线性调频带宽决定的完整空间分辨率，而多通道瑞利迹线的组合有效地抑制了衰落。在10.84公里的传感实验中，该系统实现了50厘米的空间分辨率，与传统的啁啾脉冲φ-OTDR相比，平均归一化强度信噪比（SNR）提高了12.92 dB，衰落率降低了54%，相位SNR提高了22.36 dB。以高保真度准确恢复两个远程振动事件。结果证明，基于CEOFC的φ-OTDR具有高空间分辨率、强衰落鲁棒性，在长距离分布式声学传感应用中具有巨大潜力。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.578359",
            "title": "Extended depth-of-field stereo imaging system based on high-speed dual cameras embedded with variable focus lenses",
            "link": "https://doi.org/10.1364/oe.578359",
            "published": "2026-01-16",
            "author": "Shuangjiang Huang, Lihui Wang, Yan Hu, Satoshi Tabata, Yutao Huang, Xu Gui, Shi Bai, Yuan He, Tao Chen, Sandy To, Junyi Wang, Masatoshi Ishikawa",
            "summary": "<jats:p>Extended depth-of-field (DoF) technology is widely used in three-dimensional (3D) depth measurement. However, it is hard to achieve extended DoF imaging for conventional stereoscopic vision systems in dynamic scenes. Here, we propose an extended DoF vision system based on variable-focus lenses for target motion scenes. This system operates at two synergistic levels: optical-level focal sweeping and computational-level all-in-focus synthesis dynamically. Specifically, we introduce a temporally adaptive focal calibration model that precisely predicts curvature variations of varifocal lenses under non-linear electromechanical responses, ensuring sub-millisecond focal accuracy across a depth range of 0.45∼1.2 m. In addition, an adaptive homography-based multi-plane remapping mechanism is designed to compensate for disparity drift and distortion artifacts induced by rapid focus change, followed by a sharpness-weighted fusion strategy that synthesizes an all-in-focus image with preserved high-frequency details. The depth measurement performance was improved by approximately 6.2%, the relative depth error rate is optimized to 5.82%, and the RMSE is reduced to 0.0505 compared to conventional stereo vision systems in images obtained. The proposed system has the advantage of a compact form factor and dynamic extended DoF imaging. The potential applications include biomedical imaging, industrial vision inspection, robotic vision with navigation, and AR/VR.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "基于嵌入可变焦镜头的高速双摄像头的扩展景深立体成像系统",
            "abstract_cn": "<jats:p>扩展景深 (DoF) 技术广泛应用于三维 (3D) 深度测量。然而，传统立体视觉系统很难在动态场景中实现扩展景深成像。在这里，我们提出了一种基于可变焦镜头的扩展景深视觉系统，用于目标运动场景。该系统在两个协同级别上运行：光学级别焦点扫描和计算级别动态全焦点合成。具体来说，我们引入了一种时间自适应焦点校准模型，可以精确预测非线性机电响应下变焦镜头的曲率变化，确保在 0.45∼1.2 m 深度范围内实现亚毫秒级对焦精度。此外，设计了基于自适应单应性的多平面重映射机制，以补偿快速焦点变化引起的视差漂移和失真伪影，然后采用锐度加权融合策略，合成保留高频细节的全焦点图像。与传统立体视觉系统相比，获得的图像深度测量性能提高约6.2%，相对深度误差率优化至5.82%，RMSE降低至0.0505。所提出的系统具有紧凑的外形和动态扩展自由度成像的优点。潜在的应用包括生物医学成像、工业视觉检测、带导航的机器人视觉以及 AR/VR。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.584131",
            "title": "Mosaic-based waveguide lenses designed by the adjoint method based on the finite-element scheme",
            "link": "https://doi.org/10.1364/oe.584131",
            "published": "2026-01-15",
            "author": "Takeshi Fujisawa, Yasuhide Tsuji, Takuya Mitarai, Yusuke Sawada, Takuya Okimoto, Takuo Hiratani, Kento Komatsu, Hideki Yagi, Naoki Fujiwara",
            "summary": "<jats:p>Waveguide lenses based on mosaic structure are proposed and experimentally demonstrated. The devices are designed by an adjoint method based on the finite-element method (AM-FEM). In AM-FEM, it is easy to calculate the gradient of the objective function with respect to the refractive index distribution, and it is especially useful for multi-port and multi-mode problems. First, to demonstrate the effectiveness of the AM-FEM, simple 1 × 2 power splitters are designed, and the importance of the initial structure is demonstrated together with experimental results. And then, the design of single-mode waveguide lenses is demonstrated. After passing through the mosaic lens, the wavefront of the light is aligned, and the light can traverse a slab region, which has no confinement mechanism in the transverse direction. Also, multimode waveguide lenses are presented for the first time, showing low-loss and almost wavelength-independent characteristics. The designed devices are fabricated, and the measured results are in good agreement with the theory. These devices can be useful for various wavefront controlling devices.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "基于有限元格式的伴随法设计的马赛克波导透镜",
            "abstract_cn": "<jats:p>提出并通过实验证明了基于镶嵌结构的波导透镜。该装置采用基于有限元法（AM-FEM）的伴随法进行设计。在AM-FEM中，很容易计算目标函数相对于折射率分布的梯度，对于多端口和多模问题特别有用。首先，为了证明AM-FEM的有效性，设计了简单的1 × 2功率分配器，并结合实验结果证明了初始结构的重要性。然后，演示了单模波导透镜的设计。通过马赛克透镜后，光的波前对齐，并且光可以穿过平板区域，该平板区域在横向上没有限制机制。此外，首次推出了多模波导透镜，具有低损耗和几乎与波长无关的特性。所设计的器件已制作完成，测量结果与理论吻合良好。这些设备可用于各种波前控制设备。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.582385",
            "title": "Pd-coated Au core–shell nanorod metamaterial for optical hydrogen sensing",
            "link": "https://doi.org/10.1364/oe.582385",
            "published": "2026-01-16",
            "author": "Yajie Wang, Haibin Ni, Ying Shi, Tianqi Chen, Jiasheng Han, Mingzeng Sheng, Sheng Ye, Zichen Chen, Yixian Ge, Bo Ni, Jianhua Chang",
            "summary": "<jats:p>\n                    Hydrogen is widely regarded as an ideal clean-energy carrier, and its safe, efficient utilization is critical to the transition of modern energy systems. However, hydrogen’s high diffusivity and flammability make leak monitoring an urgent safety imperative. Here, we propose and fabricate an optical hydrogen sensor consisting of gold core-palladium shell nanorod arrays embedded in porous anodic aluminum oxide (Au@Pd NRAs/AAO). The sensor harnesses near-field coupling between the nanorods’ transverse localized surface plasmon resonance (LSPR) and a vertical Fabry–Pérot (F–P) cavity formed by the array, yielding a hybrid LSPR–F–P resonance that amplifies the response to refractive-index perturbations induced by palladium hydride formation in the shell. By combining simulations and experiments, we systematically investigate how geometric parameters govern performance and elucidate the enhancement mechanism. Experimentally, within 0–2 vol% H\n                    <jats:sub>2</jats:sub>\n                    , the sensor exhibits a sensitivity of 11.33 nm/% with excellent linearity. At 2 vol% H\n                    <jats:sub>2</jats:sub>\n                    , the response and recovery times are &lt;20 s and &lt;50 s, respectively, and the device shows outstanding repeatability and stability with no appreciable hysteresis or baseline drift. Numerical simulations further indicate that integrating silver nanodiscs (AgNDs) on the array surface opens a vertical plasmonic-coupling channel, improving the sensor response by ≈ 20.6% under the same hydrogenation conditions. Leveraging the mechanically robust, process-compatible anodic aluminum oxide (AAO) template, the device is compact and inherently immune to electromagnetic interference, making it promising for industrial safety monitoring and new-energy applications.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "用于光学氢传感的钯涂层金核壳纳米棒超材料",
            "abstract_cn": "<贾茨：p>\n                    氢被广泛认为是理想的清洁能源载体，其安全、高效利用对于现代能源系统的转型至关重要。然而，氢气的高扩散性和易燃性使得泄漏监测成为迫切的安全需要。在这里，我们提出并制造了一种光学氢传感器，由嵌入多孔阳极氧化铝（Au@Pd NRAs/AAO）中的金核-钯壳纳米棒阵列组成。该传感器利用纳米棒的横向局域表面等离子体共振 (LSPR) 和阵列形成的垂直法布里-珀罗 (F-P) 腔之间的近场耦合，产生混合 LSPR-F-P 共振，放大对壳中氢化钯形成引起的折射率扰动的响应。通过结合模拟和实验，我们系统地研究了几何参数如何控制性能并阐明增强机制。实验上，H 含量在 0–2 vol% 范围内\n                    <贾茨：子>2</贾茨：子>\n                    ，传感器的灵敏度为 11.33 nm/%，具有出色的线性度。 2 vol% H 时\n                    <贾茨：子>2</贾茨：子>\n                    ，响应时间和恢复时间分别小于20秒和小于50秒，并且该器件表现出出色的重复性和稳定性，没有明显的滞后或基线漂移。数值模拟进一步表明，在阵列表面集成银纳米盘（AgND）可打开垂直等离子体耦合通道，在相同的氢化条件下将传感器响应提高约 20.6%。该设备采用机械坚固、工艺兼容的阳极氧化铝 (AAO) 模板，结构紧凑，本质上不受电磁干扰，使其在工业安全监控和新能源应用中具有广阔的前景。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.585302",
            "title": "Diamond nitrogen-vacancy center quantum sensor with light input and electricity output for ultra-high voltage",
            "link": "https://doi.org/10.1364/oe.585302",
            "published": "2026-01-20",
            "author": "Chaoqiang Dong, Chenggang Guan, Yucheng Yao, Junchang Huang, Linfeng Zhan, Qingtao Guo, Xuelong Fan, Yifeng Chen, Qiang Wan, Chen Xu, Weiqi Wang, Yifan Xiao, Xuan Chen, Junzhu Ye, Heng Luo, Xiang Chen, Jiaoli Gong",
            "summary": "<jats:p>\n                    Diamond nitrogen-vacancy (NV) center quantum magnetic sensors show great potential for high-precision magnetic field measurement, but their complex, bulky discrete systems limit high-voltage electrical applications. This paper designs a compact “optical input-electrical output” sensing probe (3.12cm\n                    <jats:sup>3</jats:sup>\n                    ) integrating optical excitation, fluorescence collection, and photoelectric conversion. With optimal magnetic sensitivity of 4.92nT/Hz\n                    <jats:sup>1</jats:sup>\n                    /\n                    <jats:sup>2</jats:sup>\n                    , average 6.5nT/Hz\n                    <jats:sup>1</jats:sup>\n                    /\n                    <jats:sup>2</jats:sup>\n                    , and low standard deviation (0.8nT/Hz\n                    <jats:sup>1</jats:sup>\n                    /\n                    <jats:sup>2</jats:sup>\n                    ), it resolves insulation, anti-interference, and power consumption bottlenecks, enabling high-voltage equipment magnetic field monitoring.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "超高压光输入电输出金刚石氮空位中心量子传感器",
            "abstract_cn": "<贾茨：p>\n                    金刚石氮空位（NV）中心量子磁传感器在高精度磁场测量方面显示出巨大潜力，但其复杂、庞大的分立系统限制了高压电气应用。本文设计了一种紧凑型“光输入-电输出”传感探头（3.12cm\n                    <贾茨：sup>3</贾茨：sup>\n                    ）集光学激发、荧光收集、光电转换于一体。最佳磁灵敏度为 4.92nT/Hz\n                    <贾茨：sup>1</贾茨：sup>\n                    /\n                    <贾茨：sup>2</贾茨：sup>\n                    ，平均 6.5nT/Hz\n                    <贾茨：sup>1</贾茨：sup>\n                    /\n                    <贾茨：sup>2</贾茨：sup>\n                    ，和低标准偏差（0.8nT/Hz\n                    <贾茨：sup>1</贾茨：sup>\n                    /\n                    <贾茨：sup>2</贾茨：sup>\n                    ），解决绝缘、抗干扰、功耗瓶颈，实现高压设备磁场监测。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.582413",
            "title": "Investigating the performance of adaptive optics on different bases of spatial modes in turbulent channels",
            "link": "https://doi.org/10.1364/oe.582413",
            "published": "2026-01-26",
            "author": "Rojan Abolhassani, Lukas Scarfe, Francesco Di Colandrea, Alessio D’Errico, Khabat Heshami, Ebrahim Karimi",
            "summary": "<jats:p>\n                    Quantum key distribution (QKD) allows secure key exchange based on the principles of quantum mechanics, with higher-dimensional photonic states offering enhanced channel capacity and resilience to noise. Free-space QKD is crucial for global networks where fibres are impractical, but atmospheric turbulence introduces severe states’ distortions, particularly for spatial modes. Adaptive optics (AO) provides a pathway to correct these errors, though its effectiveness depends on the encoding basis. Here, we experimentally evaluate a high-speed AO system for orbital angular momentum (OAM) modes, mutually unbiased bases (MUB), and symmetric, informationally complete, positive operator-valued measures (SIC-POVM) up to dimension\n                    <jats:italic>d</jats:italic>\n                     = 8 in a turbulent free-space channel. While OAM states are strongly distorted, their cylindrical symmetry makes them optimally corrected by AO, yielding error rates below QKD security thresholds. MUB and SIC-POVM exhibit greater intrinsic robustness to turbulence but are less precisely corrected; however their performance remains within protocol tolerances. These results establish AO as a key enabler of secure, high-dimensional QKD and highlight the role of basis choice in optimizing resilience and correction.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "研究湍流通道中不同空间模式下自适应光学的性能",
            "abstract_cn": "<贾茨：p>\n                    量子密钥分发 (QKD) 允许基于量子力学原理的安全密钥交换，高维光子态可提供增强的通道容量和抗噪声能力。自由空间 QKD 对于光纤不切实际的全球网络至关重要，但大气湍流会引入严重的状态扭曲，特别是对于空间模式。自适应光学 (AO) 提供了纠正这些错误的途径，尽管其有效性取决于编码基础。在这里，我们通过实验评估了轨道角动量 (OAM) 模式、互不偏基 (MUB) 以及对称、信息完整、正算子值测量 (SIC-POVM) 的高速 AO 系统，直至维度\n                    <jats:斜体>d</jats:斜体>\n                     = 8 在湍流自由空间通道中。虽然 OAM 状态严重扭曲，但它们的圆柱对称性使其能够通过 AO 进行最佳校正，从而产生低于 QKD 安全阈值的错误率。 MUB 和 SIC-POVM 对湍流表现出更强的内在鲁棒性，但校正精度较差；然而，它们的性能仍然在协议容差范围内。这些结果使 AO 成为安全、高维 QKD 的关键推动者，并强调了基础选择在优化弹性和校正方面的作用。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.580482",
            "title": "Enhanced optical superfocusing effect at an all-dielectric nanocone tip",
            "link": "https://doi.org/10.1364/oe.580482",
            "published": "2026-01-16",
            "author": "Weinan Feng, Makoto Tsubokawa",
            "summary": "<jats:p>\n                    We present a novel method for generating an extremely confined nanoscale light field using an all-dielectric conical nanotip coupled to a microfiber. By launching a radially polarized TM\n                    <jats:sub>01</jats:sub>\n                    mode into the tip, we achieve constructive interference of longitudinal electric field components at the apex, resulting in a highly localized optical hotspot with sub-10 nm dimensions and a mode volume as small as 10\n                    <jats:sup>−7</jats:sup>\n                    λ\n                    <jats:sup>3</jats:sup>\n                    . This approach overcomes the limitations of conventional dielectric tips and rivals plasmonic superfocusing without incurring ohmic losses. Numerical simulations reveal that the focal spot features a high intensity enhancement ratio (&gt; 3500), strong peak-to-background contrast (&gt; 30 dB), and circular symmetry. Furthermore, we demonstrate the ability to shape the light field into arbitrary nanoscale patterns by modifying the tip geometry. These findings open new avenues for low-loss, high-precision light confinement in applications such as optical nano tweezers, nanoscopy, nano lasers, and nanoparticle spectroscopy.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "全电介质纳米锥尖端增强光学超聚焦效果",
            "abstract_cn": "<贾茨：p>\n                    我们提出了一种利用耦合到微纤维的全电介质锥形纳米尖端产生极其有限的纳米级光场的新方法。通过发射径向极化 TM\n                    <jats:sub>01</jats:sub>\n                    模式进入尖端，我们在顶点实现了纵向电场分量的相长干涉，从而产生了尺寸低于 10 nm 且模式体积小至 10 的高度局部化的光学热点。\n                    <jats:sup>−7</jats:sup>\n                    λ\n                    <贾茨：sup>3</贾茨：sup>\n                    。这种方法克服了传统介电尖端的局限性，可与等离子体超聚焦相媲美，而不会产生欧姆损耗。数值模拟表明，焦点具有高强度增强比（> 3500）、强峰背景对比度（> 30 dB）和圆形对称性。此外，我们展示了通过修改尖端几何形状将光场塑造成任意纳米级图案的能力。这些发现为光学纳米镊子、纳米显微镜、纳米激光器和纳米颗粒光谱等应用中的低损耗、高精度光限制开辟了新途径。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.581278",
            "title": "Two-level optimizer for large-scale metasurfaces with strong near-field coupling",
            "link": "https://doi.org/10.1364/oe.581278",
            "published": "2026-01-13",
            "author": "Yiwen Fan, Jannick P. Rolland, A. Nick Vamivakas, Daniel K. Nikolov",
            "summary": "<jats:p>We introduce a two-level window-based optimization architecture that enables the inverse-design of metasurfaces containing hundreds of adjustable parameters while accurately modeling near-field coupling effects. Our method contains two nested iterative optimizers and effectively optimizes a 300 unit-cell metalens (aperture diameter of 108 µm) and yields a 73.2% increase in focusing intensity, addressing the established fabrication-performance tradeoff for low aspect-ratio (&lt;3) metasurfaces.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "具有强近场耦合的大规模超表面的两级优化器",
            "abstract_cn": "<jats:p>我们引入了一种基于两级窗口的优化架构，该架构能够对包含数百个可调节参数的超表面进行逆向设计，同时精确建模近场耦合效应。我们的方法包含两个嵌套迭代优化器，有效优化了 300 个单元元超透镜（孔径为 108 μm），聚焦强度提高了 73.2%，解决了低纵横比 (<3) 超表面的既定制造性能权衡问题。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.586871",
            "title": "Submillisecond-response liquid-crystal-on-silicon for augmented reality displays",
            "link": "https://doi.org/10.1364/oe.586871",
            "published": "2026-01-16",
            "author": "Po-Sheng Chiu, Yuge Huang, Hosna Tajvidi Safa, Yongziyan Ma, Zhiyong Yang, Fenglin Peng, Ying Geng, Dan Hu, Shin-Tson Wu",
            "summary": "<jats:p>\n                    We report a new nematic liquid crystal (LC) mixture with an extremely low rotational viscosity (\n                    <jats:italic>\n                      γ\n                      <jats:sub>1</jats:sub>\n                    </jats:italic>\n                     = 38 mPa·s @ 20.7 °C), relatively high birefringence (\n                    <jats:italic>Δn</jats:italic>\n                     = 0.159 @ 550 nm), and moderate dielectric anisotropy (\n                    <jats:italic>Δε</jats:italic>\n                     = 2.86 @ 25 °C). An average submillisecond response time is achieved at room temperature without overdrive and undershoot voltages when it is employed in a reflective liquid-crystal cell. Such a fast response time enables a 1 kHz field-sequential color (FSC) field rate, which not only triples the optical efficiency and resolution density but also mitigates image blur and color breakup. Furthermore, the required cell gap of 1.34 µm remains manageable for acheiving a good mass-production yield. This LC holds great potential for the emerging artificial intelligence (AI)-powered augmented reality (AR) glasses.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "用于增强现实显示器的亚毫秒响应硅基液晶",
            "abstract_cn": "<贾茨：p>\n                    我们报告了一种具有极低旋转粘度的新型向列液晶 (LC) 混合物（\n                    <贾茨：斜体>\n                      γ\n                      <jats:sub>1</jats:sub>\n                    </贾茨：斜体>\n                     = 38 mPa·s @ 20.7 °C)，相对较高的双折射（\n                    <jats:斜体>Δn</jats:斜体>\n                     = 0.159 @ 550 nm) 和中等介电各向异性 (\n                    <jats:斜体>Δε</jats:斜体>\n                     = 2.86 @ 25 °C)。当其用于反射液晶单元时，在室温下可实现平均亚毫秒响应时间，而不会出现过驱动和下冲电压。如此快速的响应时间可实现 1 kHz 场序彩色 (FSC) 场速率，这不仅使光学效率和分辨率密度提高了三倍，而且还减轻了图像模糊和色彩破碎的情况。此外，所需的 1.34 μm 单元间隙仍然可以控制，以实现良好的批量生产良率。这种液晶对于新兴的人工智能 (AI) 驱动的增强现实 (AR) 眼镜具有巨大的潜力。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.29026/oea.2026.250149",
            "title": "High-fidelity full-color self-interference incoherent digital holography via quarter-wave geometric phase optics",
            "link": "https://doi.org/10.29026/oea.2026.250149",
            "published": "2026",
            "author": "Jae-Won Lee, Jin-Hyeok Seo, Jung-Yeop Shin, Jing-Wen Bu, Kihong Choi, Keehoon Hong, Hak-Rin Kim",
            "summary": "<p>We present a compact self-interference incoherent digital holography (SIDH) system that incorporates a quarter-waveplate (QWP)-based geometric phase (GP) lens to achieve high-fidelity, full-color holographic imaging under broadband incoherent illumination. Traditional SIDH systems that utilize half-waveplate (HWP)-based GP lenses are hindered by unavoidable triple-wavefront polarization interference, stemming from chromatic dispersion in phase retardation. This interference introduces color-dependent artifacts in the reconstructed images. In contrast, our QWP-based design inherently suppresses such interference by using the non-diffracted beam as the reference, enabling stable dual-wavefront modulation. This approach produces phase-encoded polarization interference patterns that remain spectrally consistent across the red, green, and blue (RGB) channels. Experimental results demonstrate substantial noise suppression and significantly improved full-color image fidelity, supported by channel-specific noise analysis and structural similarity metrics. The system also preserves a simplified optical configuration without active polarization control, allowing for compact integration and cost-effective fabrication. These advantages position the proposed QWP-GP SIDH architecture as a promising solution for portable, real-time digital holographic 3D imaging, with scalable potential in applications such as augmented reality, optical diagnostics, and spectral holography.</p>",
            "journal": "Opto-Electronic Advances",
            "title_cn": "通过四分之一波几何相位光学实现高保真全彩自干涉非相干数字全息术",
            "abstract_cn": "<p>我们提出了一种紧凑型自干涉非相干数字全息 (SIDH) 系统，该系统结合了基于四分之一波片 (QWP) 的几何相位 (GP) 透镜，可在宽带非相干照明下实现高保真、全彩全息成像。使用基于半波片 (HWP) 的 GP 镜头的传统 SIDH 系统会受到相位延迟中色散造成的不可避免的三波前偏振干扰的阻碍。这种干扰在重建图像中引入了与颜色相关的伪影。相比之下，我们基于 QWP 的设计通过使用非衍射光束作为参考来本质上抑制此类干扰，从而实现稳定的双波前调制。这种方法产生的相位编码偏振干涉图案在红、绿和蓝 (RGB) 通道上保持光谱一致。实验结果表明，在通道特定噪声分析和结构相似性指标的支持下，噪声得到了显着抑制，并显着提高了全彩图像保真度。该系统还保留了简化的光学配置，无需主动偏振控制，从而实现紧凑的集成和经济高效的制造。这些优势使所提出的 QWP-GP SIDH 架构成为便携式实时数字全息 3D 成像的一种有前途的解决方案，在增强现实、光学诊断和光谱全息等应用中具有可扩展的潜力。</p>"
        },
        {
            "id": "https://doi.org/10.29026/oea.2026.250193",
            "title": "Electric-field-induced second-harmonic generation",
            "link": "https://doi.org/10.29026/oea.2026.250193",
            "published": "2026",
            "author": "Hangkai Fan, Alexey Proskurin, Mingzhao Song, Andrey Bogdanov",
            "summary": "<p>Second-harmonic generation (SHG) is a fundamental nonlinear optical process widely used in photonics; however, it is strictly forbidden in the bulk of centrosymmetric materials due to their inversion symmetry. Nevertheless, applying an external electric field breaks this inversion symmetry. It induces an effective second-order nonlinear response known as the electric-field-induced second-harmonic generation (EFISH) effect. This mechanism enables SHG in centrosymmetric media and provides a effective mechanism for electrically tunable nonlinear nanophotonics. Here, we present a comprehensive overview of the EFISH effect, covering the fundamentals, various material platforms (including bulk semiconductor crystals, ferroelectrics, van der Waals materials, and polymers), as well as diverse strategies for electric field engineering. We distinguish EFISH from related effects including current-induced SHG and the quantum-confined Stark effect, and highlight emerging applications of EFISH in tunable photonic devices, carrier dynamics probing, and nonlinear optical modulation across optical, electronic, and THz regimes. Finally, we outline key challenges and prospects for the future development of electrically controlled nonlinear optical systems.</p>",
            "journal": "Opto-Electronic Advances",
            "title_cn": "电场感应二次谐波产生",
            "abstract_cn": "<p>二次谐波产生（SHG）是一种广泛应用于光子学的基本非线性光学过程；然而，由于其反演对称性，它在大部分中心对称材料中是被严格禁止的。然而，施加外部电场打破了这种反演对称性。它会产生有效的二阶非线性响应，称为电场感应二次谐波产生 (EFISH) 效应。这种机制使得二次谐波在中心对称介质中得以实现，并为电可调非线性纳米光子学提供了有效的机制。在这里，我们全面概述了 EFISH 效应，涵盖基本原理、各种材料平台（包括块状半导体晶体、铁电体、范德华材料和聚合物）以及电场工程的各种策略。我们将 EFISH 与相关效应（包括电流感应 SHG 和量子限制斯塔克效应）区分开来，并重点介绍 EFISH 在可调谐光子器件、载流子动力学探测以及跨光学、电子和太赫兹范围的非线性光学调制中的新兴应用。最后，我们概述了电控非线性光学系统未来发展的主要挑战和前景。</p>"
        },
        {
            "id": "https://doi.org/10.29026/oea.2026.250265",
            "title": "Shedding light on glucose",
            "link": "https://doi.org/10.29026/oea.2026.250265",
            "published": "2026",
            "author": "Mohsen Rahmani",
            "summary": "<p>Non-invasive glucose monitoring remains a key challenge due to the molecule's inherently weak Raman signal. While surface-enhanced Raman spectroscopy (SERS) offers potential, it often suffers from incomplete spectral coverage. A recent work using tip-enhanced Raman scattering (TERS) successfully captures glucose's complete vibrational fingerprint. This label-free approach paves the way for highly sensitive metabolite detection and future in vivo biosensing applications.</p>",
            "journal": "Opto-Electronic Advances",
            "title_cn": "揭示葡萄糖",
            "abstract_cn": "<p>由于分子固有的微弱拉曼信号，无创血糖监测仍然是一个关键挑战。虽然表面增强拉曼光谱 (SERS) 具有潜力，但它经常受到光谱覆盖不完整的影响。最近的一项工作使用尖端增强拉曼散射（TERS）成功捕获了葡萄糖的完整振动指纹。这种无标记方法为高灵敏度代谢物检测和未来体内生物传感应用铺平了道路。</p>"
        },
        {
            "id": "https://doi.org/10.29026/oea.2026.250271",
            "title": "Fiber-optic photoacoustic enables targeted neuromodulation and stress reduction in mice",
            "link": "https://doi.org/10.29026/oea.2026.250271",
            "published": "2026",
            "author": "Yuan Bo Peng",
            "summary": "<p>Ultrasound neuromodulation offers a non-invasive approach to modulate neural activity in the central nervous system. Precise, minimally invasive devices capable of targeted stimulation remain limited. A 200 µm diameter fiber-optic photoacoustic emitter (FPE) was developed, coated with a MXene (Ti<sub>3</sub>C<sub>2</sub>T<italic><sub>x</sub></italic>) and polydimethylsiloxane composite to generate controllable, broadband ultrasonic waves with high spatial precision. Using this FPE to stimulate the medial prefrontal cortex in mice, it was observed marked alleviation of acute social defeat stress-induced emotional stress, evidenced by reduced anxiety-like behavior and increased social interaction. This approach enables near-field, broadband, and tunable ultrasound neuromodulation with potential applications in treating neuropsychiatric disorders involving emotional regulation.</p>",
            "journal": "Opto-Electronic Advances",
            "title_cn": "光纤光声能够对小鼠进行有针对性的神经调节和减轻压力",
            "abstract_cn": "<p>超声神经调节提供了一种非侵入性方法来调节中枢神经系统的神经活动。能够进行定向刺激的精确微创设备仍然有限。开发了直径为 200 µm 的光纤光声发射器（FPE），涂有 MXene（Ti<sub>3</sub>C<sub>2</sub>T<斜体><sub>x</sub></italic>）和聚二甲基硅氧烷复合材料，可产生具有高空间精度的可控宽带超声波。使用这种 FPE 刺激小鼠的内侧前额叶皮层，观察到急性社交失败压力引起的情绪压力显着减轻，焦虑样行为减少和社交互动增加就证明了这一点。这种方法实现了近场、宽带和可调谐超声神经调节，在治疗涉及情绪调节的神经精神疾病方面具有潜在的应用。</p>"
        },
        {
            "id": "https://doi.org/10.1016/j.optcom.2025.132805",
            "title": "Corrigendum to “Coherent fading suppression method in the COTDR system based on multi-band filtering” [Opt. Commun. 583 (2025) 131696]",
            "link": "https://doi.org/10.1016/j.optcom.2025.132805",
            "published": "2026-06-01",
            "author": "Xiang Sui, Ying Shang, Sheng Huang, Wenan Zhao, Xiaohan Qiao, Guangqiang Liu, Chunmei Yao, Shouling Liu, Na Wan, Xianggui Kong, Hong Zhao, Fengming Mou, Zhengying Li, Weitao Wang, Chen Wang, Gangding Peng",
            "summary": "Abstract not available.",
            "journal": "Optics Communications",
            "title_cn": "“基于多频带滤波的COTDR系统相干衰落抑制方法”的勘误[选项2]交流。 [583(2025)131696]",
            "abstract_cn": "（摘要暂缺，等待官方补全）"
        },
        {
            "id": "https://doi.org/10.1364/oe.582749",
            "title": "Research on pump light transmission efficiency and energy distribution in (8 + 1)×1 high-power pump and signal combiner",
            "link": "https://doi.org/10.1364/oe.582749",
            "published": "2026-01-07",
            "author": "Mengyuan Ji, Kai Liu, Wenqi Chen, Junqing Meng",
            "summary": "<jats:p>\n                    We report a fabrication method for the (8 + 1)×1 pump and signal combiner (PSC) and investigate its pump light transmission characteristics. It employs three specifications of fibers: the pump fiber is 220/242 µm and NA = 0.22; the signal fiber is 25/250 µm and NA = 0.065/0.46; the double-clad fiber (DCF) is 20/400 µm, and NA = 0.065/0.46. Based on the arrangement characteristics of the pump fibers and signal fiber, as well as the principle of brightness conservation, the optimal preparation parameters for the (8 + 1)×1 PSC are determined. In order to optimize the performance of the PSCs with different numbers of pump ports, the transmission efficiencies of pump light and pump light divergence angles are calculated for pump port numbers of 6, 7, 8, 9, 10, and 11, respectively. The results indicate that the maximum number of pump ports it can support is 8. Experimental results show that the transmission efficiencies of pump light and signal light are 98.20% and 96.66%, respectively. The measured beam quality of the (8 + 1)×1 PSC is M\n                    <jats:sup>2</jats:sup>\n                     = 1.19, and the beam quality degradation is ΔM\n                    <jats:sup>2</jats:sup>\n                     = 0.10. The total pump power is 5.736 kW, which is limited by the pump powers of the laser diodes (LDs). Compared to the (6 + 1)×1 PSC fabricated using the same method, the pump power increased by 1.604 kW. When the pump powers of both are approximately 4 kW, the temperature of the DCF coating layer in (8 + 1)×1 PSC is 17.8 ℃ higher than that in the (6 + 1)×1 PSC. The divergence angle of pump light combined by the (8 + 1)×1 PSC is 1.007 rad, and the experimental results are in good agreement with the simulation results.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "(8 + 1)×1大功率泵浦信号合路器泵浦光传输效率及能量分布研究",
            "abstract_cn": "<贾茨：p>\n                    我们报告了（8 + 1）×1泵浦和信号组合器（PSC）的制造方法，并研究了其泵浦光传输特性。它采用三种规格的光纤：泵浦光纤为220/242 μm，NA = 0.22；信号光纤为25/250 μm，NA = 0.065/0.46；双包层光纤（DCF）为20/400 μm，NA = 0.065/0.46。根据泵浦光纤和信号光纤的排列特点以及亮度守恒定律，确定了(8 + 1)×1 PSC的最佳制备参数。为了优化具有不同泵浦端口数的PSC的性能，分别计算了泵浦端口数为6、7、8、9、10和11时的泵浦光传输效率和泵浦光发散角。结果表明，该器件最多可支持8个泵浦口。实验结果表明，泵浦光和信号光的传输效率分别为98.20%和96.66%。 (8 + 1)×1 PSC 的测量光束质量为 M\n                    <贾茨：sup>2</贾茨：sup>\n                     = 1.19，光束质量衰减为ΔM\n                    <贾茨：sup>2</贾茨：sup>\n                     = 0.10。总泵浦功率为 5.736 kW，受到激光二极管 (LD) 泵浦功率的限制。与采用相同方法制备的(6 + 1)×1 PSC相比，泵浦功率增加了1.604 kW。当两者的泵浦功率约为4 kW时，(8 + 1)×1 PSC中的DCF涂层温度比(6 + 1)×1 PSC中的DCF涂层温度高17.8 ℃。 (8 + 1)×1 PSC合成的泵浦光发散角为1.007 rad，实验结果与仿真结果吻合较好。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.584387",
            "title": "Deep-learning-driven dual-channel dynamic digital virtual phase-shifting Fresnel incoherent correlation holography (D\n                    <sup>4</sup>\n                    FINCH)",
            "link": "https://doi.org/10.1364/oe.584387",
            "published": "2026-01-14",
            "author": "Yuheng Wang, Rouqian Li, Tao Huang, Jianhui Wan, Huiyang Wang, Weina Zhang, Jianglei Di, Xiaoxu Lu, Liyun Zhong",
            "summary": "<jats:p>\n                    Fresnel incoherent correlation holography (FINCH) enables scan-free 3D imaging with an incoherent light source. However, traditional reconstruction techniques rely on multi-step phase-shifting processes to suppress background noise and eliminate twin-image interference, which inherently limits temporal resolution. Here we present a deep-learning-driven, dual-channel dynamic FINCH framework with digital virtual phase shifting (D\n                    <jats:sup>4</jats:sup>\n                    FINCH). Using a dual-channel module, two fixed phase-shifted holograms are captured simultaneously in a single exposure, and a tailored network (H-Net) synthesizes the missing phase steps computationally, forming a “virtual four-step” set equivalent to conventional acquisition. Reconstruction experiments show that the virtually phase-shifted holograms closely match their multi-exposure counterparts. Quantitative evaluations (PSNR and SSIM) indicate reconstruction quality comparable to the four-step method, with effective suppression of background noise and twin-image interference. Multi-depth focusing experiments further verify faithful 3D reconstruction across axial planes. Since D\n                    <jats:sup>4</jats:sup>\n                    FINCH requires only a single exposure, it markedly improves temporal resolution while preserving high-fidelity reconstructions, making it well suited for real-time holography of dynamic scenes and providing a powerful and efficient approach toward real-time, high-quality 3D imaging in FINCH systems.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "深度学习驱动的双通道动态数字虚拟相移菲涅耳非相干相关全息术（D <sup>4</sup> FINCH）",
            "abstract_cn": "<贾茨：p>\n                    菲涅尔非相干相关全息术 (FINCH) 可利用非相干光源实现免扫描 3D 成像。然而，传统的重建技术依赖于多步相移过程来抑制背景噪声并消除双图像干扰，这本质上限制了时间分辨率。在这里，我们提出了一种深度学习驱动的双通道动态 FINCH 框架，具有数字虚拟相移 (D\n                    <贾茨：sup>4</贾茨：sup>\n                    芬奇）。使用双通道模块，在一次曝光中同时捕获两个固定相移全息图，并且定制网络（H-Net）通过计算合成缺失的相位步骤，形成相当于传统采集的“虚拟四步”集。重建实验表明，虚拟相移全息图与多次曝光的全息图非常匹配。定量评估（PSNR 和 SSIM）表明重建质量与四步法相当，并且有效抑制了背景噪声和双图像干扰。多深度聚焦实验进一步验证了跨轴向平面的忠实 3D 重建。自从D\n                    <贾茨：sup>4</贾茨：sup>\n                    FINCH 只需要一次曝光，它显着提高了时间分辨率，同时保留了高保真重建，使其非常适合动态场景的实时全息，并为 FINCH 系统中的实时、高质量 3D 成像提供了强大而高效的方法。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.585773",
            "title": "Infrared vortex detection with nonlinear Young’s double-slit interference",
            "link": "https://doi.org/10.1364/oe.585773",
            "published": "2026-01-05",
            "author": "Haizheng Li, Yidan Sun, Xiaodong Qiu, Lixiang Chen",
            "summary": "<jats:p>Different from the plane wave, the vortex beam passing through a Young’s double slit will produce an interference pattern with lateral shear, where the degree of lateral shear is determined by the beam’s topological charge, namely, providing a quantitative method for measuring the topological charge of vortex beams. However, limited by the detection efficiency, noise, and cost of infrared cameras, using Young’s double-slit interference to measure infrared optical vortex modes remains relatively unexplored. Here, we construct a nonlinear Young’s double slit, such that when an infrared optical vortex beam passes through it, interference fringes with lateral shear can be observed in the visible region. In our experiment, we successfully measured nine vortex modes with different topological charges using a visible camera, overcoming the performance limitations of infrared detectors. This scheme holds great promise for infrared vortex-encoded optical communications.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "非线性杨氏双缝干涉红外涡旋探测",
            "abstract_cn": "<jats:p>与平面波不同，涡旋光束通过杨氏双缝时会产生带有横向剪切的干涉图样，其中横向剪切的程度由光束的​​拓扑电荷决定，即为测量涡旋光束的拓扑荷提供了一种定量方法。然而，受限于红外相机的探测效率、噪声和成本，利用杨氏双缝干涉测量红外光学涡旋模式仍然相对未被探索。在这里，我们构造了一个非线性杨氏双缝，使得当红外光学涡旋光束通过它时，可以在可见光区域观察到具有横向剪切的干涉条纹。在我们的实验中，我们使用可见光相机成功测量了具有不同拓扑电荷的九种涡旋模式，克服了红外探测器的性能限制。该方案对于红外涡旋编码光通信具有广阔的前景。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.579576",
            "title": "Removal of specular highlights in 3D reconstruction based on fringe projection complementarity",
            "link": "https://doi.org/10.1364/oe.579576",
            "published": "2026-01-13",
            "author": "Xiang Sun, Yunpeng Zhang, Lingbao Kong, Zhenjun Luo, Jianjun Zeng, Shizhao Wang, Shuyan Ma",
            "summary": "<jats:p>In the field of 3D reconstruction, accurately and effectively removing specular highlights remains a challenging problem. Existing highlight removal methods mainly focus on processing each image independently, neglecting the interrelationship among images. This paper explores the correlations between different images and, within the traditional three-frequency four-step phase-shifting method of fringe projection profilometry (FPP), leverages the complementarity among images to propose a novel highlight removal approach. Experimental results demonstrate that the proposed method significantly reduces unreliable pixels caused by manual fitting compared to previous techniques, thereby enhancing the accuracy of 3D measurements.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "基于条纹投影互补性的3D重建中镜面高光去除",
            "abstract_cn": "<jats:p>在3D重建领域，准确有效地去除镜面高光仍然是一个具有挑战性的问题。现有的高光去除方法主要集中于对每幅图像进行独立处理，忽略了图像之间的相互关系。本文探讨了不同图像之间的相关性，并在传统的条纹投影轮廓测量（FPP）三频四步相移方法中，利用图像之间的互补性提出了一种新颖的高光去除方法。实验结果表明，与之前的技术相比，该方法显着减少了手动拟合带来的不可靠像素，从而提高了3D测量的准确性。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.583828",
            "title": "Characterization of the phase noise in a cavity-enhanced frequency doubler",
            "link": "https://doi.org/10.1364/oe.583828",
            "published": "2026-01-20",
            "author": "Meichen Yan, Xingyang Cui, Xiaodong Lin, Dequan Kong, Wenlan Song, Ping Xu, Qi Shen, Hanning Dai",
            "summary": "<jats:p>\n                    In optical atomic clocks, the low phase noise of the frequency conversion is essential to maintain the high frequency stability and phase coherence of clock lasers. Higher power of interrogation lasers is required for future optical clocks. In this work, we present a cavity-enhanced frequency doubler based on second harmonic generation with an intra-cavity PPLN crystal. The frequency doubler is highly efficient in obtaining the strontium atomic clock laser from the fundamental laser at 1397 nm. We measure the excess phase noise introduced by the enhancement cavity. The cavity-enhanced frequency doubler introduces excess phase noise with a power spectral density that is nearly an order of magnitude lower than that of state-of-the-art interrogation lasers for offset frequencies between 0.001 Hz and 1 Hz. The modified Allan deviation of fractional frequency instability is 5.3×10\n                    <jats:sup>−18</jats:sup>\n                    at a 1-second averaging time under a homemade housing. It indicates that the doubler can be used to improve the short-term stability of strontium optical clocks with the best up-to-date ultra-stable lasers. Meanwhile, its high efficiency can match increasing interrogation laser power for further applications.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "腔体增强倍频器中相位噪声的表征",
            "abstract_cn": "<贾茨：p>\n                    在光学原子钟中，频率转换的低相位噪声对于保持时钟激光器的高频率稳定性和相位相干性至关重要。未来的光学时钟需要更高功率的询问激光器。在这项工作中，我们提出了一种基于腔内 PPLN 晶体二次谐波生成的腔增强倍频器。倍频器能够高效地从1397 nm的基频激光获得锶原子钟激光。我们测量增强腔引入的过量相位噪声。腔增强倍频器引入了过多的相位噪声，其功率谱密度比偏移频率在 0.001 Hz 至 1 Hz 之间的最先进询问激光器低了近一个数量级。分数频率不稳定性的修正Allan偏差为5.3×10\n                    <jats:sup>−18</jats:sup>\n                    在自制外壳下平均时间为 1 秒。这表明倍频器可用于提高具有最新超稳定激光器的锶光钟的短期稳定性。同时，其高效率可以与不断增加的询问激光功率相匹配，以实现进一步的应用。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.582818",
            "title": "Differential organic photodetectors with nanograting-defined spectral responsivity",
            "link": "https://doi.org/10.1364/oe.582818",
            "published": "2026-01-13",
            "author": "Jan Schardt, Martina Gerken",
            "summary": "<jats:p>\n                    Optoelectronic sensing devices based on organic semiconductor materials are a promising technology due to their integrability in several sensing platforms and applications. Many sensing applications require narrowband detection, and suppression of background noise is desired. We introduce a differential readout concept using organic photodetectors (OPDs) that share an identical material stack but incorporate different nanograting periods to couple light resonantly into guided modes at distinct wavelengths. We fabricate CuPc/C\n                    <jats:sub>60</jats:sub>\n                    OPDs with grating periods Λ\n                    <jats:sub>1</jats:sub>\n                     = 350 nm and Λ\n                    <jats:sub>2</jats:sub>\n                     = 400 nm, targeting resonances at wavelengths\n                    <jats:italic>λ</jats:italic>\n                    <jats:sub>1</jats:sub>\n                     = 550 nm and\n                    <jats:italic>λ</jats:italic>\n                    <jats:sub>2</jats:sub>\n                     = 600 nm, respectively, and we measure their optical transmission and spectral photocurrent. Under tunable laser excitation in the visible, we observe guided-mode resonances that translate into narrowband responsivity enhancements at the designed wavelengths. Differential and subtractive analyses between the two OPDs isolate the nanostructure-induced response and show responsivity enhancements up to 40% at resonance. Under white-light and selective LED spectra, we quantify photoconversion efficiency and demonstrate that narrowband sensitivity is enhanced for signals near resonance.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "具有纳米光栅定义的光谱响应度的差分有机光电探测器",
            "abstract_cn": "<贾茨：p>\n                    基于有机半导体材料的光电传感器件由于其在多种传感平台和应用中的可集成性而成为一项有前途的技术。许多传感应用需要窄带检测，并且需要抑制背景噪声。我们引入了一种使用有机光电探测器（OPD）的差分读出概念，该光电探测器共享相同的材料堆栈，但结合了不同的纳米光栅周期，以将光谐振耦合到不同波长的导模中。我们制造 CuPc/C\n                    <jats:sub>60</jats:sub>\n                    光栅周期为 Λ 的 OPD\n                    <jats:sub>1</jats:sub>\n                     = 350 nm 和 Λ\n                    <贾茨：子>2</贾茨：子>\n                     = 400 nm，针对波长处的共振\n                    <jats:斜体>λ</jats:斜体>\n                    <jats:sub>1</jats:sub>\n                     = 550 nm 且\n                    <jats:斜体>λ</jats:斜体>\n                    <贾茨：子>2</贾茨：子>\n                     分别= 600 nm，我们测量了它们的光学透射率和光谱光电流。在可见光的可调谐激光激发下，我们观察到导模谐振，该谐振转化为设计波长下的窄带响应度增强。两种 OPD 之间的微分和减法分析分离了纳米结构引起的响应，并显示共振时响应率增强高达 40%。在白光和选择性 LED 光谱下，我们量化了光电转换效率，并证明了共振附近信号的窄带灵敏度得到了增强。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.584389",
            "title": "715 W sub-kHz single-frequency all-fiber amplifier at 1064 nm based on commercial PM-LMA fiber",
            "link": "https://doi.org/10.1364/oe.584389",
            "published": "2026-01-12",
            "author": "Ye Yuan, Yuxin Sun, Litao Xu, Qilai Zhao, Changsheng Yang, Shanhui Xu",
            "summary": "<jats:p>\n                    We report a high-power single-frequency fiber amplifier operating at 1064 nm, delivering 715 W output with a sub-kHz linewidth of 400 Hz, based on commercially available polarization-maintaining large-mode-area fiber. To the best of our knowledge, this represents the highest output power achieved for sub-kHz linewidth systems using commercial fibers. The amplifier maintains near-diffraction-limited beam quality with a beam quality factor M\n                    <jats:sup>2</jats:sup>\n                    of 1.16 and a polarization extinction ratio exceeding 18.3 dB. Built on a master oscillator power amplifier architecture, the system incorporates segmented thermal management to suppress thermally induced mode instabilities and employs minimal fiber length to mitigate stimulated Brillouin scattering. The optical signal-to-noise ratio remains above 65.6 dB across the full power range. The demonstrated all-fiber amplifier combines high power, sub-kHz linewidth, and high polarization purity with long-term stability, offering a compact and scalable platform that bridges laboratory demonstrations and industrial applications such as coherent beam combining and optical metrology.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "基于商用 PM-LMA 光纤的 1064 nm 715 W sub-kHz 单频全光纤放大器",
            "abstract_cn": "<贾茨：p>\n                    我们报告了一种工作在 1064nm 的高功率单频光纤放大器，基于商用保偏大模面积光纤，可提供 715W 输出，亚 kHz 线宽为 400Hz。据我们所知，这代表了使用商用光纤的亚kHz线宽系统所实现的最高输出功率。放大器保持近衍射极限的光束质量，光束质量因数为 M\n                    <贾茨：sup>2</贾茨：sup>\n                    1.16，偏振消光比超过18.3 dB。该系统建立在主振荡器功率放大器架构之上，采用分段热管理来抑制热引起的模式不稳定性，并采用最小的光纤长度来减轻受激布里渊散射。在整个功率范围内，光信噪比保持在 65.6 dB 以上。演示的全光纤放大器将高功率、亚kHz线宽、高偏振纯度与长期稳定性结合在一起，提供了一个紧凑且可扩展的平台，可连接实验室演示和工业应用，例如相干光束组合和光学计量。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.583109",
            "title": "Highly efficient near-infrared phosphorescence from aggregated gold nanoclusters with humidity response",
            "link": "https://doi.org/10.1364/oe.583109",
            "published": "2026-01-12",
            "author": "Lulu Qiao, Lin Cai, Bingbing Li, Yanping Liu, Dan Mo, Zhongran Wei, Xia Ran, Lijun Guo",
            "summary": "<jats:p>Luminescent gold nanoclusters (Au NCs) hold promise for various applications due to their unique optical properties. However, enhancing their near-infrared (NIR) photoluminescence quantum yield (QY) and elucidating the underlying emission mechanisms are challenging. In this study, we successfully synthesized glutathione-stabilized Au NCs (GSH-Au NCs) and achieved a NIR phosphorescence QY over 71% in solid. Time-resolved spectroscopy reveals that aggregation effectively suppresses structural vibrations and facilitates intersystem crossing (ISC), while modulation of the Au(0)/Au(I) ratio enhances radiative decay, presenting an effective strategy for improving the phosphorescence of Au NCs. Moreover, the resulting ultrabright GSH-Au NCs exhibit aggregation-induced emission tunable by humidity, demonstrating high potential as optical humidity sensors.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "具有湿度响应的聚集金纳米团簇的高效近红外磷光",
            "abstract_cn": "<jats:p>发光金纳米团簇 (Au NC) 因其独特的光学特性而有望在各种应用中发挥作用。然而，提高其近红外（NIR）光致发光量子产率（QY）并阐明潜在的发射机制具有挑战性。在这项研究中，我们成功合成了谷胱甘肽稳定的Au NCs（GSH-Au NCs），并在固体中实现了超过71%的近红外磷光QY。时间分辨光谱表明，聚集有效抑制结构振动并促进系间窜越（ISC），而Au(0)/Au(I)比率的调制增强辐射衰减，为改善Au NCs的磷光性提供了有效策略。此外，由此产生的超亮 GSH-Au NC 表现出可通过湿度调节的聚集诱导发射，展现出作为光学湿度传感器的巨大潜力。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.584216",
            "title": "Rejection of wavefront aberrations in an atomic gradiometer",
            "link": "https://doi.org/10.1364/oe.584216",
            "published": "2025-12-29",
            "author": "Louis Pagot, Sebastien Merlet, Leonid Sidorenkov, Franck Pereira dos Santos",
            "summary": "One of the main residual limitations of inertial sensors based on atom interferometry stems from laser beam distortions, which cause parasitic phase shifts and non-homogeneous matter-light couplings. Here we present numerical simulations, accompanied by analytical calculations, which quantify the impact of these effects in a cold atom gradiometer. We demonstrate that the propagation of interferometric laser beam aberrations, combined with initial asymmetry and significant time-of-flight expansion of the the two atomic sources, limit the common-mode rejection of phase noise in a differential configuration. The resulting deviations in gravitational acceleration and its gradient are within reach of current experimental devices. Our study allows us to evaluate the surface quality requirements for retroreflective optics in cold-atom gradiometers of various baselines, and can be extended to other sensors based on different interferometer geometries.",
            "journal": "Optics Express",
            "title_cn": "原子梯度计中波前像差的抑制",
            "abstract_cn": "基于原子干涉测量的惯性传感器的主要残余局限性之一源于激光束畸变，它会导致寄生相移和非均匀物质-光耦合。在这里，我们提出了数值模拟，并附有分析计算，量化了冷原子梯度计中这些效应的影响。我们证明，干涉激光束像差的传播，加上两个原子源的初始不对称性和显着的飞行时间扩展，限制了差分配置中相位噪声的共模抑制。由此产生的重力加速度及其梯度的偏差在当前实验装置的范围内。我们的研究使我们能够评估各种基线的冷原子梯度仪中回射光学器件的表面质量要求，并且可以扩展到基于不同干涉仪几何形状的其他传感器。"
        },
        {
            "id": "https://doi.org/10.1364/oe.582991",
            "title": "Accurate and efficient MLPs–CA-based full-chain dynamic aero-optics modeling for infrared imaging prediction",
            "link": "https://doi.org/10.1364/oe.582991",
            "published": "2026-01-13",
            "author": "Ning Yang, Chao Zhang, Fafa Ren, Xiaorui Wang, Ying Yuan",
            "summary": "<jats:p>Dynamic aero-optical effects under high-speed flight conditions can severely impair the detection performance of infrared imaging systems, while existing numerical approaches often fail to simultaneously achieve the high accuracy and computational efficiency required for rapid prediction in full-field, multi-spectral scenarios. In this work, a full-chain, end-to-end integration of optical-field dynamics with transient fluid–structure–thermal multiphysics coupling is established, forming a unified aero-optical light-field transmission model spanning spatial, temporal, spectral, and energy dimensions. The multi-dimensional light field is parameterized using low-dimensional, continuously differentiable representations, and a multilayer perceptron integrated with cellular automata (MLPs–CA) parallel ray-tracing framework is developed to efficiently solve coupled transmission across rays, multiphysics fields, optical systems, and sensors, while preserving high accuracy and fidelity. Numerical simulations indicate physical accuracy with point spread function (PSF) structural similarity index (SSIM) ≥ 0.98, together with a computational speedup of 1.29×–9.87× compared to conventional approaches. Analysis under two representative flight conditions further shows that: (1) dynamic aero-optical effects exhibit pronounced sensitivity to temporal, spatial, and spectral variations across different fields of view, with central-field image quality exceeding that of edge fields; and (2) aero-thermal radiation induces temporally, spatially, and spectrally correlated non-uniform image-plane radiance, resulting in average signal-to-noise ratio (SNR) decreases of 33.94% and 40.23% under a 500 K blackbody input. This framework offers a rapid, high-accuracy, and high-fidelity prediction capability for dynamic infrared imaging performance degradation, providing a robust basis for optimizing infrared imaging systems within realistic and complex aero-optical environments.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "准确高效的MLP-基于CA的全链动态气动光学建模用于红外成像预测",
            "abstract_cn": "<jats:p>高速飞行条件下的动态气动光学效应会严重损害红外成像系统的探测性能，而现有的数值方法往往无法同时实现全场、多光谱场景中快速预测所需的高精度和计算效率。在这项工作中，建立了光场动力学与瞬态流-结构-热多物理场耦合的全链、端到端集成，形成了跨越空间、时间、光谱和能量维度的统一的气动光场传输模型。多维光场使用低维、连续可微表示进行参数化，并开发了与元胞自动机 (MLP-CA) 并行光线追踪框架集成的多层感知器，以有效解决跨光线、多物理场、光学系统和传感器的耦合传输，同时保持高精度和保真度。数值模拟表明，与传统方法相比，点扩散函数 (PSF) 结构相似指数 (SSIM) ≥ 0.98 的物理精度以及计算速度提高了 1.29×–9.87×。两种代表性飞行条件下的分析进一步表明：（1）动态气动光学效应对不同视场的时间、空间和光谱变化表现出明显的敏感性，中心场图像质量超过边缘场； (2) 航空热辐射会引起时间、空间和光谱相关的非均匀像面辐射，导致在 500 K 黑体输入下平均信噪比 (SNR) 降低 33.94% 和 40.23%。该框架为动态红外成像性能退化提供了快速、高精度、高保真预测能力，为在现实复杂的航空光学环境中优化红外成像系统提供了坚实的基础。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.584817",
            "title": "Absolute flat test by a coherent shift-rotation method with yaw-angle monitoring",
            "link": "https://doi.org/10.1364/oe.584817",
            "published": "2026-01-16",
            "author": "Renhu Liu, Baojian Ji, Wenhui Deng, Qiao Xu, Lei Zhang",
            "summary": "<jats:p>A coherent shift-rotation method with yaw-angle monitoring (CSR-YAM) is proposed for the absolute measurement of flat surfaces. The method features a simple testing configuration and a convenient procedure, which requires only a single auxiliary mirror for yaw-angle monitoring and avoids redundant homing operation of the test surface. A corresponding surface reconstruction system is established based on the shift-rotation difference maps and the measured relative yaw angles, which is complete and can recover pixel-level absolute surface without theoretical error. Also, considering the high dimensionality of the reconstruction system, an efficient and low-cost iterative solver is provided for surface recovery. Simulations demonstrate the high accuracy, efficiency, and robustness of the proposed method, and experimental results show good agreement with direct measurements using a sub-nanometer root-mean-square (RMS) transmission flat.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "通过带有偏航角监控的相干平移旋转方法进行绝对平坦测试",
            "abstract_cn": "<jats:p>提出了一种具有偏航角监控的相干移位旋转方法（CSR-YAM），用于平面的绝对测量。该方法测试配置简单，流程方便，仅需要单个辅助镜进行偏航角监测，避免了测试面的冗余归零操作。基于平移-旋转差值图和测量的相对偏航角建立了相应的表面重建系统，该系统是完整的并且可以恢复像素级绝对表面而没有理论误差。此外，考虑到重建系统的高维性，为表面恢复提供了高效且低成本的迭代求解器。仿真证明了该方法的高精度、高效性和鲁棒性，实验结果与使用亚纳米均方根（RMS）传输平面的直接测量结果吻合良好。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.585669",
            "title": "Solution to the shearing problem via guided diffusion",
            "link": "https://doi.org/10.1364/oe.585669",
            "published": "2026-01-16",
            "author": "Xin Tang, Keke Liu, Jie Chen, Yong Kong, Zhisong Li",
            "summary": "<jats:p>Wavefront reconstruction from lateral shearing interferometry (LSI) represents a challenging ill-posed inverse problem due to shear-periodic information loss and noise sensitivity. Conventional techniques typically mandate multiple shearograms or impose rigid, potentially biasing priors. We introduce pseudoinverse-guided diffusion models (ΠGDM), qwhich we believe to be a novel framework leveraging a pre-trained unconditional diffusion model as a robust data-driven prior. By integrating the LSI physics via Vector-Jacobian product guidance, ΠGDM ensures measurement consistency while plausibly recovering missing spatial frequencies. We comprehensively benchmark ΠGDM against four distinct methods: classical Zonal integration, Fourier, Tikhonov regularization, and a supervised deep learning network. Simulations and experimental validation using a Michelson-based setup demonstrate that ΠGDM yields superior fidelity and noise robustness from single shearograms. Crucially, it offers a versatile, zero-shot alternative to supervised methods, achieving high-precision metrology without requiring task-specific training.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "通过引导扩散解决剪切问题",
            "abstract_cn": "<jats:p>由于剪切周期信息丢失和噪声敏感性，横向剪切干涉测量 (LSI) 的波前重建是一个具有挑战性的不适定反问题。传统技术通常要求使用多个剪切图或施加严格的、可能存在偏差的先验。我们引入了伪逆引导扩散模型（ΠGDM），我们认为这是一种新颖的框架，利用预先训练的无条件扩散模型作为强大的数据驱动先验。通过 Vector-Jacobian 产品指导集成 LSI 物理原理，ΠGDM 确保测量一致性，同时合理地恢复丢失的空间频率。我们针对四种不同的方法对 ΠGDM 进行了全面的基准测试：经典的区域积分、傅立叶、吉洪诺夫正则化和监督深度学习网络。使用基于 Michelson 的设置进行的模拟和实验验证表明，ΠGDM 从单个剪切图中产生了卓越的保真度和噪声鲁棒性。至关重要的是，它为监督方法提供了一种多功能、零样本的替代方案，无需特定任务的培训即可实现高精度计量。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.580562",
            "title": "All-photonic reservoir computing for dynamic image classification via spatial-to-temporal encoding",
            "link": "https://doi.org/10.1364/oe.580562",
            "published": "2026-01-16",
            "author": "Ryota Nakayama, Keigo Takabayashi, Takeo Maruyama, Tomoaki Niiyama, Satoshi Sunada",
            "summary": "<jats:p>We present an all-photonic reservoir computing device that integrates the reservoir and readout layers on a silicon photonic chip, enabling end-to-end optical processing of time-series data with ultralow latency. The photonic reservoir computing achieves real-time high-speed image processing by incorporating a photonic spatial-to-temporal encoding technique, which converts visual information into a time-domain signal at a rate of 25 Gigasamples per second. We experimentally demonstrated that the proposed photonic approach can recognize microsecond-scale switching events that are challenging to capture using conventional electronic systems. This approach offers a scalable solution for photonic processors targeting time-critical tasks such as anomaly detection and real-time sensing applications.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "通过时空编码进行动态图像分类的全光子储层计算",
            "abstract_cn": "<jats:p>我们提出了一种全光子储层计算设备，该设备将储层和读出层集成在硅光子芯片上，从而能够以超低延迟对时间序列数据进行端到端光学处理。光子库计算通过结合光子时空编码技术实现实时高速图像处理，以每秒25 Gigasamples的速率将视觉信息转换为时域信号。我们通过实验证明，所提出的光子方法可以识别微秒级的开关事件，而使用传统电子系统很难捕获这些事件。这种方法为针对时间关键任务（例如异常检测和实时传感应用）的光子处理器提供了可扩展的解决方案。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.587142",
            "title": "On-axis energy backflow in the focal fields of vector vortex beams with arbitrary initial phase",
            "link": "https://doi.org/10.1364/oe.587142",
            "published": "2026-01-09",
            "author": "Lei Han, Jiale Qi, Chuchu Gao, Fuli Li",
            "summary": "<jats:p>\n                    Energy backflow is an intriguing counterintuitive phenomenon, which has been reported in the focal region of light beams with phase or polarization singularities. Although the scenarios involving vector vortex beams with both polarization and phase singularities have been discussed, the impact of the light beam’s initial phase on energy backflow remains not fully clear. Here, we theoretically prove and numerically demonstrate that the longitudinal component of the Poynting vector in the focal plane is independent of the initial phase of incident light beams. We further reveal the general condition for the emergence of on-axis energy backflow near the focus of such light beams with arbitrary initial phase: specifically, the polarization order\n                    <jats:italic>l</jats:italic>\n                    and the phase topological charge\n                    <jats:italic>m</jats:italic>\n                    need to satisfy\n                    <jats:italic>l</jats:italic>\n                     ± \n                    <jats:italic>m</jats:italic>\n                     = 2. And we unveil the existing Poynting vector singularities associated with on-axis energy backflow. More remarkably, the exceptional cases are uncovered, where\n                    <jats:italic>l</jats:italic>\n                     = 1 and\n                    <jats:italic>m</jats:italic>\n                     = ±1. And we find that it is possible to construct on-axis energy backflow by appropriately modulating the amplitude of the incident light beam. Furthermore, we propose a general method to achieve a strong longitudinal electric field on the optical axis by utilizing light beams satisfying the condition with\n                    <jats:italic>l</jats:italic>\n                     ± \n                    <jats:italic>m</jats:italic>\n                     = 1. The results enrich the toolkit for constructing and modulating light fields as well as energy flow distributions in the focal region.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "任意初始相位矢量涡旋光束焦场内的轴上能量回流",
            "abstract_cn": "<贾茨：p>\n                    能量回流是一种有趣的反直觉现象，已在具有相位或偏振奇点的光束的焦点区域中报道过这种现象。尽管已经讨论了涉及具有偏振和相位奇点的矢量涡旋光束的场景，但光束初始相位对能量回流的影响仍不完全清楚。在这里，我们从理论上证明并数值证明了焦平面中坡印廷矢量的纵向分量与入射光束的初始相位无关。我们进一步揭示了这种具有任意初始相位的光束在焦点附近出现轴上能量回流的一般条件：具体来说，偏振阶数\n                    <jats:斜体>l</jats:斜体>\n                    和相拓扑电荷\n                    <贾茨：斜体>米</贾茨：斜体>\n                    需要满足\n                    <jats:斜体>l</jats:斜体>\n                     ± \n                    <贾茨：斜体>米</贾茨：斜体>\n                     = 2.并且我们揭示了与轴上能量回流相关的现有坡印廷矢量奇点。更值得注意的是，异常情况被发现了，其中\n                    <jats:斜体>l</jats:斜体>\n                     = 1 且\n                    <贾茨：斜体>米</贾茨：斜体>\n                     = ±1。我们发现通过适当调制入射光束的振幅可以构建轴上能量回流。此外，我们提出了一种利用满足条件的光束在光轴上实现强纵向电场的通用方法\n                    <jats:斜体>l</jats:斜体>\n                     ± \n                    <贾茨：斜体>米</贾茨：斜体>\n                     = 1.结果丰富了构建和调制光场以及焦点区域能量流分布的工具包。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.584647",
            "title": "Intrinsic distributed sensing using wavelength-multiplexed QPSK signals in fiber-optic communication",
            "link": "https://doi.org/10.1364/oe.584647",
            "published": "2026-01-12",
            "author": "George Y. Chen, Runlong Zhu, Xing Rao, Junmin Liu, Zhixiang Deng, Shuqing Chen, Yiping Wang",
            "summary": "<jats:p>The integration between fiber-optic communication and sensing has gained enormous interest worldwide due to the potential for utilizing existing communication cable infrastructure for low cost structural-health monitoring and security applications. Forward distributed acoustic sensing is particularly promising for such integration, as the sensing and communication signals co-propagate, and grants advantages including long sensing distance, high sensitivity and wide frequency response. In this work, an integrated architecture is proposed and experimentally demonstrated for unidirectional fiber-optic communication and distributed sensing, which solves the detector synchronization problem that has hindered practical application. The sensing demodulator is separated from the communication demodulator by choice, in order to address practical deployment requirements regarding a closed-source commercial communication system and data security. The adoption of the self-referencing forward interferometry scheme improves optical stability, streamlines design and reduces cost. As demonstration, a quadrature phase-shift keying (QPSK) communication signal at a 1 Gbps modulation rate is multiplexed onto the optical carrier, with a transmission fiber length of ∼90 km. The experimental results show that enabling the communication modulation does not cause significant degradation in sensing performance. The system demonstrated a sensitivity of 0.83 rad/V at 50 MHz, facilitating high-frequency ultrasonic detection in the 1MHz–50 MHz range, with a spatial resolution of 0.64 m at 5 MHz. This integrated architecture enables distributed sensing within the existing framework of communications while providing a means for data security, does not occupy additional bandwidth, and has the potential to unlock massively scalable sensing solutions.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "光纤通信中使用波长复用 QPSK 信号的固有分布式传感",
            "abstract_cn": "<jats:p>由于利用现有通信电缆基础设施进行低成本结构健康监测和安全应用的潜力，光纤通信和传感之间的集成在全世界范围内引起了极大的兴趣。前向分布式声学传感对于这种集成特别有前景，因为传感和通信信号共同传播，并具有传感距离长、灵敏度高和频率响应宽等优点。在这项工作中，提出了一种用于单向光纤通信和分布式传感的集成架构并进行了实验演示，解决了阻碍实际应用的探测器同步问题。传感解调器选择与通信解调器分离，以满足闭源商业通信系统和数据安全的实际部署要求。采用自参考前向干涉测量方案提高了光学稳定性，简化了设计并降低了成本。作为演示，调制速率为 1 Gbps 的正交相移键控 (QPSK) 通信信号被复用到光载波上，传输光纤长度为 ∼90 km。实验结果表明，启用通信调制不会导致传感性能显着下降。该系统在50MHz时的灵敏度为0.83rad/V，有助于在1MHz-50MHz范围内进行高频超声检测，在5MHz时空间分辨率为0.64m。这种集成架构可以在现有通信框架内实现分布式传感，同时提供数据安全手段，不占用额外带宽，并且有潜力解锁大规模可扩展的传感解决方案。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/optcon.575071",
            "title": "Modular 3D-printed biophotonic platform for cost-effective hyperspectral and polarimetric imaging",
            "link": "https://doi.org/10.1364/optcon.575071",
            "published": "2026-01-26",
            "author": "Rabbi Boateng, Hampus Månefjord, Jerry Opoku-Ansah, Peter Osei-Wusu Adueming, Andrew Huzortey, Moses Jojo Eghan, Benjamin Anderson, Kingsley Taah, Charles Lloyd Yeboah Amuah",
            "summary": "<jats:p>Hyperspectral imaging (HSI) provides a powerful, non-destructive method for obtaining spatially and spectrally resolved information across diverse applications. However, conventional systems remain limited by high cost, complexity, and bulkiness, restricting their use in resource-constrained environments. This study presents a cost-effective, modular hyperspectral and polarimetric imaging platform developed using 3D-printed components and open-source software control. The system integrates a linear variable long-pass filter (LV-LPF) mounted on a motorized translation stage with a monochrome CMOS camera and LED-based diffuse illumination, enabling continuous spectral scanning between 450–720 nm. Calibration and validation using laser and LED sources yielded a mean absolute error (MAE) of 10.0 nm, a spectral precision of 10 ± 1 nm FWHM, and a stable wavelength registration drift of ±4 nm. Radiometric analysis achieved an average signal-to-noise ratio (SNR) of 20 ± 3 dB across the visible spectrum. Application to healthy and diseased rice seeds demonstrated clear spectral and polarization-dependent contrasts, with mean degrees of linear polarization (DoLP) of 0.18 ± 0.05, revealing distinct structural and subsurface variations. The results confirm the system’s potential as an adaptable, low-cost optical imaging tool for crop-health assessment.</jats:p>",
            "journal": "Optics Continuum",
            "title_cn": "模块化 3D 打印生物光子平台，实现经济高效的高光谱和偏振成像",
            "abstract_cn": "<jats:p>高光谱成像 (HSI) 提供了一种强大的非破坏性方法，用于在不同的应用中获取空间和光谱分辨率的信息。然而，传统系统仍然受到高成本、复杂性和体积大的限制，限制了它们在资源有限的环境中的使用。这项研究提出了一种使用 3D 打印组件和开源软件控制开发的经济高效的模块化高光谱和偏振成像平台。该系统将安装在电动平移台上的线性可变长通滤光片 (LV-LPF) 与单色 CMOS 相机和基于 LED 的漫射照明集成在一起，可实现 450–720nm 之间的连续光谱扫描。使用激光和 LED 光源进行校准和验证，平均绝对误差 (MAE) 为 10.0 nm，光谱精度为 10± 1 nm FWHM，稳定的波长配准漂移为 ±4 nm。辐射分析在可见光谱范围内实现了 20±±3 dB 的平均信噪比 (SNR)。对健康和患病水稻种子的应用显示出清晰的光谱和偏振依赖性对比度，平均线性偏振度 (DoLP) 为 0.18±0.05，揭示了明显的结构和地下变化。结果证实了该系统作为一种适应性强、成本低的光学成像工具用于作物健康评估的潜力。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/optcon.580127",
            "title": "Study of the computational insights and the nonlinear optical properties of scandium (sc) and titanium (Ti) doped benzocryptand by the DFT approach",
            "link": "https://doi.org/10.1364/optcon.580127",
            "published": "2025-12-23",
            "author": "Muhammad Ismaeel, Muhammad Hanan, Qasim Ali, Haiqa Javed, Aurangzeb, Ali Raza Ayub, Hafiz Junaid Akbar, Javed Iqbal, M. Shabir Mahr",
            "summary": "<jats:p>\n                    Nonlinear optical (NLO) materials are at the forefront in the field of optics and laser-based devices. The search for NLO materials continues and has attracted great attention to designing and fabricating remarkable materials with improved electro-optical properties. Herein, we present the geometric, electronic, and nonlinear optical properties of a theoretically designed benzo-cryptand (BC) doped with transition metals. It was found by frontier molecular orbital (FMO) analysis that transition metals with polarized electrons are located on the HOMO. Doping strategies enhanced charge transfer by lowering the energy bandgap to a range of 0.72 to 2.09 eV, significantly below the 5.41 eV gap of pure BC. All newly designed complexes are predicted to be stable by their negative energy interaction values. Various analysis like the density of state (DOS), electron density difference map (EDDM), transition density matrix (TDM), and natural bond orbital (NBO) analysis, were done to examine properties of charge transfer. Non-covalent interactions (NCI) and quantum theory of atoms in molecules (QTAIM) analysis were performed to investigate the intermolecular interactions in all molecules. The TD-DFT computation reveals that the designed complexes have maximum absorption ranging from 2100 to 7400 nm in the IR and visible regions, while they are opaque in the UV region. Hyperpolarizability and polarizability increased in doped systems due to low excitation energy and excess electrons. Owing to the increase in isotropic linear polarizability, the complexes kept significant optoelectronic properties ranging from 526.51 to 945.69 au. Also, the first hyperpolarizability of these systems was remarkably large (\n                    <jats:italic toggle=\"yes\">β</jats:italic>\n                    <jats:sub>t</jats:sub>\n                    ), ranging from 15219.99–146401.37 au. This study revealed that transition metals doped benzo-cryptand can be used as a competitive of brilliant non-linear optical traits along with practical applications in the field of optoelectronics.\n                  </jats:p>",
            "journal": "Optics Continuum",
            "title_cn": "通过 DFT 方法研究钪 (sc) 和钛 (Ti) 掺杂苯并隐配体的计算见解和非线性光学性质",
            "abstract_cn": "<贾茨：p>\n                    非线性光学（NLO）材料处于光学和激光器件领域的前沿。对非线性光学材料的研究仍在继续，并引起了人们对设计和制造具有改进的电光性能的卓越材料的极大关注。在此，我们提出了理论上设计的掺杂过渡金属的苯并穴状配体（BC）的几何、电子和非线性光学性质。通过前沿分子轨道（FMO）分析发现，具有极化电子的过渡金属位于HOMO上。掺杂策略通过将能带隙降低至 0.72 至 2.09 eV 范围来增强电荷转移，远低于纯 BC 的 5.41 eV 能隙。所有新设计的配合物都通过其负能量相互作用值预测是稳定的。进行了各种分析，如态密度 (DOS)、电子密度差图 (EDDM)、跃迁密度矩阵 (TDM) 和自然键轨道 (NBO) 分析，以检查电荷转移的特性。进行非共价相互作用（NCI）和分子中原子量子理论（QTAIM）分析来研究所有分子中的分子间相互作用。 TD-DFT 计算表明，设计的配合物在红外和可见光区域具有 2100 至 7400nm 的最大吸收，而在紫外区域不透明。由于低激发能和过量电子，掺杂系统中的超极化率和极化率增加。由于各向同性线性极化率的增加，配合物在526.51至945.69 au范围内保持了显着的光电特性。此外，这些系统的第一超极化率非常大（\n                    <jats：斜体切换=“是”>β</jats：斜体>\n                    <贾茨：子>t</贾茨：子>\n                    ），范围从 15219.99–146401.37 au。这项研究表明，过渡金属掺杂的苯并穴状配体可以作为一种具有竞争力的出色的非线性光学特性以及在光电子领域的实际应用。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1002/lpor.202503040",
            "title": "Super Persistent Luminescence and Photochromism in Cr\n                    <sup>3+</sup>\n                    ‐Doped Pyroxene for Multimodal Applications",
            "link": "https://doi.org/10.1002/lpor.202503040",
            "published": "2026-01-26",
            "author": "Jingyi Li, Lele Gao, Huihui Cao, Hongzhen Liu, Chao Dou, Zhen Song, Quanlin Liu",
            "summary": "<jats:title>ABSTRACT</jats:title>\n                  <jats:p>\n                    Conventional photoluminescent materials are limited by their single optical response, constraining their use in information storage and anti‐counterfeiting. Emerging strategies, therefore, are focused on multifunctional materials with multimodal, dynamically tunable optical behaviors to achieve higher storage capacity and security. Herein, a pyroxene‐type phosphor Ca(Zn,Mg)Ge\n                    <jats:sub>2</jats:sub>\n                    O\n                    <jats:sub>6</jats:sub>\n                    :Cr\n                    <jats:sup>3+</jats:sup>\n                    integrating both persistent luminescence (PersL) and photochromism has been developed. Under ultraviolet irradiation, the material exhibits a broad near‐infrared persistent emission spanning 700–1300 nm, accompanied by a distinct color change from white (gray) to gray‐pink. By combining bandgap engineering with crystallographic site regulation, the trap depth can be continuously tuned, thereby extending the afterglow lifetime from 20 to over 200 h. The optimized phosphor can be effectively recharged under sunlight, while bandgap engineering further enhances its UV‐induced photochromism behavior. Compared with CaZnGe\n                    <jats:sub>2</jats:sub>\n                    O\n                    <jats:sub>6</jats:sub>\n                    :Cr\n                    <jats:sup>3+</jats:sup>\n                    , CaZn\n                    <jats:sub>0.65</jats:sub>\n                    Mg\n                    <jats:sub>0.45</jats:sub>\n                    Ge\n                    <jats:sub>2</jats:sub>\n                    O\n                    <jats:sub>6</jats:sub>\n                    :Cr\n                    <jats:sup>3+</jats:sup>\n                    is characterized by a remarkable 41.7% increase in the reflectance difference (∆R) at 466 nm, together with improved color retention stability. By synergistically coupling PersL with photochromism functionality, the optimized material opens new avenues for multimodal anti‐counterfeiting applications.\n                  </jats:p>",
            "journal": "Laser & Photonics Reviews",
            "title_cn": "用于多峰应用的 Cr <sup>3+</sup> 掺杂辉石的超持久发光和光致变色",
            "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    传统的光致发光材料受到其单一光学响应的限制，限制了它们在信息存储和防伪方面的应用。因此，新兴策略的重点是具有多模态、动态可调光学行为的多功能材料，以实现更高的存储容量和安全性。在此，辉石型荧光粉Ca(Zn,Mg)Ge\n                    <贾茨：子>2</贾茨：子>\n                    氧\n                    <贾茨：子>6</贾茨：子>\n                    :Cr\n                    <贾茨：sup>3+</贾茨：sup>\n                    已经开发出将持久发光（PersL）和光致变色相结合的技术。在紫外线照射下，该材料表现出跨度为 700-1300 nm 的广泛近红外持续发射，并伴有从白色（灰色）到灰粉色的明显颜色变化。通过将带隙工程与晶体位点调节相结合，可以连续调节陷阱深度，从而将余辉寿命从 20 小时延长到 200 小时以上。优化的荧光粉可以在阳光下有效地充电，而带隙工程进一步增强了其紫外线诱导的光致变色行为。与钙锌锗相比\n                    <贾茨：子>2</贾茨：子>\n                    氧\n                    <贾茨：子>6</贾茨：子>\n                    :Cr\n                    <贾茨：sup>3+</贾茨：sup>\n                    , 钙锌\n                    <贾茨：子>0.65</贾茨：子>\n                    镁\n                    <贾茨：子>0.45</贾茨：子>\n                    锗\n                    <贾茨：子>2</贾茨：子>\n                    氧\n                    <贾茨：子>6</贾茨：子>\n                    :Cr\n                    <贾茨：sup>3+</贾茨：sup>\n                    其特点是 466 nm 处的反射率差异 (ΔR) 显着增加 41.7%，同时颜色保持稳定性也得到改善。通过将 PersL 与光致变色功能协同耦合，优化后的材料为多模式防伪应用开辟了新途径。\n                  </贾茨：p>"
        },
        {
            "id": "http://arxiv.org/abs/2510.13408v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2510.13408v1",
            "title": "Semantic Communication Enabled Holographic Video Processing and Transmission",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Semantic Communication Enabled Holographic Video Processing and Transmission"
            },
            "updated": "2025-10-15T11:06:48Z",
            "updated_parsed": [
                2025,
                10,
                15,
                11,
                6,
                48,
                2,
                288,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2510.13408v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2510.13408v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Holographic video communication is considered a paradigm shift in visual communications, becoming increasingly popular for its ability to offer immersive experiences. This article provides an overview of holographic video communication and outlines the requirements of a holographic video communication system. Particularly, following a brief review of semantic com- munication, an architecture for a semantic-enabled holographic video communication system is presented. Key technologies, including semantic sampling, joint semantic-channel coding, and semantic-aware transmission, are designed based on the proposed architecture. Two related use cases are presented to demonstrate the performance gain of the proposed methods. Finally, potential research topics are discussed to pave the way for the realization of semantic-enabled holographic video communications.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Holographic video communication is considered a paradigm shift in visual communications, becoming increasingly popular for its ability to offer immersive experiences. This article provides an overview of holographic video communication and outlines the requirements of a holographic video communication system. Particularly, following a brief review of semantic com- munication, an architecture for a semantic-enabled holographic video communication system is presented. Key technologies, including semantic sampling, joint semantic-channel coding, and semantic-aware transmission, are designed based on the proposed architecture. Two related use cases are presented to demonstrate the performance gain of the proposed methods. Finally, potential research topics are discussed to pave the way for the realization of semantic-enabled holographic video communications."
            },
            "tags": [
                {
                    "term": "eess.IV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.IT",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.MM",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "eess.SP",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-10-15T11:06:48Z",
            "published_parsed": [
                2025,
                10,
                15,
                11,
                6,
                48,
                2,
                288,
                0
            ],
            "arxiv_comment": "7 pages, 6 figures, Submit for review",
            "arxiv_primary_category": {
                "term": "eess.IV"
            },
            "authors": [
                {
                    "name": "Jingkai Ying"
                },
                {
                    "name": "Zhiyuan Qi"
                },
                {
                    "name": "Yulong Feng"
                },
                {
                    "name": "Zhijin Qin"
                },
                {
                    "name": "Zhu Han"
                },
                {
                    "name": "Rahim Tafazolli"
                },
                {
                    "name": "Yonina C. Eldar"
                }
            ],
            "author_detail": {
                "name": "Yonina C. Eldar"
            },
            "author": "Yonina C. Eldar",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "语义通信支持全息视频处理和传输",
            "abstract_cn": "全息视频通信被认为是视觉通信的范式转变，因其提供沉浸式体验的能力而变得越来越受欢迎。本文概述了全息视频通信，并概述了全息视频通信系统的要求。特别是，在简要回顾语义通信之后，提出了一种支持语义的全息视频通信系统的架构。基于所提出的架构设计了语义采样、联合语义信道编码和语义感知传输等关键技术。提出了两个相关的用例来证明所提出的方法的性能增益。最后，讨论了潜在的研究主题，为实现语义全息视频通信铺平道路。"
        },
        {
            "id": "http://arxiv.org/abs/2510.13480v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2510.13480v1",
            "title": "A Quantitative Holographic Agglutination Assay for Immunoglobulin A",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "A Quantitative Holographic Agglutination Assay for Immunoglobulin A"
            },
            "updated": "2025-10-15T12:27:10Z",
            "updated_parsed": [
                2025,
                10,
                15,
                12,
                27,
                10,
                2,
                288,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2510.13480v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2510.13480v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "This study introduces a Holographic Agglutination Assay for quantifying levels of the immunoglobulin protein IgA in biological samples. This is the first example of a label-free and bead-free assay that quantifies protein agglutinates by direct detection using Total Holographic Characterization. A proof-of-concept assay for human serum immunoglobulins is demonstrated using Jacalin, the galactose-specific plant lectin, to induce selective agglutination.\n  By analyzing the size, refractive index, and number of particles in an assay sample, we obtain a reproducible and quantitative measurement of galactosylated immunoglobulins in a given sample. The assay is calibrated for a physiologically relevant reference interval of IgA concentrations in a 10x diluted emulated biological sample from low (80 mg/dL, 5 μM) to high (320 mg/dL, 20 μM) levels. The assay clearly distinguishes samples containing IgA from samples containing IgG.\n  More broadly, this study introduces a platform for creating lectin-mediated Holographic Agglutination Assays to monitor levels of immunoglobulins in biological samples. The ability to quantify immunoglobulin levels efficiently in clinical samples is likely to be valuable for diagnostics and will provide a basis for assaying other proteins that can be induced to agglutinate.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "This study introduces a Holographic Agglutination Assay for quantifying levels of the immunoglobulin protein IgA in biological samples. This is the first example of a label-free and bead-free assay that quantifies protein agglutinates by direct detection using Total Holographic Characterization. A proof-of-concept assay for human serum immunoglobulins is demonstrated using Jacalin, the galactose-specific plant lectin, to induce selective agglutination.\n  By analyzing the size, refractive index, and number of particles in an assay sample, we obtain a reproducible and quantitative measurement of galactosylated immunoglobulins in a given sample. The assay is calibrated for a physiologically relevant reference interval of IgA concentrations in a 10x diluted emulated biological sample from low (80 mg/dL, 5 μM) to high (320 mg/dL, 20 μM) levels. The assay clearly distinguishes samples containing IgA from samples containing IgG.\n  More broadly, this study introduces a platform for creating lectin-mediated Holographic Agglutination Assays to monitor levels of immunoglobulins in biological samples. The ability to quantify immunoglobulin levels efficiently in clinical samples is likely to be valuable for diagnostics and will provide a basis for assaying other proteins that can be induced to agglutinate."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.med-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "q-bio.QM",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-10-15T12:27:10Z",
            "published_parsed": [
                2025,
                10,
                15,
                12,
                27,
                10,
                2,
                288,
                0
            ],
            "arxiv_comment": "13 pages, 4 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Rushna Quddus"
                },
                {
                    "name": "Kent Kirshenbaum"
                },
                {
                    "name": "David G. Grier"
                }
            ],
            "author_detail": {
                "name": "David G. Grier"
            },
            "author": "David G. Grier",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "免疫球蛋白 A 的定量全息凝集测定",
            "abstract_cn": "本研究介绍了一种全息凝集测定法，用于定量生物样品中免疫球蛋白 IgA 的水平。这是第一个无标记、无珠测定的例子，通过使用全全息表征直接检测来量化蛋白质凝集物。使用 Jacalin（半乳糖特异性植物凝集素）诱导选择性凝集，证明了人血清免疫球蛋白的概念验证测定。\n  通过分析测定样品中颗粒的大小、折射率和数量，我们获得了给定样品中半乳糖基化免疫球蛋白的可重复且定量的测量结果。该测定针对 10 倍稀释的模拟生物样品中 IgA 浓度的生理相关参考区间进​​行校准，从低水平（80 mg/dL，5 μM）到高水平（320 mg/dL，20 μM）。该检测可以清楚地区分含有 IgA 的样品和含有 IgG 的样品。\n  更广泛地说，本研究介绍了一个用于创建凝集素介导的全息凝集测定的平台，以监测生物样品中免疫球蛋白的水平。有效定量临床样本中免疫球蛋白水平的能力可能对诊断有价值，并将为测定其他可诱导凝集的蛋白质提供基础。"
        },
        {
            "id": "http://arxiv.org/abs/2510.14138v2",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2510.14138v2",
            "title": "Bell-State Quantum Holography with Metasurfaces",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Bell-State Quantum Holography with Metasurfaces"
            },
            "updated": "2025-11-10T14:52:21Z",
            "updated_parsed": [
                2025,
                11,
                10,
                14,
                52,
                21,
                0,
                314,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2510.14138v2",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2510.14138v2",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Metasurfaces composed of subwavelength nanostructures enable simultaneous control of polarization and wavefront, greatly enhancing holographic information capacity. Building on this capability, we extend holography into the quantum domain by experimentally realizing Bell-state holograms-distinct holographic images encoded in polarization-entangled Bell states of photon pairs. A polarization-multiplexed dielectric metasurface generates spatial modes conditioned on both input and output polarizations, entangling the holographic pattern with the two-photon state. To characterize these quantum holograms, we further develop quantum hologram tomography, reconstructing the full density matrix of the holographic state pixel by pixel. The reconstructed density-matrix hologram reveals tailor-made holographic symbols attached to individual Bell states through the metasurface, with contrast built up among the different Bell components as theory shows. This framework unifies metasurface photonics with quantum-state reconstruction and provides a scalable route toward high-dimensional quantum communication, encryption and information processing based on holographically encoded quantum light.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Metasurfaces composed of subwavelength nanostructures enable simultaneous control of polarization and wavefront, greatly enhancing holographic information capacity. Building on this capability, we extend holography into the quantum domain by experimentally realizing Bell-state holograms-distinct holographic images encoded in polarization-entangled Bell states of photon pairs. A polarization-multiplexed dielectric metasurface generates spatial modes conditioned on both input and output polarizations, entangling the holographic pattern with the two-photon state. To characterize these quantum holograms, we further develop quantum hologram tomography, reconstructing the full density matrix of the holographic state pixel by pixel. The reconstructed density-matrix hologram reveals tailor-made holographic symbols attached to individual Bell states through the metasurface, with contrast built up among the different Bell components as theory shows. This framework unifies metasurface photonics with quantum-state reconstruction and provides a scalable route toward high-dimensional quantum communication, encryption and information processing based on holographically encoded quantum light."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "quant-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-10-15T22:15:02Z",
            "published_parsed": [
                2025,
                10,
                15,
                22,
                15,
                2,
                2,
                288,
                0
            ],
            "arxiv_comment": "21 pages, 4 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Qinmiao Chen"
                },
                {
                    "name": "Guangzhou Geng"
                },
                {
                    "name": "Hong Liang"
                },
                {
                    "name": "Wai Chun Wong"
                },
                {
                    "name": "Tailin An"
                },
                {
                    "name": "Randy Stefan Tanuwijaya"
                },
                {
                    "name": "Junjie Li"
                },
                {
                    "name": "Jensen Li"
                }
            ],
            "author_detail": {
                "name": "Jensen Li"
            },
            "author": "Jensen Li",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "贝尔态量子全息与超表面",
            "abstract_cn": "由亚波长纳米结构组成的超表面可以同时控制偏振和波前，大大增强全息信息容量。在此能力的基础上，我们通过实验实现贝尔态全息图——以光子对的偏振纠缠贝尔态编码的独特全息图像，将全息术扩展到量子域。偏振复用介电超表面产生以输入和输出偏振为条件的空间模式，使全息图案与双光子态纠缠在一起。为了表征这些量子全息图，我们进一步开发了量子全息断层扫描，逐像素重建全息状态的全密度矩阵。重建的密度矩阵全息图揭示了通过超表面附着在各个贝尔态上的定制全息符号，正如理论所示，不同贝尔组件之间建立了对比度。该框架将超表面光子学与量子态重建相结合，并为基于全息编码量子光的高维量子通信、加密和信息处理提供了可扩展的途径。"
        },
        {
            "id": "http://arxiv.org/abs/2510.14195v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2510.14195v1",
            "title": "A Flying Focus with Arbitrary Directionality",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "A Flying Focus with Arbitrary Directionality"
            },
            "updated": "2025-10-16T01:03:37Z",
            "updated_parsed": [
                2025,
                10,
                16,
                1,
                3,
                37,
                3,
                289,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2510.14195v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2510.14195v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Flying focus techniques produce laser pulses whose focal points travel at arbitrary, controllable velocities. While this flexibility can enhance a broad range of laser-based applications, existing techniques constrain the motion of the focal point to the propagation direction of the pulse. Here, we introduce a flying focus configuration that decouples the motion of the focus from the propagation direction. A chirped laser pulse focused and diffracted by a diffractive lens and grating creates a focal point that can move both along and transverse to the propagation direction. The focal length of the lens, grating period, and chirp can be tuned to control the direction and velocity of the focus. Simulations demonstrate this control for a holographic configuration suited to high-power pulses, in which two off-axis pump beams with different focal lengths encode the equivalent phase of a chromatic lens and grating in a gas or plasma. For low-power pulses, conventional solid-state or adaptive optics can be used instead. Multi-dimensional control over the focal trajectory enables new configurations for applications, including laser wakefield acceleration of ions, steering of broadband THz radiation, and surface harmonic generation.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Flying focus techniques produce laser pulses whose focal points travel at arbitrary, controllable velocities. While this flexibility can enhance a broad range of laser-based applications, existing techniques constrain the motion of the focal point to the propagation direction of the pulse. Here, we introduce a flying focus configuration that decouples the motion of the focus from the propagation direction. A chirped laser pulse focused and diffracted by a diffractive lens and grating creates a focal point that can move both along and transverse to the propagation direction. The focal length of the lens, grating period, and chirp can be tuned to control the direction and velocity of the focus. Simulations demonstrate this control for a holographic configuration suited to high-power pulses, in which two off-axis pump beams with different focal lengths encode the equivalent phase of a chromatic lens and grating in a gas or plasma. For low-power pulses, conventional solid-state or adaptive optics can be used instead. Multi-dimensional control over the focal trajectory enables new configurations for applications, including laser wakefield acceleration of ions, steering of broadband THz radiation, and surface harmonic generation."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.plasm-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-10-16T01:03:37Z",
            "published_parsed": [
                2025,
                10,
                16,
                1,
                3,
                37,
                3,
                289,
                0
            ],
            "arxiv_comment": "9 pages, 4 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Sida Cao"
                },
                {
                    "name": "Devdigvijay Singh"
                },
                {
                    "name": "Lavonne S. Mack"
                },
                {
                    "name": "John P. Palastro"
                },
                {
                    "name": "Matthew R. Edwards"
                }
            ],
            "author_detail": {
                "name": "Matthew R. Edwards"
            },
            "author": "Matthew R. Edwards",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "任意方向的飞行焦点",
            "abstract_cn": "飞焦技术产生的激光脉冲的焦点以任意、可控的速度移动。虽然这种灵活性可以增强基于激光的广泛应用，但现有技术将焦点的运动限制在脉冲的传播方向上。在这里，我们引入了一种飞行焦点配置，它将焦点的运动与传播方向解耦。由衍射透镜和光栅聚焦和衍射的啁啾激光脉冲产生一个焦点，该焦点可以沿着传播方向移动，也可以横向于传播方向移动。可以调整透镜的焦距、光栅周期和啁啾来控制焦点的方向和速度。仿真证明了这种适用于高功率脉冲的全息配置的控制，其中两个具有不同焦距的离轴泵浦光束对气体或等离子体中的彩色透镜和光栅的等效相位进行编码。对于低功率脉冲，可以使用传统的固态或自适应光学器件。对焦点轨迹的多维控制可实现新的应用配置，包括离子的激光尾场加速、宽带太赫兹辐射的转向和表面谐波生成。"
        },
        {
            "id": "http://arxiv.org/abs/2510.14782v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2510.14782v1",
            "title": "Raman-Accelerated Power Depletion of Fundamental Mode in a Few-Mode Fiber in the Visible Spectral Range",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Raman-Accelerated Power Depletion of Fundamental Mode in a Few-Mode Fiber in the Visible Spectral Range"
            },
            "updated": "2025-10-16T15:16:22Z",
            "updated_parsed": [
                2025,
                10,
                16,
                15,
                16,
                22,
                3,
                289,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2510.14782v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2510.14782v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We experimentally and numerically investigate Raman-driven power depletion in the fundamental mode of few-mode fibers (FMFs) excited by visible ultrashort pulses. Using a tunable femtosecond laser and SMF-28 fibers operated below the single-mode cutoff wavelength, we explore nonlinear mode dynamics through precise coupling, holographic mode decomposition, and spectral analysis. Experiments on 12-meter and 50-meter fibers reveal significant energy transfer to higher-order modes via intermodal Raman scattering. These findings advance our understanding of nonlinear propagation in FMFs, with important implications for high-power laser delivery and next-generation optical communication systems.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We experimentally and numerically investigate Raman-driven power depletion in the fundamental mode of few-mode fibers (FMFs) excited by visible ultrashort pulses. Using a tunable femtosecond laser and SMF-28 fibers operated below the single-mode cutoff wavelength, we explore nonlinear mode dynamics through precise coupling, holographic mode decomposition, and spectral analysis. Experiments on 12-meter and 50-meter fibers reveal significant energy transfer to higher-order modes via intermodal Raman scattering. These findings advance our understanding of nonlinear propagation in FMFs, with important implications for high-power laser delivery and next-generation optical communication systems."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-10-16T15:16:22Z",
            "published_parsed": [
                2025,
                10,
                16,
                15,
                16,
                22,
                3,
                289,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Wasyhun A. Gemechu"
                },
                {
                    "name": "Guohao Fu"
                },
                {
                    "name": "Mario Zitelli"
                }
            ],
            "author_detail": {
                "name": "Mario Zitelli"
            },
            "author": "Mario Zitelli",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "可见光谱范围内少模光纤基模的拉曼加速功率损耗",
            "abstract_cn": "我们通过实验和数值研究了可见超短脉冲激发的少模光纤（FMF）基模中拉曼驱动的功率损耗。我们使用可调谐飞秒激光器和在单模截止波长以下运行的 SMF-28 光纤，通过精确耦合、全息模式分解和光谱分析来探索非线性模式动力学。 12 米和 50 米光纤的实验表明，通过模间拉曼散射，能量可以显着转移到高阶模式。这些发现增进了我们对FMF非线性传播的理解，对高功率激光传输和下一代光通信系统具有重要意义。"
        },
        {
            "id": "http://arxiv.org/abs/2510.14858v2",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2510.14858v2",
            "title": "Exploiting Non-Diffracting Beams for Resilient Near-Field Millimeter-Wave Communications A Quantitative Roadmap",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Exploiting Non-Diffracting Beams for Resilient Near-Field Millimeter-Wave Communications A Quantitative Roadmap"
            },
            "updated": "2025-10-26T15:06:42Z",
            "updated_parsed": [
                2025,
                10,
                26,
                15,
                6,
                42,
                6,
                299,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2510.14858v2",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2510.14858v2",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Non diffracting (ND) beams are often cited as a promising solution to mitigate blockage in millimeter wave (mmWave) systems. However, a quantitative answer to the fundamental question, under what specific conditions do ND beams actually outperform conventional pencil beams, has remained elusive, especially in the emerging context of near-field communications. This paper provides the first systematic answer by mapping the performance advantage regimes of ND beams for blockage-resilient near-field links. We propose a unified holographic generator that synthesizes various structured beams (e.g., Bessel, Mathieu) under the physical constraints of a planar phased array, ensuring a fair comparison against a boresight baseline with identical EIRP and aperture. Through extensive, unbiased Monte Carlo simulations, we construct advantage regime maps that delineate the specific regions where ND beams offer a tangible link-level gain. Our key finding is that the advantage of ND beams is a powerful but conditional near field phenomenon. While offering a positive average gain, its performance is highly variable, with a 60-70% probability of outperforming the baseline in its optimal range. Crucially, this performance is strongly modulated by the obstacle's geometry, revealing a significant weakness against large blockers. These findings provide not just a practical roadmap for judiciously employing ND beams but also a clear motivation for future work in environment-aware, adaptively shaped structured beams.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Non diffracting (ND) beams are often cited as a promising solution to mitigate blockage in millimeter wave (mmWave) systems. However, a quantitative answer to the fundamental question, under what specific conditions do ND beams actually outperform conventional pencil beams, has remained elusive, especially in the emerging context of near-field communications. This paper provides the first systematic answer by mapping the performance advantage regimes of ND beams for blockage-resilient near-field links. We propose a unified holographic generator that synthesizes various structured beams (e.g., Bessel, Mathieu) under the physical constraints of a planar phased array, ensuring a fair comparison against a boresight baseline with identical EIRP and aperture. Through extensive, unbiased Monte Carlo simulations, we construct advantage regime maps that delineate the specific regions where ND beams offer a tangible link-level gain. Our key finding is that the advantage of ND beams is a powerful but conditional near field phenomenon. While offering a positive average gain, its performance is highly variable, with a 60-70% probability of outperforming the baseline in its optimal range. Crucially, this performance is strongly modulated by the obstacle's geometry, revealing a significant weakness against large blockers. These findings provide not just a practical roadmap for judiciously employing ND beams but also a clear motivation for future work in environment-aware, adaptively shaped structured beams."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "eess.SP",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-10-16T16:32:28Z",
            "published_parsed": [
                2025,
                10,
                16,
                16,
                32,
                28,
                3,
                289,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Yifeng Qin"
                },
                {
                    "name": "Jing Chen"
                },
                {
                    "name": "Zhi Hao Jiang"
                },
                {
                    "name": "Zhining Chen"
                },
                {
                    "name": "Yongming Huang"
                }
            ],
            "author_detail": {
                "name": "Yongming Huang"
            },
            "author": "Yongming Huang",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "利用非衍射光束实现弹性近场毫米波通信定量路线图",
            "abstract_cn": "非衍射 (ND) 光束通常被认为是减轻毫米波 (mmWave) 系统阻塞的有前景的解决方案。然而，ND 光束在什么特定条件下实际上优于传统笔形光束这一基本问题的定量答案仍然难以捉摸，特别是在新兴的近场通信背景下。本文通过绘制抗阻塞近场链路 ND 光束的性能优势机制，提供了第一个系统答案。我们提出了一种统一的全息发生器，可以在平面相控阵的物理约束下合成各种结构光束（例如，Bessel、Mathieu），确保与具有相同 EIRP 和孔径的视轴基线进行公平比较。通过广泛、公正的蒙特卡洛模拟，我们构建了优势机制图，描绘了 ND 光束提供切实链路级增益的特定区域。我们的主要发现是 ND 光束的优势是强大但有条件的近场现象。虽然提供正的平均增益，但其性能变化很大，在最佳范围内有 60-70% 的可能性超越基线。至关重要的是，这种性能受到障碍物几何形状的强烈调节，揭示了对抗大型障碍物的显着弱点。这些发现不仅为明智地使用 ND 光束提供了实用的路线图，而且为未来环境感知、自适应形状的结构光束的工作提供了明确的动力。"
        },
        {
            "id": "http://arxiv.org/abs/2510.16269v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2510.16269v1",
            "title": "Observation of spatially structured Montgomery effect in free space",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Observation of spatially structured Montgomery effect in free space"
            },
            "updated": "2025-10-17T23:48:56Z",
            "updated_parsed": [
                2025,
                10,
                17,
                23,
                48,
                56,
                4,
                290,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2510.16269v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2510.16269v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We report the first direct observation of the spatially structured Montgomery effect, a lensless self-imaging phenomenon that generalizes the Talbot effect to aperiodic structures, unfolding repeated tightly focused spots (~10 $μ$m) in free space. Using a dynamic optical hologram to discretize radial spatial frequencies, we demonstrate self-imaging at distances ranging from 30 to 100 mm. Our method independently controls the focal spot size and self-imaging period, enabling dynamic three-dimensional light patterns. We also show the arbitrary tunability of the transverse profile by demonstrating revivals of Laguerre-Gaussian, Hermite-Gaussian, Ince-Gaussian modes, and Airy beams. These findings open opportunities for multi-plane microscopy, optical atom traps, and quantum atomic systems.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We report the first direct observation of the spatially structured Montgomery effect, a lensless self-imaging phenomenon that generalizes the Talbot effect to aperiodic structures, unfolding repeated tightly focused spots (~10 $μ$m) in free space. Using a dynamic optical hologram to discretize radial spatial frequencies, we demonstrate self-imaging at distances ranging from 30 to 100 mm. Our method independently controls the focal spot size and self-imaging period, enabling dynamic three-dimensional light patterns. We also show the arbitrary tunability of the transverse profile by demonstrating revivals of Laguerre-Gaussian, Hermite-Gaussian, Ince-Gaussian modes, and Airy beams. These findings open opportunities for multi-plane microscopy, optical atom traps, and quantum atomic systems."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-10-17T23:48:56Z",
            "published_parsed": [
                2025,
                10,
                17,
                23,
                48,
                56,
                4,
                290,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Murat Yessenov"
                },
                {
                    "name": "Luca Sacchi"
                },
                {
                    "name": "Alfonso Palmieri"
                },
                {
                    "name": "Layton A. Hall"
                },
                {
                    "name": "Ayman F. Abouraddy"
                },
                {
                    "name": "Federico Capasso"
                }
            ],
            "author_detail": {
                "name": "Federico Capasso"
            },
            "author": "Federico Capasso",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "自由空间中空间结构蒙哥马利效应的观察",
            "abstract_cn": "我们报告了对空间结构蒙哥马利效应的首次直接观察，这是一种无透镜自成像现象，将塔尔伯特效应推广到非周期性结构，在自由空间中展开重复的紧密聚焦点（~10 $μ$m）。使用动态光学全息图离散径向空间频率，我们演示了在 30 至 100 毫米距离范围内的自成像。我们的方法独立控制焦点尺寸和自成像周期，从而实现动态三维光图案。我们还通过演示拉盖尔高斯模式、埃尔米高斯模式、因斯高斯模式和艾里光束的复兴来展示横向轮廓的任意可调性。这些发现为多平面显微镜、光学原子陷阱和量子原子系统带来了机遇。"
        },
        {
            "id": "http://arxiv.org/abs/2510.20421v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2510.20421v1",
            "title": "Active control the peak value of Hanbury Brown-Twiss effect with classical light by holographic projection",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Active control the peak value of Hanbury Brown-Twiss effect with classical light by holographic projection"
            },
            "updated": "2025-10-23T10:49:34Z",
            "updated_parsed": [
                2025,
                10,
                23,
                10,
                49,
                34,
                3,
                296,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2510.20421v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2510.20421v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "The Manipulation of g^(2)(0) peak value of Hanbury Brown-Twiss (HBT) effect is discussed with a holographic projection scheme. By the aid of target pattern artificially designed in the projection imaging system, the statistical distribution of projection pattern will be highly controllable. In this work, we theoretically point out key factors influencing the g^(2)(0) peak value of HBT effect in a single-lens incoherent imaging system. We find the peak value is not only decided by statistical property and coherence length of target pattern but also depends on the intrinsic characteristics of projection system, such as numerical aperture and projection quality. Then, we experimentally measured the g^(2)(0) peak value of HBT effect with a phase-only holographic projection scheme and demonstrate the applicability of our theoretical analysis on the holographic scheme. Here, the super-bunching effect in the projection plane has been observed, when target patterns originated from chaotic speckle or it's function transformation patterns. Moreover, we design some sparse target patterns, whose holographic reconstruction patterns show the super-bunching effect achieving g^(2)(0)=39.77. Finally, we discussed the positive influence of holographic noise on increasing the g^(2)(0) peak value. The presented work predicting the peak value of HBT effect not only is applicable for the lens imaging system but also in other projection systems, such as the holographic projection.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "The Manipulation of g^(2)(0) peak value of Hanbury Brown-Twiss (HBT) effect is discussed with a holographic projection scheme. By the aid of target pattern artificially designed in the projection imaging system, the statistical distribution of projection pattern will be highly controllable. In this work, we theoretically point out key factors influencing the g^(2)(0) peak value of HBT effect in a single-lens incoherent imaging system. We find the peak value is not only decided by statistical property and coherence length of target pattern but also depends on the intrinsic characteristics of projection system, such as numerical aperture and projection quality. Then, we experimentally measured the g^(2)(0) peak value of HBT effect with a phase-only holographic projection scheme and demonstrate the applicability of our theoretical analysis on the holographic scheme. Here, the super-bunching effect in the projection plane has been observed, when target patterns originated from chaotic speckle or it's function transformation patterns. Moreover, we design some sparse target patterns, whose holographic reconstruction patterns show the super-bunching effect achieving g^(2)(0)=39.77. Finally, we discussed the positive influence of holographic noise on increasing the g^(2)(0) peak value. The presented work predicting the peak value of HBT effect not only is applicable for the lens imaging system but also in other projection systems, such as the holographic projection."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-10-23T10:49:34Z",
            "published_parsed": [
                2025,
                10,
                23,
                10,
                49,
                34,
                3,
                296,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Liming Li"
                },
                {
                    "name": "Xueying Wu"
                },
                {
                    "name": "Gongxiang Wei"
                }
            ],
            "author_detail": {
                "name": "Gongxiang Wei"
            },
            "author": "Gongxiang Wei",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "全息投影主动控制经典光Hanbury Brown-Twiss效应的峰值",
            "abstract_cn": "讨论了全息投影方案对汉伯里布朗特威斯（HBT）效应g^(2)(0)峰值的操纵。借助投影成像系统中人工设计的目标图案，投影图案的统计分布将是高度可控的。在这项工作中，我们从理论上指出了单镜头非相干成像系统中影响HBT效应g^(2)(0)峰值的关键因素。我们发现峰值不仅取决于目标图案的统计特性和相干长度，还取决于投影系统的固有特性，例如数值孔径和投影质量。然后，我们用纯相位全息投影方案实验测量了HBT效应的g^(2)(0)峰值，并证明了我们的理论分析对全息方案的适用性。在这里，当目标图案源自混沌散斑或其函数变换图案时，在投影平面中观察到超聚束效应。此外，我们设计了一些稀疏目标图案，其全息重建图案显示出超聚束效应，达到g^(2)(0)=39.77。最后，我们讨论了全息噪声对增加 g^(2)(0) 峰值的积极影响。所提出的预测 HBT 效应峰值的工作不仅适用于镜头成像系统，也适用于其他投影系统，例如全息投影。"
        },
        {
            "id": "http://arxiv.org/abs/2510.25330v3",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2510.25330v3",
            "title": "Illuminating the lantern: coherent, spectro-polarimetric characterisation of a multimode converter",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Illuminating the lantern: coherent, spectro-polarimetric characterisation of a multimode converter"
            },
            "updated": "2026-01-08T09:11:46Z",
            "updated_parsed": [
                2026,
                1,
                8,
                9,
                11,
                46,
                3,
                8,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2510.25330v3",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2510.25330v3",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                },
                {
                    "rel": "related",
                    "href": "https://doi.org/10.1364/OE.583186",
                    "title": "doi",
                    "type": "text/html"
                }
            ],
            "summary": "While photonic lanterns efficiently and uniquely map a set of input modes to single-mode outputs (or vice versa), the optical mode transfer matrix of any particular fabricated device cannot be constrained at the design stage due to manufacturing imperfections. Accurate knowledge of the mapping enables complex sensing or beam control applications that leverage multimode conversion. In this work, we present a characterisation system to directly measure the electric field from a photonic lantern using digital off-axis holography, following its evolution over a 73 nm range near 1550 nm and in two orthogonal, linear polarisations. We provide the first multi-wavelength, polarisation decomposed characterisation of the principal modes of a photonic lantern. Performance of our testbed is validated on a single-mode fibre then harnessed to characterise a 19-port, multicore fibre fed photonic lantern. We uncover the typical wavelength scale at which the modal mapping evolves and measure the relative dispersion in the device, finding significant differences with idealised simulations. In addition to detailing the system, we also share the empirical mode transfer matrices, enabling future work in astrophotonic design, computational imaging, device fabrication feedback loops and beam shaping.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "While photonic lanterns efficiently and uniquely map a set of input modes to single-mode outputs (or vice versa), the optical mode transfer matrix of any particular fabricated device cannot be constrained at the design stage due to manufacturing imperfections. Accurate knowledge of the mapping enables complex sensing or beam control applications that leverage multimode conversion. In this work, we present a characterisation system to directly measure the electric field from a photonic lantern using digital off-axis holography, following its evolution over a 73 nm range near 1550 nm and in two orthogonal, linear polarisations. We provide the first multi-wavelength, polarisation decomposed characterisation of the principal modes of a photonic lantern. Performance of our testbed is validated on a single-mode fibre then harnessed to characterise a 19-port, multicore fibre fed photonic lantern. We uncover the typical wavelength scale at which the modal mapping evolves and measure the relative dispersion in the device, finding significant differences with idealised simulations. In addition to detailing the system, we also share the empirical mode transfer matrices, enabling future work in astrophotonic design, computational imaging, device fabrication feedback loops and beam shaping."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "astro-ph.IM",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-10-29T09:46:57Z",
            "published_parsed": [
                2025,
                10,
                29,
                9,
                46,
                57,
                2,
                302,
                0
            ],
            "arxiv_comment": "14 pages, 6 figures plus supplementary document",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "arxiv_journal_ref": "Opt. Express 34, 1012-1025 (2026)",
            "authors": [
                {
                    "name": "Adam K. Taras"
                },
                {
                    "name": "Barnaby R. M. Norris"
                },
                {
                    "name": "Christopher Betters"
                },
                {
                    "name": "Andrew Ross-Adams"
                },
                {
                    "name": "Peter G. Tuthill"
                },
                {
                    "name": "Jin Wei"
                },
                {
                    "name": "Sergio Leon-Saval"
                }
            ],
            "author_detail": {
                "name": "Sergio Leon-Saval"
            },
            "author": "Sergio Leon-Saval",
            "arxiv_doi": "10.1364/OE.583186",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "照亮灯笼：多模转换器的相干光谱偏振表征",
            "abstract_cn": "虽然光子灯有效且唯一地将一组输入模式映射到单模输出（反之亦然），但由于制造缺陷，任何特定制造设备的光学模式转移矩阵都不能在设计阶段受到限制。准确的映射知识可实现利用多模转换的复杂传感或光束控制应用。在这项工作中，我们提出了一种表征系统，可以使用数字离轴全息术直接测量光子灯笼的电场，跟踪其在 1550 nm 附近的 73 nm 范围内以及两个正交线偏振中的演变。我们首次提供了光子灯主模式的多波长、偏振分解表征。我们的测试台的性能在单模光纤上进行了验证，然后用于表征 19 端口、多芯光纤馈送光子灯笼。我们揭示了模态映射演变的典型波长尺度，并测量了器件中的相对色散，发现与理想化模拟的显着差异。除了详细介绍该系统之外，我们还分享了经验模式转移矩阵，从而使未来在天体光子设计、计算成像、设备制造反馈环路和光束整形方面的工作成为可能。"
        },
        {
            "id": "http://arxiv.org/abs/2510.26348v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2510.26348v1",
            "title": "Incoherent dielectric tensor tomography for quantitative 3D measurement of biaxial anisotropy",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Incoherent dielectric tensor tomography for quantitative 3D measurement of biaxial anisotropy"
            },
            "updated": "2025-10-30T10:55:34Z",
            "updated_parsed": [
                2025,
                10,
                30,
                10,
                55,
                34,
                3,
                303,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2510.26348v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2510.26348v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Biaxial anisotropy, arising from distinct optical responses along three principal directions, underlies the complex structure of many crystalline, polymeric, and biological materials. However, existing techniques such as X-ray diffraction and electron microscopy require specialized facilities or destructive preparation and cannot provide full three-dimensional (3D) information. Here we introduce incoherent dielectric tensor tomography (iDTT), a non-interferometric optical imaging method that quantitatively reconstructs the 3D dielectric tensor under incoherent, polarization-diverse illumination. By combining polarization diversity and angular-spectrum modulation, iDTT achieves speckle-free and vibration-robust mapping of biaxial birefringence with submicron resolution. Simulations and experiments on uniaxial and biaxial samples validate its quantitative accuracy. Applied to mixed and polycrystalline materials, iDTT distinguishes crystal types by their birefringent properties and reveals 3D grain orientations and boundaries. This approach establishes iDTT as a practical and accessible tool for quantitative, label-free characterization of biaxial anisotropy in diverse materials.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Biaxial anisotropy, arising from distinct optical responses along three principal directions, underlies the complex structure of many crystalline, polymeric, and biological materials. However, existing techniques such as X-ray diffraction and electron microscopy require specialized facilities or destructive preparation and cannot provide full three-dimensional (3D) information. Here we introduce incoherent dielectric tensor tomography (iDTT), a non-interferometric optical imaging method that quantitatively reconstructs the 3D dielectric tensor under incoherent, polarization-diverse illumination. By combining polarization diversity and angular-spectrum modulation, iDTT achieves speckle-free and vibration-robust mapping of biaxial birefringence with submicron resolution. Simulations and experiments on uniaxial and biaxial samples validate its quantitative accuracy. Applied to mixed and polycrystalline materials, iDTT distinguishes crystal types by their birefringent properties and reveals 3D grain orientations and boundaries. This approach establishes iDTT as a practical and accessible tool for quantitative, label-free characterization of biaxial anisotropy in diverse materials."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-10-30T10:55:34Z",
            "published_parsed": [
                2025,
                10,
                30,
                10,
                55,
                34,
                3,
                303,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Juheon Lee"
                },
                {
                    "name": "Yeon Wook Kim"
                },
                {
                    "name": "Hwanseok Chang"
                },
                {
                    "name": "Herve Hugonnet"
                },
                {
                    "name": "Seung-Mo Hong"
                },
                {
                    "name": "Seokwoo Jeon"
                },
                {
                    "name": "YongKeun Park"
                }
            ],
            "author_detail": {
                "name": "YongKeun Park"
            },
            "author": "YongKeun Park",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "用于双轴各向异性定量 3D 测量的非相干介电张量断层扫描",
            "abstract_cn": "双轴各向异性是由沿三个主要方向的不同光学响应引起的，是许多晶体、聚合物和生物材料复杂结构的基础。然而，X射线衍射和电子显微镜等现有技术需要专门的设施或破坏性制备，并且无法提供完整的三维（3D）信息。在这里，我们介绍非相干介电张量断层扫描 (iDTT)，这是一种非干涉光学成像方法，可在非相干、偏振分集照明下定量重建 3D 介电张量。通过结合偏振分集和角谱调制，iDTT 实现了亚微米分辨率的双轴双折射的无散斑和振动鲁棒映射。单轴和双轴样品的模拟和实验验证了其定量精度。应用于混合和多晶材料时，iDTT 通过双折射特性来区分晶体类型，并揭示 3D 晶粒取向和边界。这种方法使 iDTT 成为一种实用且易于使用的工具，用于定量、无标记地表征不同材料中的双轴各向异性。"
        },
        {
            "id": "http://arxiv.org/abs/2510.26414v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2510.26414v1",
            "title": "Generation and detection of squeezed states via a synchronously pumped optical parametric oscillator",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Generation and detection of squeezed states via a synchronously pumped optical parametric oscillator"
            },
            "updated": "2025-10-30T12:02:23Z",
            "updated_parsed": [
                2025,
                10,
                30,
                12,
                2,
                23,
                3,
                303,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2510.26414v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2510.26414v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "A synchronously pumped optical parametric oscillator (SPOPO) operating at 93 MHz is used to generate squeezed states at 1035 nm. The system features a counter-propagating beam at the same wavelength as the quantum state, which simultaneously actively stabilizes the cavity and, after transmission, acts as the local oscillator for homodyne detection. By deriving the local oscillator directly from the SPOPO cavity, the setup establishes an intrinsically excellent spatial mode overlap and high interference visibility, forming a distinctive self-referenced architecture. Two spatial light modulators enable precise spectral shaping of both the pump and the local oscillator in amplitude and phase, allowing investigation of the spectral properties of the generated states. The versatility of the setup further allows exploration of different SPOPO configurations, including regimes with varied finesse and escape efficiency. Representative measurements, including homodyne traces and squeezing levels as functions of pump power and local oscillator bandwidth, demonstrate the performance of the system. Theoretical simulations based on a multimode singular-value-decomposition model reproduce well the measured dependence of squeezing on pump power and LO bandwidth, confirming the accuracy of the description and the robustness of the setup. Measured squeezing levels up to -3.3 dB are achieved, corresponding to -5.7 dB at SPOPO output, evidencing the robustness and versatility of this platform for stable pulsed squeezed-light generation and advanced quantum optical applications.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "A synchronously pumped optical parametric oscillator (SPOPO) operating at 93 MHz is used to generate squeezed states at 1035 nm. The system features a counter-propagating beam at the same wavelength as the quantum state, which simultaneously actively stabilizes the cavity and, after transmission, acts as the local oscillator for homodyne detection. By deriving the local oscillator directly from the SPOPO cavity, the setup establishes an intrinsically excellent spatial mode overlap and high interference visibility, forming a distinctive self-referenced architecture. Two spatial light modulators enable precise spectral shaping of both the pump and the local oscillator in amplitude and phase, allowing investigation of the spectral properties of the generated states. The versatility of the setup further allows exploration of different SPOPO configurations, including regimes with varied finesse and escape efficiency. Representative measurements, including homodyne traces and squeezing levels as functions of pump power and local oscillator bandwidth, demonstrate the performance of the system. Theoretical simulations based on a multimode singular-value-decomposition model reproduce well the measured dependence of squeezing on pump power and LO bandwidth, confirming the accuracy of the description and the robustness of the setup. Measured squeezing levels up to -3.3 dB are achieved, corresponding to -5.7 dB at SPOPO output, evidencing the robustness and versatility of this platform for stable pulsed squeezed-light generation and advanced quantum optical applications."
            },
            "tags": [
                {
                    "term": "quant-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-10-30T12:02:23Z",
            "published_parsed": [
                2025,
                10,
                30,
                12,
                2,
                23,
                3,
                303,
                0
            ],
            "arxiv_primary_category": {
                "term": "quant-ph"
            },
            "authors": [
                {
                    "name": "Edoardo Suerra"
                },
                {
                    "name": "Samuele Altilia"
                },
                {
                    "name": "Stefano Olivares"
                },
                {
                    "name": "Alessandro Ferraro"
                },
                {
                    "name": "Francesco Canella"
                },
                {
                    "name": "Dario Giannotti"
                },
                {
                    "name": "Gianluca Galzerano"
                },
                {
                    "name": "Sebastiano Corli"
                },
                {
                    "name": "Enrico Prati"
                },
                {
                    "name": "Simone Cialdi"
                }
            ],
            "author_detail": {
                "name": "Simone Cialdi"
            },
            "author": "Simone Cialdi",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "通过同步泵浦光参量振荡器生成和检测压缩态",
            "abstract_cn": "工作频率为 93 MHz 的同步泵浦光参量振荡器 (SPOPO) 用于生成 1035 nm 的压缩态。该系统具有与量子态波长相同的反向传播光束，它同时主动稳定腔体，并在传输后充当零差检测的本地振荡器。通过直接从 SPOPO 腔导出本地振荡器，该装置建立了本质上优异的空间模式重叠和高干扰可见性，形成了独特的自参考架构。两个空间光调制器可以对泵浦和本地振荡器的幅度和相位进行精确的光谱整形，从而可以研究所生成状态的光谱特性。该设置的多功能性进一步允许探索不同的 SPOPO 配置，包括具有不同技巧和逃逸效率的机制。代表性测量，包括作为泵浦功率和本地振荡器带宽函数的零差迹线和压缩水平，展示了系统的性能。基于多模奇异值分解模型的理论模拟很好地再现了测量到的压缩对泵浦功率和本振带宽的依赖性，证实了描述的准确性和设置的鲁棒性。测得的压缩水平高达 -3.3 dB，相当于 SPOPO 输出的 -5.7 dB，证明了该平台在稳定脉冲压缩光生成和先进量子光学应用方面的稳健性和多功能性。"
        },
        {
            "id": "http://arxiv.org/abs/2510.27620v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2510.27620v1",
            "title": "Intensity-Correlation Synthetic Wavelength Imaging in Dynamic Scattering Media",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Intensity-Correlation Synthetic Wavelength Imaging in Dynamic Scattering Media"
            },
            "updated": "2025-10-31T16:44:24Z",
            "updated_parsed": [
                2025,
                10,
                31,
                16,
                44,
                24,
                4,
                304,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2510.27620v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2510.27620v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Imaging through dynamic scattering media, such as biological tissue, presents a fundamental challenge due to light scattering and the formation of speckle patterns. These patterns not only degrade image quality but also decorrelate rapidly, limiting the effectiveness of conventional approaches, such as those based on transmission matrix measurements. Here, we introduce an imaging approach based on second-order correlations and synthetic wavelength holography (SWH) to enable robust image reconstruction through thick and dynamic scattering media. By exploiting intensity speckle correlations and using short-exposure intensity images, our method computationally reconstructs images from a hologram without requiring phase stability or static speckles, making it inherently resilient to phase noise. Experimental results demonstrate high-resolution imaging in both static and dynamic scattering scenarios, offering a promising solution for biomedical imaging, remote sensing, and real-time imaging in complex environments.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Imaging through dynamic scattering media, such as biological tissue, presents a fundamental challenge due to light scattering and the formation of speckle patterns. These patterns not only degrade image quality but also decorrelate rapidly, limiting the effectiveness of conventional approaches, such as those based on transmission matrix measurements. Here, we introduce an imaging approach based on second-order correlations and synthetic wavelength holography (SWH) to enable robust image reconstruction through thick and dynamic scattering media. By exploiting intensity speckle correlations and using short-exposure intensity images, our method computationally reconstructs images from a hologram without requiring phase stability or static speckles, making it inherently resilient to phase noise. Experimental results demonstrate high-resolution imaging in both static and dynamic scattering scenarios, offering a promising solution for biomedical imaging, remote sensing, and real-time imaging in complex environments."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-10-31T16:44:24Z",
            "published_parsed": [
                2025,
                10,
                31,
                16,
                44,
                24,
                4,
                304,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Khaled Kassem"
                },
                {
                    "name": "Areeba Fatima"
                },
                {
                    "name": "Patrick Cornwall"
                },
                {
                    "name": "Muralidhar Madabhushi Balaji"
                },
                {
                    "name": "Daniele Faccio"
                },
                {
                    "name": "Florian Willomitzer"
                }
            ],
            "author_detail": {
                "name": "Florian Willomitzer"
            },
            "author": "Florian Willomitzer",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "动态散射介质中的强度相关合成波长成像",
            "abstract_cn": "由于光散射和散斑图案的形成，通过动态散射介质（例如生物组织）成像提出了根本性的挑战。这些图案不仅会降低图像质量，还会快速去相关，从而限制了传统方法（例如基于传输矩阵测量的方法）的有效性。在这里，我们介绍了一种基于二阶相关性和合成波长全息术（SWH）的成像方法，以通过厚的动态散射介质实现稳健的图像重建。通过利用强度散斑相关性并使用短曝光强度图像，我们的方法通过计算从全息图重建图像，而不需要相位稳定性或静态散斑，使其具有固有的抗相位噪声能力。实验结果证明了静态和动态散射场景下的高分辨率成像，为复杂环境下的生物医学成像、遥感和实时成像提供了有前景的解决方案。"
        },
        {
            "id": "http://arxiv.org/abs/2511.02202v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2511.02202v1",
            "title": "Lithium Niobate Vertical Cavity Electro-Optic Modulator",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Lithium Niobate Vertical Cavity Electro-Optic Modulator"
            },
            "updated": "2025-11-04T02:45:36Z",
            "updated_parsed": [
                2025,
                11,
                4,
                2,
                45,
                36,
                1,
                308,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2511.02202v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2511.02202v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Electro-optic modulators (EOMs) are vital for optical imaging and information processing, with free-space devices enabling LiDAR and beam control. Lithium niobate (LN), powered by the strong Pockels effect and scalable LN-on-insulator (LNOI) platform, has become a leading material for high-performance EOMs. Here we realize a vertical-cavity EOM in which an LN membrane is sandwiched between two photonic crystal (PhC) mirrors with integrated electrodes. The cavity supports sharp defect-mode resonances that shift efficiently under the Pockels effect, enabling strong modulation of transmission. Experiments show a depth of 43 % at 50 V and a bandwidth of 5 MHz. This architecture combines free-space compatibility with fabrication simplicity, opening new routes to compact electro-optic platforms for ranging, holography, and beam steering.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Electro-optic modulators (EOMs) are vital for optical imaging and information processing, with free-space devices enabling LiDAR and beam control. Lithium niobate (LN), powered by the strong Pockels effect and scalable LN-on-insulator (LNOI) platform, has become a leading material for high-performance EOMs. Here we realize a vertical-cavity EOM in which an LN membrane is sandwiched between two photonic crystal (PhC) mirrors with integrated electrodes. The cavity supports sharp defect-mode resonances that shift efficiently under the Pockels effect, enabling strong modulation of transmission. Experiments show a depth of 43 % at 50 V and a bandwidth of 5 MHz. This architecture combines free-space compatibility with fabrication simplicity, opening new routes to compact electro-optic platforms for ranging, holography, and beam steering."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-04T02:45:36Z",
            "published_parsed": [
                2025,
                11,
                4,
                2,
                45,
                36,
                1,
                308,
                0
            ],
            "arxiv_comment": "7 pages, 4 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Jikun Liu"
                },
                {
                    "name": "Weiye Liu"
                },
                {
                    "name": "Wei Wu"
                },
                {
                    "name": "Ziang Guo"
                },
                {
                    "name": "Changrui Zhu"
                },
                {
                    "name": "Lun Qu"
                },
                {
                    "name": "Pengfei Zhu"
                },
                {
                    "name": "Yiting Zhang"
                },
                {
                    "name": "Zhihao Chen"
                },
                {
                    "name": "Qinglian Li"
                },
                {
                    "name": "Dahuai Zheng"
                },
                {
                    "name": "Hongde Liu"
                },
                {
                    "name": "Shaowei Wang"
                },
                {
                    "name": "Wei Cai"
                },
                {
                    "name": "Mengxin Ren"
                },
                {
                    "name": "Jingjun Xu"
                }
            ],
            "author_detail": {
                "name": "Jingjun Xu"
            },
            "author": "Jingjun Xu",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "铌酸锂垂直腔电光调制器",
            "abstract_cn": "电光调制器 (EOM) 对于光学成像和信息处理至关重要，自由空间设备可实现激光雷达和光束控制。铌酸锂 (LN) 凭借强大的普克尔斯效应和可扩展的绝缘体上 LN (LNOI) 平台，已成为高性能 EOM 的领先材料。在这里，我们实现了一个垂直腔 EOM，其中 LN 膜夹在两个带有集成电极的光子晶体 (PhC) 镜之间。该腔支持尖锐的缺陷模式谐振，该谐振在普克尔斯效应下有效转移，从而实现强传输调制。实验显示，50 V 电压下深度为 43%，带宽为 5 MHz。该架构将自由空间兼容性与制造简单性结合起来，为紧凑型电光平台的测距、全息和光束控制开辟了新途径。"
        },
        {
            "id": "http://arxiv.org/abs/2511.03175v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2511.03175v1",
            "title": "Correcting Fabrication-Induced Curvature in Micromirror-Based Spatial Light Modulators with a Microlens Array",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Correcting Fabrication-Induced Curvature in Micromirror-Based Spatial Light Modulators with a Microlens Array"
            },
            "updated": "2025-11-05T04:48:20Z",
            "updated_parsed": [
                2025,
                11,
                5,
                4,
                48,
                20,
                2,
                309,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2511.03175v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2511.03175v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Computer generated holography requires high-speed spatial light modulators (SLMs) for dynamically patterning light in 3D. Piston-motion micromirror-based SLMs support high-speed ($\\geq$ 10 kHz) phase modulation; however, fabricating micromirror arrays with sufficient fill factor necessary for high diffraction efficiency is challenging. In particular, the larger mirrors of high fill factor designs are susceptible to stress-induced curvature that significantly degrades optical performance. In this work, we introduce an optical compensation method using a pitch-matched microlens array (MLA) to focus light onto just the center of each mirror. Our approach thus avoids curvature-induced artifacts and improves optical fill factor to nearly 100$\\%$, independent of the original mechanical fill factor. Through simulations and experiments on a fabricated micromirror array with bowed mirrors, we show that the Pearson correlation coefficient of the imparted phase profile is improved from 0.11 to 0.85 and the brightness of a holographically-generated single spot is enhanced by 8$\\times$ with our microlens array in place. Our hybrid optical-electromechanical strategy thus provides a scalable path toward high-speed, high-fidelity wavefront control for applications such as adaptive optics, holographic displays, and optogenetics.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Computer generated holography requires high-speed spatial light modulators (SLMs) for dynamically patterning light in 3D. Piston-motion micromirror-based SLMs support high-speed ($\\geq$ 10 kHz) phase modulation; however, fabricating micromirror arrays with sufficient fill factor necessary for high diffraction efficiency is challenging. In particular, the larger mirrors of high fill factor designs are susceptible to stress-induced curvature that significantly degrades optical performance. In this work, we introduce an optical compensation method using a pitch-matched microlens array (MLA) to focus light onto just the center of each mirror. Our approach thus avoids curvature-induced artifacts and improves optical fill factor to nearly 100$\\%$, independent of the original mechanical fill factor. Through simulations and experiments on a fabricated micromirror array with bowed mirrors, we show that the Pearson correlation coefficient of the imparted phase profile is improved from 0.11 to 0.85 and the brightness of a holographically-generated single spot is enhanced by 8$\\times$ with our microlens array in place. Our hybrid optical-electromechanical strategy thus provides a scalable path toward high-speed, high-fidelity wavefront control for applications such as adaptive optics, holographic displays, and optogenetics."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-05T04:48:20Z",
            "published_parsed": [
                2025,
                11,
                5,
                4,
                48,
                20,
                2,
                309,
                0
            ],
            "arxiv_comment": "This paper has been submitted to Optica for peer review",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Munkyu Kang"
                },
                {
                    "name": "Elizabeth Murray"
                },
                {
                    "name": "Leyla A. Kabuli"
                },
                {
                    "name": "Rikky Muller"
                },
                {
                    "name": "Laura Waller"
                }
            ],
            "author_detail": {
                "name": "Laura Waller"
            },
            "author": "Laura Waller",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "使用微透镜阵列校正基于微镜的空间光调制器中制造引起的曲率",
            "abstract_cn": "计算机生成的全息术需要高速空间光调制器 (SLM) 来动态形成 3D 光图案。基于活塞运动微镜的 SLM 支持高速（$\\geq$ 10 kHz）相位调制；然而，制造具有高衍射效率所需的足够填充因子的微镜阵列具有挑战性。特别是，高填充因子设计的较大反射镜容易受到应力引起的曲率的影响，从而显着降低光学性能。在这项工作中，我们引入了一种光学补偿方法，使用间距匹配的微透镜阵列（MLA）将光线聚焦到每个镜子的中心。因此，我们的方法避免了曲率引起的伪影，并将光学填充因子提高到接近 100$\\%$，与原始机械填充因子无关。通过对带有弓形镜的制造微镜阵列进行模拟和实验，我们表明，在我们的微透镜阵列到位的情况下，所赋予的相位轮廓的皮尔逊相关系数从 0.11 提高到 0.85，全息生成的单点亮度提高了 8 倍。因此，我们的混合光机电策略为自适应光学、全息显示和光遗传学等应用提供了一条实现高速、高保真波前控制的可扩展路径。"
        },
        {
            "id": "http://arxiv.org/abs/2511.03583v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2511.03583v1",
            "title": "2D Addressable Mid-infrared Metasurface Spatial Light Modulator",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "2D Addressable Mid-infrared Metasurface Spatial Light Modulator"
            },
            "updated": "2025-11-05T16:04:32Z",
            "updated_parsed": [
                2025,
                11,
                5,
                16,
                4,
                32,
                2,
                309,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2511.03583v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2511.03583v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Active metasurfaces enable dynamic control of light for applications in beam steering, pixelated holography, and adaptive optics, but demonstrations of two-dimensional (2D) electrically addressable arrays have so far been limited. Here we introduce a scalable 2D architecture based on phase-change materials (PCMs) integrated metasurfaces and apply it to realize the first transmissive mid-infrared (mid-IR) spatial light modulator (SLM). The device is fabricated through standard silicon photonic foundry processing combined with backend-of-line (BEOL) integration and employs multilayer backend metal interconnects to implement a crossbar addressing scheme. Each pixel is integrated with a silicon diode selector to suppress sneak-path currents, a feature essential for scaling to large arrays. The result establishes a foundry-compatible route to high-density, large-area active metasurfaces with independently tunable pixels.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Active metasurfaces enable dynamic control of light for applications in beam steering, pixelated holography, and adaptive optics, but demonstrations of two-dimensional (2D) electrically addressable arrays have so far been limited. Here we introduce a scalable 2D architecture based on phase-change materials (PCMs) integrated metasurfaces and apply it to realize the first transmissive mid-infrared (mid-IR) spatial light modulator (SLM). The device is fabricated through standard silicon photonic foundry processing combined with backend-of-line (BEOL) integration and employs multilayer backend metal interconnects to implement a crossbar addressing scheme. Each pixel is integrated with a silicon diode selector to suppress sneak-path currents, a feature essential for scaling to large arrays. The result establishes a foundry-compatible route to high-density, large-area active metasurfaces with independently tunable pixels."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-05T16:04:32Z",
            "published_parsed": [
                2025,
                11,
                5,
                16,
                4,
                32,
                2,
                309,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Cosmin-Constantin Popescu"
                },
                {
                    "name": "Maarten Robbert Anton Peters"
                },
                {
                    "name": "Oleg Maksimov"
                },
                {
                    "name": "Harish Bhandari"
                },
                {
                    "name": "Rashi Sharma"
                },
                {
                    "name": "Kathleen Richardson"
                },
                {
                    "name": "Arka Majumdar"
                },
                {
                    "name": "Hyun Jung Kim"
                },
                {
                    "name": "Rui Chen"
                },
                {
                    "name": "Khoi Phuong Dao"
                },
                {
                    "name": "Luigi Ranno"
                },
                {
                    "name": "Brian Mills"
                },
                {
                    "name": "Dennis Calahan"
                },
                {
                    "name": "Tian Gu"
                },
                {
                    "name": "Juejun Hu"
                }
            ],
            "author_detail": {
                "name": "Juejun Hu"
            },
            "author": "Juejun Hu",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "二维可寻址中红外超表面空间光调制器",
            "abstract_cn": "有源超表面能够动态控制光束控制、像素化全息术和自适应光学等应用中的光，但二维 (2D) 电可寻址阵列的演示迄今为止还很有限。在这里，我们介绍了一种基于相变材料（PCM）集成超表面的可扩展2D架构，并将其应用于实现第一个透射式中红外（mid-IR）空间光调制器（SLM）。该器件通过标准硅光子代工工艺与后端生产线 (BEOL) 集成相结合而制造，并采用多层后端金属互连来实现交叉寻址方案。每个像素都与硅二极管选择器集成，以抑制潜行电流，这是扩展到大型阵列的重要功能。结果建立了一条与铸造厂兼容的路线，以实现具有独立可调像素的高密度、大面积有源超表面。"
        },
        {
            "id": "http://arxiv.org/abs/2511.03860v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2511.03860v1",
            "title": "Ultrafast, reconfigurable all-optical beam steering and spatial light modulation",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Ultrafast, reconfigurable all-optical beam steering and spatial light modulation"
            },
            "updated": "2025-11-05T21:04:56Z",
            "updated_parsed": [
                2025,
                11,
                5,
                21,
                4,
                56,
                2,
                309,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2511.03860v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2511.03860v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Achieving spatiotemporal control of light at subwavelength and subcycle scales is an important milestone in the development of new photonic materials and technologies. Ultrafast spatiotemporal light modulation currently relies on electronic interband and intraband transitions that yield pronounced refractive index changes but typically suffer from slow, picosecond response times due to carrier relaxation. Here we show that by leveraging resonant light-matter interactions in a high-quality factor metasurface it is possible to use the optical Kerr effect, a weaker, but instantaneous optoelectronic polarization effect, to achieve ultrafast, reconfigurable light modulation with unprecedented spatial and temporal control. By the subwavelength all-optical tuning of the refractive index of the dielectric metasurface unit cells, we experimentally demonstrate pulse-limited beam steering with a 74-fs response time at angles up to $\\pm $13° in the near-infrared. The steering originates from the Kerr effect with a background contribution arising from slower two-photon-excited free carrier absorption. Additionally, we observe spatial back-action, linear frequency conversion, and demonstrate arbitrary ultrafast spatial light modulation in two dimensions. Our findings open the possibility of realizing new ultrafast physics in metastructures with applications in signal processing, pulse shaping, and ultrafast imaging.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Achieving spatiotemporal control of light at subwavelength and subcycle scales is an important milestone in the development of new photonic materials and technologies. Ultrafast spatiotemporal light modulation currently relies on electronic interband and intraband transitions that yield pronounced refractive index changes but typically suffer from slow, picosecond response times due to carrier relaxation. Here we show that by leveraging resonant light-matter interactions in a high-quality factor metasurface it is possible to use the optical Kerr effect, a weaker, but instantaneous optoelectronic polarization effect, to achieve ultrafast, reconfigurable light modulation with unprecedented spatial and temporal control. By the subwavelength all-optical tuning of the refractive index of the dielectric metasurface unit cells, we experimentally demonstrate pulse-limited beam steering with a 74-fs response time at angles up to $\\pm $13° in the near-infrared. The steering originates from the Kerr effect with a background contribution arising from slower two-photon-excited free carrier absorption. Additionally, we observe spatial back-action, linear frequency conversion, and demonstrate arbitrary ultrafast spatial light modulation in two dimensions. Our findings open the possibility of realizing new ultrafast physics in metastructures with applications in signal processing, pulse shaping, and ultrafast imaging."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-05T21:04:56Z",
            "published_parsed": [
                2025,
                11,
                5,
                21,
                4,
                56,
                2,
                309,
                0
            ],
            "arxiv_comment": "27 pages, 20 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Claudio U. Hail"
                },
                {
                    "name": "Lior Michaeli"
                },
                {
                    "name": "Harry A. Atwater"
                }
            ],
            "author_detail": {
                "name": "Harry A. Atwater"
            },
            "author": "Harry A. Atwater",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "超快、可重构的全光束控制和空间光调制",
            "abstract_cn": "在亚波长和亚周期尺度上实现光的时空控制是新型光子材料和技术发展的一个重要里程碑。超快时空光调制目前依赖于电子带间和带内跃迁，这些跃迁会产生显着的折射率变化，但通常会因载流子弛豫而受到缓慢的皮秒响应时间的影响。在这里，我们表明，通过利用高质量因子超表面中的共振光与物质相互作用，可以使用光学克尔效应（一种较弱但瞬时的光电偏振效应）来实现具有前所未有的空间和时间控制的超快、可重构光调制。通过对介电超表面晶胞的折射率进行亚波长全光学调谐，我们通过实验证明了脉冲限制光束控制，在近红外区域的角度高达 $\\pm $13° 时具有 74-fs 的响应时间。转向源自克尔效应，其背景贡献来自较慢的双光子激发自由载流子吸收。此外，我们观察了空间反作用、线性频率转换，并演示了二维中的任意超快空间光调制。我们的研究结果开启了在元结构中实现新的超快物理学及其在信号处理、脉冲整形和超快成像中的应用的可能性。"
        },
        {
            "id": "http://arxiv.org/abs/2511.07149v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2511.07149v1",
            "title": "Geometric phase metasurfaces for linearly polarized light",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Geometric phase metasurfaces for linearly polarized light"
            },
            "updated": "2025-11-10T14:40:43Z",
            "updated_parsed": [
                2025,
                11,
                10,
                14,
                40,
                43,
                0,
                314,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2511.07149v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2511.07149v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "The geometric phase is a universal concept in modern physics and has enabled the development of metasurfaces for versatile wavefront shaping. However, its realization in metasurfaces has been restricted to circularly polarized light, confining geometric phase metasurfaces to helicity-dependent operation and excluding them from the linear-polarization domain that dominates modern optics. In this work, we overcome this limitation by harnessing exceptional points of non-Hermitian physics. We introduce and experimentally realize quasi-exceptional-point metasurfaces that exploit engineered singularities to directly impart a geometric phase onto linearly polarized light. Proof-of-principle demonstrations with gratings and holograms confirm broadband and high-fidelity wavefront shaping across arbitrary linear polarizations, which has not been achieved with previous phase modulation approaches. By revealing an intrinsic connection between geometric phase and non-Hermitian photonics, our work resolves a long-standing theoretical impasse and establishes a new framework for high-dimensional light control, opening opportunities for scalable polarization optics, advanced imaging, holography, optical communications, and integrated photonics.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "The geometric phase is a universal concept in modern physics and has enabled the development of metasurfaces for versatile wavefront shaping. However, its realization in metasurfaces has been restricted to circularly polarized light, confining geometric phase metasurfaces to helicity-dependent operation and excluding them from the linear-polarization domain that dominates modern optics. In this work, we overcome this limitation by harnessing exceptional points of non-Hermitian physics. We introduce and experimentally realize quasi-exceptional-point metasurfaces that exploit engineered singularities to directly impart a geometric phase onto linearly polarized light. Proof-of-principle demonstrations with gratings and holograms confirm broadband and high-fidelity wavefront shaping across arbitrary linear polarizations, which has not been achieved with previous phase modulation approaches. By revealing an intrinsic connection between geometric phase and non-Hermitian photonics, our work resolves a long-standing theoretical impasse and establishes a new framework for high-dimensional light control, opening opportunities for scalable polarization optics, advanced imaging, holography, optical communications, and integrated photonics."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-10T14:40:43Z",
            "published_parsed": [
                2025,
                11,
                10,
                14,
                40,
                43,
                0,
                314,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Yubin Gao"
                },
                {
                    "name": "Qikai Chen"
                },
                {
                    "name": "Yaoguang Ma"
                }
            ],
            "author_detail": {
                "name": "Yaoguang Ma"
            },
            "author": "Yaoguang Ma",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "线偏振光的几何相位超表面",
            "abstract_cn": "几何相位是现代物理学中的一个普遍概念，并促进了用于多功能波前整形的超表面的发展。然而，它在超表面中的实现仅限于圆偏振光，将几何相位超表面限制为依赖于螺旋性的操作，并将它们排除在主导现代光学的线偏振域之外。在这项工作中，我们通过利用非厄米物理学的特殊点克服了这一限制。我们引入并通过实验实现了准例外点超表面，该超表面利用工程奇点将几何相位直接传递给线偏振光。使用光栅和全息图的原理验证演示证实了跨任意线性偏振的宽带和高保真波前整形，这是以前的相位调制方法无法实现的。通过揭示几何相位和非厄米光子学之间的内在联系，我们的工作解决了长期存在的理论僵局，并建立了高维光控制的新框架，为可扩展的偏振光学、先进成像、全息术、光通信和集成光子学提供了机会。"
        },
        {
            "id": "http://arxiv.org/abs/2511.09440v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2511.09440v1",
            "title": "Tutorial: A practical guide to the alignment of defocused spatial light modulators for fast diffractive neural networks",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Tutorial: A practical guide to the alignment of defocused spatial light modulators for fast diffractive neural networks"
            },
            "updated": "2025-11-12T15:55:04Z",
            "updated_parsed": [
                2025,
                11,
                12,
                15,
                55,
                4,
                2,
                316,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2511.09440v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2511.09440v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "The conjugation of multiple spatial light modulators (SLMs) enables the construction of optical diffractive neural networks (DNNs). To accelerate training, limited by the low refresh rate of SLMs, spatial multiplexing of the input data across different spatial channels is possible maximizing the number of available spatial degrees of freedom (DoFs). Precise alignment is required in order to ensure that the same physical operation is performed across each channel. We present a semi-automatic procedure for this experimentally challenging alignment resulting in a pixel-level conjugation. It is scalable to any number of SLMs and may be useful in wavefront shaping setups where precise conjugation of SLMs is required, e.g. for the control of optical waves in phase and amplitude. The resulting setup functions as an optical DNN able to process hundreds of inputs simultaneously, thereby reducing training times and experimental noise through spatial averaging. We further present a characterization of the setup and an alignment method.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "The conjugation of multiple spatial light modulators (SLMs) enables the construction of optical diffractive neural networks (DNNs). To accelerate training, limited by the low refresh rate of SLMs, spatial multiplexing of the input data across different spatial channels is possible maximizing the number of available spatial degrees of freedom (DoFs). Precise alignment is required in order to ensure that the same physical operation is performed across each channel. We present a semi-automatic procedure for this experimentally challenging alignment resulting in a pixel-level conjugation. It is scalable to any number of SLMs and may be useful in wavefront shaping setups where precise conjugation of SLMs is required, e.g. for the control of optical waves in phase and amplitude. The resulting setup functions as an optical DNN able to process hundreds of inputs simultaneously, thereby reducing training times and experimental noise through spatial averaging. We further present a characterization of the setup and an alignment method."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-12T15:55:04Z",
            "published_parsed": [
                2025,
                11,
                12,
                15,
                55,
                4,
                2,
                316,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Guillaume Noetinger"
                },
                {
                    "name": "Tim Tuuva"
                },
                {
                    "name": "Romain Fleury"
                }
            ],
            "author_detail": {
                "name": "Romain Fleury"
            },
            "author": "Romain Fleury",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "教程：用于快速衍射神经网络的散焦空间光调制器对齐的实用指南",
            "abstract_cn": "多个空间光调制器 (SLM) 的结合可以构建光学衍射神经网络 (DNN)。为了加速训练，受 SLM 低刷新率的限制，可以跨不同空间通道对输入数据进行空间复用，从而最大化可用空间自由度 (DoF) 的数量。需要精确对齐以确保在每个通道上执行相同的物理操作。我们提出了一种半自动程序，用于这种具有实验挑战性的对齐，从而产生像素级共轭。它可扩展至任意数量的 SLM，并且在需要 SLM 精确共轭的波前整形设置中可能很有用，例如用于控制光波的相位和幅度。由此产生的设置充当光学 DNN，能够同时处理数百个输入，从而通过空间平均减少训练时间和实验噪声。我们进一步介绍了该设置的特征和对齐方法。"
        },
        {
            "id": "http://arxiv.org/abs/2511.11158v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2511.11158v1",
            "title": "Deep Learning-Enhanced Analysis for Delineating Anticoagulant Essay Efficacy Using Phase Microscopy",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Deep Learning-Enhanced Analysis for Delineating Anticoagulant Essay Efficacy Using Phase Microscopy"
            },
            "updated": "2025-11-14T10:39:21Z",
            "updated_parsed": [
                2025,
                11,
                14,
                10,
                39,
                21,
                4,
                318,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2511.11158v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2511.11158v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "The coagulation of blood after it is drawn from the body poses a significant challenge for hematological analysis, potentially leading to inaccurate test results and altered cellular characteristics, compromising diagnostic reliability. This paper presents a deep learning-enhanced framework for delineating anticoagulant efficacy ex vivo using Digital Holographic Microscopy (DHM). We demonstrate a label-free, non-invasive approach for analyzing human blood samples, capable of accurate cell counting and morphological estimation. A DHM with an automated image processing and deep learning pipeline is built for morphological analysis of the blood cells under two different anti-coagulation agents, e.g. conventional EDTA and novel potassium ferric oxalate nanoparticles (KFeOx-NPs). This enables automated high-throughput screening of cells and estimation of blood coagulation rates when samples are treated with different anticoagulants. Results indicated that KFeOx-NPs prevented human blood coagulation without altering the cellular morphology of red blood cells (RBCs), whereas EDTA incubation caused notable changes within 6 hours of incubation. The system allows for quantitative analysis of coagulation dynamics by assessing parameters like cell clustering and morphology over time in these prepared samples, offering insights into the comparative efficacy and effects of anticoagulants outside the body.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "The coagulation of blood after it is drawn from the body poses a significant challenge for hematological analysis, potentially leading to inaccurate test results and altered cellular characteristics, compromising diagnostic reliability. This paper presents a deep learning-enhanced framework for delineating anticoagulant efficacy ex vivo using Digital Holographic Microscopy (DHM). We demonstrate a label-free, non-invasive approach for analyzing human blood samples, capable of accurate cell counting and morphological estimation. A DHM with an automated image processing and deep learning pipeline is built for morphological analysis of the blood cells under two different anti-coagulation agents, e.g. conventional EDTA and novel potassium ferric oxalate nanoparticles (KFeOx-NPs). This enables automated high-throughput screening of cells and estimation of blood coagulation rates when samples are treated with different anticoagulants. Results indicated that KFeOx-NPs prevented human blood coagulation without altering the cellular morphology of red blood cells (RBCs), whereas EDTA incubation caused notable changes within 6 hours of incubation. The system allows for quantitative analysis of coagulation dynamics by assessing parameters like cell clustering and morphology over time in these prepared samples, offering insights into the comparative efficacy and effects of anticoagulants outside the body."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-14T10:39:21Z",
            "published_parsed": [
                2025,
                11,
                14,
                10,
                39,
                21,
                4,
                318,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "S. Shrivastava"
                },
                {
                    "name": "M. Rathor"
                },
                {
                    "name": "D. Yenurkar"
                },
                {
                    "name": "S. K. Chaubey"
                },
                {
                    "name": "S. Mukherjee"
                },
                {
                    "name": "R. K. Singh"
                }
            ],
            "author_detail": {
                "name": "R. K. Singh"
            },
            "author": "R. K. Singh",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "使用相差显微镜描绘抗凝论文功效的深度学习增强分析",
            "abstract_cn": "从体内抽取血液后的凝固对血液学分析提出了重大挑战，可能导致测试结果不准确和细胞特征改变，从而损害诊断可靠性。本文提出了一种深度学习增强框架，用于使用数字全息显微镜 (DHM) 描述离体抗凝功效。我们展示了一种用于分析人类血液样本的无标记、非侵入性方法，能够进行准确的细胞计数和形态学估计。构建具有自动图像处理和深度学习流程的 DHM，用于对两种不同抗凝剂（例如，抗凝血剂）下的血细胞进行形态学分析。传统的 EDTA 和新型草酸铁钾纳米粒子 (KFeOx-NPs)。当样品用不同的抗凝剂处理时，这可以实现细胞的自动高通量筛选和血液凝固率的估计。结果表明，KFeOx-NPs 可防止人体血液凝固，但不会改变红细胞 (RBC) 的细胞形态，而 EDTA 孵育在孵育 6 小时内会引起显着变化。该系统可以通过评估这些准备好的样品中细胞簇和形态等参数随时间的变化来定量分析凝血动力学，从而深入了解体外抗凝剂的比较功效和作用。"
        },
        {
            "id": "http://arxiv.org/abs/2511.12440v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2511.12440v1",
            "title": "Spectro-Polarimetric Holographic Multiplexing Metasurface with Super-High Capacity Empowered by Mechanical Rotation",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Spectro-Polarimetric Holographic Multiplexing Metasurface with Super-High Capacity Empowered by Mechanical Rotation"
            },
            "updated": "2025-11-16T03:49:55Z",
            "updated_parsed": [
                2025,
                11,
                16,
                3,
                49,
                55,
                6,
                320,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2511.12440v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2511.12440v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Mechanically reconfigurable metasurfaces capable of translation, rotation, and permutation have attracted considerable attention for high-capacity optical information storage and full-color holographic displays, owing to their low-power and high functional scalability, despite the additional system-level complexity introduced by precision rotation stages. This study presents a differentiable inverse design framework for such metasurfaces, creating an accurate mapping between meta-atom geometries and their multi-channel optical responses across diverse optical dimensions. Using a deep neural network-driven, end-to-end optimization pipeline, the framework enables intelligent, iterative refinement of rotatable metasurface within constrained design space. Using this approach, we show high-fidelity holographic video display by rotating a single element in a cascaded metasurface doublet around the optical axis. The doublet enables pixel-resolved holographic imaging with 288 independent channels, and by switching input/output polarization states, the system demonstrates four distinct full-color dynamic holographic videos. This work establishes an alternative paradigm for optical parameter multiplexing and end-to-end inverse design in mechanically reconfigurable metasurfaces, suggesting applications in compact optical systems, dynamic holography, information processing, and optical computing.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Mechanically reconfigurable metasurfaces capable of translation, rotation, and permutation have attracted considerable attention for high-capacity optical information storage and full-color holographic displays, owing to their low-power and high functional scalability, despite the additional system-level complexity introduced by precision rotation stages. This study presents a differentiable inverse design framework for such metasurfaces, creating an accurate mapping between meta-atom geometries and their multi-channel optical responses across diverse optical dimensions. Using a deep neural network-driven, end-to-end optimization pipeline, the framework enables intelligent, iterative refinement of rotatable metasurface within constrained design space. Using this approach, we show high-fidelity holographic video display by rotating a single element in a cascaded metasurface doublet around the optical axis. The doublet enables pixel-resolved holographic imaging with 288 independent channels, and by switching input/output polarization states, the system demonstrates four distinct full-color dynamic holographic videos. This work establishes an alternative paradigm for optical parameter multiplexing and end-to-end inverse design in mechanically reconfigurable metasurfaces, suggesting applications in compact optical systems, dynamic holography, information processing, and optical computing."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-16T03:49:55Z",
            "published_parsed": [
                2025,
                11,
                16,
                3,
                49,
                55,
                6,
                320,
                0
            ],
            "arxiv_comment": "5 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Ting Ma"
                },
                {
                    "name": "Xianjin Liu"
                },
                {
                    "name": "Qiwen Bao"
                },
                {
                    "name": "Bolun Zhang"
                },
                {
                    "name": "Jun-Jun Xiao"
                }
            ],
            "author_detail": {
                "name": "Jun-Jun Xiao"
            },
            "author": "Jun-Jun Xiao",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "机械旋转驱动的超高容量分光偏振全息复用超表面",
            "abstract_cn": "尽管精密旋转平台带来了额外的系统级复杂性，但由于其低功耗和高功能可扩展性，能够进行平移、旋转和排列的机械可重构超表面在高容量光学信息存储和全彩全息显示器方面引起了相当大的关注。这项研究提出了此类超表面的可微逆设计框架，在超原子几何形状与其跨不同光学维度的多通道光学响应之间创建了精确的映射。该框架使用深度神经网络驱动的端到端优化管道，能够在受限设计空间内对可旋转超表面进行智能迭代细化。使用这种方法，我们通过绕光轴旋转级联超表面双合透镜中的单个元件来展示高保真全息视频显示。该双合透镜可实现具有 288 个独立通道的像素分辨全息成像，并且通过切换输入/输出偏振状态，该系统演示了四个不同的全彩动态全息视频。这项工作为机械可重构超表面中的光学参数复用和端到端逆向设计建立了替代范例，建议在紧凑光学系统、动态全息术、信息处理和光学计算中应用。"
        },
        {
            "id": "http://arxiv.org/abs/2511.15022v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2511.15022v1",
            "title": "Complex-Valued 2D Gaussian Representation for Computer-Generated Holography",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Complex-Valued 2D Gaussian Representation for Computer-Generated Holography"
            },
            "updated": "2025-11-19T01:41:14Z",
            "updated_parsed": [
                2025,
                11,
                19,
                1,
                41,
                14,
                2,
                323,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2511.15022v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2511.15022v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We propose a new hologram representation based on structured complex-valued 2D Gaussian primitives, which replaces per-pixel information storage and reduces the parameter search space by up to 10:1. To enable end-to-end training, we develop a differentiable rasterizer for our representation, integrated with a GPU-optimized light propagation kernel in free space. Our extensive experiments show that our method achieves up to 2.5x lower VRAM usage and 50% faster optimization while producing higher-fidelity reconstructions than existing methods. We further introduce a conversion procedure that adapts our representation to practical hologram formats, including smooth and random phase-only holograms. Our experiments show that this procedure can effectively suppress noise artifacts observed in previous methods. By reducing the hologram parameter search space, our representation enables a more scalable hologram estimation in the next-generation computer-generated holography systems.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We propose a new hologram representation based on structured complex-valued 2D Gaussian primitives, which replaces per-pixel information storage and reduces the parameter search space by up to 10:1. To enable end-to-end training, we develop a differentiable rasterizer for our representation, integrated with a GPU-optimized light propagation kernel in free space. Our extensive experiments show that our method achieves up to 2.5x lower VRAM usage and 50% faster optimization while producing higher-fidelity reconstructions than existing methods. We further introduce a conversion procedure that adapts our representation to practical hologram formats, including smooth and random phase-only holograms. Our experiments show that this procedure can effectively suppress noise artifacts observed in previous methods. By reducing the hologram parameter search space, our representation enables a more scalable hologram estimation in the next-generation computer-generated holography systems."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.GR",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.LG",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-19T01:41:14Z",
            "published_parsed": [
                2025,
                11,
                19,
                1,
                41,
                14,
                2,
                323,
                0
            ],
            "arxiv_comment": "8 pages, 11 figures",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Yicheng Zhan"
                },
                {
                    "name": "Xiangjun Gao"
                },
                {
                    "name": "Long Quan"
                },
                {
                    "name": "Kaan Akşit"
                }
            ],
            "author_detail": {
                "name": "Kaan Akşit"
            },
            "author": "Kaan Akşit",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "计算机生成全息术的复值二维高斯表示",
            "abstract_cn": "我们提出了一种基于结构化复值 2D 高斯基元的新全息图表示，它取代了每像素信息存储，并将参数搜索空间减少了 10:1。为了实现端到端训练，我们为我们的表示开发了一个可微分光栅器，与自由空间中的 GPU 优化的光传播内核集成。我们的大量实验表明，与现有方法相比，我们的方法可将 VRAM 使用率降低 2.5 倍，优化速度提高 50%，同时产生更高保真度的重建。我们进一步介绍了一种转换程序，使我们的表示适应实际的全息图格式，包括平滑和随机的纯相位全息图。我们的实验表明，该过程可以有效抑制以前方法中观察到的噪声伪影。通过减少全息图参数搜索空间，我们的表示可以在下一代计算机生成的全息系统中实现更具可扩展性的全息图估计。"
        },
        {
            "id": "http://arxiv.org/abs/2511.16310v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2511.16310v1",
            "title": "Theoretical Analysis of Chirped Pulse Effects on Plasma Formation in Water Liquid Jet",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Theoretical Analysis of Chirped Pulse Effects on Plasma Formation in Water Liquid Jet"
            },
            "updated": "2025-11-20T12:37:59Z",
            "updated_parsed": [
                2025,
                11,
                20,
                12,
                37,
                59,
                3,
                324,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2511.16310v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2511.16310v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We present a theoretical study of how linear chirp controls plasma density in a water jet using a two-stage framework. Stage I solves carrier-population and current equations at a single point, driven by a chirped super-Gaussian pulse. By fixing bandwidth and normalizing for intensity, we isolate a chirp-only response of plasma density, which exceeds unity and shows a consistent advantage for negative over positive chirp. Stage II propagates the field in water via the angular-spectrum method and applies the same equations across space. Normal dispersion reverses the trend: the chirp-only plasma density decreases as chirp grows, negative chirp remains less detrimental, and suppression is strongest for longer FTL pulses (e.g., 80 fs) due to dispersion-induced temporal spreading and spatio-temporal desynchronization. This study separates spectral-phase effects from bandwidth and intensity, yields testable predictions for water jets, and provides a foundation for future experiments and self-consistent propagation models.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We present a theoretical study of how linear chirp controls plasma density in a water jet using a two-stage framework. Stage I solves carrier-population and current equations at a single point, driven by a chirped super-Gaussian pulse. By fixing bandwidth and normalizing for intensity, we isolate a chirp-only response of plasma density, which exceeds unity and shows a consistent advantage for negative over positive chirp. Stage II propagates the field in water via the angular-spectrum method and applies the same equations across space. Normal dispersion reverses the trend: the chirp-only plasma density decreases as chirp grows, negative chirp remains less detrimental, and suppression is strongest for longer FTL pulses (e.g., 80 fs) due to dispersion-induced temporal spreading and spatio-temporal desynchronization. This study separates spectral-phase effects from bandwidth and intensity, yields testable predictions for water jets, and provides a foundation for future experiments and self-consistent propagation models."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-20T12:37:59Z",
            "published_parsed": [
                2025,
                11,
                20,
                12,
                37,
                59,
                3,
                324,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Shireen Hilal"
                },
                {
                    "name": "Azat O. Ismagilov"
                },
                {
                    "name": "Anton N. Tsypkin"
                },
                {
                    "name": "Maksim V. Melnik"
                }
            ],
            "author_detail": {
                "name": "Maksim V. Melnik"
            },
            "author": "Maksim V. Melnik",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "啁啾脉冲对水液体射流等离子体形成影响的理论分析",
            "abstract_cn": "我们提出了线性调频如何使用两级框架控制水射流中等离子体密度的理论研究。第一阶段在啁啾超高斯脉冲的驱动下，在单点求解载流子数量和电流方程。通过固定带宽和强度归一化，我们隔离了等离子体密度的仅线性调频响应，该响应超过了统一性，并显示出负线性调频相对于正线性调频的一致优势。第二阶段通过角谱方法在水中传播场，并在空间中应用相同的方程。正常色散逆转了这一趋势：仅线性调频的等离子体密度随着线性调频的增长而降低，负线性调频的危害仍然较小，并且由于色散引起的时间扩展和时空去同步，较长 FTL 脉冲（例如 80 fs）的抑制最强。这项研究将光谱相位效应与带宽和强度分开，对水射流进行了可测试的预测，并为未来的实验和自洽传播模型提供了基础。"
        },
        {
            "id": "http://arxiv.org/abs/2511.17768v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2511.17768v1",
            "title": "Manipulation of the orbital angular momentum of soft x-ray beams by consecutive diffractive optics",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Manipulation of the orbital angular momentum of soft x-ray beams by consecutive diffractive optics"
            },
            "updated": "2025-11-21T20:30:36Z",
            "updated_parsed": [
                2025,
                11,
                21,
                20,
                30,
                36,
                4,
                325,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2511.17768v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2511.17768v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Production and manipulation of orbital angular momentum (OAM) of coherent soft x-ray beams is demonstrated utilizing consecutive diffractive optics. OAM addition is observed upon passing the beam through consecutive fork gratings. The OAM of the beam was found to be decoupled from its spin angular momentum (SAM). Practical implementation of angular momentum control by consecutive devices in the x-ray regime opens new experimental opportunities, such as direct measurement of OAM beams without resorting to phase sensitive techniques, including holography. OAM analyzers utilizing fork gratings can be used to characterize the beams produced by synchrotron and free electron lasers sources; they can also be used in scattering experiments.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Production and manipulation of orbital angular momentum (OAM) of coherent soft x-ray beams is demonstrated utilizing consecutive diffractive optics. OAM addition is observed upon passing the beam through consecutive fork gratings. The OAM of the beam was found to be decoupled from its spin angular momentum (SAM). Practical implementation of angular momentum control by consecutive devices in the x-ray regime opens new experimental opportunities, such as direct measurement of OAM beams without resorting to phase sensitive techniques, including holography. OAM analyzers utilizing fork gratings can be used to characterize the beams produced by synchrotron and free electron lasers sources; they can also be used in scattering experiments."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-21T20:30:36Z",
            "published_parsed": [
                2025,
                11,
                21,
                20,
                30,
                36,
                4,
                325,
                0
            ],
            "arxiv_comment": "4 pages, 3 figures, 1 supplemental document",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Nazir Khan"
                },
                {
                    "name": "Rahul Jangid"
                },
                {
                    "name": "Taras Stanislavchuk"
                },
                {
                    "name": "Aaron Stein"
                },
                {
                    "name": "Oleg Chubar"
                },
                {
                    "name": "Andi Barbour"
                },
                {
                    "name": "Andrei Sirenko"
                },
                {
                    "name": "Valery Kiryukhin"
                },
                {
                    "name": "Claudio Mazzoli"
                }
            ],
            "author_detail": {
                "name": "Claudio Mazzoli"
            },
            "author": "Claudio Mazzoli",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "通过连续衍射光学器件操纵软 X 射线束的轨道角动量",
            "abstract_cn": "利用连续衍射光学器件演示了相干软 X 射线束的轨道角动量 (OAM) 的产生和操纵。当光束通过连续的叉形光栅时，可以观察到 OAM 的增加。研究发现，光束的 OAM 与其自旋角动量 (SAM) 是解耦的。在 X 射线范围内通过连续装置实际实现角动量控制开辟了新的实验机会，例如直接测量 OAM 光束，而无需求助于包括全息术在内的相敏技术。利用叉形光栅的 OAM 分析仪可用于表征同步加速器和自由电子激光源产生的光束；它们也可用于散射实验。"
        },
        {
            "id": "http://arxiv.org/abs/2512.05127v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.05127v1",
            "title": "Bayesian Optimization and Convolutional Neural Networks for Zernike-Based Wavefront Correction in High Harmonic Generation",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Bayesian Optimization and Convolutional Neural Networks for Zernike-Based Wavefront Correction in High Harmonic Generation"
            },
            "updated": "2025-11-23T20:03:42Z",
            "updated_parsed": [
                2025,
                11,
                23,
                20,
                3,
                42,
                6,
                327,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.05127v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.05127v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "High harmonic generation (HHG) is a nonlinear process that enables table-top generation of tunable, high-energy, coherent, ultrashort radiation pulses in the extreme ultraviolet (EUV) to soft X-ray range. These pulses find applications in photoemission spectroscopy in condensed matter physics, pump-probe spectroscopy for high-energy-density plasmas, and attosecond science. However, optical aberrations in the high-power laser systems required for HHG degrade beam quality and reduce efficiency. We present a machine learning approach to optimize aberration correction using a spatial light modulator. We implemented and compared Bayesian optimization and convolutional neural network (CNN) methods to predict optimal Zernike polynomial coefficients for wavefront correction. Our CNN achieved promising results with 80.39% accuracy on test data, demonstrating the potential for automated aberration correction in HHG systems.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "High harmonic generation (HHG) is a nonlinear process that enables table-top generation of tunable, high-energy, coherent, ultrashort radiation pulses in the extreme ultraviolet (EUV) to soft X-ray range. These pulses find applications in photoemission spectroscopy in condensed matter physics, pump-probe spectroscopy for high-energy-density plasmas, and attosecond science. However, optical aberrations in the high-power laser systems required for HHG degrade beam quality and reduce efficiency. We present a machine learning approach to optimize aberration correction using a spatial light modulator. We implemented and compared Bayesian optimization and convolutional neural network (CNN) methods to predict optimal Zernike polynomial coefficients for wavefront correction. Our CNN achieved promising results with 80.39% accuracy on test data, demonstrating the potential for automated aberration correction in HHG systems."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.LG",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-23T20:03:42Z",
            "published_parsed": [
                2025,
                11,
                23,
                20,
                3,
                42,
                6,
                327,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Guilherme Grancho D. Fernandes"
                },
                {
                    "name": "Duarte Alexandrino"
                },
                {
                    "name": "Eduardo Silva"
                },
                {
                    "name": "João Matias"
                },
                {
                    "name": "Joaquim Pereira"
                }
            ],
            "author_detail": {
                "name": "Joaquim Pereira"
            },
            "author": "Joaquim Pereira",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "高次谐波产生中基于 Zernike 的波前校正的贝叶斯优化和卷积神经网络",
            "abstract_cn": "高谐波发生 (HHG) 是一种非线性过程，可在桌面上生成极紫外 (EUV) 到软 X 射线范围内的可调谐、高能、相干、超短辐射脉冲。这些脉冲在凝聚态物理的光电发射光谱、高能量密度等离子体的泵浦探针光谱和阿秒科学中都有应用。然而，HHG 所需的高功率激光系统中的光学像差会降低光束质量并降低效率。我们提出了一种机器学习方法，使用空间光调制器来优化像差校正。我们实施并比较了贝叶斯优化和卷积神经网络 (CNN) 方法来预测波前校正的最佳泽尼克多项式系数。我们的 CNN 在测试数据上取得了令人鼓舞的结果，准确率为 80.39%，展示了 HHG 系统中自动像差校正的潜力。"
        },
        {
            "id": "http://arxiv.org/abs/2511.20238v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2511.20238v1",
            "title": "Establishing a library of metasurface building blocks through coherence-controlled holographic microscopy",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Establishing a library of metasurface building blocks through coherence-controlled holographic microscopy"
            },
            "updated": "2025-11-25T12:12:13Z",
            "updated_parsed": [
                2025,
                11,
                25,
                12,
                12,
                13,
                1,
                329,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2511.20238v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2511.20238v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Digital holographic microscopy is a powerful tool for characterizing transparent and reflective phase objects. Its ability to reconstruct amplitude and phase can also offer great insight into wavefront shaping and design of all-dielectric optical metasurfaces. While metasurfaces have reached widespread popularity, their design is often based purely on the results of numerical simulations which can overlook many of the real-world fabrication imperfections. Being able to verify the real phase response of a fabricated device is of great utility for high-performance devices. Here, we use holographic microscopy to validate metalibraries of rectangular TiO2 and Si building blocks. Illumination effects are studied for wavelengths from 600 to 740 nm and linear polarization rotating within the full range of unique states (0 to 180deg). Finally, by varying the numerical aperture of the condenser lens from 0.05 to 0.5 we also study the effects of an off-axis illumination. Comparing the experimental results with simulations from finite-difference time-domain and rigorous coupled-wave analysis, we highlight the limitations of these theoretical predictions and underscore the utility of an experimentally established library of building blocks. We demonstrate that our proposed method of holographic microscopy is both practical and effective for creating a metalibrary that accounts for all fabrication and material imperfections, which is crucial for designing high-efficiency metasurfaces.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Digital holographic microscopy is a powerful tool for characterizing transparent and reflective phase objects. Its ability to reconstruct amplitude and phase can also offer great insight into wavefront shaping and design of all-dielectric optical metasurfaces. While metasurfaces have reached widespread popularity, their design is often based purely on the results of numerical simulations which can overlook many of the real-world fabrication imperfections. Being able to verify the real phase response of a fabricated device is of great utility for high-performance devices. Here, we use holographic microscopy to validate metalibraries of rectangular TiO2 and Si building blocks. Illumination effects are studied for wavelengths from 600 to 740 nm and linear polarization rotating within the full range of unique states (0 to 180deg). Finally, by varying the numerical aperture of the condenser lens from 0.05 to 0.5 we also study the effects of an off-axis illumination. Comparing the experimental results with simulations from finite-difference time-domain and rigorous coupled-wave analysis, we highlight the limitations of these theoretical predictions and underscore the utility of an experimentally established library of building blocks. We demonstrate that our proposed method of holographic microscopy is both practical and effective for creating a metalibrary that accounts for all fabrication and material imperfections, which is crucial for designing high-efficiency metasurfaces."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-25T12:12:13Z",
            "published_parsed": [
                2025,
                11,
                25,
                12,
                12,
                13,
                1,
                329,
                0
            ],
            "arxiv_comment": "15 pages, 7 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Ondřej Červinka"
                },
                {
                    "name": "Vlastimil Weiss"
                },
                {
                    "name": "Martin Hrtoň"
                },
                {
                    "name": "Petr Bouchal"
                },
                {
                    "name": "Petr Liška"
                },
                {
                    "name": "Filip Ligmajer"
                },
                {
                    "name": "Tomáš Šikola"
                },
                {
                    "name": "Petr Viewegh"
                }
            ],
            "author_detail": {
                "name": "Petr Viewegh"
            },
            "author": "Petr Viewegh",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "通过相干控制全息显微镜建立超表面构建块库",
            "abstract_cn": "数字全息显微镜是表征透明和反射相物体的强大工具。其重建振幅和相位的能力还可以为全电介质光学超表面的波前整形和设计提供深入的见解。虽然超表面已经广泛流行，但它们的设计通常纯粹基于数值模拟的结果，而忽略了许多现实世界的制造缺陷。能够验证所制造器件的真实相位响应对于高性能器件非常有用。在这里，我们使用全息显微镜来验证矩形 TiO2 和 Si 构建块的金属库。研究了 600 至 740 nm 波长以及在整个独特状态范围（0 至 180 度）内旋转的线性偏振的照明效果。最后，通过将聚光透镜的数值孔径从 0.05 更改为 0.5，我们还研究了离轴照明的影响。将实验结果与有限差分时域和严格耦合波分析的模拟进行比较，我们强调了这些理论预测的局限性，并强调了实验建立的构建块库的实用性。我们证明，我们提出的全息显微镜方法对于创建一个能够解释所有制造和材料缺陷的金属库来说既实用又有效，这对于设计高效超表面至关重要。"
        },
        {
            "id": "http://arxiv.org/abs/2511.20245v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2511.20245v1",
            "title": "HistoSpeckle-Net: Mutual Information-Guided Deep Learning for high-fidelity reconstruction of complex OrganAMNIST images via perturbed Multimode Fibers",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "HistoSpeckle-Net: Mutual Information-Guided Deep Learning for high-fidelity reconstruction of complex OrganAMNIST images via perturbed Multimode Fibers"
            },
            "updated": "2025-11-25T12:20:50Z",
            "updated_parsed": [
                2025,
                11,
                25,
                12,
                20,
                50,
                1,
                329,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2511.20245v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2511.20245v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Existing deep learning methods in multimode fiber (MMF) imaging often focus on simpler datasets, limiting their applicability to complex, real-world imaging tasks. These models are typically data-intensive, a challenge that becomes more pronounced when dealing with diverse and complex images. In this work, we propose HistoSpeckle-Net, a deep learning architecture designed to reconstruct structurally rich medical images from MMF speckles. To build a clinically relevant dataset, we develop an optical setup that couples laser light through a spatial light modulator (SLM) into an MMF, capturing output speckle patterns corresponding to input OrganAMNIST images. Unlike previous MMF imaging approaches, which have not considered the underlying statistics of speckles and reconstructed images, we introduce a distribution-aware learning strategy. We employ a histogram-based mutual information loss to enhance model robustness and reduce reliance on large datasets. Our model includes a histogram computation unit that estimates smooth marginal and joint histograms for calculating mutual information loss. It also incorporates a unique Three-Scale Feature Refinement Module, which leads to multiscale Structural Similarity Index Measure (SSIM) loss computation. Together, these two loss functions enhance both the structural fidelity and statistical alignment of the reconstructed images. Our experiments on the complex OrganAMNIST dataset demonstrate that HistoSpeckle-Net achieves higher fidelity than baseline models such as U-Net and Pix2Pix. It gives superior performance even with limited training samples and across varying fiber bending conditions. By effectively reconstructing complex anatomical features with reduced data and under fiber perturbations, HistoSpeckle-Net brings MMF imaging closer to practical deployment in real-world clinical environments.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Existing deep learning methods in multimode fiber (MMF) imaging often focus on simpler datasets, limiting their applicability to complex, real-world imaging tasks. These models are typically data-intensive, a challenge that becomes more pronounced when dealing with diverse and complex images. In this work, we propose HistoSpeckle-Net, a deep learning architecture designed to reconstruct structurally rich medical images from MMF speckles. To build a clinically relevant dataset, we develop an optical setup that couples laser light through a spatial light modulator (SLM) into an MMF, capturing output speckle patterns corresponding to input OrganAMNIST images. Unlike previous MMF imaging approaches, which have not considered the underlying statistics of speckles and reconstructed images, we introduce a distribution-aware learning strategy. We employ a histogram-based mutual information loss to enhance model robustness and reduce reliance on large datasets. Our model includes a histogram computation unit that estimates smooth marginal and joint histograms for calculating mutual information loss. It also incorporates a unique Three-Scale Feature Refinement Module, which leads to multiscale Structural Similarity Index Measure (SSIM) loss computation. Together, these two loss functions enhance both the structural fidelity and statistical alignment of the reconstructed images. Our experiments on the complex OrganAMNIST dataset demonstrate that HistoSpeckle-Net achieves higher fidelity than baseline models such as U-Net and Pix2Pix. It gives superior performance even with limited training samples and across varying fiber bending conditions. By effectively reconstructing complex anatomical features with reduced data and under fiber perturbations, HistoSpeckle-Net brings MMF imaging closer to practical deployment in real-world clinical environments."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-25T12:20:50Z",
            "published_parsed": [
                2025,
                11,
                25,
                12,
                20,
                50,
                1,
                329,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Jawaria Maqbool"
                },
                {
                    "name": "M. Imran Cheema"
                }
            ],
            "author_detail": {
                "name": "M. Imran Cheema"
            },
            "author": "M. Imran Cheema",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "HistoSpeckle-Net：互信息引导深度学习，通过扰动多模光纤高保真重建复杂的 OrganAMNIST 图像",
            "abstract_cn": "多模光纤 (MMF) 成像中现有的深度学习方法通​​常侧重于更简单的数据集，限制了它们对复杂的现实世界成像任务的适用性。这些模型通常是数据密集型的，在处理多样化和复杂的图像时，这一挑战变得更加明显。在这项工作中，我们提出了 HistoSpeckle-Net，这是一种深度学习架构，旨在从 MMF 散斑中重建结构丰富的医学图像。为了构建临床相关的数据集，我们开发了一种光学装置，将激光通过空间光调制器 (SLM) 耦合到 MMF，捕获与输入 OrganAMNIST 图像相对应的输出散斑图案。与以前的 MMF 成像方法不同，我们引入了一种分布感知的学习策略，这些方法没有考虑散斑和重建图像的基础统计数据。我们采用基于直方图的互信息损失来增强模型的稳健性并减少对大型数据集的依赖。我们的模型包括一个直方图计算单元，用于估计平滑边缘和联合直方图，以计算互信息损失。它还采用了独特的三尺度特征细化模块，可实现多尺度结构相似性指数测量（SSIM）损失计算。这两个损失函数共同增强了重建图像的结构保真度和统计对齐。我们在复杂的 OrganAMNIST 数据集上进行的实验表明，HistoSpeckle-Net 比 U-Net 和 Pix2Pix 等基线模型具有更高的保真度。即使训练样本有限且光纤弯曲条件不同，它也能提供卓越的性能。通过减少数据并在光纤扰动下有效重建复杂的解剖特征，HistoSpeckle-Net 使 MMF 成像更接近现实临床环境中的实际部署。"
        },
        {
            "id": "http://arxiv.org/abs/2511.21138v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2511.21138v1",
            "title": "All-Optical Varifocal Switching in a Polarization-Insensitive Si--GST Metalens",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "All-Optical Varifocal Switching in a Polarization-Insensitive Si--GST Metalens"
            },
            "updated": "2025-11-26T07:42:32Z",
            "updated_parsed": [
                2025,
                11,
                26,
                7,
                42,
                32,
                2,
                330,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2511.21138v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2511.21138v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Metasurfaces have become a cornerstone of flat-optics, enabling precise control over light propagation through nanoengineered materials. Dynamic and reconfigurable metalenses are key to next-generation flat-optics platforms, yet their practical realization remains limited by slow response, optical loss, and polarization sensitivity. The integration of chalcogenide phase-change materials with metasurface architectures offers a powerful platform for dynamic optical tunability, owing to materials such as Ge$_2$Sb$_2$Te$_5$ (GST) that can reversibly switch between amorphous and crystalline states with distinct refractive indices. However, the strong optical absorption of crystalline GST in the visible to near-infrared range has hindered its widespread use in reconfigurable metalenses. In this study, we design an all-dielectric polarization-insensitive metasurface based on hybrid Si--GST nanostructures to realize a dynamically tunable bifocal metalens operating at 1.55 μm. The device achieves a variable focal length from 70 μm to 200 μm, with focusing efficiencies of 30% in the amorphous state and 20% in the crystalline state, as validated through finite-difference time-domain (FDTD) simulations. Using COMSOL Multiphysics, we show that flat-top laser excitation enables uniform, reversible phase transitions within tens of nanoseconds -- amorphization in approximately 13~ns and crystallization in approximately 90~ns -- without mechanical motion or electrical bias. For next-generation metasurfaces intended for uses including beam steering, dynamic holography, optical routing, multi-depth imaging, and optical communication, this method shows great promise due to its control and stability.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Metasurfaces have become a cornerstone of flat-optics, enabling precise control over light propagation through nanoengineered materials. Dynamic and reconfigurable metalenses are key to next-generation flat-optics platforms, yet their practical realization remains limited by slow response, optical loss, and polarization sensitivity. The integration of chalcogenide phase-change materials with metasurface architectures offers a powerful platform for dynamic optical tunability, owing to materials such as Ge$_2$Sb$_2$Te$_5$ (GST) that can reversibly switch between amorphous and crystalline states with distinct refractive indices. However, the strong optical absorption of crystalline GST in the visible to near-infrared range has hindered its widespread use in reconfigurable metalenses. In this study, we design an all-dielectric polarization-insensitive metasurface based on hybrid Si--GST nanostructures to realize a dynamically tunable bifocal metalens operating at 1.55 μm. The device achieves a variable focal length from 70 μm to 200 μm, with focusing efficiencies of 30% in the amorphous state and 20% in the crystalline state, as validated through finite-difference time-domain (FDTD) simulations. Using COMSOL Multiphysics, we show that flat-top laser excitation enables uniform, reversible phase transitions within tens of nanoseconds -- amorphization in approximately 13~ns and crystallization in approximately 90~ns -- without mechanical motion or electrical bias. For next-generation metasurfaces intended for uses including beam steering, dynamic holography, optical routing, multi-depth imaging, and optical communication, this method shows great promise due to its control and stability."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-26T07:42:32Z",
            "published_parsed": [
                2025,
                11,
                26,
                7,
                42,
                32,
                2,
                330,
                0
            ],
            "arxiv_comment": "20 pages, 13 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Dipika Rani Nath"
                },
                {
                    "name": "Sadid Muneer"
                },
                {
                    "name": "Sajid Muhaimin Choudhury"
                }
            ],
            "author_detail": {
                "name": "Sajid Muhaimin Choudhury"
            },
            "author": "Sajid Muhaimin Choudhury",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "偏振不敏感 Si--GST 超透镜中的全光变焦切换",
            "abstract_cn": "超表面已成为平面光学的基石，能够通过纳米工程材料精确控制光传播。动态和可重构超透镜是下一代平面光学平台的关键，但其实际实现仍然受到响应缓慢、光学损耗和偏振灵敏度的限制。硫族化物相变材料与超表面结构的集成为动态光学可调性提供了强大的平台，因为Ge$_2$Sb$_2$Te$_5$ (GST)等材料可以在具有不同折射率的非晶态和晶态之间可逆地切换。然而，晶体GST在可见光到近红外范围内的强光吸收阻碍了其在可重构超透镜中的广泛应用。在这项研究中，我们设计了一种基于混合 Si-GST 纳米结构的全介电质极化不敏感超表面，以实现在 1.55 μm 下工作的动态可调双焦超透镜。通过时域有限差分 (FDTD) 模拟验证，该器件实现了 70 μm 至 200 μm 的可变焦距，非晶态聚焦效率为 30%，晶态聚焦效率为 20%。使用 COMSOL Multiphysics，我们证明平顶激光激发能够在数十纳秒内实现均匀、可逆的相变——大约 13~ns 内非晶化，大约 90~ns 内结晶——无需机械运动或电偏压。对于用于光束控制、动态全息、光学路由、多深度成像和光通信等用途的下一代超表面，这种方法因其控制和稳定性而显示出巨大的前景。"
        },
        {
            "id": "http://arxiv.org/abs/2511.21311v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2511.21311v1",
            "title": "Low-dose Chemically Specific Bioimaging via Deep-UV Lensless Holographic Microscopy on a Standard Camera",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Low-dose Chemically Specific Bioimaging via Deep-UV Lensless Holographic Microscopy on a Standard Camera"
            },
            "updated": "2025-11-26T11:59:09Z",
            "updated_parsed": [
                2025,
                11,
                26,
                11,
                59,
                9,
                2,
                330,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2511.21311v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2511.21311v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Deep-ultraviolet (DUV) microscopy can provide label-free biochemical contrast by exploiting the intrinsic absorption of nucleic acids, proteins and lipids, offering chemically specific morphological information that complements structural optical thickness contrast from phase-sensitive imaging. However, existing DUV microscopes typically rely on specialized optics and DUV-sensitive cameras, which restrict field of view, increase system complexity and cost, and often require high illumination doses that risk photodamage. Here, we report a low-dose deep-UV lensless holographic microscopy platform that uses standard board-level CMOS sensors designed for visible light, eliminating all imaging optics and dedicated DUV detectors. Our system achieves large field-of-view (up to 116 mm2) DUV imaging with low illumination and label-free phase and chemically specific amplitude contrast. A specialized defocus/wavelength diverse pixel super-resolution reconstruction with total-variation regularization and robust autofocusing halves the effective sensor pixel pitch and yields down to 870 nm lateral resolution. We demonstrate chemically specific, label-free bioimaging on challenging specimens, including Saccharomyces cerevisiae, extracellular vesicles and unstained mouse liver tissue. In liver sections, imaging at λ = 330 nm reveals lipid- and retinoid-rich accumulations that co-localize with Oil Red O staining, enabling label-free identification of hepatic stellate (Ito) cells. This combination of low-dose operation, chemically specific contrast and standard CMOS hardware establishes DUV lensless holographic microscopy as a practical and scalable route to high-content submicron-resolution whole-slide preparation-free bioimaging without exogenous labels.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Deep-ultraviolet (DUV) microscopy can provide label-free biochemical contrast by exploiting the intrinsic absorption of nucleic acids, proteins and lipids, offering chemically specific morphological information that complements structural optical thickness contrast from phase-sensitive imaging. However, existing DUV microscopes typically rely on specialized optics and DUV-sensitive cameras, which restrict field of view, increase system complexity and cost, and often require high illumination doses that risk photodamage. Here, we report a low-dose deep-UV lensless holographic microscopy platform that uses standard board-level CMOS sensors designed for visible light, eliminating all imaging optics and dedicated DUV detectors. Our system achieves large field-of-view (up to 116 mm2) DUV imaging with low illumination and label-free phase and chemically specific amplitude contrast. A specialized defocus/wavelength diverse pixel super-resolution reconstruction with total-variation regularization and robust autofocusing halves the effective sensor pixel pitch and yields down to 870 nm lateral resolution. We demonstrate chemically specific, label-free bioimaging on challenging specimens, including Saccharomyces cerevisiae, extracellular vesicles and unstained mouse liver tissue. In liver sections, imaging at λ = 330 nm reveals lipid- and retinoid-rich accumulations that co-localize with Oil Red O staining, enabling label-free identification of hepatic stellate (Ito) cells. This combination of low-dose operation, chemically specific contrast and standard CMOS hardware establishes DUV lensless holographic microscopy as a practical and scalable route to high-content submicron-resolution whole-slide preparation-free bioimaging without exogenous labels."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.app-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-26T11:59:09Z",
            "published_parsed": [
                2025,
                11,
                26,
                11,
                59,
                9,
                2,
                330,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Piotr Arcab"
                },
                {
                    "name": "Mikolaj Rogalski"
                },
                {
                    "name": "Karolina Niedziela"
                },
                {
                    "name": "Anna Chwastowicz"
                },
                {
                    "name": "Emilia Wdowiak"
                },
                {
                    "name": "Julia Dudek"
                },
                {
                    "name": "Julianna Winnik"
                },
                {
                    "name": "Pawel Matryba"
                },
                {
                    "name": "Jolanta Mierzejewska"
                },
                {
                    "name": "Malgorzata Lenarcik"
                },
                {
                    "name": "Ewa Stepien"
                },
                {
                    "name": "Piotr Zdankowski"
                },
                {
                    "name": "Grzegorz Szewczyk"
                },
                {
                    "name": "Maciej Trusiak"
                }
            ],
            "author_detail": {
                "name": "Maciej Trusiak"
            },
            "author": "Maciej Trusiak",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "通过标准相机上的深紫外无透镜全息显微镜进行低剂量化学特异性生物成像",
            "abstract_cn": "深紫外 (DUV) 显微镜可以利用核酸、蛋白质和脂质的固有吸收来提供无标记的生化对比，提供化学特异性形态信息，补充相敏成像的结构光学厚度对比。然而，现有的 DUV 显微镜通常依赖于专用光学器件和 DUV 敏感相机，这限制了视野，增加了系统复杂性和成本，并且通常需要高照明剂量，从而存在光损伤的风险。在这里，我们报告了一种低剂量深紫外无透镜全息显微镜平台，该平台使用专为可见光设计的标准板级 CMOS 传感器，消除了所有成像光学器件和专用 DUV 探测器。我们的系统可实现大视场（高达 116 mm2）DUV 成像，具有低照度、无标记相位和化学特定振幅对比度。专门的散焦/波长不同像素超分辨率重建具有全变差正则化和强大的自动对焦功能，可将有效传感器像素间距减半，并产生低至 870 nm 的横向分辨率。我们在具有挑战性的样本上展示了化学特异性、无标记的生物成像，包括酿酒酵母、细胞外囊泡和未染色的小鼠肝组织。在肝脏切片中，λ = 330 nm 处的成像显示富含脂质和类视黄醇的积累，这些积累与油红 O 染色共定位，从而能够实现肝星状 (Ito) 细胞的无标记识别。这种低剂量操作、化学特异性对比度和标准 CMOS 硬件的结合使 DUV 无透镜全息显微镜成为一种实用且可扩展的途径，可实现高内涵亚微米分辨率全玻片免制备生物成像，无需外源标记。"
        },
        {
            "id": "http://arxiv.org/abs/2511.22639v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2511.22639v1",
            "title": "A 160 ° x 160 ° Dynamic Holographic Meta-Projector",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "A 160 ° x 160 ° Dynamic Holographic Meta-Projector"
            },
            "updated": "2025-11-27T17:18:09Z",
            "updated_parsed": [
                2025,
                11,
                27,
                17,
                18,
                9,
                3,
                331,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2511.22639v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2511.22639v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Holography can reconstruct immersive light fields for virtual and augmented reality by modulating optical wavefront. Due to huge pixel sizes, current spatial light modulators (SLMs) have small field-of-view (FOV) for holographic displays. Despite various methods for etendue expansion, the largest full-screen FOV for dynamic holography is only 70 ° X 70 °, which remains insufficient for large-scale, high-resolution, three-dimensional displays. Here, we report a pixel-interpolation-assisted holographic meta-projector that substantially expands the FOV by integrating multiple subwavelength metasurface pixels within each microscale pixel of a traditional SLM. Leveraging large-angle diffraction of the metasurface and implementing k-space distortion correction for ultra-wide angles, we experimentally demonstrate dynamic holographic image reconstruction with a FOV of 160 ° X 160 ° -equivalent to a system numerical aperture of 0.985-at a high framerate of 60 Hz, surpassing the temporal resolution threshold of human vision. This system represents the state-of-the-art near-full-screen holographic dynamic display, thereby opening the door to high-dynamic-range and large-FOV holographic displays.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Holography can reconstruct immersive light fields for virtual and augmented reality by modulating optical wavefront. Due to huge pixel sizes, current spatial light modulators (SLMs) have small field-of-view (FOV) for holographic displays. Despite various methods for etendue expansion, the largest full-screen FOV for dynamic holography is only 70 ° X 70 °, which remains insufficient for large-scale, high-resolution, three-dimensional displays. Here, we report a pixel-interpolation-assisted holographic meta-projector that substantially expands the FOV by integrating multiple subwavelength metasurface pixels within each microscale pixel of a traditional SLM. Leveraging large-angle diffraction of the metasurface and implementing k-space distortion correction for ultra-wide angles, we experimentally demonstrate dynamic holographic image reconstruction with a FOV of 160 ° X 160 ° -equivalent to a system numerical aperture of 0.985-at a high framerate of 60 Hz, surpassing the temporal resolution threshold of human vision. This system represents the state-of-the-art near-full-screen holographic dynamic display, thereby opening the door to high-dynamic-range and large-FOV holographic displays."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-27T17:18:09Z",
            "published_parsed": [
                2025,
                11,
                27,
                17,
                18,
                9,
                3,
                331,
                0
            ],
            "arxiv_comment": "5 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Feng-Jun Li"
                },
                {
                    "name": "Ruixing Xia"
                },
                {
                    "name": "Qianmei Deng"
                },
                {
                    "name": "Yuze Lu"
                },
                {
                    "name": "Xiangping Li"
                },
                {
                    "name": "Fangwen Sun"
                },
                {
                    "name": "Dong Zhao"
                },
                {
                    "name": "Zi-Lan Deng"
                },
                {
                    "name": "Kun Huang"
                }
            ],
            "author_detail": {
                "name": "Kun Huang"
            },
            "author": "Kun Huang",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "160° x 160° 动态全息超投影仪",
            "abstract_cn": "全息术可以通过调制光学波前来重建虚拟和增强现实的沉浸式光场。由于像素尺寸巨大，当前的空间光调制器 (SLM) 的全息显示视场 (FOV) 较小。尽管扩展光学扩展量的方法多种多样，但动态全息的最大全屏视场仅为70°X 70°，这对于大尺寸、高分辨率、三维显示来说仍然不够。在这里，我们报告了一种像素插值辅助全息超投影仪，它通过在传统 SLM 的每个微米级像素内集成多个亚波长超表面像素来大幅扩展视场。利用超表面的大角度衍射并实现超广角的k空间畸变校正，我们实验证明了在60 Hz高帧率下，FOV为160° X 160°（相当于系统数值孔径为0.985）的动态全息图像重建，超越了人类视觉的时间分辨率阈值。该系统代表了最先进的近全屏全息动态显示，从而为高动态范围和大视场全息显示打开了大门。"
        },
        {
            "id": "http://arxiv.org/abs/2511.23394v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2511.23394v1",
            "title": "Analytical Fresnel Treatment of Double-Slit Diffraction with Multiple Coherent Waves",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Analytical Fresnel Treatment of Double-Slit Diffraction with Multiple Coherent Waves"
            },
            "updated": "2025-11-28T17:39:58Z",
            "updated_parsed": [
                2025,
                11,
                28,
                17,
                39,
                58,
                4,
                332,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2511.23394v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2511.23394v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We present an analytical and numerical investigation of double-slit diffraction under coherent illumination by three plane waves: one normally incident and two symmetrically angled at plus/minus theta. By imposing an edge-zero condition on the incident field, we derive compact closed-form Fresnel expressions written solely in terms of standard Fresnel integrals. The framework generalizes straightforwardly to an arbitrary number of incident plane-wave components, enabling intuitive control of the transmitted angular spectrum through interference engineered at the aperture. Numerical simulations confirm the accuracy of the closed-form model and characterize the influence of slit geometry, wavelength, partial coherence, and Gaussian beam width. We also discuss experimental feasibility and highlight potential applications in apodization, structured illumination, beam shaping, and multiplexed sensing. Overall, the results show that multi-wave coherent illumination provides a simple and tunable route to tailoring diffraction patterns and generating propagation-robust field profiles.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We present an analytical and numerical investigation of double-slit diffraction under coherent illumination by three plane waves: one normally incident and two symmetrically angled at plus/minus theta. By imposing an edge-zero condition on the incident field, we derive compact closed-form Fresnel expressions written solely in terms of standard Fresnel integrals. The framework generalizes straightforwardly to an arbitrary number of incident plane-wave components, enabling intuitive control of the transmitted angular spectrum through interference engineered at the aperture. Numerical simulations confirm the accuracy of the closed-form model and characterize the influence of slit geometry, wavelength, partial coherence, and Gaussian beam width. We also discuss experimental feasibility and highlight potential applications in apodization, structured illumination, beam shaping, and multiplexed sensing. Overall, the results show that multi-wave coherent illumination provides a simple and tunable route to tailoring diffraction patterns and generating propagation-robust field profiles."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-11-28T17:39:58Z",
            "published_parsed": [
                2025,
                11,
                28,
                17,
                39,
                58,
                4,
                332,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "J. Sumaya-Martinez"
                },
                {
                    "name": "MA Ortiz-Ferreyro"
                },
                {
                    "name": "O. Rojas-Hernandez"
                }
            ],
            "author_detail": {
                "name": "O. Rojas-Hernandez"
            },
            "author": "O. Rojas-Hernandez",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "多相干波双缝衍射的解析菲涅尔处理",
            "abstract_cn": "我们对三个平面波相干照明下的双缝衍射进行了分析和数值研究：一个垂直入射，两个以正负θ角对称入射。通过在入射场上施加边缘零条件，我们推导出仅用标准菲涅尔积分编写的紧凑封闭式菲涅尔表达式。该框架直接推广到任意数量的入射平面波分量，从而能够通过在孔径处设计的干涉来直观地控制传输的角谱。数值模拟证实了封闭模型的准确性，并表征了狭缝几何形状、波长、部分相干性和高斯光束宽度的影响。我们还讨论了实验可行性，并重点介绍了在变迹、结构照明、光束整形和多重传感方面的潜在应用。总体而言，结果表明多波相干照明提供了一种简单且可调的途径来定制衍射图案和生成传播鲁棒的场分布。"
        },
        {
            "id": "http://arxiv.org/abs/2512.01180v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.01180v1",
            "title": "Metasurface Holography on a Relative-Phase Manifold for Stable and High Fidelity Tweezer-Array Generation",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Metasurface Holography on a Relative-Phase Manifold for Stable and High Fidelity Tweezer-Array Generation"
            },
            "updated": "2025-12-01T01:38:05Z",
            "updated_parsed": [
                2025,
                12,
                1,
                1,
                38,
                5,
                0,
                335,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.01180v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.01180v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We present a new holographic approach for generating large scale, polarization resolved optical tweezer arrays. By analyzing the ideal Jones fields that realize a target pattern, we identify that the fundamental degrees of freedom are the relative phases of the individual tweezers, rather than the full spatial phase profile. Leveraging this insight, we formulate a reverse projection optimization that adjusts only a small set of phase parameters to approximate the ideal operator within the physical constraints of a metasurface. This produces significantly higher fidelity and robustness than Gerchberg_Saxton type algorithms. Experimentally, we demonstrate H, V, L, and R polarized tweezer arrays using a single layer metasurface. A key advantage of our method is its phase stability, yielding strong resistance to optical aberrations and enabling coherent global phase modulation such as forming vortex tweezer lattice, without degrading trap quality. This framework provides a conceptually clear and experimentally powerful route for scalable optical field synthesis.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We present a new holographic approach for generating large scale, polarization resolved optical tweezer arrays. By analyzing the ideal Jones fields that realize a target pattern, we identify that the fundamental degrees of freedom are the relative phases of the individual tweezers, rather than the full spatial phase profile. Leveraging this insight, we formulate a reverse projection optimization that adjusts only a small set of phase parameters to approximate the ideal operator within the physical constraints of a metasurface. This produces significantly higher fidelity and robustness than Gerchberg_Saxton type algorithms. Experimentally, we demonstrate H, V, L, and R polarized tweezer arrays using a single layer metasurface. A key advantage of our method is its phase stability, yielding strong resistance to optical aberrations and enabling coherent global phase modulation such as forming vortex tweezer lattice, without degrading trap quality. This framework provides a conceptually clear and experimentally powerful route for scalable optical field synthesis."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-01T01:38:05Z",
            "published_parsed": [
                2025,
                12,
                1,
                1,
                38,
                5,
                0,
                335,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Yichen Zhu"
                },
                {
                    "name": "Zifeng Li"
                },
                {
                    "name": "Xiaopeng Li"
                },
                {
                    "name": "Jiacheng Sun"
                },
                {
                    "name": "Baichuan Yang"
                },
                {
                    "name": "Yi Cui"
                },
                {
                    "name": "Tao Li"
                }
            ],
            "author_detail": {
                "name": "Tao Li"
            },
            "author": "Tao Li",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "相对相位流形上的超表面全息术用于稳定和高保真镊子阵列生成",
            "abstract_cn": "我们提出了一种新的全息方法，用于生成大规模偏振分辨光镊阵列。通过分析实现目标图案的理想琼斯场，我们确定基本自由度是各个镊子的相对相位，而不是完整的空间相位分布。利用这种洞察力，我们制定了一种反向投影优化，仅调整一小组相位参数，以在超表面的物理约束内逼近理想算子。与 Gerchberg_Saxton 类型算法相比，这产生了显着更高的保真度和鲁棒性。在实验上，我们使用单层超表面演示了 H、V、L 和 R 偏振镊子阵列。我们的方法的一个关键优势是其相位稳定性，对光学像差产生强大的抵抗力，并实现相干全局相位调制，例如形成涡旋镊子晶格，而不会降低陷阱质量。该框架为可扩展的光场合成提供了概念清晰且实验强大的途径。"
        },
        {
            "id": "http://arxiv.org/abs/2512.02782v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.02782v1",
            "title": "Universality and Falsifiability of Quantum Spacetime Decoherence: A Gauge-Invariant Framework for Gravitational-Wave Phase Diffusion",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Universality and Falsifiability of Quantum Spacetime Decoherence: A Gauge-Invariant Framework for Gravitational-Wave Phase Diffusion"
            },
            "updated": "2025-12-02T13:56:06Z",
            "updated_parsed": [
                2025,
                12,
                2,
                13,
                56,
                6,
                1,
                336,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.02782v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.02782v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We develop a fully gauge-invariant and rigorously derived framework for computing the cumulative decoherence of gravitational waves (GWs) propagating through a stochastic quantum spacetime. Working directly with the Riemann-tensor two-point function and exploiting the extreme adiabaticity of cosmological GW propagation, we show that phase diffusion, rather than amplitude attenuation or mode mixing, is the unique leading-order imprint of microscopic curvature fluctuations. Our main theoretical result is a universality theorem: for any quantum-gravity model whose curvature fluctuations possess a finite correlation length, the accumulated phase variance grows linearly with distance, independent of the underlying microphysics. This diffusive scaling contrasts sharply with coherent astrophysical effects and with nonlocal models. The frequency exponent therefore becomes a clean spectral discriminator, separating string-foam recoil, holographic or scale-invariant noise, and causal-set discreteness. We obtain these results from first principles by evaluating the projected Riemann correlator along null geodesics and determining the exact conditions under which deviations from universality can arise. Finally, we outline a hierarchical Bayesian strategy for measuring this effect with LIGO, LISA, and Pulsar Timing Arrays. Although standard Planck-scale fluctuations remain far below current sensitivity, this framework provides a sharp and falsifiable test of exotic quantum-spacetime scenarios, particularly those with macroscopic correlation lengths or strong energy dependence.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We develop a fully gauge-invariant and rigorously derived framework for computing the cumulative decoherence of gravitational waves (GWs) propagating through a stochastic quantum spacetime. Working directly with the Riemann-tensor two-point function and exploiting the extreme adiabaticity of cosmological GW propagation, we show that phase diffusion, rather than amplitude attenuation or mode mixing, is the unique leading-order imprint of microscopic curvature fluctuations. Our main theoretical result is a universality theorem: for any quantum-gravity model whose curvature fluctuations possess a finite correlation length, the accumulated phase variance grows linearly with distance, independent of the underlying microphysics. This diffusive scaling contrasts sharply with coherent astrophysical effects and with nonlocal models. The frequency exponent therefore becomes a clean spectral discriminator, separating string-foam recoil, holographic or scale-invariant noise, and causal-set discreteness. We obtain these results from first principles by evaluating the projected Riemann correlator along null geodesics and determining the exact conditions under which deviations from universality can arise. Finally, we outline a hierarchical Bayesian strategy for measuring this effect with LIGO, LISA, and Pulsar Timing Arrays. Although standard Planck-scale fluctuations remain far below current sensitivity, this framework provides a sharp and falsifiable test of exotic quantum-spacetime scenarios, particularly those with macroscopic correlation lengths or strong energy dependence."
            },
            "tags": [
                {
                    "term": "gr-qc",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-02T13:56:06Z",
            "published_parsed": [
                2025,
                12,
                2,
                13,
                56,
                6,
                1,
                336,
                0
            ],
            "arxiv_primary_category": {
                "term": "gr-qc"
            },
            "authors": [
                {
                    "name": "Hu Cang"
                },
                {
                    "name": "Yuan Wang"
                }
            ],
            "author_detail": {
                "name": "Yuan Wang"
            },
            "author": "Yuan Wang",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "量子时空退相干的普遍性和可证伪性：引力波相扩散的规范不变框架",
            "abstract_cn": "我们开发了一个完全规范不变且严格推导的框架，用于计算通过随机量子时空传播的引力波（GW）的累积退相干。直接使用黎曼张量两点函数并利用宇宙引力波传播的极端绝热性，我们表明相位扩散，而不是振幅衰减或模式混合，是微观曲率波动的独特前导印记。我们的主要理论结果是普适性定理：对于任何曲率涨落具有有限相关长度的量子引力模型，累积的相位方差随距离线性增长，与底层的微观物理无关。这种扩散尺度与相干天体物理效应和非局域模型形成鲜明对比。因此，频率指数成为一个干净的频谱鉴别器，分离线泡沫反冲、全息或尺度不变噪声以及因果集离散性。我们通过评估沿着零测地线的投影黎曼相关器并确定可能出现偏离普遍性的确切条件，从第一原理获得这些结果。最后，我们概述了使用 LIGO、LISA 和 Pulsar 定时阵列测量这种效应的分层贝叶斯策略。尽管标准普朗克尺度的波动仍然远低于当前的灵敏度，但该框架提供了对奇异量子时空场景的尖锐且可证伪的测试，特别是那些具有宏观相关长度或强能量依赖性的场景。"
        },
        {
            "id": "http://arxiv.org/abs/2512.03539v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.03539v1",
            "title": "Real-Time Control and Automation Framework for Acousto-Holographic Microscopy",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Real-Time Control and Automation Framework for Acousto-Holographic Microscopy"
            },
            "updated": "2025-12-03T08:00:10Z",
            "updated_parsed": [
                2025,
                12,
                3,
                8,
                0,
                10,
                2,
                337,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.03539v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.03539v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Manual operation of microscopes for repetitive tasks in cell biology is a significant bottleneck, consuming invaluable expert time, and introducing human error. Automation is essential, and while Digital Holographic Microscopy (DHM) offers powerful, label-free quantitative phase imaging (QPI), its inherently noisy and low-contrast holograms make robust autofocus and object detection challenging. We present the design, integration, and validation of a fully automated closed-loop DHM system engineered for high-throughput mechanical characterization of biological cells. The system integrates automated serpentine scanning, real-time YOLO-based object detection, and a high-performance, multi-threaded software architecture using pinned memory and SPSC queues. This design enables the GPU-accelerated reconstruction pipeline to run fully in parallel with the 50 fps data acquisition, adding no sequential overhead. A key contribution is the validation of a robust, multi-stage holographic autofocus strategy; we demonstrate that a selected metric (based on a low-pass filter and standard deviation) provides reliable focusing for noisy holograms where conventional methods (e.g., Tenengrad, Laplacian) fail entirely. Performance analysis of the complete system identifies the 2.23-second autofocus operation-not reconstruction-as the primary throughput bottleneck, resulting in a 9.62-second analysis time per object. This work delivers a complete functional platform for autonomous DHM screening and provides a clear, data-driven path for future optimization, proposing a hybrid brightfield imaging modality to address current bottlenecks.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Manual operation of microscopes for repetitive tasks in cell biology is a significant bottleneck, consuming invaluable expert time, and introducing human error. Automation is essential, and while Digital Holographic Microscopy (DHM) offers powerful, label-free quantitative phase imaging (QPI), its inherently noisy and low-contrast holograms make robust autofocus and object detection challenging. We present the design, integration, and validation of a fully automated closed-loop DHM system engineered for high-throughput mechanical characterization of biological cells. The system integrates automated serpentine scanning, real-time YOLO-based object detection, and a high-performance, multi-threaded software architecture using pinned memory and SPSC queues. This design enables the GPU-accelerated reconstruction pipeline to run fully in parallel with the 50 fps data acquisition, adding no sequential overhead. A key contribution is the validation of a robust, multi-stage holographic autofocus strategy; we demonstrate that a selected metric (based on a low-pass filter and standard deviation) provides reliable focusing for noisy holograms where conventional methods (e.g., Tenengrad, Laplacian) fail entirely. Performance analysis of the complete system identifies the 2.23-second autofocus operation-not reconstruction-as the primary throughput bottleneck, resulting in a 9.62-second analysis time per object. This work delivers a complete functional platform for autonomous DHM screening and provides a clear, data-driven path for future optimization, proposing a hybrid brightfield imaging modality to address current bottlenecks."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "eess.IV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "eess.SY",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-03T08:00:10Z",
            "published_parsed": [
                2025,
                12,
                3,
                8,
                0,
                10,
                2,
                337,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Hasan Berkay Abdioğlu"
                },
                {
                    "name": "Yağmur Işık"
                },
                {
                    "name": "Mustafa İsmail İnal"
                },
                {
                    "name": "Nehir Serin"
                },
                {
                    "name": "Kerem Bayer"
                },
                {
                    "name": "Muhammed Furkan Koşar"
                },
                {
                    "name": "Taha Ünal"
                },
                {
                    "name": "Hüseyin Üvet"
                }
            ],
            "author_detail": {
                "name": "Hüseyin Üvet"
            },
            "author": "Hüseyin Üvet",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "声全息显微镜的实时控制和自动化框架",
            "abstract_cn": "在细胞生物学中，手动操作显微镜来执行重复性任务是一个重大瓶颈，不仅消耗宝贵的专家时间，而且会引入人为错误。自动化至关重要，虽然数字全息显微镜 (DHM) 提供强大的无标记定量相位成像 (QPI)，但其固有的噪声和低对比度全息图使得强大的自动对焦和物体检测具有挑战性。我们展示了全自动闭环 DHM 系统的设计、集成和验证，该系统专为生物细胞的高通量机械表征而设计。该系统集成了自动蛇形扫描、基于 YOLO 的实时对象检测以及使用固定内存和 SPSC 队列的高性能、多线程软件架构。这种设计使 GPU 加速的重建管道能够与 50 fps 数据采集完全并行运行，不会增加顺序开销。一个关键贡献是验证了稳健的多级全息自动对焦策略；我们证明，选定的度量（基于低通滤波器和标准差）可以为噪声全息图提供可靠的聚焦，而传统方法（例如 Tenengrad、拉普拉斯算子）完全失败。整个系统的性能分析确定 2.23 秒的自动对焦操作（而非重建）是主要吞吐量瓶颈，导致每个对象的分析时间为 9.62 秒。这项工作为自主 DHM 筛选提供了一个完整的功能平台，并为未来的优化提供了一条清晰的、数据驱动的路径，提出了一种混合明场成像模式来解决当前的瓶颈。"
        },
        {
            "id": "http://arxiv.org/abs/2512.04503v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.04503v1",
            "title": "Sub-cycle pulse control of holographic and non-holographic electron interferences",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Sub-cycle pulse control of holographic and non-holographic electron interferences"
            },
            "updated": "2025-12-04T06:22:21Z",
            "updated_parsed": [
                2025,
                12,
                4,
                6,
                22,
                21,
                3,
                338,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.04503v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.04503v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We investigate the influence of sub-cycle laser pulses on holographic and non-holographic intracycle interferences by analyzing the photoelectron momentum distributions of helium using TDSE simulations supported by classical trajectory calculations. The results show that the forward-scattering holographic (FSH), backward-scattering holographic (BSH), and time double-slit (TDS) structures are found to be highly sensitive to the pulse duration, carrier-envelope phase (CEP), and temporal envelope in the sub-cycle regime. Sub-cycle pulses with CEP values of $0^\\circ$ and $90^\\circ$ selectively enhance or suppress distinct features, isolating holographic patterns and enhancing BSH fringes. Classical analysis reveals that the intrinsic chirp inherent to sub-cycle fields shortens the recollision time for scattering trajectories, thereby increasing the fringe spacing in FSH and BSH patterns, while simultaneously enlarging the ATI peak spacing associated with TDS interference. Pulse envelope variations, even at fixed FWHM duration, further reshape the fringe spacings by modifying the instantaneous frequency and vector potential slope near ionization times. These results demonstrate that sub-cycle pulses enable precise temporal control of holographic interference, offering new opportunities for probing and manipulating attosecond electron dynamics.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We investigate the influence of sub-cycle laser pulses on holographic and non-holographic intracycle interferences by analyzing the photoelectron momentum distributions of helium using TDSE simulations supported by classical trajectory calculations. The results show that the forward-scattering holographic (FSH), backward-scattering holographic (BSH), and time double-slit (TDS) structures are found to be highly sensitive to the pulse duration, carrier-envelope phase (CEP), and temporal envelope in the sub-cycle regime. Sub-cycle pulses with CEP values of $0^\\circ$ and $90^\\circ$ selectively enhance or suppress distinct features, isolating holographic patterns and enhancing BSH fringes. Classical analysis reveals that the intrinsic chirp inherent to sub-cycle fields shortens the recollision time for scattering trajectories, thereby increasing the fringe spacing in FSH and BSH patterns, while simultaneously enlarging the ATI peak spacing associated with TDS interference. Pulse envelope variations, even at fixed FWHM duration, further reshape the fringe spacings by modifying the instantaneous frequency and vector potential slope near ionization times. These results demonstrate that sub-cycle pulses enable precise temporal control of holographic interference, offering new opportunities for probing and manipulating attosecond electron dynamics."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.atm-clus",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.atom-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-04T06:22:21Z",
            "published_parsed": [
                2025,
                12,
                4,
                6,
                22,
                21,
                3,
                338,
                0
            ],
            "arxiv_comment": "13 pages, 13 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Rambabu Rajpoot"
                },
                {
                    "name": "Eiji J. Takahashi"
                }
            ],
            "author_detail": {
                "name": "Eiji J. Takahashi"
            },
            "author": "Eiji J. Takahashi",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "全息和非全息电子干扰的子周期脉冲控制",
            "abstract_cn": "我们通过使用经典轨迹计算支持的 TDSE 模拟分析氦的光电子动量分布，研究了子周期激光脉冲对全息和非全息周期内干涉的影响。结果表明，前向散射全息（FSH）、后向散射全息（BSH）和时间双缝（TDS）结构对子周期区域的脉冲持续时间、载波包络相位（CEP）和时间包络高度敏感。 CEP 值为 $0^\\circ$ 和 $90^\\circ$ 的子周期脉冲选择性增强或抑制明显特征，隔离全息图案并增强 BSH 条纹。经典分析表明，子周期场固有的线性调频脉冲缩短了散射轨迹的重碰撞时间，从而增加了 FSH 和 BSH 图案中的条纹间距，同时扩大了与 TDS 干扰相关的 ATI 峰值间距。即使在固定的半高宽持续时间下，脉冲包络变化也会通过修改电离时间附近的瞬时频率和矢量势斜率来进一步重塑条纹间距。这些结果表明，子周期脉冲能够实现全息干涉的精确时间控制，为探测和操纵阿秒电子动力学提供新的机会。"
        },
        {
            "id": "http://arxiv.org/abs/2512.04767v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.04767v1",
            "title": "Demultiplexing through a multimode fiber using chip-scale diffractive neural networks",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Demultiplexing through a multimode fiber using chip-scale diffractive neural networks"
            },
            "updated": "2025-12-04T13:05:05Z",
            "updated_parsed": [
                2025,
                12,
                4,
                13,
                5,
                5,
                3,
                338,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.04767v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.04767v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "In today's information age, advanced fiber optic transmission technology is of paramount importance. Multimode fibers (MMFs) using space-division multiplexing (SDM) are promising for improved transmission capacity, connection flexibility, and security of data. However, the complex transmission characteristics of MMFs significantly hinder precise mode demultiplexing. Conventional approaches, including holographic measurements, phase retrieval algorithms, photonic lanterns, and multiplane light conversion, are limited by system complexity, size, and flexibility. In this paper, we demonstrate for the first time a purely optical, chip-scale AI solution for high-mode isolation, speed-of-light demultiplexing of MMF modes using a three-dimensional diffractive neural network (DNN). The DNN is trained with synthetic modal data and fabricated using two-photon nanolithography. It features a compact size of $120μm \\times 120μm \\times 80μm$ and a diffractive structure size of $1μm^{2}$ for the neurons at the hidden layers of the network. Experimentally, the DNN demultiplexer achieves a relative demultiplexing accuracy of over 80%. The AI approach of DNN allows for flexible design and overcomes the size and performance limitations of digital-optical demultiplexers. This work paves the way for compact, low-latency optical processors for high-performance demultiplexers and enables scalable, chip-integrated solutions for next-generation fiber optic networks.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "In today's information age, advanced fiber optic transmission technology is of paramount importance. Multimode fibers (MMFs) using space-division multiplexing (SDM) are promising for improved transmission capacity, connection flexibility, and security of data. However, the complex transmission characteristics of MMFs significantly hinder precise mode demultiplexing. Conventional approaches, including holographic measurements, phase retrieval algorithms, photonic lanterns, and multiplane light conversion, are limited by system complexity, size, and flexibility. In this paper, we demonstrate for the first time a purely optical, chip-scale AI solution for high-mode isolation, speed-of-light demultiplexing of MMF modes using a three-dimensional diffractive neural network (DNN). The DNN is trained with synthetic modal data and fabricated using two-photon nanolithography. It features a compact size of $120μm \\times 120μm \\times 80μm$ and a diffractive structure size of $1μm^{2}$ for the neurons at the hidden layers of the network. Experimentally, the DNN demultiplexer achieves a relative demultiplexing accuracy of over 80%. The AI approach of DNN allows for flexible design and overcomes the size and performance limitations of digital-optical demultiplexers. This work paves the way for compact, low-latency optical processors for high-performance demultiplexers and enables scalable, chip-integrated solutions for next-generation fiber optic networks."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-04T13:05:05Z",
            "published_parsed": [
                2025,
                12,
                4,
                13,
                5,
                5,
                3,
                338,
                0
            ],
            "arxiv_comment": "12 pages, 4 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Qian Zhang"
                },
                {
                    "name": "Haoyi Yu"
                },
                {
                    "name": "Jie Zhang"
                },
                {
                    "name": "Yuedi Zhang"
                },
                {
                    "name": "Chao Meng"
                },
                {
                    "name": "Jiali Sun"
                },
                {
                    "name": "Yu Miao"
                },
                {
                    "name": "Qiming Zhang"
                },
                {
                    "name": "Min Gu"
                },
                {
                    "name": "Juergen W Czarske"
                }
            ],
            "author_detail": {
                "name": "Juergen W Czarske"
            },
            "author": "Juergen W Czarske",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "使用芯片级衍射神经网络通过多模光纤进行解复用",
            "abstract_cn": "在当今的信息时代，先进的光纤传输技术至关重要。使用空分复用 (SDM) 的多模光纤 (MMF) 有望提高传输容量、连接灵活性和数据安全性。然而，MMF 复杂的传输特性极大地阻碍了精确的模式解复用。传统方法，包括全息测量、相位检索算法、光子灯笼和多平面光转换，受到系统复杂性、尺寸和灵活性的限制。在本文中，我们首次展示了一种纯光学、芯片级 AI 解决方案，用于使用三维衍射神经网络 (DNN) 进行 MMF 模式的高模式隔离和光速解复用。 DNN 使用合成模态数据进行训练，并使用双光子纳米光刻技术制造。它的特点是网络隐藏层神经元的紧凑尺寸为 $120μm \\times 120μm \\times 80μm$，衍射结构尺寸为 $1μm^{2}$。实验上，DNN 解复用器实现了超过 80% 的相对解复用精度。 DNN 的 AI 方法可实现灵活的设计，并克服数字光解复用器的尺寸和性能限制。这项工作为高性能解复用器的紧凑、低延迟光学处理器铺平了道路，并为下一代光纤网络提供可扩展的芯片集成解决方案。"
        },
        {
            "id": "http://arxiv.org/abs/2512.04901v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.04901v1",
            "title": "Adaptive Optics-Enhanced Michelson Interferometer for Spectroscopy of Narrow-Band Light Sources",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Adaptive Optics-Enhanced Michelson Interferometer for Spectroscopy of Narrow-Band Light Sources"
            },
            "updated": "2025-12-04T15:29:32Z",
            "updated_parsed": [
                2025,
                12,
                4,
                15,
                29,
                32,
                3,
                338,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.04901v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.04901v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Adaptive optics enables the deployment of interferometer-based spectroscopy without the need for moving parts necessary for scanning the interferometer arms. Here, we employ a Michelson Interferometer in conjunction with a Spatial Light Modulator (SLM) for determining the spectral profile of a narrow-band light source. Interestingly, we observe that the fringes across the interferometer output beam are inherently shifted in wavelength even when a constant phase profile is provided to the SLM. We calibrate the spectral shifts as a function of fringe spatial location by measuring the incident light spectrum at various points across the fringe pattern, and observe that the spectral peak traces out a `teardrop' shape, whose width is dependent on the spectral bandwidth of the source, the relative tilt and path difference between the two arms of the interferometer, and the divergence of the beam. Next, we demonstrate that this inherent spectral variation of the fringes can be used to perform fast single-snapshot spectroscopy of narrow-band light sources, while a time-varied phase profile provided to the SLM leads to multi-step spectroscopy with lower noise, higher resolution, and better contrast. Our findings establish that the Michelson Interferometer can be used to perform spectroscopy of any source within a certain spectral range from simple images of the fringe pattern, so as to facilitate exciting applications towards hyperspectral imaging.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Adaptive optics enables the deployment of interferometer-based spectroscopy without the need for moving parts necessary for scanning the interferometer arms. Here, we employ a Michelson Interferometer in conjunction with a Spatial Light Modulator (SLM) for determining the spectral profile of a narrow-band light source. Interestingly, we observe that the fringes across the interferometer output beam are inherently shifted in wavelength even when a constant phase profile is provided to the SLM. We calibrate the spectral shifts as a function of fringe spatial location by measuring the incident light spectrum at various points across the fringe pattern, and observe that the spectral peak traces out a `teardrop' shape, whose width is dependent on the spectral bandwidth of the source, the relative tilt and path difference between the two arms of the interferometer, and the divergence of the beam. Next, we demonstrate that this inherent spectral variation of the fringes can be used to perform fast single-snapshot spectroscopy of narrow-band light sources, while a time-varied phase profile provided to the SLM leads to multi-step spectroscopy with lower noise, higher resolution, and better contrast. Our findings establish that the Michelson Interferometer can be used to perform spectroscopy of any source within a certain spectral range from simple images of the fringe pattern, so as to facilitate exciting applications towards hyperspectral imaging."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "astro-ph.IM",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.ins-det",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-04T15:29:32Z",
            "published_parsed": [
                2025,
                12,
                4,
                15,
                29,
                32,
                3,
                338,
                0
            ],
            "arxiv_comment": "6 pages, 7 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Jesneil Lauren Lewis"
                },
                {
                    "name": "Ayan Banerjee"
                }
            ],
            "author_detail": {
                "name": "Ayan Banerjee"
            },
            "author": "Ayan Banerjee",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "用于窄带光源光谱学的自适应光学增强型迈克尔逊干涉仪",
            "abstract_cn": "自适应光学技术可以部署基于干涉仪的光谱学，而无需扫描干涉仪臂所需的移动部件。在这里，我们将迈克尔逊干涉仪与空间光调制器 (SLM) 结合使用来确定窄带光源的光谱轮廓。有趣的是，我们观察到，即使向 SLM 提供恒定的相位分布，干涉仪输出光束上的条纹本质上也会发生波长偏移。我们通过测量条纹图案上各个点的入射光谱来校准光谱偏移作为条纹空间位置的函数，并观察到光谱峰值描绘出“泪滴”形状，其宽度取决于光源的光谱带宽、干涉仪两个臂之间的相对倾斜和路径差以及光束的发散度。接下来，我们证明了条纹的这种固有光谱变化可用于执行窄带光源的快速单快照光谱，而提供给 SLM 的时变相位分布可实现具有更低噪声、更高分辨率和更好对比度的多步光谱。我们的研究结果表明，迈克尔逊干涉仪可用于从条纹图案的简单图像对特定光谱范围内的任何光源进行光谱分析，从而促进高光谱成像的令人兴奋的应用。"
        },
        {
            "id": "http://arxiv.org/abs/2512.05042v2",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.05042v2",
            "title": "Structured Light at the Extreme: Harnessing Spatiotemporal Control for High-Field Laser-Matter Interactions",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Structured Light at the Extreme: Harnessing Spatiotemporal Control for High-Field Laser-Matter Interactions"
            },
            "updated": "2025-12-05T19:48:32Z",
            "updated_parsed": [
                2025,
                12,
                5,
                19,
                48,
                32,
                4,
                339,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.05042v2",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.05042v2",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "This review charts the emerging paradigm of intelligent structured light for high-field laser-matter interactions, where the precise spatiotemporal and vectorial control of light is a critical degree of freedom. We outline a transformative framework built upon three synergistic pillars. First, we survey the advanced electromagnetic toolkit, moving beyond conventional spatial light modulators to include robust static optics and the promising frontier of plasma light modulators. Second, we detail the optimization engine for this high-dimensional design space, focusing on physics-informed digital twins and AI-driven inverse design to automate the discovery of optimal light structures. Finally, we explore the groundbreaking applications enabled by this integrated approach, including programmable electron beams, orbital-angular-momentum-carrying γ-rays, compact THz accelerators, and robust communications. The path forward necessitates overcoming grand challenges in material science, real-time adaptive control at MHz rates, and the extension of these principles to the quantum realm. This review serves as a call to action for a coordinated, interdisciplinary effort to command, rather than merely observe, light-matter interactions at the extreme.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "This review charts the emerging paradigm of intelligent structured light for high-field laser-matter interactions, where the precise spatiotemporal and vectorial control of light is a critical degree of freedom. We outline a transformative framework built upon three synergistic pillars. First, we survey the advanced electromagnetic toolkit, moving beyond conventional spatial light modulators to include robust static optics and the promising frontier of plasma light modulators. Second, we detail the optimization engine for this high-dimensional design space, focusing on physics-informed digital twins and AI-driven inverse design to automate the discovery of optimal light structures. Finally, we explore the groundbreaking applications enabled by this integrated approach, including programmable electron beams, orbital-angular-momentum-carrying γ-rays, compact THz accelerators, and robust communications. The path forward necessitates overcoming grand challenges in material science, real-time adaptive control at MHz rates, and the extension of these principles to the quantum realm. This review serves as a call to action for a coordinated, interdisciplinary effort to command, rather than merely observe, light-matter interactions at the extreme."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "math-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.comp-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-04T17:58:57Z",
            "published_parsed": [
                2025,
                12,
                4,
                17,
                58,
                57,
                3,
                338,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Sergio Carbajo"
                },
                {
                    "name": "Seung-Whan Bahk"
                },
                {
                    "name": "Justin Baker"
                },
                {
                    "name": "Andrea Bertozzi"
                },
                {
                    "name": "Abhimanyu Borthakur"
                },
                {
                    "name": "Antonino Di Piazza"
                },
                {
                    "name": "Andrew Forbes"
                },
                {
                    "name": "Spencer Gessner"
                },
                {
                    "name": "Jack Hirschman"
                },
                {
                    "name": "Maciej Lewenstein"
                },
                {
                    "name": "Yuhang Li"
                },
                {
                    "name": "Inhyuk Nam"
                },
                {
                    "name": "Eileen Otte"
                },
                {
                    "name": "James Rozensweig"
                },
                {
                    "name": "Yijie Shen"
                },
                {
                    "name": "Liwei Song"
                },
                {
                    "name": "Ye Tian"
                },
                {
                    "name": "Yu Wang"
                },
                {
                    "name": "Yuntian Wang"
                },
                {
                    "name": "Logan Wright"
                },
                {
                    "name": "Xiaojun Wu"
                },
                {
                    "name": "Hao Zhang"
                }
            ],
            "author_detail": {
                "name": "Hao Zhang"
            },
            "author": "Hao Zhang",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "极端结构光：利用时空控制实现高场激光与物质相互作用",
            "abstract_cn": "这篇综述描绘了用于高场激光与物质相互作用的智能结构光的新兴范例，其中光的精确时空和矢量控制是一个关键的自由度。我们概述了一个基于三个协同支柱的变革框架。首先，我们调查了先进的电磁工具包，超越了传统的空间光调制器，包括强大的静态光学器件和等离子体光调制器的前景广阔的前沿。其次，我们详细介绍了这个高维设计空间的优化引擎，重点关注基于物理的数字孪生和人工智能驱动的逆向设计，以自动发现最佳的光结构。最后，我们探索了这种集成方法所实现的突破性应用，包括可编程电子束、携带γ射线的轨道角动量、紧凑型太赫兹加速器和强大的通信。前进的道路需要克服材料科学、兆赫兹速率实时自适应控制以及将这些原理扩展到量子领域的巨大挑战。这篇综述呼吁采取协调一致的跨学科努力来指挥而不是仅仅观察极端的光与物质相互作用。"
        },
        {
            "id": "http://arxiv.org/abs/2512.06209v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.06209v1",
            "title": "Lensless and Lossless HoloVAM",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Lensless and Lossless HoloVAM"
            },
            "updated": "2025-12-05T23:06:41Z",
            "updated_parsed": [
                2025,
                12,
                5,
                23,
                6,
                41,
                4,
                339,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.06209v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.06209v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We report the first successful fabrication of three-dimensional models using our fully lensless holographic volumetric additive manufacturing (HoloVAM) platform. In this configuration, tomographic light fields are generated directly from a phase-only spatial light modulator (SLM) and delivered into a rotating vial of photopolymer without any imaging optics, relays, or index-matching bath. Building on the HoloTile framework for tiled Fourier holography and point-spread function (PSF) shaping, the system creates volumetric dose distributions with high photon efficiency and well-controlled axial propagation. Using a simple acrylate resin formulation and a minimalized optical train, we demonstrate reproducible fabrication of complex geometries. These results establish lensless HoloVAM as a practical and mechanically minimal route to volumetric fabrication, opening a new pathway toward compact and application-flexible VAM devices.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We report the first successful fabrication of three-dimensional models using our fully lensless holographic volumetric additive manufacturing (HoloVAM) platform. In this configuration, tomographic light fields are generated directly from a phase-only spatial light modulator (SLM) and delivered into a rotating vial of photopolymer without any imaging optics, relays, or index-matching bath. Building on the HoloTile framework for tiled Fourier holography and point-spread function (PSF) shaping, the system creates volumetric dose distributions with high photon efficiency and well-controlled axial propagation. Using a simple acrylate resin formulation and a minimalized optical train, we demonstrate reproducible fabrication of complex geometries. These results establish lensless HoloVAM as a practical and mechanically minimal route to volumetric fabrication, opening a new pathway toward compact and application-flexible VAM devices."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-05T23:06:41Z",
            "published_parsed": [
                2025,
                12,
                5,
                23,
                6,
                41,
                4,
                339,
                0
            ],
            "arxiv_comment": "7 pages, 3 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Andreas Erik Gejl Madsen"
                },
                {
                    "name": "Jesper Glückstad"
                }
            ],
            "author_detail": {
                "name": "Jesper Glückstad"
            },
            "author": "Jesper Glückstad",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "无镜头无损 HoloVAM",
            "abstract_cn": "我们报告了首次使用我们的完全无透镜全息体积增材制造 (HoloVAM) 平台成功制造三维模型。在此配置中，断层摄影光场直接从纯相位空间光调制器 (SLM) 生成，并传送到旋转的光聚合物小瓶中，无需任何成像光学器件、继电器或折射率匹配槽。该系统基于平铺傅里叶全息和点扩散函数 (PSF) 整形的 HoloTile 框架构建，可创建具有高光子效率和良好控制的轴向传播的体积剂量分布。使用简单的丙烯酸酯树脂配方和最小化的光学系统，我们展示了复杂几何形状的可重复制造。这些结果确立了无透镜 HoloVAM 作为体积制造的实用且机械最小化的途径，为紧凑且应用灵活的 VAM 设备开辟了一条新途径。"
        },
        {
            "id": "http://arxiv.org/abs/2512.09694v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.09694v1",
            "title": "Constraint-Free Coherent Diffraction Imaging via Physics-Guided Neural Fields",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Constraint-Free Coherent Diffraction Imaging via Physics-Guided Neural Fields"
            },
            "updated": "2025-12-10T14:41:03Z",
            "updated_parsed": [
                2025,
                12,
                10,
                14,
                41,
                3,
                2,
                344,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.09694v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.09694v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "CDI is a lensless imaging technique that enables atomic-resolution imaging of non-crystalline specimens and their dynamics. However, its broader implementation has been hindered by the instability and ill-posedness of its reconstruction process, known as phase retrieval, which relies heavily on handcrafted, object-specific constraints. To overcome the key limitations, we propose CDIP, a robust phase-retrieval framework that eliminates the need for such constraints by combining untrained coordinate-based neural fields for static and dynamic reconstructions and a physics-consistent forward model. We evaluate CDIP on simulated and experimental datasets that involve both static samples and dynamic processes, demonstrating that it substantially outperforms classical iterative algorithms and deep-learning baselines in terms of fidelity and stability. These results highlight a paradigm shift in both static and time-resolved CDI reconstruction, providing a broadly applicable framework for coherent imaging modalities such as ptychography and holography, across X-ray, electron, and optical probes.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "CDI is a lensless imaging technique that enables atomic-resolution imaging of non-crystalline specimens and their dynamics. However, its broader implementation has been hindered by the instability and ill-posedness of its reconstruction process, known as phase retrieval, which relies heavily on handcrafted, object-specific constraints. To overcome the key limitations, we propose CDIP, a robust phase-retrieval framework that eliminates the need for such constraints by combining untrained coordinate-based neural fields for static and dynamic reconstructions and a physics-consistent forward model. We evaluate CDIP on simulated and experimental datasets that involve both static samples and dynamic processes, demonstrating that it substantially outperforms classical iterative algorithms and deep-learning baselines in terms of fidelity and stability. These results highlight a paradigm shift in both static and time-resolved CDI reconstruction, providing a broadly applicable framework for coherent imaging modalities such as ptychography and holography, across X-ray, electron, and optical probes."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-10T14:41:03Z",
            "published_parsed": [
                2025,
                12,
                10,
                14,
                41,
                3,
                2,
                344,
                0
            ],
            "arxiv_comment": "20 pages, 5 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Zhe Hu"
                },
                {
                    "name": "Zisheng Yao"
                },
                {
                    "name": "Yuhe Zhang"
                },
                {
                    "name": "Pablo Villanueva-Perez"
                }
            ],
            "author_detail": {
                "name": "Pablo Villanueva-Perez"
            },
            "author": "Pablo Villanueva-Perez",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "通过物理引导神经场进行无约束相干衍射成像",
            "abstract_cn": "CDI 是一种无透镜成像技术，可以对非晶体样品及其动力学进行原子分辨率成像。然而，其更广泛的实施受到其重建过程（称为相位检索）的不稳定性和不适定性的阻碍，该过程严重依赖于手工制作的特定于对象的约束。为了克服关键限制，我们提出了 CDIP，这是一种强大的相位检索框架，通过结合用于静态和动态重建的未经训练的基于坐标的神经场和物理一致的前向模型，消除了对此类约束的需要。我们在涉及静态样本和动态过程的模拟和实验数据集上评估 CDIP，证明它在保真度和稳定性方面远远优于经典迭代算法和深度学习基线。这些结果凸显了静态和时间分辨 CDI 重建的范式转变，为 X 射线、电子和光学探针的相干成像模式（例如叠层照相术和全息术）提供了广泛适用的框架。"
        },
        {
            "id": "http://arxiv.org/abs/2512.09696v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.09696v1",
            "title": "Structures resistant to Manipulation by all Wavefronts",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Structures resistant to Manipulation by all Wavefronts"
            },
            "updated": "2025-12-10T14:42:53Z",
            "updated_parsed": [
                2025,
                12,
                10,
                14,
                42,
                53,
                2,
                344,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.09696v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.09696v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Using light to manipulate small particles is a tool with many practical applications throughout biophysics and nanotechnology. These tools have seen a significant increase in performance by utilizing shaped wavefronts, most commonly created with spatial light modulators. Wavefront shaping has also enabled the manipulation of seemingly arbitrary objects, which was impossible with conventional beams. In contrast, we show here the existence of a wide variety of objects that cannot be manipulated as desired, even with the optimal wavefront shaping protocol. The counterintuitive shapes of these objects are found using inverse design. Specifically, we show that the maximal pulling force is reduced by up to three orders of magnitude, and the maximal trapping stiffness is reduced by up to nearly two orders of magnitude. Our findings could prove useful in the development of micromachines that require a predictable mechanical reaction to an arbitrary wave.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Using light to manipulate small particles is a tool with many practical applications throughout biophysics and nanotechnology. These tools have seen a significant increase in performance by utilizing shaped wavefronts, most commonly created with spatial light modulators. Wavefront shaping has also enabled the manipulation of seemingly arbitrary objects, which was impossible with conventional beams. In contrast, we show here the existence of a wide variety of objects that cannot be manipulated as desired, even with the optimal wavefront shaping protocol. The counterintuitive shapes of these objects are found using inverse design. Specifically, we show that the maximal pulling force is reduced by up to three orders of magnitude, and the maximal trapping stiffness is reduced by up to nearly two orders of magnitude. Our findings could prove useful in the development of micromachines that require a predictable mechanical reaction to an arbitrary wave."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-10T14:42:53Z",
            "published_parsed": [
                2025,
                12,
                10,
                14,
                42,
                53,
                2,
                344,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Asher Sabbagh"
                },
                {
                    "name": "Michael Horodynski"
                },
                {
                    "name": "Rida Khan"
                },
                {
                    "name": "Brian Shi"
                },
                {
                    "name": "Marin Soljačić"
                }
            ],
            "author_detail": {
                "name": "Marin Soljačić"
            },
            "author": "Marin Soljačić",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "抵抗所有波前操纵的结构",
            "abstract_cn": "利用光来操纵小颗粒是一种在生物物理学和纳米技术中具有许多实际应用的工具。这些工具通过利用成形波前（最常见的是空间光调制器创建），性能显着提高。波前整形还可以操纵看似任意的物体，而这对于传统光束来说是不可能的。相比之下，我们在这里展示了各种各样的物体的存在，即使使用最佳的波前整形协议，也无法根据需要进行操纵。这些物体的违反直觉的形状是通过逆向设计发现的。具体来说，我们表明最大拉力减少了多达三个数量级，最大捕获刚度减少了近两个数量级。我们的研究结果可能有助于开发需要对任意波产生可预测机械反应的微型机器。"
        },
        {
            "id": "http://arxiv.org/abs/2512.12367v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.12367v1",
            "title": "JPEG-Inspired Cloud-Edge Holography",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "JPEG-Inspired Cloud-Edge Holography"
            },
            "updated": "2025-12-13T15:49:41Z",
            "updated_parsed": [
                2025,
                12,
                13,
                15,
                49,
                41,
                5,
                347,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.12367v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.12367v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Computer-generated holography (CGH) presents a transformative solution for near-eye displays in augmented and virtual reality. Recent advances in deep learning have greatly improved CGH in reconstructed quality and computational efficiency. However, deploying neural CGH pipelines directly on compact, eyeglass-style devices is hindered by stringent constraints on computation and energy consumption, while cloud offloading followed by transmission with natural image codecs often distorts phase information and requires high bandwidth to maintain reconstruction quality. Neural compression methods can reduce bandwidth but impose heavy neural decoders at the edge, increasing inference latency and hardware demand. In this work, we introduce JPEG-Inspired Cloud-Edge Holography, an efficient pipeline designed around a learnable transform codec that retains the block-structured and hardware-friendly nature of JPEG. Our system shifts all heavy neural processing to the cloud, while the edge device performs only lightweight decoding without any neural inference. To further improve throughput, we implement custom CUDA kernels for entropy coding on both cloud and edge. This design achieves a peak signal-to-noise ratio of 32.15 dB at $<$ 2 bits per pixel with decode latency as low as 4.2 ms. Both numerical simulations and optical experiments confirm the high reconstruction quality of the holograms. By aligning CGH with a codec that preserves JPEG's structural efficiency while extending it with learnable components, our framework enables low-latency, bandwidth-efficient hologram streaming on resource-constrained wearable devices-using only simple block-based decoding readily supported by modern system-on-chips, without requiring neural decoders or specialized hardware.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Computer-generated holography (CGH) presents a transformative solution for near-eye displays in augmented and virtual reality. Recent advances in deep learning have greatly improved CGH in reconstructed quality and computational efficiency. However, deploying neural CGH pipelines directly on compact, eyeglass-style devices is hindered by stringent constraints on computation and energy consumption, while cloud offloading followed by transmission with natural image codecs often distorts phase information and requires high bandwidth to maintain reconstruction quality. Neural compression methods can reduce bandwidth but impose heavy neural decoders at the edge, increasing inference latency and hardware demand. In this work, we introduce JPEG-Inspired Cloud-Edge Holography, an efficient pipeline designed around a learnable transform codec that retains the block-structured and hardware-friendly nature of JPEG. Our system shifts all heavy neural processing to the cloud, while the edge device performs only lightweight decoding without any neural inference. To further improve throughput, we implement custom CUDA kernels for entropy coding on both cloud and edge. This design achieves a peak signal-to-noise ratio of 32.15 dB at $<$ 2 bits per pixel with decode latency as low as 4.2 ms. Both numerical simulations and optical experiments confirm the high reconstruction quality of the holograms. By aligning CGH with a codec that preserves JPEG's structural efficiency while extending it with learnable components, our framework enables low-latency, bandwidth-efficient hologram streaming on resource-constrained wearable devices-using only simple block-based decoding readily supported by modern system-on-chips, without requiring neural decoders or specialized hardware."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-13T15:49:41Z",
            "published_parsed": [
                2025,
                12,
                13,
                15,
                49,
                41,
                5,
                347,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Shuyang Xie"
                },
                {
                    "name": "Jie Zhou"
                },
                {
                    "name": "Jun Wang"
                },
                {
                    "name": "Renjing Xu"
                }
            ],
            "author_detail": {
                "name": "Renjing Xu"
            },
            "author": "Renjing Xu",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "受 JPEG 启发的云边全息",
            "abstract_cn": "计算机生成全息术 (CGH) 为增强现实和虚拟现实中的近眼显示提供了一种变革性的解决方案。深度学习的最新进展极大地提高了 CGH 的重建质量和计算效率。然而，直接在紧凑的眼镜式设备上部署神经 CGH 管道受到计算和能耗的严格限制的阻碍，而云卸载和自然图像编解码器传输通常会扭曲相位信息，并且需要高带宽来维持重建质量。神经压缩方法可以减少带宽，但会在边缘施加繁重的神经解码器，从而增加推理延迟和硬件需求。在这项工作中，我们介绍了受 JPEG 启发的云边缘全息，这是一种围绕可学习变换编解码器设计的高效管道，保留了 JPEG 的块结构和硬件友好性质。我们的系统将所有繁重的神经处理转移到云端，而边缘设备仅执行轻量级解码，而不进行任何神经推理。为了进一步提高吞吐量，我们在云端和边缘实现了用于熵编码的自定义 CUDA 内核。该设计在每像素<2 位的情况下实现了 32.15 dB 的峰值信噪比，解码延迟低至 4.2 毫秒。数值模拟和光学实验都证实了全息图的高重建质量。通过将 CGH 与编解码器结合起来，保留 JPEG 的结构效率，同时使用可学习组件对其进行扩展，我们的框架可以在资源有限的可穿戴设备上实现低延迟、带宽高效的全息图流，仅使用现代片上系统支持的简单的基于块的解码，无需神经解码器或专用硬件。"
        },
        {
            "id": "http://arxiv.org/abs/2512.12401v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.12401v1",
            "title": "Poisson wavefront imaging in photon-starved scenarios",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Poisson wavefront imaging in photon-starved scenarios"
            },
            "updated": "2025-12-13T17:28:31Z",
            "updated_parsed": [
                2025,
                12,
                13,
                17,
                28,
                31,
                5,
                347,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.12401v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.12401v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Low-photon phase imaging is essential in applications where the signal is limited by short exposure times, faint targets, or the need to protect delicate samples. We address this challenge with Poisson Wavefront Imaging (PWI), an optimization-based method that incorporates Poisson photon statistics and a smoothness prior to improve wavefront reconstruction. By using multiple spatial light modulator's phase patterns, PWI enhances Fisher information, boosting theoretical accuracy and regularizing the retrieval process effectively. In simulations, PWI approaches the theoretical phase error limit, and in experiments it reduces phase error by up to 1.6x compared to the Gerchberg-Saxton algorithm, achieving 1.8x higher resolution wavefront imaging in low photon regime. This method advances photon-limited imaging with applications in astronomy, semiconductor metrology, and biological systems.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Low-photon phase imaging is essential in applications where the signal is limited by short exposure times, faint targets, or the need to protect delicate samples. We address this challenge with Poisson Wavefront Imaging (PWI), an optimization-based method that incorporates Poisson photon statistics and a smoothness prior to improve wavefront reconstruction. By using multiple spatial light modulator's phase patterns, PWI enhances Fisher information, boosting theoretical accuracy and regularizing the retrieval process effectively. In simulations, PWI approaches the theoretical phase error limit, and in experiments it reduces phase error by up to 1.6x compared to the Gerchberg-Saxton algorithm, achieving 1.8x higher resolution wavefront imaging in low photon regime. This method advances photon-limited imaging with applications in astronomy, semiconductor metrology, and biological systems."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-13T17:28:31Z",
            "published_parsed": [
                2025,
                12,
                13,
                17,
                28,
                31,
                5,
                347,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Seungman Choi"
                },
                {
                    "name": "Peter Menart"
                },
                {
                    "name": "Andrew Schramka"
                },
                {
                    "name": "Leif Bauer"
                },
                {
                    "name": "Vaneet Aggarwal"
                },
                {
                    "name": "In-Yong Park"
                },
                {
                    "name": "Zubin Jacob"
                }
            ],
            "author_detail": {
                "name": "Zubin Jacob"
            },
            "author": "Zubin Jacob",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "光子匮乏场景中的泊松波前成像",
            "abstract_cn": "在信号因曝光时间短、目标微弱或需要保护精致样品而受到限制的应用中，低光子相位成像至关重要。我们通过泊松波前成像 (PWI) 来应对这一挑战，这是一种基于优化的方法，结合了泊松光子统计和先于平滑度来改进波前重建。通过使用多个空间光调制器的相位模式，PWI增强了Fisher信息，提高了理论准确性并有效规范了检索过程。在模拟中，PWI 接近理论相位误差极限，在实验中，与 Gerchberg-Saxton 算法相比，它可将相位误差降低高达 1.6 倍，在低光子状态下实现更高分辨率 1.8 倍的波前成像。该方法推进了光子限制成像在天文学、半导体计量学和生物系统中的应用。"
        },
        {
            "id": "http://arxiv.org/abs/2512.12625v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.12625v1",
            "title": "Deep-learning-enabled inverse design of large-scale metasurfaces with full-wave accuracy",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Deep-learning-enabled inverse design of large-scale metasurfaces with full-wave accuracy"
            },
            "updated": "2025-12-14T10:09:51Z",
            "updated_parsed": [
                2025,
                12,
                14,
                10,
                9,
                51,
                6,
                348,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.12625v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.12625v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Recent advances in meta-optics have enabled diverse functionalities in compact optical devices; however, conventional forward design approaches become inadequate as device complexity and scale grow. Inverse design offers a powerful alternative but often requires massive computational resources and neglects mutual coupling effects. Here, we propose and experimentally validate a deep-learning-enabled framework for rapid inverse design of large-scale, aperiodic metasurfaces with full-wave accuracy.The framework integrates an inverse design network responsible that maps target near-field responses to metasurface geometries in a non-iterative and scalable manner. A lightweight forward prediction network, integrated as a full-wave solver surrogate within the framework, enables efficient end-to-end training of the inverse design network while capturing mutual coupling effects by considering both local and neighboring geometries.The framework's effectiveness is experimentally verified through a multi-foci metalens and a holographic metasurface. This framework enables the inverse design from micrometer to centimeter scales (> 20kλ), with near-field responses discrepancies less than 3% compared to full-wave solvers at subwavelength (< λ/10) resolution.Moreover, it is generalizable to metasurfaces of arbitrary size and operates efficiently without high-performance resources, overcoming the computational bottlenecks of previous inverse design methods.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Recent advances in meta-optics have enabled diverse functionalities in compact optical devices; however, conventional forward design approaches become inadequate as device complexity and scale grow. Inverse design offers a powerful alternative but often requires massive computational resources and neglects mutual coupling effects. Here, we propose and experimentally validate a deep-learning-enabled framework for rapid inverse design of large-scale, aperiodic metasurfaces with full-wave accuracy.The framework integrates an inverse design network responsible that maps target near-field responses to metasurface geometries in a non-iterative and scalable manner. A lightweight forward prediction network, integrated as a full-wave solver surrogate within the framework, enables efficient end-to-end training of the inverse design network while capturing mutual coupling effects by considering both local and neighboring geometries.The framework's effectiveness is experimentally verified through a multi-foci metalens and a holographic metasurface. This framework enables the inverse design from micrometer to centimeter scales (> 20kλ), with near-field responses discrepancies less than 3% compared to full-wave solvers at subwavelength (< λ/10) resolution.Moreover, it is generalizable to metasurfaces of arbitrary size and operates efficiently without high-performance resources, overcoming the computational bottlenecks of previous inverse design methods."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-14T10:09:51Z",
            "published_parsed": [
                2025,
                12,
                14,
                10,
                9,
                51,
                6,
                348,
                0
            ],
            "arxiv_comment": "28 pages, 22 figures; Accepted for publication in Laser & Photonics Reviews",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Borui Xu"
                },
                {
                    "name": "Jingzhu Shao"
                },
                {
                    "name": "Xiangyu Zhao"
                },
                {
                    "name": "Haishan Xu"
                },
                {
                    "name": "Yudong Tian"
                },
                {
                    "name": "Nanxi Chen"
                },
                {
                    "name": "Jielin Sun"
                },
                {
                    "name": "Han Lin"
                },
                {
                    "name": "Qiaoliang Bao"
                },
                {
                    "name": "Yiyong Mai"
                },
                {
                    "name": "Chongzhao Wu"
                }
            ],
            "author_detail": {
                "name": "Chongzhao Wu"
            },
            "author": "Chongzhao Wu",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "支持深度学习的全波精度大规模超表面逆向设计",
            "abstract_cn": "元光学的最新进展使得紧凑型光学设备具有多种功能。然而，随着设备复杂性和规模的增长，传统的正向设计方法变得不够充分。逆向设计提供了一种强大的替代方案，但通常需要大量的计算资源并且忽略了相互耦合效应。在这里，我们提出并实验验证了一种支持深度学习的框架，用于以全波精度快速逆向设计大规模非周期性超表面。该框架集成了一个逆向设计网络，负责以非迭代和可扩展的方式将目标近场响应映射到超表面几何形状。轻量级前向预测网络作为全波求解器代理集成在框架内，可实现逆向设计网络的高效端到端训练，同时通过考虑局部和邻近几何形状来捕获相互耦合效应。该框架的有效性通过多焦点超透镜和全息超表面进行了实验验证。该框架可实现从微米到厘米尺度（> 20kλ）的逆设计，与亚波长（< λ/10）分辨率的全波求解器相比，近场响应差异小于3%。而且，它可推广到任意尺寸的超表面，无需高性能资源即可高效运行，克服了以往逆设计方法的计算瓶颈。"
        },
        {
            "id": "http://arxiv.org/abs/2512.12912v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.12912v1",
            "title": "High-visibility ghost imaging by holographic projection with classical light",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "High-visibility ghost imaging by holographic projection with classical light"
            },
            "updated": "2025-12-15T01:54:46Z",
            "updated_parsed": [
                2025,
                12,
                15,
                1,
                54,
                46,
                0,
                349,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.12912v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.12912v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "By adopting computational holography, we realized the super-bunching effect achieving the peak-to-background ratio 39.77 proposed in the article [arXiv:2510.20421v1]. In this paper, various reference signals from computational holography and corresponding bucket detection signals are used in the intensity correlation algorithm of ghost imaging (GI) scheme. In the experiment, we use two types of target patterns, intensity squared chaotic speckle and artificially designed sparse matrix, performing GI by holographic projection. Those imaging results show that the visibility of ghost image can be significantly improved whether the reference signal is the reconstruction pattern or the target pattern of computational holography. Furthermore, we realize positive and negative copies of ghost image by the aid of computational holography in which symmetrical target patterns are artificially designed. Thus, our study by means of computational holography not only presents a step toward meeting the visibility requirement for practical applications but also broadens the category of intensity correlation algorithm of classical light GI scheme.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "By adopting computational holography, we realized the super-bunching effect achieving the peak-to-background ratio 39.77 proposed in the article [arXiv:2510.20421v1]. In this paper, various reference signals from computational holography and corresponding bucket detection signals are used in the intensity correlation algorithm of ghost imaging (GI) scheme. In the experiment, we use two types of target patterns, intensity squared chaotic speckle and artificially designed sparse matrix, performing GI by holographic projection. Those imaging results show that the visibility of ghost image can be significantly improved whether the reference signal is the reconstruction pattern or the target pattern of computational holography. Furthermore, we realize positive and negative copies of ghost image by the aid of computational holography in which symmetrical target patterns are artificially designed. Thus, our study by means of computational holography not only presents a step toward meeting the visibility requirement for practical applications but also broadens the category of intensity correlation algorithm of classical light GI scheme."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-15T01:54:46Z",
            "published_parsed": [
                2025,
                12,
                15,
                1,
                54,
                46,
                0,
                349,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Liming Li"
                },
                {
                    "name": "Xueying Wu"
                },
                {
                    "name": "Gongxiang Wei"
                },
                {
                    "name": "Huiqiang Liu"
                }
            ],
            "author_detail": {
                "name": "Huiqiang Liu"
            },
            "author": "Huiqiang Liu",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "通过经典光全息投影实现高可见度重影成像",
            "abstract_cn": "通过采用计算全息术，我们实现了超级聚束效应，达到了文章[arXiv:2510.20421v1]中提出的峰背景比39.77。本文在鬼影成像（GI）方案的强度相关算法中使用了来自计算全息术的各种参考信号和相应的桶检测信号。实验中，我们使用强度平方混沌散斑和人工设计的稀疏矩阵两种目标图案，通过全息投影进行GI。成像结果表明，无论参考信号是重建图案还是计算全息的目标图案，重影图像的可见度都能得到显着提高。此外，我们借助计算全息技术实现了鬼像的正片和负片副本，其中人工设计了对称的目标图案。因此，我们通过计算全息技术进行的研究不仅朝着满足实际应用的可见性要求迈出了一步，而且拓宽了经典光GI方案的强度相关算法的类别。"
        },
        {
            "id": "http://arxiv.org/abs/2512.13882v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.13882v1",
            "title": "Achieving $10^{-5}$ level relative intensity crosstalk in optical holographic qubit addressing via a double-pass digital micromirror device",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Achieving $10^{-5}$ level relative intensity crosstalk in optical holographic qubit addressing via a double-pass digital micromirror device"
            },
            "updated": "2025-12-15T20:35:40Z",
            "updated_parsed": [
                2025,
                12,
                15,
                20,
                35,
                40,
                0,
                349,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.13882v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.13882v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Holographic beam shaping is a powerful approach for generating individually addressable optical spots for controlling atomic qubits, such as those in trapped-ion quantum processors. However, its application in qubit control is limited by residual intensity crosstalk at neighboring sites and by a nonzero background floor in the far wings of the addressing beam, leading to accumulated errors from many exposed qubits. Here, we present an all-optical scheme that mitigates both effects using a single digital micromirror device (DMD) operated in a double-pass configuration, in which light interacts with two separate regions of the same device. In the first pass, one region of the DMD is placed in a Fourier plane and implements a binary-amplitude hologram for individual addressing, while in the second pass a different region serves as a programmable intermediate image-plane aperture for spatial filtering. By multiplexing the Fourier-plane hologram to include secondary holograms, we generate weak auxiliary fields that interfere destructively with unwanted light at selected sites, while image-plane filtering suppresses the residual tail at larger distances. Together, these techniques maintain relative intensity crosstalk at or below $10^{-5}$ ($-50\\,\\mathrm{dB}$) across the full field of view relevant for qubit addressing, and further reduce the far-wing background to approximately $10^{-6}$ at large distances from the addressed qubit, approaching the detection limit. These results provide a compact, DMD-based solution for low-crosstalk optical holographic qubit addressing that is directly applicable to trapped ions and other spatially ordered quantum systems.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Holographic beam shaping is a powerful approach for generating individually addressable optical spots for controlling atomic qubits, such as those in trapped-ion quantum processors. However, its application in qubit control is limited by residual intensity crosstalk at neighboring sites and by a nonzero background floor in the far wings of the addressing beam, leading to accumulated errors from many exposed qubits. Here, we present an all-optical scheme that mitigates both effects using a single digital micromirror device (DMD) operated in a double-pass configuration, in which light interacts with two separate regions of the same device. In the first pass, one region of the DMD is placed in a Fourier plane and implements a binary-amplitude hologram for individual addressing, while in the second pass a different region serves as a programmable intermediate image-plane aperture for spatial filtering. By multiplexing the Fourier-plane hologram to include secondary holograms, we generate weak auxiliary fields that interfere destructively with unwanted light at selected sites, while image-plane filtering suppresses the residual tail at larger distances. Together, these techniques maintain relative intensity crosstalk at or below $10^{-5}$ ($-50\\,\\mathrm{dB}$) across the full field of view relevant for qubit addressing, and further reduce the far-wing background to approximately $10^{-6}$ at large distances from the addressed qubit, approaching the detection limit. These results provide a compact, DMD-based solution for low-crosstalk optical holographic qubit addressing that is directly applicable to trapped ions and other spatially ordered quantum systems."
            },
            "tags": [
                {
                    "term": "quant-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-15T20:35:40Z",
            "published_parsed": [
                2025,
                12,
                15,
                20,
                35,
                40,
                0,
                349,
                0
            ],
            "arxiv_comment": "7 pages, 3 figures",
            "arxiv_primary_category": {
                "term": "quant-ph"
            },
            "authors": [
                {
                    "name": "Shilpa Mahato"
                },
                {
                    "name": "Rajibul Islam"
                }
            ],
            "author_detail": {
                "name": "Rajibul Islam"
            },
            "author": "Rajibul Islam",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "通过双通道数字微镜器件在光学全息量子位寻址中实现 10^{-5}$ 级相对强度串扰",
            "abstract_cn": "全息光束整形是一种生成可单独寻址的光点以控制原子量子位（例如捕获离子量子处理器中的原子量子位）的强大方法。然而，其在量子位控制中的应用受到相邻位点的残余强度串扰以及寻址光束远翼中的非零背景基底的限制，从而导致许多暴露的量子位产生累积误差。在这里，我们提出了一种全光学方案，该方案使用在双通道配置中运行的单个数字微镜器件（DMD）来减轻这两种影响，其中光与同一器件的两个独立区域相互作用。在第一遍中，DMD 的一个区域被放置在傅里叶平面中，并实现用于单独寻址的二进制振幅全息图，而在第二遍中，不同的区域用作用于空间滤波的可编程中间图像平面孔径。通过复用傅里叶平面全息图以包含二次全息图，我们生成了弱辅助场，这些辅助场在选定位置对不需要的光进行破坏性干扰，而图像平面滤波则抑制了较大距离处的残留尾部。这些技术共同将与量子位寻址相关的整个视场的相对强度串扰保持在 $10^{-5}$ ($-50\\,\\mathrm{dB}$) 或以下，并在距寻址量子位较远的距离处进一步将远翼背景降低至大约 $10^{-6}$，接近检测极限。这些结果为低串扰光学全息量子位寻址提供了一种紧凑的、基于 DMD 的解决方案，可直接应用于捕获离子和其他空间有序量子系统。"
        },
        {
            "id": "http://arxiv.org/abs/2512.15967v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.15967v1",
            "title": "Full-field-of-view aberration correction for large arrays of focused beams",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Full-field-of-view aberration correction for large arrays of focused beams"
            },
            "updated": "2025-12-17T20:52:42Z",
            "updated_parsed": [
                2025,
                12,
                17,
                20,
                52,
                42,
                2,
                351,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.15967v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.15967v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We propose and implement an aberration correction method for the creation of extended arrays of spots well beyond the isoplanatic region of any optical system. The method relies on an extensive calibration of aberrations in terms of Zernike polynomials over the full accessible field of an optical system. We introduce a modified Gerchberg-Saxton algorithm for generating holographic phase masks creating fully corrected arbitrary arrays of spots. By applying the method to an aspherical lens, and using a liquid-crystal spatial light modulator (SLM), we increase the aberration-free field of view from 50 to 500 $μ$m, only limited by the largest diffraction angles accessible to the SLM. This opens new perspectives for the generation of large arrays of optical tweezers, especially for neutral atom based quantum processors and simulators.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We propose and implement an aberration correction method for the creation of extended arrays of spots well beyond the isoplanatic region of any optical system. The method relies on an extensive calibration of aberrations in terms of Zernike polynomials over the full accessible field of an optical system. We introduce a modified Gerchberg-Saxton algorithm for generating holographic phase masks creating fully corrected arbitrary arrays of spots. By applying the method to an aspherical lens, and using a liquid-crystal spatial light modulator (SLM), we increase the aberration-free field of view from 50 to 500 $μ$m, only limited by the largest diffraction angles accessible to the SLM. This opens new perspectives for the generation of large arrays of optical tweezers, especially for neutral atom based quantum processors and simulators."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "quant-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-17T20:52:42Z",
            "published_parsed": [
                2025,
                12,
                17,
                20,
                52,
                42,
                2,
                351,
                0
            ],
            "arxiv_comment": "9 pages,6 figures,",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Yohann Machu"
                },
                {
                    "name": "Gautier Creutzer"
                },
                {
                    "name": "Clément Sayrin"
                },
                {
                    "name": "Michel Brune"
                }
            ],
            "author_detail": {
                "name": "Michel Brune"
            },
            "author": "Michel Brune",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "对大型聚焦光束阵列进行全视场像差校正",
            "abstract_cn": "我们提出并实施了一种像差校正方法，用于创建远远超出任何光学系统等晕区域的扩展光斑阵列。该方法依赖于在光学系统的整个可访问区域上根据泽尼克多项式对像差进行广泛的校准。我们引入了一种改进的 Gerchberg-Saxton 算法，用于生成全息相位掩模，创建完全校正的任意点阵列。通过将该方法应用于非球面透镜，并使用液晶空间光调制器 (SLM)，我们将无像差视场从 50 $μ$m 增加到 500 $μ$m，仅受 SLM 可获得的最大衍射角限制。这为大型光镊阵列的产生开辟了新的视角，特别是对于基于中性原子的量子处理器和模拟器。"
        },
        {
            "id": "http://arxiv.org/abs/2512.16308v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.16308v1",
            "title": "Polygonal Spatiotemporal Optical Vortices Wavepackets with Prescribed Vortex Structure",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Polygonal Spatiotemporal Optical Vortices Wavepackets with Prescribed Vortex Structure"
            },
            "updated": "2025-12-18T08:48:02Z",
            "updated_parsed": [
                2025,
                12,
                18,
                8,
                48,
                2,
                3,
                352,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.16308v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.16308v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Optical vortices carrying orbital angular momentum offer additional degrees of freedom. According to the orientation of orbital angular momentum, optical vortices can be classified into spatial optical vortex beam carrying longitudinalorbital angular momentum and spatiotemporal optical vortices carrying transverse orbital angular momentum. As an emerging subset of optical vortices, polygonal optical vortices provide a unique platform for a wide range of frontier applications by introducing a new degree of freedom in the form of a customizable intensity structure. In the spatial domain, polygonal spatial optical vortex beam carrying longitudinal orbital angular momentum have already demonstrated great potential in optical manipulation and two-photon lithography. However, polygonal spatiotemporal optical vortex wavepackets contain multiple sub spatiotemporal optical vortices carrying transverse orbital angular momentum remains unrealized to date. In this work, we theoretically propose and experimentally demonstrate polygonal spatiotemporal optical vortices wavepackets embedded with prescribed vortex structures. Within the structure, a prescribed number of sub spatiotemporal optical vortices carrying transverse orbital angular momentum is set along a designed polygonal spatiotemporal trajectory. Using the spatiotemporal holographic shaping approach, we generate polygonal perfect spatiotemporal optical vortex wavepacket and use the combination of multiple polygonal perfect spatiotemporal optical vortex wavepacket to form polygonal spatiotemporal optical vortex wavepacket with the prescribed vortex structure. A full control over multiple key properties of the polygonal spatiotemporal optical vortex wavepackets such as the geometry, number of phase singularities, and spatiotemporal distribution of sub spatiotemporal optical vortices is also achieved.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Optical vortices carrying orbital angular momentum offer additional degrees of freedom. According to the orientation of orbital angular momentum, optical vortices can be classified into spatial optical vortex beam carrying longitudinalorbital angular momentum and spatiotemporal optical vortices carrying transverse orbital angular momentum. As an emerging subset of optical vortices, polygonal optical vortices provide a unique platform for a wide range of frontier applications by introducing a new degree of freedom in the form of a customizable intensity structure. In the spatial domain, polygonal spatial optical vortex beam carrying longitudinal orbital angular momentum have already demonstrated great potential in optical manipulation and two-photon lithography. However, polygonal spatiotemporal optical vortex wavepackets contain multiple sub spatiotemporal optical vortices carrying transverse orbital angular momentum remains unrealized to date. In this work, we theoretically propose and experimentally demonstrate polygonal spatiotemporal optical vortices wavepackets embedded with prescribed vortex structures. Within the structure, a prescribed number of sub spatiotemporal optical vortices carrying transverse orbital angular momentum is set along a designed polygonal spatiotemporal trajectory. Using the spatiotemporal holographic shaping approach, we generate polygonal perfect spatiotemporal optical vortex wavepacket and use the combination of multiple polygonal perfect spatiotemporal optical vortex wavepacket to form polygonal spatiotemporal optical vortex wavepacket with the prescribed vortex structure. A full control over multiple key properties of the polygonal spatiotemporal optical vortex wavepackets such as the geometry, number of phase singularities, and spatiotemporal distribution of sub spatiotemporal optical vortices is also achieved."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-18T08:48:02Z",
            "published_parsed": [
                2025,
                12,
                18,
                8,
                48,
                2,
                3,
                352,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Haifa Fan"
                },
                {
                    "name": "Qian Cao"
                },
                {
                    "name": "Andy Chong"
                },
                {
                    "name": "Qiwen Zhan"
                }
            ],
            "author_detail": {
                "name": "Qiwen Zhan"
            },
            "author": "Qiwen Zhan",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "具有规定涡旋结构的多边形时空光学涡旋波包",
            "abstract_cn": "携带轨道角动量的光学涡旋提供了额外的自由度。根据轨道角动量的方向，光学涡旋可分为承载纵向轨道角动量的空间光学涡旋光束和承载横向轨道角动量的时空光学涡旋。作为光学涡旋的新兴子集，多边形光学涡旋通过以可定制强度结构的形式引入新的自由度，为广泛的前沿应用提供了独特的平台。在空间领域，携带纵向轨道角动量的多边形空间光学涡旋光束已经在光学操纵和双光子光刻方面展现出巨大的潜力。然而，包含多个携带横向轨道角动量的子时空光学涡旋的多边形时空光学涡旋波包迄今为止仍未实现。在这项工作中，我们从理论上提出并通过实验证明了嵌入指定涡旋结构的多边形时空光学涡旋波包。在该结构内，沿着设计的多边形时空轨迹设置规定数量的携带横向轨道角动量的亚时空光学涡旋。利用时空全息整形方法，生成多边形完美时空光学涡旋波包，并利用多个多边形完美时空光学涡旋波包的组合形成具有指定涡旋结构的多边形时空光学涡旋波包。还实现了对多边形时空光学涡旋波包的多个关键属性的完全控制，例如几何形状、相位奇异点的数量以及亚时空光学涡旋的时空分布。"
        },
        {
            "id": "http://arxiv.org/abs/2512.16471v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.16471v1",
            "title": "An epsilon-near-zero-based nonlinear platform for ultrafast re-writable holography",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "An epsilon-near-zero-based nonlinear platform for ultrafast re-writable holography"
            },
            "updated": "2025-12-18T12:44:08Z",
            "updated_parsed": [
                2025,
                12,
                18,
                12,
                44,
                8,
                3,
                352,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.16471v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.16471v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We re-examine real-time holography for all-optical structuring of light and optical computation using a contemporary material: a subwavelength-thick, spatially unstructured film of indium tin oxide (ITO). When excited by spatially structured light at epsilon-near-zero frequencies, the film acts as an efficient and reconfigurable diffractive optical platform for all-optical modulation of light such as spatial structuring and optical computations. We demonstrate a few percent of absolute diffraction efficiency over greater than 300 nm bandwidth around telecom wavelengths using a film four orders of magnitude thinner than and up to six orders of magnitude faster than standard holographic materials. Our findings highlight the potential of using epsilon-near-zero-based nanostructures for efficient modulation of spatially structured light and rapid prototyping without complex nanofabrication processes.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We re-examine real-time holography for all-optical structuring of light and optical computation using a contemporary material: a subwavelength-thick, spatially unstructured film of indium tin oxide (ITO). When excited by spatially structured light at epsilon-near-zero frequencies, the film acts as an efficient and reconfigurable diffractive optical platform for all-optical modulation of light such as spatial structuring and optical computations. We demonstrate a few percent of absolute diffraction efficiency over greater than 300 nm bandwidth around telecom wavelengths using a film four orders of magnitude thinner than and up to six orders of magnitude faster than standard holographic materials. Our findings highlight the potential of using epsilon-near-zero-based nanostructures for efficient modulation of spatially structured light and rapid prototyping without complex nanofabrication processes."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-18T12:44:08Z",
            "published_parsed": [
                2025,
                12,
                18,
                12,
                44,
                8,
                3,
                352,
                0
            ],
            "arxiv_comment": "9 pages, 7 figures (including supplemental document)",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "M. Zahirul Alam"
                },
                {
                    "name": "Robert Fickler"
                },
                {
                    "name": "Yiyu Zhou"
                },
                {
                    "name": "Enno Giese"
                },
                {
                    "name": "Jeremy Upham"
                },
                {
                    "name": "Robert W. Boyd"
                }
            ],
            "author_detail": {
                "name": "Robert W. Boyd"
            },
            "author": "Robert W. Boyd",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "用于超快可重写全息术的基于ε的近零非线性平台",
            "abstract_cn": "我们使用当代材料重新审视实时全息术，以实现光的全光学结构和光学计算：亚波长厚的、空间非结构化的氧化铟锡 (ITO) 薄膜。当受到ε接近零频率的空间结构光激发时，该薄膜充当高效且可重构的衍射光学平台，用于光的全光学调制，例如空间结构和光学计算。我们使用比标准全息材料薄四个数量级且比标准全息材料快六个数量级的薄膜，展示了在电信波长周围超过 300 nm 带宽内的绝对衍射效率为百分之几。我们的研究结果强调了使用基于ε的近零纳米结构有效调制空间结构光和快速原型制作的潜力，而无需复杂的纳米制造过程。"
        },
        {
            "id": "http://arxiv.org/abs/2512.17879v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.17879v1",
            "title": "Inverse-Designed Phase Prediction in Digital Lasers Using Deep Learning and Transfer Learning",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Inverse-Designed Phase Prediction in Digital Lasers Using Deep Learning and Transfer Learning"
            },
            "updated": "2025-12-19T18:32:22Z",
            "updated_parsed": [
                2025,
                12,
                19,
                18,
                32,
                22,
                4,
                353,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.17879v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.17879v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Digital lasers control the laser beam by dynamically updating the phase patterns of the spatial light modulator (SLM) within the laser cavity. Due to the presence of nonlinear effects, such as mode competition and gain saturation in digital laser systems, it is often necessary to rely on specifically manually tailored approach or iteration processes to find suitable loaded phases in Digital lasers. This study proposes a model based on Conditional Generative Adversarial Networks (cGAN) and a modified U-Net architecture, with designed loss functions to inverse design the loaded phases. In this work, we employ deep neural networks to learn the nonlinear effects in simulated L-shape digital lasers, enabling the prediction of SLM-loaded phases for both analytical and non-analytical arbitrary structured light fields. The results demonstrate superior performance on non-analytical light fields compared to the current methods in L-shape Digital lasers. Furthermore, a transfer learning strategy is introduced, allowing knowledge obtained from one class of structured beams to be effectively reused for another, thereby enhancing generalization and improving performance under limited training data. Importantly, this method, the first proposed learning framework for digital lasers, is not limited to the L-shaped digital lasers discussed in this study, providing an efficient alternative for generating structured light in other digital laser systems.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Digital lasers control the laser beam by dynamically updating the phase patterns of the spatial light modulator (SLM) within the laser cavity. Due to the presence of nonlinear effects, such as mode competition and gain saturation in digital laser systems, it is often necessary to rely on specifically manually tailored approach or iteration processes to find suitable loaded phases in Digital lasers. This study proposes a model based on Conditional Generative Adversarial Networks (cGAN) and a modified U-Net architecture, with designed loss functions to inverse design the loaded phases. In this work, we employ deep neural networks to learn the nonlinear effects in simulated L-shape digital lasers, enabling the prediction of SLM-loaded phases for both analytical and non-analytical arbitrary structured light fields. The results demonstrate superior performance on non-analytical light fields compared to the current methods in L-shape Digital lasers. Furthermore, a transfer learning strategy is introduced, allowing knowledge obtained from one class of structured beams to be effectively reused for another, thereby enhancing generalization and improving performance under limited training data. Importantly, this method, the first proposed learning framework for digital lasers, is not limited to the L-shaped digital lasers discussed in this study, providing an efficient alternative for generating structured light in other digital laser systems."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-19T18:32:22Z",
            "published_parsed": [
                2025,
                12,
                19,
                18,
                32,
                22,
                4,
                353,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Yu-Che Wu"
                },
                {
                    "name": "Kuo-Chih Chang"
                },
                {
                    "name": "Shu-Chun Chu"
                }
            ],
            "author_detail": {
                "name": "Shu-Chun Chu"
            },
            "author": "Shu-Chun Chu",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "使用深度学习和迁移学习的数字激光器逆向设计相位预测",
            "abstract_cn": "数字激光器通过动态更新激光腔内空间光调制器 (SLM) 的相位图案来控制激光束。由于数字激光系统中存在非线性效应，例如模式竞争和增益饱和，通常需要依靠专门手动定制的方法或迭代过程来找到数字激光器中合适的负载相位。本研究提出了一种基于条件生成对抗网络（cGAN）和改进的 U-Net 架构的模型，并设计了损失函数来逆向设计加载阶段。在这项工作中，我们采用深度神经网络来学习模拟 L 形数字激光器中的非线性效应，从而能够预测分析和非分析任意结构光场的 SLM 加载相位。结果表明，与 L 形数字激光器中的当前方法相比，在非分析光场上具有卓越的性能。此外，引入了迁移学习策略，允许从一类结构化梁中获得的知识可以有效地重用于另一类结构化梁，从而增强泛化能力并提高有限训练数据下的性能。重要的是，该方法是第一个提出的数字激光器学习框架，不仅限于本研究中讨论的L形数字激光器，为在其他数字激光系统中生成结构光提供了有效的替代方案。"
        },
        {
            "id": "http://arxiv.org/abs/2512.19072v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.19072v1",
            "title": "A fast, large-scale optimal transport algorithm for holographic beam shaping",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "A fast, large-scale optimal transport algorithm for holographic beam shaping"
            },
            "updated": "2025-12-22T06:21:45Z",
            "updated_parsed": [
                2025,
                12,
                22,
                6,
                21,
                45,
                0,
                356,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.19072v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.19072v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Optimal transport methods have recently established state of the art accuracy and efficiency for holographic laser beam shaping. However, use of such methods is hindered by severe $\\mathcal{O}(N^2)$ memory and $\\mathcal{O}(N^2)$ time requirements for large scale input or output images with $N$ total pixels. Here we leverage the dual formulation of the optimal transport problem and the separable structure of the cost to implement algorithms with greatly reduced $\\mathcal{O}(N)$ memory and $\\mathcal{O}(N\\log N)$ to $\\mathcal{O}(N^{3/2})$ time complexity. These algorithms are parallelizable and can solve megapixel-scale beam shaping problems in tens of seconds on a CPU or seconds on a GPU.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Optimal transport methods have recently established state of the art accuracy and efficiency for holographic laser beam shaping. However, use of such methods is hindered by severe $\\mathcal{O}(N^2)$ memory and $\\mathcal{O}(N^2)$ time requirements for large scale input or output images with $N$ total pixels. Here we leverage the dual formulation of the optimal transport problem and the separable structure of the cost to implement algorithms with greatly reduced $\\mathcal{O}(N)$ memory and $\\mathcal{O}(N\\log N)$ to $\\mathcal{O}(N^{3/2})$ time complexity. These algorithms are parallelizable and can solve megapixel-scale beam shaping problems in tens of seconds on a CPU or seconds on a GPU."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.atom-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "quant-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-22T06:21:45Z",
            "published_parsed": [
                2025,
                12,
                22,
                6,
                21,
                45,
                0,
                356,
                0
            ],
            "arxiv_comment": "8 pages, 4 figures, plus supplement",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Andrii Torchylo"
                },
                {
                    "name": "Hunter Swan"
                },
                {
                    "name": "Lucas Tellez"
                },
                {
                    "name": "Jason Hogan"
                }
            ],
            "author_detail": {
                "name": "Jason Hogan"
            },
            "author": "Jason Hogan",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "一种用于全息光束整形的快速、大规模优化传输算法",
            "abstract_cn": "最佳传输方法最近确立了全息激光束整形的最先进的精度和效率。然而，对于总像素为 N$ 的大规模输入或输出图像，严重的 $\\mathcal{O}(N^2)$ 内存和 $\\mathcal{O}(N^2)$ 时间要求阻碍了此类方法的使用。在这里，我们利用最优传输问题的双重表述和成本的可分离结构来实现算法，大大降低了 $\\mathcal{O}(N)$ 内存和 $\\mathcal{O}(N\\log N)$ 到 $\\mathcal{O}(N^{3/2})$ 时间复杂度。这些算法是可并行的，可以在 CPU 上几十秒或在 GPU 上几秒内解决百万像素级的光束整形问题。"
        },
        {
            "id": "http://arxiv.org/abs/2512.19168v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.19168v1",
            "title": "Optical design and characterization of a multi-depth vision simulator",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Optical design and characterization of a multi-depth vision simulator"
            },
            "updated": "2025-12-22T09:03:25Z",
            "updated_parsed": [
                2025,
                12,
                22,
                9,
                3,
                25,
                0,
                356,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.19168v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.19168v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We present a vision simulator device (Katsim), a compact near-eye optical display designed for assessing postoperative corrected vision, preoperative intraocular lens (IOL) assessment, and objective IOL characterization. The system forms a virtual image using an amplitude-modulated LCoS spatial light modulator (AM-SLM), RGB LED illumination, and a high-speed varifocal lens. In the proposed architecture, the LED illumination and varifocal lens diopter changes are triggered in synchrony with the SLM RGB subframes, rendering three depth planes perceptually simultaneously via high-frequency time-multiplexing. Operating at 60 frames per second (fps), the system achieves an effective 180 Hz depth-coded cycle, enabling sharp, multi-depth rendering within a dynamically adjustable depth range from 0.2 m to optical infinity. The system's eyebox is configurable from 1 to 5 mm, while maintaining a fixed spatial location and preserving angular magnification regardless of changes in focus or eyebox size. The designed system features a 9.15-degree field of view. An integrated infrared pupil-tracking module detects non-cataractous regions of the cataractous crystalline lens, and the projected imagery is mechanically steered through those clear zones in real time. The proposed vision simulator supports both subjective simulation of post-surgical vision for patient-specific counseling and objective optical evaluation of IOLs, including resolution and contrast fidelity (e.g., modulation transfer function, contrast transfer function, and defocus curves). By decoupling depth modulation from eyebox position and size, the system offers a modular, portable platform that supports enhanced preoperative planning, personalized IOL selection, objective IOL characterization, and use as a novel research vision tool.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We present a vision simulator device (Katsim), a compact near-eye optical display designed for assessing postoperative corrected vision, preoperative intraocular lens (IOL) assessment, and objective IOL characterization. The system forms a virtual image using an amplitude-modulated LCoS spatial light modulator (AM-SLM), RGB LED illumination, and a high-speed varifocal lens. In the proposed architecture, the LED illumination and varifocal lens diopter changes are triggered in synchrony with the SLM RGB subframes, rendering three depth planes perceptually simultaneously via high-frequency time-multiplexing. Operating at 60 frames per second (fps), the system achieves an effective 180 Hz depth-coded cycle, enabling sharp, multi-depth rendering within a dynamically adjustable depth range from 0.2 m to optical infinity. The system's eyebox is configurable from 1 to 5 mm, while maintaining a fixed spatial location and preserving angular magnification regardless of changes in focus or eyebox size. The designed system features a 9.15-degree field of view. An integrated infrared pupil-tracking module detects non-cataractous regions of the cataractous crystalline lens, and the projected imagery is mechanically steered through those clear zones in real time. The proposed vision simulator supports both subjective simulation of post-surgical vision for patient-specific counseling and objective optical evaluation of IOLs, including resolution and contrast fidelity (e.g., modulation transfer function, contrast transfer function, and defocus curves). By decoupling depth modulation from eyebox position and size, the system offers a modular, portable platform that supports enhanced preoperative planning, personalized IOL selection, objective IOL characterization, and use as a novel research vision tool."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "eess.SY",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-22T09:03:25Z",
            "published_parsed": [
                2025,
                12,
                22,
                9,
                3,
                25,
                0,
                356,
                0
            ],
            "arxiv_comment": "16 pages, 8 figures. Preprint submitted to Biomedical Optics Express journal",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Parviz Zolfaghari"
                },
                {
                    "name": "Ehsan Varasteh"
                },
                {
                    "name": "Koray Kavakli"
                },
                {
                    "name": "Arda Gulersoy"
                },
                {
                    "name": "Afsun Sahin"
                },
                {
                    "name": "Hakan Urey"
                }
            ],
            "author_detail": {
                "name": "Hakan Urey"
            },
            "author": "Hakan Urey",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "多深度视觉模拟器的光学设计和表征",
            "abstract_cn": "我们推出了一种视觉模拟器设备 (Katsim)，这是一种紧凑型近眼光学显示器，设计用于评估术后矫正视力、术前人工晶状体 (IOL) 评估和客观 IOL 表征。该系统使用调幅 LCoS 空间光调制器 (AM-SLM)、RGB LED 照明和高速变焦镜头形成虚拟图像。在所提出的架构中，LED 照明和变焦镜头屈光度变化与 SLM RGB 子帧同步触发，通过高频时分复用同时感知地渲染三个深度平面。该系统以每秒 60 帧 (fps) 的速度运行，可实现有效的 180 Hz 深度编码周期，从而在 0.2 m 到光学无限远的动态可调深度范围内实现清晰的多深度渲染。该系统的视窗范围可配置为 1 至 5 毫米，同时保持固定的空间位置并保持角度放大倍率，无论焦点或视窗尺寸如何变化。设计的系统具有 9.15 度的视野。集成的红外瞳孔跟踪模块可检测白内障晶状体的非白内障区域，并通过机械方式实时引导投影图像穿过这些清晰区域。所提出的视觉模拟器支持针对患者特定咨询的术后视力主观模拟和 IOL 的客观光学评估，包括分辨率和对比度保真度（例如调制传递函数、对比度传递函数和散焦曲线）。通过将深度调制与眼箱位置和尺寸解耦，该系统提供了一个模块化的便携式平台，支持增强的术前规划、个性化 IOL 选择、客观 IOL 表征以及用作新颖的研究视觉工具。"
        },
        {
            "id": "http://arxiv.org/abs/2512.19412v2",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.19412v2",
            "title": "Sculpting ultrafast mid-infrared light for solid-state high harmonic generation",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Sculpting ultrafast mid-infrared light for solid-state high harmonic generation"
            },
            "updated": "2026-01-03T03:09:12Z",
            "updated_parsed": [
                2026,
                1,
                3,
                3,
                9,
                12,
                5,
                3,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.19412v2",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.19412v2",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "The ability to sculpt light in space, time, and polarization has revolutionized studies of light-matter interaction and enabled breakthroughs in optical communication, imaging, and ultrafast science. Among the many degrees of freedom of light, orbital angular momentum (OAM) further expands these capabilities by unlocking new regimes of control in information encoding, particle trapping and manipulation, and symmetry-driven selection rules. However, exploiting OAM to drive nonlinear, non-perturbative effects in solids remains challenging, especially in the mid-infrared (MIR) spectral regime-a key region for accessing these effects in ambient air, where spatial light modulators do not operate. Here, we circumvent this limitation by generating femtosecond, few-cycle MIR Bessel-Gauss vortex (BGV) and perfect optical vortices (POVs), using a robust, static spatial-shaping strategy. By utilizing these beams to drive nonlinear optical processes such as second-harmonic generation (SHG) and high-harmonic generation (HHG) in various solid-state materials, we show that the resulting harmonic beams faithfully inherit the structural characteristics of the drivers: the constant-intensity ring of the POVs is preserved across harmonic orders, while the BGV harmonic beams retain their intrinsic topological charge-dependent intensity profiles. Furthermore, by verifying the linear OAM up-scaling law, we confirm the conservation of OAM during SHG and HHG in solids. These results establish strong-field HHG in solids as a robust platform for synthesizing ultrafast structured harmonic light with controllable, high-value OAM.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "The ability to sculpt light in space, time, and polarization has revolutionized studies of light-matter interaction and enabled breakthroughs in optical communication, imaging, and ultrafast science. Among the many degrees of freedom of light, orbital angular momentum (OAM) further expands these capabilities by unlocking new regimes of control in information encoding, particle trapping and manipulation, and symmetry-driven selection rules. However, exploiting OAM to drive nonlinear, non-perturbative effects in solids remains challenging, especially in the mid-infrared (MIR) spectral regime-a key region for accessing these effects in ambient air, where spatial light modulators do not operate. Here, we circumvent this limitation by generating femtosecond, few-cycle MIR Bessel-Gauss vortex (BGV) and perfect optical vortices (POVs), using a robust, static spatial-shaping strategy. By utilizing these beams to drive nonlinear optical processes such as second-harmonic generation (SHG) and high-harmonic generation (HHG) in various solid-state materials, we show that the resulting harmonic beams faithfully inherit the structural characteristics of the drivers: the constant-intensity ring of the POVs is preserved across harmonic orders, while the BGV harmonic beams retain their intrinsic topological charge-dependent intensity profiles. Furthermore, by verifying the linear OAM up-scaling law, we confirm the conservation of OAM during SHG and HHG in solids. These results establish strong-field HHG in solids as a robust platform for synthesizing ultrafast structured harmonic light with controllable, high-value OAM."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-22T14:10:45Z",
            "published_parsed": [
                2025,
                12,
                22,
                14,
                10,
                45,
                0,
                356,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Camilo Granados"
                },
                {
                    "name": "Bálint Kiss"
                },
                {
                    "name": "Eric Cormier"
                },
                {
                    "name": "Bikash Kumar Das"
                },
                {
                    "name": "Debobrata Rajak"
                },
                {
                    "name": "Carmelo Rosales-Guzman"
                },
                {
                    "name": "Rajaram Shrestha"
                },
                {
                    "name": "Qiwen Zhan"
                },
                {
                    "name": "Wenlong Gao"
                }
            ],
            "author_detail": {
                "name": "Wenlong Gao"
            },
            "author": "Wenlong Gao",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "塑造超快中红外光以产生固态高次谐波",
            "abstract_cn": "在空间、时间和偏振方面塑造光的能力彻底改变了光与物质相互作用的研究，并实现了光通信、成像和超快科学的突破。在光的多个自由度中，轨道角动量（OAM）通过解锁信息编码、粒子捕获和操纵以及对称驱动的选择规则方面的新控制机制，进一步扩展了这些能力。然而，利用 OAM 来驱动固体中的非线性、非微扰效应仍然具有挑战性，特别是在中红外 (MIR) 光谱范围内，这是在环境空气中获取这些效应的关键区域，空间光调制器在该区域不工作。在这里，我们通过使用稳健的静态空间整形策略生成飞秒、少周期中红外贝塞尔-高斯涡旋 (BGV) 和完美光学涡旋 (POV) 来规避这一限制。通过利用这些光束来驱动非线性光学过程，例如各种固态材料中的二次谐波产生（SHG）和高次谐波产生（HHG），我们表明所产生的谐波光束忠实地继承了驱动器的结构特征：POV的恒定强度环在谐波阶上得以保留，而BGV谐波光束保留了其固有的拓扑电荷相关强度分布。此外，通过验证线性OAM放大定律，我们证实了固体中SHG和HHG期间OAM的守恒。这些结果将固体中的强场 HHG 建立为一个强大的平台，用于合成具有可控、高值 OAM 的超快结构谐波光。"
        },
        {
            "id": "http://arxiv.org/abs/2512.19419v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.19419v1",
            "title": "Hair-thin confocal fluorescence endo-microscopy for deep-brain in-vivo imaging",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Hair-thin confocal fluorescence endo-microscopy for deep-brain in-vivo imaging"
            },
            "updated": "2025-12-22T14:20:58Z",
            "updated_parsed": [
                2025,
                12,
                22,
                14,
                20,
                58,
                0,
                356,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.19419v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.19419v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Confocal and multi-photon microscopy are widely used for in-vivo fluorescence imaging of biological tissues such as the brain, offering non-invasive access up to ~1 mm depth without major loss in performance. A recently-developed alternative is holographic endoscopy, which exploits controlled light transport through hair-thin optical fibres. With minimal invasiveness, it provides observations at comparable spatial resolution, while extending its applicability to unprecedented depths. It has been used to resolve details of sub-cellular structural connectivity, record neuronal signalling, and monitor blood flow from the deepest locations of the living brain. Yet, its use, particularly in densely labelled brain regions, has so far been constrained by significant contrast loss, primarily due to the absence of a practical mechanism for rejecting out-of-focus fluorescence light -- a capability inherently provided by confocal and multi-photon microscopy. Exploring opportunities in the structure of light modes of different MMF types we identify the possibility of achieving an analogue to confocal fluorescence microscopy through MMF-based endoscopes. Using a novel composite fibre probe that combines graded-index and step-index MMFs, we enable spatially resolved signal collection and selective rejection of out-of-focus light. This confocal filtering significantly enhances image contrast and resolution by suppressing background and off-plane signals. We demonstrate improved imaging performance on fine structural connectivity and intracellular calcium signalling in living mouse brain.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Confocal and multi-photon microscopy are widely used for in-vivo fluorescence imaging of biological tissues such as the brain, offering non-invasive access up to ~1 mm depth without major loss in performance. A recently-developed alternative is holographic endoscopy, which exploits controlled light transport through hair-thin optical fibres. With minimal invasiveness, it provides observations at comparable spatial resolution, while extending its applicability to unprecedented depths. It has been used to resolve details of sub-cellular structural connectivity, record neuronal signalling, and monitor blood flow from the deepest locations of the living brain. Yet, its use, particularly in densely labelled brain regions, has so far been constrained by significant contrast loss, primarily due to the absence of a practical mechanism for rejecting out-of-focus fluorescence light -- a capability inherently provided by confocal and multi-photon microscopy. Exploring opportunities in the structure of light modes of different MMF types we identify the possibility of achieving an analogue to confocal fluorescence microscopy through MMF-based endoscopes. Using a novel composite fibre probe that combines graded-index and step-index MMFs, we enable spatially resolved signal collection and selective rejection of out-of-focus light. This confocal filtering significantly enhances image contrast and resolution by suppressing background and off-plane signals. We demonstrate improved imaging performance on fine structural connectivity and intracellular calcium signalling in living mouse brain."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "q-bio.NC",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-22T14:20:58Z",
            "published_parsed": [
                2025,
                12,
                22,
                14,
                20,
                58,
                0,
                356,
                0
            ],
            "arxiv_comment": "11 pages (3 figures) + 6 pages of Supplementary information (6 figures, 11 media)",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Tomáš Pikálek"
                },
                {
                    "name": "Miroslav Stibůrek"
                },
                {
                    "name": "Tereza Tučková"
                },
                {
                    "name": "Petra Kolbábková"
                },
                {
                    "name": "Sergey Turtaev"
                },
                {
                    "name": "Jana Krejčí"
                },
                {
                    "name": "Petra Ondráčková"
                },
                {
                    "name": "Hana Uhlířová"
                },
                {
                    "name": "Tomáš Čižmár"
                }
            ],
            "author_detail": {
                "name": "Tomáš Čižmár"
            },
            "author": "Tomáš Čižmár",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "用于深部脑体内成像的细如发丝的共焦荧光内窥镜",
            "abstract_cn": "共焦和多光子显微镜广泛用于生物组织（例如大脑）的体内荧光成像，可提供高达约 1 毫米深度的非侵入性成像，且性能不会出现重大损失。最近开发的替代方案是全息内窥镜，它利用通过头发丝细的光纤进行受控光传输。它具有最小的侵入性，可以以相当的空间分辨率提供观测，同时将其适用性扩展到前所未有的深度。它已被用来解析亚细胞结构连接的细节，记录神经元信号传导，并监测活体大脑最深处的血流。然而，它的使用，特别是在密集标记的大脑区域，迄今为止受到显着对比度损失的限制，这主要是由于缺乏拒绝离焦荧光的实用机制——这是共焦和多光子显微镜固有提供的功能。通过探索不同 MMF 类型的光模式结构中的机会，我们确定了通过基于 MMF 的内窥镜实现类似于共焦荧光显微镜的可能性。使用结合了渐变折射率和阶跃折射率多模光纤的新型复合光纤探头，我们能够实现空间分辨信号收集并选择性抑制离焦光。这种共焦滤波通过抑制背景和离面信号显着增强图像对比度和分辨率。我们证明了活体小鼠大脑精细结构连接和细胞内钙信号传导的成像性能得到改善。"
        },
        {
            "id": "http://arxiv.org/abs/2512.19815v2",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.19815v2",
            "title": "Power-Scalable Generation of High-Order Optical Vortices Via Coherent Beam Combining",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Power-Scalable Generation of High-Order Optical Vortices Via Coherent Beam Combining"
            },
            "updated": "2025-12-25T11:24:43Z",
            "updated_parsed": [
                2025,
                12,
                25,
                11,
                24,
                43,
                3,
                359,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.19815v2",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.19815v2",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Structured light beams, such as optical vortices carrying orbital angular momentum, are essential for applications ranging from low-power optical communications to high-intensity laser-matter interactions. However, scaling their power and energy while preserving complex phase and spatial structures remains a fundamental challenge. In this work, we demonstrate coherent beam combining as a versatile and scalable method for generating high-power structured beams without limitations on topological charge or spatial structure, while maintaining exceptionally high modal purity. We experimentally implement coherent beam combining for optical vortex beams with topological charges l = 1, 5, and 8, achieving a combined average power of 100 W and a peak power of 100 kW, with combining efficiencies of 95.0%, 93.9%, and 91.2%, respectively. Off-axis digital holography confirms that the phase and intensity profiles of the combined beams retain high modal purity, even at high topological charges. These results establish coherent beam combining as an effective route to high modal purity structured light at high power levels, unlocking new opportunities for advanced photonics and high-intensity light-matter interaction studies.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Structured light beams, such as optical vortices carrying orbital angular momentum, are essential for applications ranging from low-power optical communications to high-intensity laser-matter interactions. However, scaling their power and energy while preserving complex phase and spatial structures remains a fundamental challenge. In this work, we demonstrate coherent beam combining as a versatile and scalable method for generating high-power structured beams without limitations on topological charge or spatial structure, while maintaining exceptionally high modal purity. We experimentally implement coherent beam combining for optical vortex beams with topological charges l = 1, 5, and 8, achieving a combined average power of 100 W and a peak power of 100 kW, with combining efficiencies of 95.0%, 93.9%, and 91.2%, respectively. Off-axis digital holography confirms that the phase and intensity profiles of the combined beams retain high modal purity, even at high topological charges. These results establish coherent beam combining as an effective route to high modal purity structured light at high power levels, unlocking new opportunities for advanced photonics and high-intensity light-matter interaction studies."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-22T19:08:45Z",
            "published_parsed": [
                2025,
                12,
                22,
                19,
                8,
                45,
                0,
                356,
                0
            ],
            "arxiv_comment": "Version 2 includes supplementary material",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Hossein Fathi"
                },
                {
                    "name": "Rafael F. Barros"
                },
                {
                    "name": "Regina Gumenyuk"
                }
            ],
            "author_detail": {
                "name": "Regina Gumenyuk"
            },
            "author": "Regina Gumenyuk",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "通过相干光束组合产生功率可扩展的高阶光学涡旋",
            "abstract_cn": "结构光束，例如携带轨道角动量的光学涡旋，对于从低功率光通信到高强度激光与物质相互作用的应用至关重要。然而，在保持复杂的相位和空间结构的同时扩展它们的功率和能量仍然是一个基本挑战。在这项工作中，我们展示了相干光束组合作为一种通用且可扩展的方法，用于生成高功率结构光束，不受拓扑电荷或空间结构的限制，同时保持极高的模态纯度。我们实验性地对拓扑电荷l=1、5和8的光学涡旋光束进行相干合成，实现了100 W的合成平均功率和100 kW的峰值功率，合成效率分别为95.0%、93.9%和91.2%。离轴数字全息术证实，即使在高拓扑电荷下，组合光束的相位和强度分布也保持高模态纯度。这些结果确立了相干光束组合作为高功率水平下高模态纯度结构光的有效途径，为先进光子学和高强度光与物质相互作用研究带来了新的机遇。"
        },
        {
            "id": "http://arxiv.org/abs/2512.20464v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.20464v1",
            "title": "Snapshot 3D image projection using a diffractive decoder",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Snapshot 3D image projection using a diffractive decoder"
            },
            "updated": "2025-12-23T15:57:08Z",
            "updated_parsed": [
                2025,
                12,
                23,
                15,
                57,
                8,
                1,
                357,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.20464v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.20464v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "3D image display is essential for next-generation volumetric imaging; however, dense depth multiplexing for 3D image projection remains challenging because diffraction-induced cross-talk rapidly increases as the axial image planes get closer. Here, we introduce a 3D display system comprising a digital encoder and a diffractive optical decoder, which simultaneously projects different images onto multiple target axial planes with high axial resolution. By leveraging multi-layer diffractive wavefront decoding and deep learning-based end-to-end optimization, the system achieves high-fidelity depth-resolved 3D image projection in a snapshot, enabling axial plane separations on the order of a wavelength. The digital encoder leverages a Fourier encoder network to capture multi-scale spatial and frequency-domain features from input images, integrates axial position encoding, and generates a unified phase representation that simultaneously encodes all images to be axially projected in a single snapshot through a jointly-optimized diffractive decoder. We characterized the impact of diffractive decoder depth, output diffraction efficiency, spatial light modulator resolution, and axial encoding density, revealing trade-offs that govern axial separation and 3D image projection quality. We further demonstrated the capability to display volumetric images containing 28 axial slices, as well as the ability to dynamically reconfigure the axial locations of the image planes, performed on demand. Finally, we experimentally validated the presented approach, demonstrating close agreement between the measured results and the target images. These results establish the diffractive 3D display system as a compact and scalable framework for depth-resolved snapshot 3D image projection, with potential applications in holographic displays, AR/VR interfaces, and volumetric optical computing.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "3D image display is essential for next-generation volumetric imaging; however, dense depth multiplexing for 3D image projection remains challenging because diffraction-induced cross-talk rapidly increases as the axial image planes get closer. Here, we introduce a 3D display system comprising a digital encoder and a diffractive optical decoder, which simultaneously projects different images onto multiple target axial planes with high axial resolution. By leveraging multi-layer diffractive wavefront decoding and deep learning-based end-to-end optimization, the system achieves high-fidelity depth-resolved 3D image projection in a snapshot, enabling axial plane separations on the order of a wavelength. The digital encoder leverages a Fourier encoder network to capture multi-scale spatial and frequency-domain features from input images, integrates axial position encoding, and generates a unified phase representation that simultaneously encodes all images to be axially projected in a single snapshot through a jointly-optimized diffractive decoder. We characterized the impact of diffractive decoder depth, output diffraction efficiency, spatial light modulator resolution, and axial encoding density, revealing trade-offs that govern axial separation and 3D image projection quality. We further demonstrated the capability to display volumetric images containing 28 axial slices, as well as the ability to dynamically reconfigure the axial locations of the image planes, performed on demand. Finally, we experimentally validated the presented approach, demonstrating close agreement between the measured results and the target images. These results establish the diffractive 3D display system as a compact and scalable framework for depth-resolved snapshot 3D image projection, with potential applications in holographic displays, AR/VR interfaces, and volumetric optical computing."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.NE",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.app-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-23T15:57:08Z",
            "published_parsed": [
                2025,
                12,
                23,
                15,
                57,
                8,
                1,
                357,
                0
            ],
            "arxiv_comment": "22 Pages, 8 Figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Cagatay Isil"
                },
                {
                    "name": "Alexander Chen"
                },
                {
                    "name": "Yuhang Li"
                },
                {
                    "name": "F. Onuralp Ardic"
                },
                {
                    "name": "Shiqi Chen"
                },
                {
                    "name": "Che-Yung Shen"
                },
                {
                    "name": "Aydogan Ozcan"
                }
            ],
            "author_detail": {
                "name": "Aydogan Ozcan"
            },
            "author": "Aydogan Ozcan",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "使用衍射解码器进行快照 3D 图像投影",
            "abstract_cn": "3D图像显示对于下一代体积成像至关重要；然而，3D 图像投影的密集深度复用仍然具有挑战性，因为随着轴向图像平面越来越近，衍射引起的串扰迅速增加。在这里，我们介绍了一种由数字编码器和衍射光学解码器组成的 3D 显示系统，该系统能够以高轴向分辨率同时将不同图像投影到多个目标轴向平面上。通过利用多层衍射波前解码和基于深度学习的端到端优化，该系统可在快照中实现高保真深度分辨 3D 图像投影，从而实现波长数量级的轴平面分离。数字编码器利用傅里叶编码器网络从输入图像中捕获多尺度空间和频域特征，集成轴向位置编码，并生成统一的相位表示，该相位表示通过联合优化的衍射解码器同时对要在单个快照中轴向投影的所有图像进行编码。我们描述了衍射解码器深度、输出衍射效率、空间光调制器分辨率和轴向编码密度的影响，揭示了控制轴向分离和 3D 图像投影质量的权衡。我们进一步展示了显示包含 28 个轴向切片的体积图像的能力，以及根据需要动态重新配置图像平面的轴向位置的能力。最后，我们通过实验验证了所提出的方法，证明测量结果与目标图像之间非常吻合。这些结果将衍射 3D 显示系统确立为用于深度分辨快照 3D 图像投影的紧凑且可扩展的框架，在全息显示、AR/VR 接口和体积光学计算方面具有潜在的应用。"
        },
        {
            "id": "http://arxiv.org/abs/2512.21040v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.21040v1",
            "title": "A Large-Depth-Range Layer-Based Hologram Dataset for Machine Learning-Based 3D Computer-Generated Holography",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "A Large-Depth-Range Layer-Based Hologram Dataset for Machine Learning-Based 3D Computer-Generated Holography"
            },
            "updated": "2025-12-24T08:07:39Z",
            "updated_parsed": [
                2025,
                12,
                24,
                8,
                7,
                39,
                2,
                358,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.21040v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.21040v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Machine learning-based computer-generated holography (ML-CGH) has advanced rapidly in recent years, yet progress is constrained by the limited availability of high-quality, large-scale hologram datasets. To address this, we present KOREATECH-CGH, a publicly available dataset comprising 6,000 pairs of RGB-D images and complex holograms across resolutions ranging from 256*256 to 2048*2048, with depth ranges extending to the theoretical limits of the angular spectrum method for wide 3D scene coverage. To improve hologram quality at large depth ranges, we introduce amplitude projection, a post-processing technique that replaces amplitude components of hologram wavefields at each depth layer while preserving phase. This approach enhances reconstruction fidelity, achieving 27.01 dB PSNR and 0.87 SSIM, surpassing a recent optimized silhouette-masking layer-based method by 2.03 dB and 0.04 SSIM, respectively. We further validate the utility of KOREATECH-CGH through experiments on hologram generation and super-resolution using state-of-the-art ML models, confirming its applicability for training and evaluating next-generation ML-CGH systems.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Machine learning-based computer-generated holography (ML-CGH) has advanced rapidly in recent years, yet progress is constrained by the limited availability of high-quality, large-scale hologram datasets. To address this, we present KOREATECH-CGH, a publicly available dataset comprising 6,000 pairs of RGB-D images and complex holograms across resolutions ranging from 256*256 to 2048*2048, with depth ranges extending to the theoretical limits of the angular spectrum method for wide 3D scene coverage. To improve hologram quality at large depth ranges, we introduce amplitude projection, a post-processing technique that replaces amplitude components of hologram wavefields at each depth layer while preserving phase. This approach enhances reconstruction fidelity, achieving 27.01 dB PSNR and 0.87 SSIM, surpassing a recent optimized silhouette-masking layer-based method by 2.03 dB and 0.04 SSIM, respectively. We further validate the utility of KOREATECH-CGH through experiments on hologram generation and super-resolution using state-of-the-art ML models, confirming its applicability for training and evaluating next-generation ML-CGH systems."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-24T08:07:39Z",
            "published_parsed": [
                2025,
                12,
                24,
                8,
                7,
                39,
                2,
                358,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Jaehong Lee"
                },
                {
                    "name": "You Chan No"
                },
                {
                    "name": "YoungWoo Kim"
                },
                {
                    "name": "Duksu Kim"
                }
            ],
            "author_detail": {
                "name": "Duksu Kim"
            },
            "author": "Duksu Kim",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "用于基于机器学习的 3D 计算机生成全息术的大深度范围层全息图数据集",
            "abstract_cn": "基于机器学习的计算机生成全息术（ML-CGH）近年来发展迅速，但进展受到高质量、大规模全息图数据集有限的限制。为了解决这个问题，我们推出了 KOREATECH-CGH，这是一个公开可用的数据集，包含 6,000 对 RGB-D 图像和复杂的全息图，分辨率范围从 256*256 到 2048*2048，深度范围扩展到宽 3D 场景覆盖的角谱方法的理论极限。为了提高大深度范围内的全息图质量，我们引入了幅度投影，这是一种后处理技术，可以在保留相位的同时替换每个深度层的全息图波场的幅度分量。这种方法增强了重建保真度，实现了 27.01 dB PSNR 和 0.87 SSIM，分别超过了最近优化的基于轮廓掩模层的方法 2.03 dB 和 0.04 SSIM。我们通过使用最先进的 ML 模型进行全息图生成和超分辨率实验，进一步验证 KOREATECH-CGH 的实用性，确认其适用于训练和评估下一代 ML-CGH 系统。"
        },
        {
            "id": "http://arxiv.org/abs/2512.21057v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.21057v1",
            "title": "Generation of hallow vector beam by high-order cylindrical vector beams",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Generation of hallow vector beam by high-order cylindrical vector beams"
            },
            "updated": "2025-12-24T08:50:05Z",
            "updated_parsed": [
                2025,
                12,
                24,
                8,
                50,
                5,
                2,
                358,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.21057v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.21057v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We propose a method for generating hollow beams using higher-order cylindrical vector modes of the form R-TEMpl, where the radial index p is varied from 1 to 3 while the azimuthal index is fixed at l = 1. It is found that this scheme performs identically under incident illumination with either radial or azimuthal polarization. For this purpose, we use a focusing lens in combination with a diffractive optical element formed by a computer-generated hologram containing multiple alternate opaque and transparent regions. Based on vector diffraction theory, our analysis shows that the multi-zone amplitude mask redistributes the beam energy, thereby leading to the formation of a hollow beam. The proposed method provides control over the beam width which maintains a uniform dark core size after focusing through the various NA lens across all the higher order modes. Further the width of high intensity ring can be tuned by varying the NA of the focusing lens. This study shows that the proposed method is well suited for trapping particles or atoms while avoiding exposure to high central intensity, enabling improved contrast and resolution, facilitating ring-shaped ablation or heating, guiding atoms through dark regions to minimize thermal effects, and supporting information encoding using orbital angular momentum and other advanced optical applications.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We propose a method for generating hollow beams using higher-order cylindrical vector modes of the form R-TEMpl, where the radial index p is varied from 1 to 3 while the azimuthal index is fixed at l = 1. It is found that this scheme performs identically under incident illumination with either radial or azimuthal polarization. For this purpose, we use a focusing lens in combination with a diffractive optical element formed by a computer-generated hologram containing multiple alternate opaque and transparent regions. Based on vector diffraction theory, our analysis shows that the multi-zone amplitude mask redistributes the beam energy, thereby leading to the formation of a hollow beam. The proposed method provides control over the beam width which maintains a uniform dark core size after focusing through the various NA lens across all the higher order modes. Further the width of high intensity ring can be tuned by varying the NA of the focusing lens. This study shows that the proposed method is well suited for trapping particles or atoms while avoiding exposure to high central intensity, enabling improved contrast and resolution, facilitating ring-shaped ablation or heating, guiding atoms through dark regions to minimize thermal effects, and supporting information encoding using orbital angular momentum and other advanced optical applications."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-24T08:50:05Z",
            "published_parsed": [
                2025,
                12,
                24,
                8,
                50,
                5,
                2,
                358,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Brijesh Kumar Mishra"
                },
                {
                    "name": "Brijesh Kumar Singh"
                }
            ],
            "author_detail": {
                "name": "Brijesh Kumar Singh"
            },
            "author": "Brijesh Kumar Singh",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "高阶圆柱矢量光束生成空心矢量光束",
            "abstract_cn": "我们提出了一种使用 R-TEMpl 形式的高阶柱面矢量模式生成空心光束的方法，其中径向折射率 p 在 1 到 3 之间变化，而方位角折射率固定为 l = 1。发现该方案在具有径向或方位角偏振的入射照明下表现相同。为此，我们将聚焦透镜与衍射光学元件结合使用，该衍射光学元件由计算机生成的包含多个交替的不透明和透明区域的全息图形成。基于矢量衍射理论，我们的分析表明，多区振幅掩模重新分配光束能量，从而导致空心光束的形成。所提出的方法提供了对光束宽度的控制，在通过所有高阶模式的各种 NA 透镜聚焦后保持均匀的暗芯尺寸。此外，高强度环的宽度可以通过改变聚焦透镜的数值孔径来调节。这项研究表明，所提出的方法非常适合捕获粒子或原子，同时避免暴露在高中心强度下，从而提高对比度和分辨率，促进环形烧蚀或加热，引导原子穿过暗区以最大限度地减少热效应，并支持使用轨道角动量和其他先进光学应用进行信息编码。"
        },
        {
            "id": "http://arxiv.org/abs/2512.21587v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.21587v1",
            "title": "Incorporating rank-free coupling and external field via an amplitude-only modulated spatial photonic Ising machine",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Incorporating rank-free coupling and external field via an amplitude-only modulated spatial photonic Ising machine"
            },
            "updated": "2025-12-25T09:11:48Z",
            "updated_parsed": [
                2025,
                12,
                25,
                9,
                11,
                48,
                3,
                359,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.21587v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.21587v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Ising machines have emerged as effective solvers for combinatorial optimization problems, such as NP-hard problems, machine learning, and financial modeling. Recent spatial photonic Ising machines (SPIMs) excel in multi-node optimization and spin glass simulations, leveraging their large-scale and fully connected characteristics. However, existing laser diffraction-based SPIMs usually sacrifice time efficiency or spin count to encode high-rank spin-spin coupling and external fields, limiting their scalability for real-world applications. Here, we demonstrate an amplitude-only modulated rank-free spatial photonic Ising machine (AR-SPIM) with 200 iterations per second. By re-formulating an arbitrary Ising Hamiltonian as the sum of Hadamard products, followed by loading the corresponding matrices/vectors onto an aligned amplitude spatial light modulator and digital micro-mirrors device, we directly map a 797-spin Ising model with external fields (nearly 9-bit precision, -255 to 255) into an incoherent light field, eliminating the need for repeated and auxiliary operations. Serving as encoding accuracy metrics, the linear coefficient of determination and Pearson correlation coefficient between measured light intensities and Ising Hamiltonians exceed 0.9800, with values exceed 0.9997 globally. The AR-SPIM achieves less than 0.3% error rate for ground-state search of biased Max-cut problems with arbitrary ranks and weights, enables complex phase transition observations, and facilitates scalable spin counts for sparse Ising problems via removing zero-valued Hadamard product terms. This reconfigurable AR-SPIM can be further developed to support large-scale machine-learning training and deployed for practical applications in discrete optimization and quantum many-body simulations.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Ising machines have emerged as effective solvers for combinatorial optimization problems, such as NP-hard problems, machine learning, and financial modeling. Recent spatial photonic Ising machines (SPIMs) excel in multi-node optimization and spin glass simulations, leveraging their large-scale and fully connected characteristics. However, existing laser diffraction-based SPIMs usually sacrifice time efficiency or spin count to encode high-rank spin-spin coupling and external fields, limiting their scalability for real-world applications. Here, we demonstrate an amplitude-only modulated rank-free spatial photonic Ising machine (AR-SPIM) with 200 iterations per second. By re-formulating an arbitrary Ising Hamiltonian as the sum of Hadamard products, followed by loading the corresponding matrices/vectors onto an aligned amplitude spatial light modulator and digital micro-mirrors device, we directly map a 797-spin Ising model with external fields (nearly 9-bit precision, -255 to 255) into an incoherent light field, eliminating the need for repeated and auxiliary operations. Serving as encoding accuracy metrics, the linear coefficient of determination and Pearson correlation coefficient between measured light intensities and Ising Hamiltonians exceed 0.9800, with values exceed 0.9997 globally. The AR-SPIM achieves less than 0.3% error rate for ground-state search of biased Max-cut problems with arbitrary ranks and weights, enables complex phase transition observations, and facilitates scalable spin counts for sparse Ising problems via removing zero-valued Hadamard product terms. This reconfigurable AR-SPIM can be further developed to support large-scale machine-learning training and deployed for practical applications in discrete optimization and quantum many-body simulations."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cond-mat.dis-nn",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.LG",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "math-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.app-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-25T09:11:48Z",
            "published_parsed": [
                2025,
                12,
                25,
                9,
                11,
                48,
                3,
                359,
                0
            ],
            "arxiv_comment": "4 pages, 3 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Ze Zheng"
                },
                {
                    "name": "Yuegang Li"
                },
                {
                    "name": "Hang Xu"
                },
                {
                    "name": "Jingzheng Huang"
                },
                {
                    "name": "Tailong Xiao"
                },
                {
                    "name": "Guihua Zeng"
                }
            ],
            "author_detail": {
                "name": "Guihua Zeng"
            },
            "author": "Guihua Zeng",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "通过仅幅度调制的空间光子伊辛机结合无秩耦合和外场",
            "abstract_cn": "伊辛机已成为组合优化问题（例如 NP 难题、机器学习和金融建模）的有效求解器。最近的空间光子伊辛机（SPIM）利用其大规模和完全连接的特性，在多节点优化和自旋玻璃模拟方面表现出色。然而，现有的基于激光衍射的 SPIM 通常会牺牲时间效率或自旋计数来编码高阶自旋耦合和外部场，从而限制了它们在实际应用中的可扩展性。在这里，我们演示了每秒 200 次迭代的仅振幅调制无秩空间光子伊辛机 (AR-SPIM)。通过将任意伊辛哈密顿量重新表述为哈达玛乘积之和，然后将相应的矩阵/向量加载到对准的幅度空间光调制器和数字微镜器件上，我们将具有外部场（接近9位精度，-255至255）的797旋转伊辛模型直接映射到不相干光场中，从而消除了重复和辅助操作的需要。作为编码精度指标，测量光强与伊辛哈密顿量之间的线性决定系数和皮尔逊相关系数超过0.9800，全球范围内值超过0.9997。 AR-SPIM 在具有任意等级和权重的有偏最大割问题的基态搜索中实现了低于 0.3% 的错误率，实现了复杂的相变观测，并通过删除零值 Hadamard 乘积项促进了稀疏 Ising 问题的可扩展自旋计数。这种可重构的 AR-SPIM 可以进一步开发以支持大规模机器学习训练，并部署用于离散优化和量子多体模拟的实际应用。"
        },
        {
            "id": "http://arxiv.org/abs/2512.24993v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.24993v1",
            "title": "Noise resilient real-time phase imaging via undetected light",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Noise resilient real-time phase imaging via undetected light"
            },
            "updated": "2025-12-31T17:37:54Z",
            "updated_parsed": [
                2025,
                12,
                31,
                17,
                37,
                54,
                2,
                365,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.24993v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.24993v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Quantum imaging with undetected light has recently emerged as a technique in which quantum correlations and nonlinear interferometry are combined to decouple illumination and detection paths. This approach has been more recently extended and combined with digital phase-shifting holography and off-axis holography to extract both the amplitude and phase information of a sample relying on single-photon interference. Despite these advantages, implementing the technique in real-world scenarios where the observed system is subject to environmental noise and dynamic variations remains challenging. The primary limitation lies in the inability of quantum imaging systems to retrieve object information in real time under high-noise conditions. Here, we experimentally demonstrate real-time amplitude and phase imaging in noisy environments, building upon our previous implementation of quantum off-axis holography. Our results demonstrate real-time imaging at acquisition rates up to 4~Hz, even when the noise level exceeds the signal by an order of magnitude.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Quantum imaging with undetected light has recently emerged as a technique in which quantum correlations and nonlinear interferometry are combined to decouple illumination and detection paths. This approach has been more recently extended and combined with digital phase-shifting holography and off-axis holography to extract both the amplitude and phase information of a sample relying on single-photon interference. Despite these advantages, implementing the technique in real-world scenarios where the observed system is subject to environmental noise and dynamic variations remains challenging. The primary limitation lies in the inability of quantum imaging systems to retrieve object information in real time under high-noise conditions. Here, we experimentally demonstrate real-time amplitude and phase imaging in noisy environments, building upon our previous implementation of quantum off-axis holography. Our results demonstrate real-time imaging at acquisition rates up to 4~Hz, even when the noise level exceeds the signal by an order of magnitude."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-31T17:37:54Z",
            "published_parsed": [
                2025,
                12,
                31,
                17,
                37,
                54,
                2,
                365,
                0
            ],
            "arxiv_comment": "14 pages, 9 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Josué R. León-Torres"
                },
                {
                    "name": "Patrick Hendra"
                },
                {
                    "name": "Yugant Mukeshbhai Hadiyal"
                },
                {
                    "name": "Christopher Spiess"
                },
                {
                    "name": "Fabian Steinlechner"
                },
                {
                    "name": "Frank Setzpfandt"
                },
                {
                    "name": "Markus Gräfe"
                },
                {
                    "name": "Valerio Flavio Gili"
                }
            ],
            "author_detail": {
                "name": "Valerio Flavio Gili"
            },
            "author": "Valerio Flavio Gili",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "通过未检测到的光进行抗噪实时相位成像",
            "abstract_cn": "最近出现的利用未检测到的光进行量子成像是一种将量子相关性和非线性干涉测量相结合以解耦照明和检测路径的技术。这种方法最近得到了扩展，并与数字相移全息术和离轴全息术相结合，依靠单光子干涉提取样本的幅度和相位信息。尽管有这些优点，但在观察到的系统受到环境噪声和动态变化影响的现实场景中实施该技术仍然具有挑战性。主要限制在于量子成像系统无法在高噪声条件下实时检索物体信息。在这里，我们在之前实现的量子离轴全息术的基础上，通过实验演示了噪声环境中的实时幅度和相位成像。我们的结果表明，即使噪声水平超过信号一个数量级，也能以高达 4Hz 的采集速率进行实时成像。"
        },
        {
            "id": "http://arxiv.org/abs/2512.25048v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2512.25048v1",
            "title": "All optical Lithography for Spatiotemporal Patterning of Azopolymer Microreliefs",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "All optical Lithography for Spatiotemporal Patterning of Azopolymer Microreliefs"
            },
            "updated": "2025-12-31T18:44:29Z",
            "updated_parsed": [
                2025,
                12,
                31,
                18,
                44,
                29,
                2,
                365,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2512.25048v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2512.25048v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Microstructured surfaces are central to photonics, biointerfaces, and functional coatings, yet they are typically fabricated through multi-step lithographic workflows requiring masks or molds and post-processing. Azopolymers provide an alternative route by converting structured optical fields into surface reliefs via light-induced mass migration, but existing approaches have been limited to smooth, shallow, and engraving-like topographies produced from a flat film. Here we introduce an all-optical, maskless, fully digital lithography platform that exploits engineered darkness within computer-generated holograms to spatially localize inward mass transport and directly produce positive, protruding microreliefs. We show that isolated and array of micro-bumps can be generated from pristine flat azopolymer films in a single writing step, and we introduce spatiotemporal control through sequential tailored illumination to reshape microrelief profiles, enabling flattened-top micropillars, programmable array shapes and arrangements, and free-form continuous microrelief designs. Hierarchical microarchitectures are also demonstrated by extending the concept of multi-step illumination sequences. As functional demonstrations, we realize multi-focus microlenses and quasi-square diffraction gratings with enhanced 1st-order efficiencies. Finally, we leverage azopolymer reconfigurability to implement write-erase-rewrite cycles that reset and repurpose the same surface region for distinct micropatterns, enabling rewritable surfaces and reprogrammable master templates for replication. Overall, this work establishes a scalable spatiotemporal strategy for on-demand, all-optical microfabrication and reprogramming of structured surfaces, where spatial and temporal degrees of freedom of holographic patterns intermix to produce advanced patterning capabilities.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Microstructured surfaces are central to photonics, biointerfaces, and functional coatings, yet they are typically fabricated through multi-step lithographic workflows requiring masks or molds and post-processing. Azopolymers provide an alternative route by converting structured optical fields into surface reliefs via light-induced mass migration, but existing approaches have been limited to smooth, shallow, and engraving-like topographies produced from a flat film. Here we introduce an all-optical, maskless, fully digital lithography platform that exploits engineered darkness within computer-generated holograms to spatially localize inward mass transport and directly produce positive, protruding microreliefs. We show that isolated and array of micro-bumps can be generated from pristine flat azopolymer films in a single writing step, and we introduce spatiotemporal control through sequential tailored illumination to reshape microrelief profiles, enabling flattened-top micropillars, programmable array shapes and arrangements, and free-form continuous microrelief designs. Hierarchical microarchitectures are also demonstrated by extending the concept of multi-step illumination sequences. As functional demonstrations, we realize multi-focus microlenses and quasi-square diffraction gratings with enhanced 1st-order efficiencies. Finally, we leverage azopolymer reconfigurability to implement write-erase-rewrite cycles that reset and repurpose the same surface region for distinct micropatterns, enabling rewritable surfaces and reprogrammable master templates for replication. Overall, this work establishes a scalable spatiotemporal strategy for on-demand, all-optical microfabrication and reprogramming of structured surfaces, where spatial and temporal degrees of freedom of holographic patterns intermix to produce advanced patterning capabilities."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2025-12-31T18:44:29Z",
            "published_parsed": [
                2025,
                12,
                31,
                18,
                44,
                29,
                2,
                365,
                0
            ],
            "arxiv_comment": "36 pages; 7 main figures; 17 supplementary figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "I Komang Januariyasa"
                },
                {
                    "name": "Francesco Reda"
                },
                {
                    "name": "Nikolai Liubimtsev"
                },
                {
                    "name": "Marina Saphiannikova"
                },
                {
                    "name": "Fabio Borbone"
                },
                {
                    "name": "Marcella Salvatore"
                },
                {
                    "name": "Stefano Luigi Oscurato"
                }
            ],
            "author_detail": {
                "name": "Stefano Luigi Oscurato"
            },
            "author": "Stefano Luigi Oscurato",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "用于偶氮聚合物微浮雕时空图案化的全光学光刻",
            "abstract_cn": "微结构表面是光子学、生物界面和功能涂层的核心，但它们通常是通过需要掩模或模具和后处理的多步骤光刻工作流程来制造的。偶氮聚合物提供了一种替代途径，通过光诱导的质量迁移将结构化光场转化为表面浮雕，但现有方法仅限于由平面薄膜产生的光滑、浅且类似雕刻的形貌。在这里，我们介绍了一种全光学、无掩模、全数字光刻平台，该平台利用计算机生成的全息图中的工程黑暗来在空间上定位向内的质量传输并直接产生正的、突出的微浮雕。我们证明，可以通过单个写入步骤从原始平坦偶氮聚合物薄膜中生成孤立的微凸块阵列，并且我们通过顺序定制照明引入时空控制来重塑微浮雕轮廓，从而实现平顶微柱、可编程阵列形状和排列以及自由形式的连续微浮雕设计。还通过扩展多步照明序列的概念来演示分层微架构。作为功​​能演示，我们实现了具有增强的一阶效率的多焦点微透镜和准方形衍射光栅。最后，我们利用偶氮聚合物的可重构性来实现写入-擦除-重写循环，为不同的微图案重置和重新利用相同的表面区域，从而实现可重写表面和可重新编程的主模板以进行复制。总体而言，这项工作为结构化表面的按需、全光学微加工和重新编程建立了可扩展的时空策略，其中全息图案的空间和时间自由度混合以产生先进的图案化能力。"
        },
        {
            "id": "http://arxiv.org/abs/2601.00630v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.00630v1",
            "title": "Video-rate holographic telepresence via single-shot, reference-free wavefront measurement",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Video-rate holographic telepresence via single-shot, reference-free wavefront measurement"
            },
            "updated": "2026-01-02T10:17:03Z",
            "updated_parsed": [
                2026,
                1,
                2,
                10,
                17,
                3,
                4,
                2,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.00630v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.00630v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We present a reference-free holographic telepresence system that directly captures and replays complex optical wavefronts from a single intensity speckle measurement. Using a pre-characterized geometric phase diffuser, the incident field self-interferes to form a speckle pattern, from which the wavefront is recovered via a speckle-correlation scattering-matrix approach and refined using smoothed amplitude flow with Nesterov acceleration. The reconstructed phase is directly projected onto a spatial light modulator for holographic replay. We demonstrate volumetric refocusing, dynamic three-dimensional reconstruction, and sustained video-rate operation at approximately 28 frames per second with modest communication bandwidth. The results highlight measurement-driven wavefront acquisition as a practical pathway toward compact and physically faithful holographic telepresence.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We present a reference-free holographic telepresence system that directly captures and replays complex optical wavefronts from a single intensity speckle measurement. Using a pre-characterized geometric phase diffuser, the incident field self-interferes to form a speckle pattern, from which the wavefront is recovered via a speckle-correlation scattering-matrix approach and refined using smoothed amplitude flow with Nesterov acceleration. The reconstructed phase is directly projected onto a spatial light modulator for holographic replay. We demonstrate volumetric refocusing, dynamic three-dimensional reconstruction, and sustained video-rate operation at approximately 28 frames per second with modest communication bandwidth. The results highlight measurement-driven wavefront acquisition as a practical pathway toward compact and physically faithful holographic telepresence."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-02T10:17:03Z",
            "published_parsed": [
                2026,
                1,
                2,
                10,
                17,
                3,
                4,
                2,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Minwook Kim"
                },
                {
                    "name": "Chansuk Park"
                },
                {
                    "name": "Chulmin Oh"
                },
                {
                    "name": "KyeoReh Lee"
                },
                {
                    "name": "Herve Hugonnet"
                },
                {
                    "name": "YongKeun Park"
                }
            ],
            "author_detail": {
                "name": "YongKeun Park"
            },
            "author": "YongKeun Park",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "通过单次、无参考波前测量实现视频速率全息临场感",
            "abstract_cn": "我们提出了一种无参考的全息远程呈现系统，可以直接捕获和重放来自单个强度散斑测量的复杂光学波前。使用预先表征的几何相位扩散器，入射场自干涉形成散斑图案，通过散斑相关散射矩阵方法从中恢复波前，并使用带有 Nesterov 加速的平滑幅度流进行细化。重建的相位直接投影到空间光调制器上进行全息重放。我们演示了体积重聚焦、动态三维重建以及在适当的通信带宽下以每秒大约 28 帧的持续视频速率运行。结果强调了测量驱动的波前采集是实现紧凑且物理忠实的全息远程呈现的实用途径。"
        },
        {
            "id": "http://arxiv.org/abs/2601.01038v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.01038v1",
            "title": "Silicon-on-sapphire metasurfaces generate arrays of dark and bright traps for neutral atoms",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Silicon-on-sapphire metasurfaces generate arrays of dark and bright traps for neutral atoms"
            },
            "updated": "2026-01-03T02:24:17Z",
            "updated_parsed": [
                2026,
                1,
                3,
                2,
                24,
                17,
                5,
                3,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.01038v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.01038v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We demonstrated crystalline silicon-on-sapphire (c-SOS) metasurfaces that convert a Gaussian beam into arrays of complex optical traps, including arrays of optical bottle beams that trap atoms in dark regions interleaved with bright tweezer arrays. The high refractive index and indirect band gap of crystalline silicon makes it possible to design high-resolution near-infrared ($λ>700$ nm) metasurfaces that can be manufactured at scale using CMOS-compatible processes. Compared with active components like spatial light modulators (SLMs) that have become widely used to generate trap arrays, metasurfaces provide an indefinitely scalable number of pixels, enabling large arrays of complex traps in a very small form factor, as well as reduced dynamic noise. To design metasurfaces that can generate three-dimensional bottle beams to serve as dark traps, we modified the Gerchberg-Saxton algorithm to enforce complex-amplitude profiles at the focal plane of the metasurface and to optimize the uniformity of the traps across the array. We fabricated and measured c-SOS metasurfaces that convert a Gaussian laser beam into arrays of bright traps, dark traps, and interleaved bright/dark traps.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We demonstrated crystalline silicon-on-sapphire (c-SOS) metasurfaces that convert a Gaussian beam into arrays of complex optical traps, including arrays of optical bottle beams that trap atoms in dark regions interleaved with bright tweezer arrays. The high refractive index and indirect band gap of crystalline silicon makes it possible to design high-resolution near-infrared ($λ>700$ nm) metasurfaces that can be manufactured at scale using CMOS-compatible processes. Compared with active components like spatial light modulators (SLMs) that have become widely used to generate trap arrays, metasurfaces provide an indefinitely scalable number of pixels, enabling large arrays of complex traps in a very small form factor, as well as reduced dynamic noise. To design metasurfaces that can generate three-dimensional bottle beams to serve as dark traps, we modified the Gerchberg-Saxton algorithm to enforce complex-amplitude profiles at the focal plane of the metasurface and to optimize the uniformity of the traps across the array. We fabricated and measured c-SOS metasurfaces that convert a Gaussian laser beam into arrays of bright traps, dark traps, and interleaved bright/dark traps."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.app-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "quant-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-03T02:24:17Z",
            "published_parsed": [
                2026,
                1,
                3,
                2,
                24,
                17,
                5,
                3,
                0
            ],
            "arxiv_comment": "Main text + supplementary",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Chengyu Fang"
                },
                {
                    "name": "Minjeong Kim"
                },
                {
                    "name": "Hongyan Mei"
                },
                {
                    "name": "Xuting Yang"
                },
                {
                    "name": "Zhaoning Yu"
                },
                {
                    "name": "Yuzhe Xiao"
                },
                {
                    "name": "Sanket Deshpande"
                },
                {
                    "name": "Preston Huft"
                },
                {
                    "name": "Alan M. Dibos"
                },
                {
                    "name": "David A. Czaplewski"
                },
                {
                    "name": "Mark Saffman"
                },
                {
                    "name": "Jennifer T. Choy"
                },
                {
                    "name": "Mikhail A. Kats"
                }
            ],
            "author_detail": {
                "name": "Mikhail A. Kats"
            },
            "author": "Mikhail A. Kats",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "蓝宝石上硅超表面为中性原子产生暗光和亮光陷阱阵列",
            "abstract_cn": "我们展示了蓝宝石上晶体硅（c-SOS）超表面，可将高斯光束转换为复杂光陷阱阵列，包括将原子捕获在与明亮镊子阵列交错的暗区中的光学瓶光束阵列。晶体硅的高折射率和间接带隙使得设计高分辨率近红外（$λ>700$ nm）超表面成为可能，并且可以使用 CMOS 兼容工艺大规模制造。与广泛用于生成陷阱阵列的空间光调制器 (SLM) 等有源组件相比，超表面提供了无限可扩展的像素数量，能够以非常小的外形尺寸实现大型复杂陷阱阵列，并降低动态噪声。为了设计可以生成三维瓶光束作为暗陷阱的超表面，我们修改了 Gerchberg-Saxton 算法，以在超表面的焦平面处强制执行复振幅分布，并优化阵列上陷阱的均匀性。我们制造并测量了 c-SOS 超表面，将高斯激光束转换为亮陷阱、暗陷阱和交错的亮/暗陷阱阵列。"
        },
        {
            "id": "http://arxiv.org/abs/2601.01221v2",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.01221v2",
            "title": "Metasurface-based Terahertz Three-dimensional Holography Enabled by Physics-Informed Neural Network",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Metasurface-based Terahertz Three-dimensional Holography Enabled by Physics-Informed Neural Network"
            },
            "updated": "2026-01-20T09:59:13Z",
            "updated_parsed": [
                2026,
                1,
                20,
                9,
                59,
                13,
                1,
                20,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.01221v2",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.01221v2",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Artificial intelligence, an emerging, powerful and efficient computational tool, has played a crucial role in the design of optical devices. For the design of holographic metasurfaces, traditional algorithms require multiple iterations between the metasurface and target planes, resulting in excessive computation time. Here, a physics-informed neural network (PINN) is proposed for the fast design of terahertz three-dimensional (3D) holographic metasurfaces. Trained in a self-supervised manner, the PINN eliminates the need for paired input-label datasets. After training, the PINN enables end-to-end mapping between the target holographic patterns and metasurface structures. Both simulation and experimental results of single-plane and 3D multi-plane holography demonstrate that metasurfaces designed by PINN offer higher imaging quality than traditional iterative algorithms. Moreover, the PINN can find approximate solutions of metasurface structures even in physically counterintuitive scenarios, where the holographic patterns of two parallel imaging planes are completely distinct. Furthermore, the inference process of PINN typically takes less than 1 second, much faster than the traditional algorithms requiring iterative computation. Notably, the PINN simultaneously accounts for both phase and amplitude modulation, thereby outperforming traditional phase-only modulation algorithms in handling complex physical scenarios and offering superior imaging quality. This end-to-end design approach has the potential to pave the way for the realization of high-quality, real-time, and large-scale terahertz 3D holographic display technology.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Artificial intelligence, an emerging, powerful and efficient computational tool, has played a crucial role in the design of optical devices. For the design of holographic metasurfaces, traditional algorithms require multiple iterations between the metasurface and target planes, resulting in excessive computation time. Here, a physics-informed neural network (PINN) is proposed for the fast design of terahertz three-dimensional (3D) holographic metasurfaces. Trained in a self-supervised manner, the PINN eliminates the need for paired input-label datasets. After training, the PINN enables end-to-end mapping between the target holographic patterns and metasurface structures. Both simulation and experimental results of single-plane and 3D multi-plane holography demonstrate that metasurfaces designed by PINN offer higher imaging quality than traditional iterative algorithms. Moreover, the PINN can find approximate solutions of metasurface structures even in physically counterintuitive scenarios, where the holographic patterns of two parallel imaging planes are completely distinct. Furthermore, the inference process of PINN typically takes less than 1 second, much faster than the traditional algorithms requiring iterative computation. Notably, the PINN simultaneously accounts for both phase and amplitude modulation, thereby outperforming traditional phase-only modulation algorithms in handling complex physical scenarios and offering superior imaging quality. This end-to-end design approach has the potential to pave the way for the realization of high-quality, real-time, and large-scale terahertz 3D holographic display technology."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.class-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-03T16:02:50Z",
            "published_parsed": [
                2026,
                1,
                3,
                16,
                2,
                50,
                5,
                3,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Jingzhu Shao"
                },
                {
                    "name": "Ping Tang"
                },
                {
                    "name": "Borui Xu"
                },
                {
                    "name": "Xiangyu Zhao"
                },
                {
                    "name": "Yudong Tian"
                },
                {
                    "name": "Yuqing Liu"
                },
                {
                    "name": "Chongzhao Wu"
                }
            ],
            "author_detail": {
                "name": "Chongzhao Wu"
            },
            "author": "Chongzhao Wu",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "基于物理信息的神经网络实现的基于超表面的太赫兹三维全息术",
            "abstract_cn": "人工智能作为一种新兴、强大且高效的计算工具，在光学器件的设计中发挥了至关重要的作用。对于全息超表面的设计，传统算法需要在超表面和目标平面之间进行多次迭代，导致计算时间过长。在这里，提出了一种基于物理的神经网络（PINN），用于快速设计太赫兹三维（3D）全息超表面。 PINN 以自我监督的方式进行训练，无需配对输入标签数据集。训练后，PINN 能够在目标全息图案和超表面结构之间进行端到端映射。单平面和3D多平面全息的仿真和实验结果表明，PINN设计的超表面比传统迭代算法具有更高的成像质量。此外，即使在物理上违反直觉的场景中，PINN 也可以找到超表面结构的近似解，其中两个平行成像平面的全息图案完全不同。此外，PINN的推理过程通常需要不到1秒，比需要迭代计算的传统算法快得多。值得注意的是，PINN 同时考虑了相位和幅度调制，从而在处理复杂的物理场景和提供卓越的成像质量方面优于传统的仅相位调制算法。这种端到端的设计方法有可能为实现高质量、实时、大规模太赫兹3D全息显示技术铺平道路。"
        },
        {
            "id": "http://arxiv.org/abs/2601.04825v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.04825v1",
            "title": "Illumination Angular Spectrum Encoding for Controlling the Functionality of Diffractive Networks",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Illumination Angular Spectrum Encoding for Controlling the Functionality of Diffractive Networks"
            },
            "updated": "2026-01-08T11:00:40Z",
            "updated_parsed": [
                2026,
                1,
                8,
                11,
                0,
                40,
                3,
                8,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.04825v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.04825v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Diffractive neural networks have recently emerged as a promising framework for all-optical computing. However, these networks are typically trained for a single task, limiting their potential adoption in systems requiring multiple functionalities. Existing approaches to achieving multi-task functionality either modify the mechanical configuration of the network per task or use a different illumination wavelength or polarization state for each task. In this work, we propose a new control mechanism, which is based on the illumination's angular spectrum. Specifically, we shape the illumination using an amplitude mask that selectively controls its angular spectrum. We employ different illumination masks for achieving different network functionalities, so that the mask serves as a unique task encoder. Interestingly, we show that effective control can be achieved over a very narrow angular range, within the paraxial regime. We numerically illustrate the proposed approach by training a single diffractive network to perform multiple image-to-image translation tasks. In particular, we demonstrate translating handwritten digits into typeset digits of different values, and translating handwritten English letters into typeset numbers and typeset Greek letters, where the type of the output is determined by the illumination's angular components. As we show, the proposed framework can work under different coherence conditions, and can be combined with existing control strategies, such as different wavelengths. Our results establish the illumination angular spectrum as a powerful degree of freedom for controlling diffractive networks, enabling a scalable and versatile framework for multi-task all-optical computing.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Diffractive neural networks have recently emerged as a promising framework for all-optical computing. However, these networks are typically trained for a single task, limiting their potential adoption in systems requiring multiple functionalities. Existing approaches to achieving multi-task functionality either modify the mechanical configuration of the network per task or use a different illumination wavelength or polarization state for each task. In this work, we propose a new control mechanism, which is based on the illumination's angular spectrum. Specifically, we shape the illumination using an amplitude mask that selectively controls its angular spectrum. We employ different illumination masks for achieving different network functionalities, so that the mask serves as a unique task encoder. Interestingly, we show that effective control can be achieved over a very narrow angular range, within the paraxial regime. We numerically illustrate the proposed approach by training a single diffractive network to perform multiple image-to-image translation tasks. In particular, we demonstrate translating handwritten digits into typeset digits of different values, and translating handwritten English letters into typeset numbers and typeset Greek letters, where the type of the output is determined by the illumination's angular components. As we show, the proposed framework can work under different coherence conditions, and can be combined with existing control strategies, such as different wavelengths. Our results establish the illumination angular spectrum as a powerful degree of freedom for controlling diffractive networks, enabling a scalable and versatile framework for multi-task all-optical computing."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.LG",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-08T11:00:40Z",
            "published_parsed": [
                2026,
                1,
                8,
                11,
                0,
                40,
                3,
                8,
                0
            ],
            "arxiv_comment": "Project's code https://github.com/matankleiner/Angular-Spectrum-Encoding",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Matan Kleiner"
                },
                {
                    "name": "Lior Michaeli"
                },
                {
                    "name": "Tomer Michaeli"
                }
            ],
            "author_detail": {
                "name": "Tomer Michaeli"
            },
            "author": "Tomer Michaeli",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "用于控制衍射网络功能的照明角光谱编码",
            "abstract_cn": "衍射神经网络最近已成为全光计算的一个有前途的框架。然而，这些网络通常针对单一任务进行训练，限制了它们在需要多种功能的系统中的潜在采用。实现多任务功能的现有方法要么修改每个任务的网络机械配置，要么为每个任务使用不同的照明波长或偏振状态。在这项工作中，我们提出了一种基于照明角谱的新控制机制。具体来说，我们使用振幅掩模来塑造照明，选择性地控制其角谱。我们采用不同的照明掩模来实现不同的网络功能，以便掩模充当独特的任务编码器。有趣的是，我们表明可以在近轴范围内的非常窄的角度范围内实现有效控制。我们通过训练单个衍射网络来执行多个图像到图像的转换任务，以数字方式说明所提出的方法。特别是，我们演示了将手写数字翻译成不同值的排版数字，以及将手写英文字母翻译成排版数字和排版希腊字母，其中输出的类型由照明的角度分量决定。正如我们所展示的，所提出的框架可以在不同的相干条件下工作，并且可以与现有的控制策略（例如不同的波长）相结合。我们的结果将照明角谱确立为控制衍射网络的强大自由度，从而为多任务全光计算提供可扩展且通用的框架。"
        },
        {
            "id": "http://arxiv.org/abs/2601.04964v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.04964v1",
            "title": "Nonlinear virtual lens for programmable and multispectral infrared upconversion imaging",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Nonlinear virtual lens for programmable and multispectral infrared upconversion imaging"
            },
            "updated": "2026-01-08T14:13:55Z",
            "updated_parsed": [
                2026,
                1,
                8,
                14,
                13,
                55,
                3,
                8,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.04964v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.04964v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Conventional infrared (IR) imaging techniques depend on IR cameras based on narrow-bandgap semiconductors, which offer limited spectral bandwidth, coupled with a separate lens. Recently, advances in nonlinear flat optics have opened a novel pathway for converting IR signals into the visible through nonlinear generations, enabling the direct visualisation of IR images using standard visible cameras. However, the narrow spectral bandwidth and the requirement for an additional lens remain the key challenges. Here, we address both issues via a novel adaptive and multifunctional IR-to-visible imaging platform offering tunable bandwidth and focusing simultaneously. We utilise sum-frequency generation (SFG) to convert IR light into the visible, by introducing a pump beam modulated by a spatial light modulator (SLM) to construct a virtual metalens enabling precisely controlled focusing of the generated nonlinear optical field. As a result, we demonstrate both theoretically and experimentally an optical focusing mechanism with a tunable focal length, achieved by varying the pump and signal wavelengths and modulating the phase distribution. Furthermore, since the focal length depends on the input signal wavelength, the imaging plane position varies accordingly, indicating a promising potential for the multispectral IR imaging applications. Our upconversion platform delivers SLM-controlled, programmable multispectral focusing for next-generation IR imaging, opening new avenues in the fields of computational and multispectral imaging techniques.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Conventional infrared (IR) imaging techniques depend on IR cameras based on narrow-bandgap semiconductors, which offer limited spectral bandwidth, coupled with a separate lens. Recently, advances in nonlinear flat optics have opened a novel pathway for converting IR signals into the visible through nonlinear generations, enabling the direct visualisation of IR images using standard visible cameras. However, the narrow spectral bandwidth and the requirement for an additional lens remain the key challenges. Here, we address both issues via a novel adaptive and multifunctional IR-to-visible imaging platform offering tunable bandwidth and focusing simultaneously. We utilise sum-frequency generation (SFG) to convert IR light into the visible, by introducing a pump beam modulated by a spatial light modulator (SLM) to construct a virtual metalens enabling precisely controlled focusing of the generated nonlinear optical field. As a result, we demonstrate both theoretically and experimentally an optical focusing mechanism with a tunable focal length, achieved by varying the pump and signal wavelengths and modulating the phase distribution. Furthermore, since the focal length depends on the input signal wavelength, the imaging plane position varies accordingly, indicating a promising potential for the multispectral IR imaging applications. Our upconversion platform delivers SLM-controlled, programmable multispectral focusing for next-generation IR imaging, opening new avenues in the fields of computational and multispectral imaging techniques."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-08T14:13:55Z",
            "published_parsed": [
                2026,
                1,
                8,
                14,
                13,
                55,
                3,
                8,
                0
            ],
            "arxiv_comment": "19 pages, 7 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Ze Zheng"
                },
                {
                    "name": "Olga Sergaeva"
                },
                {
                    "name": "Davide Rocco"
                },
                {
                    "name": "Yuchen Zhang"
                },
                {
                    "name": "Guoquan Zhang"
                },
                {
                    "name": "Mohsen Rahmani"
                },
                {
                    "name": "Costantino De Angelis"
                },
                {
                    "name": "Lei Xu"
                }
            ],
            "author_detail": {
                "name": "Lei Xu"
            },
            "author": "Lei Xu",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "用于可编程和多光谱红外上转换成像的非线性虚拟镜头",
            "abstract_cn": "传统的红外 (IR) 成像技术依赖于基于窄带隙半导体的红外相机，该相机提供有限的光谱带宽，并配有单独的镜头。最近，非线性平面光学的进步开辟了一条通过非线性生成将红外信号转换为可见光的新途径，从而可以使用标准可见光相机直接可视化红外图像。然而，窄光谱带宽和对额外镜头的要求仍然是主要挑战。在这里，我们通过一种新颖的自适应多功能红外到可见光成像平台解决了这两个问题，该平台同时提供可调带宽和聚焦。我们利用和频生成（SFG）将红外光转换为可见光，通过引入由空间光调制器（SLM）调制的泵浦光束来构建虚拟超透镜，从而能够精确控制所生成的非线性光场的聚焦。因此，我们从理论上和实验上证明了一种具有可调焦距的光学聚焦机制，通过改变泵浦和信号波长以及调制相位分布来实现。此外，由于焦距取决于输入信号波长，成像平面位置也会相应变化，这表明多光谱红外成像应用具有广阔的前景。我们的上转换平台为下一代红外成像提供 SLM 控制的可编程多光谱聚焦，为计算和多光谱成像技术领域开辟了新途径。"
        },
        {
            "id": "http://arxiv.org/abs/2601.06448v2",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.06448v2",
            "title": "Physics-guided foundation model for universal speckle removal in ultrathin multimode fiber imaging",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Physics-guided foundation model for universal speckle removal in ultrathin multimode fiber imaging"
            },
            "updated": "2026-01-20T05:04:17Z",
            "updated_parsed": [
                2026,
                1,
                20,
                5,
                4,
                17,
                1,
                20,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.06448v2",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.06448v2",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Ultrathin multimode fibers (MMFs) promise endoscopes with hair-scale diameters for accessing sub-millimeter anatomy, but in MMF far-field imaging the required small collection aperture drives speckle-dominated measurements that rapidly degrade image fidelity. Here we present Speckle Clean Network (SCNet), a physics-guided foundation model for universal speckle removal that makes photon-limited, single-fiber collection compatible with high-fidelity reconstruction across diverse scattering conditions without target-specific retraining. SCNet combines a Mixture of Experts (MoE) architecture with material-aware routing, wavelet-based frequency decomposition to separate structure from speckle across sub-bands, and a curriculum-style optimization that progressively enforces spectral consistency before spatial fidelity. Using an ultrathin dual-fiber holographic probe, we deliver wavefront-shaped illumination through one MMF and collect backscattered photons through a parallel MMF. We validate SCNet on 3D plastic objects over varying working distances, resolve 5.66 lp/mm on a paper USAF target, and restore fine structures on leaves and metal surfaces. On rabbit heart and kidney tissues, SCNet improves recovery of low-contrast anatomical texture under the same ultrathin collection constraint. We further compress SCNet through multi-teacher distillation to reduce computation while preserving reconstruction quality, enabling inference at 60 FPS. This work effectively decouples image quality from probe size, establishing a speckle-free ultrathin endoscopy for stand-off imaging in confined spaces.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Ultrathin multimode fibers (MMFs) promise endoscopes with hair-scale diameters for accessing sub-millimeter anatomy, but in MMF far-field imaging the required small collection aperture drives speckle-dominated measurements that rapidly degrade image fidelity. Here we present Speckle Clean Network (SCNet), a physics-guided foundation model for universal speckle removal that makes photon-limited, single-fiber collection compatible with high-fidelity reconstruction across diverse scattering conditions without target-specific retraining. SCNet combines a Mixture of Experts (MoE) architecture with material-aware routing, wavelet-based frequency decomposition to separate structure from speckle across sub-bands, and a curriculum-style optimization that progressively enforces spectral consistency before spatial fidelity. Using an ultrathin dual-fiber holographic probe, we deliver wavefront-shaped illumination through one MMF and collect backscattered photons through a parallel MMF. We validate SCNet on 3D plastic objects over varying working distances, resolve 5.66 lp/mm on a paper USAF target, and restore fine structures on leaves and metal surfaces. On rabbit heart and kidney tissues, SCNet improves recovery of low-contrast anatomical texture under the same ultrathin collection constraint. We further compress SCNet through multi-teacher distillation to reduce computation while preserving reconstruction quality, enabling inference at 60 FPS. This work effectively decouples image quality from probe size, establishing a speckle-free ultrathin endoscopy for stand-off imaging in confined spaces."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-10T06:13:13Z",
            "published_parsed": [
                2026,
                1,
                10,
                6,
                13,
                13,
                5,
                10,
                0
            ],
            "arxiv_comment": "35 pages, 9 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Xianrui Zeng"
                },
                {
                    "name": "Yirui Zang"
                },
                {
                    "name": "Pengfei Liu"
                },
                {
                    "name": "Fei Yu"
                },
                {
                    "name": "Yang Yang"
                },
                {
                    "name": "Tomáš Čižmár"
                },
                {
                    "name": "Yang Du"
                }
            ],
            "author_detail": {
                "name": "Yang Du"
            },
            "author": "Yang Du",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "超薄多模光纤成像中通用散斑去除的物理引导基础模型",
            "abstract_cn": "超薄多模光纤 (MMF) 有望使内窥镜具有发丝般的直径，以访问亚毫米解剖结构，但在 MMF 远场成像中，所需的小收集孔径驱动以散斑为主的测量，从而迅速降低图像保真度。在这里，我们提出了散斑清洁网络 (SCNet)，这是一种用于通用散斑去除的物理引导基础模型，使光子有限的单光纤收集与跨不同散射条件的高保真重建兼容，而无需针对特定目标进行再训练。 SCNet 将专家混合 (MoE) 架构与材料感知路由、基于小波的频率分解（以跨子带将结构与散斑分离）以及课程式优化相结合，在空间保真度之前逐步增强频谱一致性。我们使用超薄双光纤全息探头，通过一个 MMF 提供波前形状照明，并通过一个平行 MMF 收集反向散射光子。我们在不同工作距离的 3D 塑料物体上验证 SCNet，在美国空军纸质目标上解析 5.66 lp/mm，并恢复树叶和金属表面的精细结构。在兔子心脏和肾脏组织上，SCNet 在相同的超薄收集约束下提高了低对比度解剖纹理的恢复。我们通过多教师蒸馏进一步压缩 SCNet，以减少计算量，同时保持重建质量，从而实现 60 FPS 的推理。这项工作有效地将图像质量与探头尺寸分离，建立了一种无散斑超薄内窥镜，可在有限空间内进行远距离成像。"
        },
        {
            "id": "http://arxiv.org/abs/2601.06459v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.06459v1",
            "title": "A High-Speed CGH Calculation Method for Mirror Images on Bézier Surfaces using Optical Path Length Minimization",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "A High-Speed CGH Calculation Method for Mirror Images on Bézier Surfaces using Optical Path Length Minimization"
            },
            "updated": "2026-01-10T07:00:17Z",
            "updated_parsed": [
                2026,
                1,
                10,
                7,
                0,
                17,
                5,
                10,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.06459v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.06459v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Rendering reflections in curved mirrors is crucial for enhancing the realism in computer-generated hologram (CGH), yet it poses a fundamental challenge due to the unique computational principles of CGH. Conventional methods using Bézier clipping are computationally prohibitive, and a previously proposed mirror surface subdivision method suffered from the computation time increasing with mirror curvature. To address these limitations, this paper proposes a novel calculation method based on Fermat's principle that directly and efficiently determines the reflection point by minimizing the optical path length from a point light source to a hologram pixel via the mirror surface, using Newton's method for optimization. Experimental results demonstrate that this method significantly reduces computation time compared to previous approaches. Furthermore, it enables the rendering of multiple reflections from several mirrors, a capability that was challenging for conventional techniques.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Rendering reflections in curved mirrors is crucial for enhancing the realism in computer-generated hologram (CGH), yet it poses a fundamental challenge due to the unique computational principles of CGH. Conventional methods using Bézier clipping are computationally prohibitive, and a previously proposed mirror surface subdivision method suffered from the computation time increasing with mirror curvature. To address these limitations, this paper proposes a novel calculation method based on Fermat's principle that directly and efficiently determines the reflection point by minimizing the optical path length from a point light source to a hologram pixel via the mirror surface, using Newton's method for optimization. Experimental results demonstrate that this method significantly reduces computation time compared to previous approaches. Furthermore, it enables the rendering of multiple reflections from several mirrors, a capability that was challenging for conventional techniques."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-10T07:00:17Z",
            "published_parsed": [
                2026,
                1,
                10,
                7,
                0,
                17,
                5,
                10,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Kodai Ono"
                },
                {
                    "name": "Seok Kang"
                },
                {
                    "name": "Yuji Sakamoto"
                }
            ],
            "author_detail": {
                "name": "Yuji Sakamoto"
            },
            "author": "Yuji Sakamoto",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "一种基于光程最小化的贝塞尔曲面镜像高速 CGH 计算方法",
            "abstract_cn": "渲染曲面镜中的反射对于增强计算机生成全息图 (CGH) 的真实感至关重要，但由于 CGH 独特的计算原理，它提出了根本性的挑战。使用贝塞尔剪裁的传统方法在计算上是令人望而却步的，并且先前提出的镜面细分方法的计算时间随着镜面曲率的增加而增加。为了解决这些限制，本文提出了一种基于费马原理的新颖计算方法，通过最小化点光源经镜面到全息图像素的光程长度，利用牛顿法进行优化，直接有效地确定反射点。实验结果表明，与以前的方法相比，该方法显着减少了计算时间。此外，它还可以渲染多个镜子的多次反射，这对传统技术来说是一个挑战。"
        },
        {
            "id": "http://arxiv.org/abs/2601.06614v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.06614v1",
            "title": "Single-exposure holographic 3D printing via inverse-designed phase masks",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Single-exposure holographic 3D printing via inverse-designed phase masks"
            },
            "updated": "2026-01-10T16:32:47Z",
            "updated_parsed": [
                2026,
                1,
                10,
                16,
                32,
                47,
                5,
                10,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.06614v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.06614v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Additive manufacturing using light is commonly constrained by serial voxel-by-voxel or layer-by-layer processing, which fundamentally limits fabrication speed and scalability. Here, we introduce a single-exposure holographic three-dimensional (3D) printing approach that synthesizes an entire volumetric dose distribution optically in one step. The method combines inverse-designed microstructured phase masks with photopolymer resins engineered for controlled optical absorption. By precisely tailoring the phase-mask topography, we generate arbitrary 3D light-intensity distributions within the resin, including intentionally encoded dark regions that define hollow internal features. Simultaneously, the resin formulation is designed to balance optical penetration with sufficient local energy deposition to achieve high-fidelity polymerization throughout the volume. Using this approach, millimeter-scale architectures comprising more than $10^{6}$ addressable voxels are fabricated in a single 7.5~s exposure, corresponding to a volumetric throughput of $\\sim$1~mm$^{3}$/s ($>10^{5}$~voxels/s). The demonstrated performance is presently limited by resin kinetics and illumination geometry rather than by the phase-mask framework itself. Because the volumetric information capacity scales with the space--bandwidth product of the phase mask, this approach provides a clear pathway toward substantially higher throughput, enabling scalable fabrication of micro-optical components, biomedical scaffolds, and other precision-engineered mesoscale systems.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Additive manufacturing using light is commonly constrained by serial voxel-by-voxel or layer-by-layer processing, which fundamentally limits fabrication speed and scalability. Here, we introduce a single-exposure holographic three-dimensional (3D) printing approach that synthesizes an entire volumetric dose distribution optically in one step. The method combines inverse-designed microstructured phase masks with photopolymer resins engineered for controlled optical absorption. By precisely tailoring the phase-mask topography, we generate arbitrary 3D light-intensity distributions within the resin, including intentionally encoded dark regions that define hollow internal features. Simultaneously, the resin formulation is designed to balance optical penetration with sufficient local energy deposition to achieve high-fidelity polymerization throughout the volume. Using this approach, millimeter-scale architectures comprising more than $10^{6}$ addressable voxels are fabricated in a single 7.5~s exposure, corresponding to a volumetric throughput of $\\sim$1~mm$^{3}$/s ($>10^{5}$~voxels/s). The demonstrated performance is presently limited by resin kinetics and illumination geometry rather than by the phase-mask framework itself. Because the volumetric information capacity scales with the space--bandwidth product of the phase mask, this approach provides a clear pathway toward substantially higher throughput, enabling scalable fabrication of micro-optical components, biomedical scaffolds, and other precision-engineered mesoscale systems."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-10T16:32:47Z",
            "published_parsed": [
                2026,
                1,
                10,
                16,
                32,
                47,
                5,
                10,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Dajun Lin"
                },
                {
                    "name": "Xiaofeng Chen"
                },
                {
                    "name": "Connor O. Dea"
                },
                {
                    "name": "Ji-Won Kim"
                },
                {
                    "name": "Keldy S. Mason"
                },
                {
                    "name": "Kwong Sang Lee"
                },
                {
                    "name": "Apratim Majumder"
                },
                {
                    "name": "Chih-Hao Chang"
                },
                {
                    "name": "Michael Cullinan"
                },
                {
                    "name": "Zachariah A. Page"
                },
                {
                    "name": "Rajesh Menon"
                }
            ],
            "author_detail": {
                "name": "Rajesh Menon"
            },
            "author": "Rajesh Menon",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "通过逆向设计的相位掩模进行单次曝光全息 3D 打印",
            "abstract_cn": "使用光的增材制造通常受到串行逐体素或逐层处理的限制，这从根本上限制了制造速度和可扩展性。在这里，我们介绍了一种单次曝光全息三维 (3D) 打印方法，该方法可以一步光学合成整个体积剂量分布。该方法将逆向设计的微结构相位掩模与专为控制光吸收而设计的光聚合物树脂相结合。通过精确定制相位掩模版形，我们在树脂内生成任意 3D 光强度分布，包括定义中空内部特征的有意编码的暗区域。同时，树脂配方旨在平衡光学渗透与足够的局部能量沉积，以在整个体积内实现高保真聚合。使用这种方法，在一次 7.5~s 曝光中制造了包含超过 $10^{6}$ 可寻址体素的毫米级架构，对应于 $\\sim$1~mm$^{3}$/s ($>10^{5}$~voxels/s) 的体积吞吐量。目前所展示的性能受到树脂动力学和照明几何形状的限制，而不是受到相位掩模框架本身的限制。由于体积信息容量随着相位掩模的空间带宽乘积而缩放，因此这种方法提供了一条通向更高吞吐量的清晰途径，从而实现了微光学组件、生物医学支架和其他精密设计的介观系统的可扩展制造。"
        },
        {
            "id": "http://arxiv.org/abs/2601.08020v2",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.08020v2",
            "title": "Canonical Clocks and Hidden Geometric Freedom in Self-Imaging",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Canonical Clocks and Hidden Geometric Freedom in Self-Imaging"
            },
            "updated": "2026-01-14T20:49:53Z",
            "updated_parsed": [
                2026,
                1,
                14,
                20,
                49,
                53,
                2,
                14,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.08020v2",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.08020v2",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Self-imaging represents a core hallmark of paraxial (quadratic)-wave evolution; yet, across its many realizations and generalizations over the past two centuries, the uniformity of recurrence planes along the propagation axis has been considered fundamental. However, by reframing the general phenomenon of self-imaging within its natural symplectic framework, we show that all self-imaging effects are necessarily tied to uniformly periodic recurrences in the canonical evolution coordinate -- metaplectic time -- and that the correspondence of that coordinate to the physical propagation axis represents an unexplored degree of freedom, which can be engineered arbitrarily by the initial transverse phase structure. Using a single programmable spatial light modulator, we demonstrate the construction of Talbot carpets characterized by recurrence spacings that accelerate and decelerate along the propagation axis, as well as those that follow polynomial, exponential, and sinusoidal axial trajectories, all of which preserve exact reconstruction in the canonical metaplectic time. These results establish metaplectic time as the fundamental invariant of self-imaging and reveal a regime of controllable axial dynamics previously thought to be fixed.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Self-imaging represents a core hallmark of paraxial (quadratic)-wave evolution; yet, across its many realizations and generalizations over the past two centuries, the uniformity of recurrence planes along the propagation axis has been considered fundamental. However, by reframing the general phenomenon of self-imaging within its natural symplectic framework, we show that all self-imaging effects are necessarily tied to uniformly periodic recurrences in the canonical evolution coordinate -- metaplectic time -- and that the correspondence of that coordinate to the physical propagation axis represents an unexplored degree of freedom, which can be engineered arbitrarily by the initial transverse phase structure. Using a single programmable spatial light modulator, we demonstrate the construction of Talbot carpets characterized by recurrence spacings that accelerate and decelerate along the propagation axis, as well as those that follow polynomial, exponential, and sinusoidal axial trajectories, all of which preserve exact reconstruction in the canonical metaplectic time. These results establish metaplectic time as the fundamental invariant of self-imaging and reveal a regime of controllable axial dynamics previously thought to be fixed."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-12T21:52:08Z",
            "published_parsed": [
                2026,
                1,
                12,
                21,
                52,
                8,
                0,
                12,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Layton A. Hall"
                },
                {
                    "name": "Samuel Alperin"
                }
            ],
            "author_detail": {
                "name": "Samuel Alperin"
            },
            "author": "Samuel Alperin",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "规范时钟和自我成像中隐藏的几何自由度",
            "abstract_cn": "自成像代表了近轴（二次）波演化的核心标志；然而，在过去两个世纪的许多认识和概括中，沿传播轴的重复平面的一致性被认为是基本的。然而，通过在自然辛框架内重新构建自成像的一般现象，我们表明所有自成像效应都必然与规范演化坐标（元波时间）中的均匀周期性重现有关，并且该坐标与物理传播轴的对应关系代表了一个未经探索的自由度，可以通过初始横向相位结构任意设计。使用单个可编程空间光调制器，我们演示了塔尔博特地毯的构造，其特征是沿着传播轴加速和减速的重复间距，以及遵循多项式、指数和正弦轴向轨迹的那些，所有这些都在规范的超波时间中保留了精确的重建。这些结果将元波时间确立为自成像的基本不变量，并揭示了先前认为是固定的可控轴向动力学机制。"
        },
        {
            "id": "http://arxiv.org/abs/2601.08906v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.08906v1",
            "title": "A 10 Megahertz Spatial Light Modulator",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "A 10 Megahertz Spatial Light Modulator"
            },
            "updated": "2026-01-13T19:00:00Z",
            "updated_parsed": [
                2026,
                1,
                13,
                19,
                0,
                0,
                1,
                13,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.08906v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.08906v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Rapid and programmable shaping of light fields is central to modern microscopy, display technologies, optical communications and sensing, quantum engineering, and quantum information processing. Current wavefront shaping technologies face a fundamental dichotomy: spatial light modulators (SLMs) offer high pixel count but suffer from low refresh rates, while acousto-optic deflectors (AODs) provide moderate speed with restricted optical beam geometries. Though recent advances in photonic integrated circuits achieve fast switching, there is currently no tool that provides MHz-rate, continuous motion, and arbitrarily reconfigurable control over a set of diffraction-limited spots. Here we introduce a new class of spatial light modulator that provides both 2D pixel geometry and high speed. The device operates by encoding spatial information in frequency bins via a broadband optical phase modulator, and decoding them via a first-of-its-kind, high-resolution 2D spectrometer. The spectrometer, based on the architecture which we call the Re-Imaging Phased Array (RIPA), achieves its sensitivity through long path-lengths, enabled by intra-spectrometer re-imaging lens-guides. We demonstrate site-resolved optical pulsing with a 44(1)~ns rise time, corresponding to frame rates exceeding 10 million frames per second, as well as arbitrary, reconfigurable 2D addressing and multi-site operations, including asynchronous, independent beam motion, splitting, and recombination. Leveraging these tools opens new horizons in rapid optical manipulation of matter across science, from fast, scalable control that approaches the inertial and radiation limits of atoms in quantum processors, to dynamically programmable, microsecond-resolved illumination in microscopy and neuro-biological imaging.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Rapid and programmable shaping of light fields is central to modern microscopy, display technologies, optical communications and sensing, quantum engineering, and quantum information processing. Current wavefront shaping technologies face a fundamental dichotomy: spatial light modulators (SLMs) offer high pixel count but suffer from low refresh rates, while acousto-optic deflectors (AODs) provide moderate speed with restricted optical beam geometries. Though recent advances in photonic integrated circuits achieve fast switching, there is currently no tool that provides MHz-rate, continuous motion, and arbitrarily reconfigurable control over a set of diffraction-limited spots. Here we introduce a new class of spatial light modulator that provides both 2D pixel geometry and high speed. The device operates by encoding spatial information in frequency bins via a broadband optical phase modulator, and decoding them via a first-of-its-kind, high-resolution 2D spectrometer. The spectrometer, based on the architecture which we call the Re-Imaging Phased Array (RIPA), achieves its sensitivity through long path-lengths, enabled by intra-spectrometer re-imaging lens-guides. We demonstrate site-resolved optical pulsing with a 44(1)~ns rise time, corresponding to frame rates exceeding 10 million frames per second, as well as arbitrary, reconfigurable 2D addressing and multi-site operations, including asynchronous, independent beam motion, splitting, and recombination. Leveraging these tools opens new horizons in rapid optical manipulation of matter across science, from fast, scalable control that approaches the inertial and radiation limits of atoms in quantum processors, to dynamically programmable, microsecond-resolved illumination in microscopy and neuro-biological imaging."
            },
            "tags": [
                {
                    "term": "quant-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.atom-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-13T19:00:00Z",
            "published_parsed": [
                2026,
                1,
                13,
                19,
                0,
                0,
                1,
                13,
                0
            ],
            "arxiv_primary_category": {
                "term": "quant-ph"
            },
            "authors": [
                {
                    "name": "Xin Wei"
                },
                {
                    "name": "Zeyang Li"
                },
                {
                    "name": "Abhishek V. Karve"
                },
                {
                    "name": "Adam L. Shaw"
                },
                {
                    "name": "David I. Schuster"
                },
                {
                    "name": "Jonathan Simon"
                }
            ],
            "author_detail": {
                "name": "Jonathan Simon"
            },
            "author": "Jonathan Simon",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "10兆赫空间光调制器",
            "abstract_cn": "光场的快速和可编程成形是现代显微镜、显示技术、光通信和传感、量子工程和量子信息处理的核心。当前的波前整形技术面临着基本的二分法：空间光调制器 (SLM) 提供高像素数，但刷新率较低，而声光偏转器 (AOD) 提供中等速度，但光束几何形状有限。尽管光子集成电路的最新进展实现了快速切换，但目前还没有工具可以提供 MHz 速率、连续运动以及对一组衍射极限点的任意可重新配置控制。在这里，我们介绍一种新型空间光调制器，它提供 2D 像素几何形状和高速。该设备的工作原理是通过宽带光学相位调制器对频率仓中的空间信息进行编码，并通过首创的高分辨率 2D 光谱仪对其进行解码。该光谱仪基于我们称为重成像相控阵 (RIPA) 的架构，通过光谱仪内重成像透镜导轨实现长路径长度，从而实现其灵敏度。我们演示了具有 44(1)~ns 上升时间（相当于每秒超过 1000 万帧）的站点分辨光脉冲，以及任意、可重新配置的 2D 寻址和多站点操作，包括异步、独立的光束运动、分裂和重组。利用这些工具为整个科学领域的物质快速光学操纵开辟了新的视野，从接近量子处理器中原子惯性和辐射极限的快速、可扩展控制，到显微镜和神经生物成像中的动态可编程、微秒级分辨率的照明。"
        },
        {
            "id": "http://arxiv.org/abs/2601.09022v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.09022v1",
            "title": "Fourier pixels for reciprocal light control",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Fourier pixels for reciprocal light control"
            },
            "updated": "2026-01-13T22:47:20Z",
            "updated_parsed": [
                2026,
                1,
                13,
                22,
                47,
                20,
                1,
                13,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.09022v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.09022v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Digital cameras and displays utilise picture elements (pixels) that perform a single function: detecting or emitting light intensity. To exploit the full information content of electromagnetic waves, more advanced elements are required. This has driven the development of multifunctional components, which for example, simultaneously detect and emit intensity or extract intensity and spectral information. However, no pixel exists that both senses and generates optical wavefronts with full control over amplitude, phase, and polarisation, limiting reciprocal control and feedback of sophisticated light fields. Here we present a route to such pixels by demonstrating a versatile platform of miniaturised diffractive elements based on Fourier optics. We exploit plasmonic surface waves, which propagate coherently and efficiently across metallic surfaces. When these plasmons are launched towards wavy microstructures designed with simple Fourier analysis, arbitrary and background-free optical wavefronts are generated. Conversely, incoming light can be sensed and its amplitude, phase, and polarisation fully characterised. By combining or superposing several such components, we create multifunctional 'Fourier pixels' that provide compact and accurate control over the optical field. Our approach, which could also use photonic waveguide modes, establishes a scalable, universal architecture for vectorially programmable pixels with applications in adaptive optics, holographic displays, optical communication, and quantum-information processing.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Digital cameras and displays utilise picture elements (pixels) that perform a single function: detecting or emitting light intensity. To exploit the full information content of electromagnetic waves, more advanced elements are required. This has driven the development of multifunctional components, which for example, simultaneously detect and emit intensity or extract intensity and spectral information. However, no pixel exists that both senses and generates optical wavefronts with full control over amplitude, phase, and polarisation, limiting reciprocal control and feedback of sophisticated light fields. Here we present a route to such pixels by demonstrating a versatile platform of miniaturised diffractive elements based on Fourier optics. We exploit plasmonic surface waves, which propagate coherently and efficiently across metallic surfaces. When these plasmons are launched towards wavy microstructures designed with simple Fourier analysis, arbitrary and background-free optical wavefronts are generated. Conversely, incoming light can be sensed and its amplitude, phase, and polarisation fully characterised. By combining or superposing several such components, we create multifunctional 'Fourier pixels' that provide compact and accurate control over the optical field. Our approach, which could also use photonic waveguide modes, establishes a scalable, universal architecture for vectorially programmable pixels with applications in adaptive optics, holographic displays, optical communication, and quantum-information processing."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-13T22:47:20Z",
            "published_parsed": [
                2026,
                1,
                13,
                22,
                47,
                20,
                1,
                13,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Yannik M. Glauser"
                },
                {
                    "name": "Sander J. W. Vonk"
                },
                {
                    "name": "David B. Seda"
                },
                {
                    "name": "Hannah Niese"
                },
                {
                    "name": "Boris de Jong"
                },
                {
                    "name": "Matthieu F. Bidaut"
                },
                {
                    "name": "Daniel Petter"
                },
                {
                    "name": "Gabriel Nagamine"
                },
                {
                    "name": "Nolan Lassaline"
                },
                {
                    "name": "David J. Norris"
                }
            ],
            "author_detail": {
                "name": "David J. Norris"
            },
            "author": "David J. Norris",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "用于相互光控制的傅里叶像素",
            "abstract_cn": "数码相机和显示器利用执行单一功能的图像元素（像素）：检测或发射光强度。为了充分利用电磁波的信息内容，需要更先进的元件。这推动了多功能组件的发展，例如，同时检测和发射强度或提取强度和光谱信息。然而，不存在既能感测又能生成光学波前并完全控制振幅、相位和偏振的像素，从而限制了复杂光场的相互控制和反馈。在这里，我们通过演示基于傅里叶光学的小型化衍射元件的多功能平台，提出了实现此类像素的途径。我们利用等离子体表面波，它可以在金属表面上一致且有效地传播。当这些等离子体激元发射到通过简单傅里叶分析设计的波状微结构时，就会生成任意且无背景的光学波前。相反，可以感测入射光并充分表征其幅度、相位和偏振。通过组合或叠加多个此类组件，我们创建了多功能“傅里叶像素”，可以对光场提供紧凑且精确的控制。我们的方法还可以使用光子波导模式，为矢量可编程像素建立可扩展的通用架构，并应用于自适应光学、全息显示、光通信和量子信息处理。"
        },
        {
            "id": "http://arxiv.org/abs/2601.11405v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.11405v1",
            "title": "General in situ feedback control of cascaded liquid crystal spatial light modulators for structured field generation",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "General in situ feedback control of cascaded liquid crystal spatial light modulators for structured field generation"
            },
            "updated": "2026-01-16T16:18:18Z",
            "updated_parsed": [
                2026,
                1,
                16,
                16,
                18,
                18,
                4,
                16,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.11405v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.11405v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Cascaded liquid crystal spatial light modulators provide a versatile strategy for the generation of structured light and matter fields, with applications including optical communications, photonic computing, and topological field engineering. However, experimental imperfections, such as temperature-dependent liquid crystal response, variations between individual pixels, and alignment errors, present significant engineering challenges in generating high-quality fields. Moreover, changes in experimental conditions over time mean that calibrating each component once is insufficient for maintaining long-term, high-quality field generation. To address this, we present a general engineering approach based on a bespoke, physically informed, and manifold-constrained gradient-descent scheme that enables in situ feedback control, compensating for such errors in real time without the need to alter the experimental setup. We further demonstrate the correction efficacy of our proposed strategy through experiments in both spatially varying light and matter field generation, including scenarios in which complex vectorial aberrations are artificially introduced into the setup. Together, these demonstrations underscore the practicality of our method and its suitability for deployment in real-world experimental environments, paving the way for robust operation of cascaded architectures for structured field generation.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Cascaded liquid crystal spatial light modulators provide a versatile strategy for the generation of structured light and matter fields, with applications including optical communications, photonic computing, and topological field engineering. However, experimental imperfections, such as temperature-dependent liquid crystal response, variations between individual pixels, and alignment errors, present significant engineering challenges in generating high-quality fields. Moreover, changes in experimental conditions over time mean that calibrating each component once is insufficient for maintaining long-term, high-quality field generation. To address this, we present a general engineering approach based on a bespoke, physically informed, and manifold-constrained gradient-descent scheme that enables in situ feedback control, compensating for such errors in real time without the need to alter the experimental setup. We further demonstrate the correction efficacy of our proposed strategy through experiments in both spatially varying light and matter field generation, including scenarios in which complex vectorial aberrations are artificially introduced into the setup. Together, these demonstrations underscore the practicality of our method and its suitability for deployment in real-world experimental environments, paving the way for robust operation of cascaded architectures for structured field generation."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-16T16:18:18Z",
            "published_parsed": [
                2026,
                1,
                16,
                16,
                18,
                18,
                4,
                16,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "An Aloysius Wang"
                },
                {
                    "name": "Yuxi Cai"
                },
                {
                    "name": "Zhenglin Li"
                },
                {
                    "name": "Ruofu Liu"
                },
                {
                    "name": "Yifei Ma"
                },
                {
                    "name": "Patrick S Salter"
                },
                {
                    "name": "Chao He"
                }
            ],
            "author_detail": {
                "name": "Chao He"
            },
            "author": "Chao He",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "用于结构化场生成的级联液晶空间光调制器的通用原位反馈控制",
            "abstract_cn": "级联液晶空间光调制器为生成结构光和物质场提供了一种通用策略，其应用包括光通信、光子计算和拓扑场工程。然而，实验缺陷，例如温度相关的液晶响应、各个像素之间的变化以及对准误差，给生成高质量场带来了重大的工程挑战。此外，实验条件随时间的变化意味着对每个组件进行一次校准不足以维持长期、高质量的场生成。为了解决这个问题，我们提出了一种基于定制的、物理信息丰富的、流形约束的梯度下降方案的通用工程方法，该方案能够实现原位反馈控制，实时补偿此类误差，而无需改变实验设置。我们通过空间变化的光场和物质场生成的实验进一步证明了我们提出的策略的校正功效，包括在设置中人为引入复杂矢量像差的场景。总之，这些演示强调了我们的方法的实用性及其在现实实验环境中部署的适用性，为结构化场生成的级联架构的稳健运行铺平了道路。"
        },
        {
            "id": "http://arxiv.org/abs/2601.14205v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.14205v1",
            "title": "Three-Dimensional Volumetric Reconstruction of Native Chilean Pollen via Lens-Free Digital In-line Holographic Microscopy",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Three-Dimensional Volumetric Reconstruction of Native Chilean Pollen via Lens-Free Digital In-line Holographic Microscopy"
            },
            "updated": "2026-01-20T18:07:32Z",
            "updated_parsed": [
                2026,
                1,
                20,
                18,
                7,
                32,
                1,
                20,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.14205v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.14205v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "This study presents a robust methodology for the 3D volumetric reconstruction of native Chileanpollen grains, specifically Gevuina avellana (hazel),Conium maculatum (hemloc) and Anthemis cotula (chamomile). Using a lens-free Digital In-line Holographic Microscopy (DLHM) system, we capture complex interference patterns that are numerically reconstructed using the Kirchhoff-Helmholtz transform. Our results demonstrate that this label-free approach provides high-fidelity morphological characterization and nanometric precision in biophysical parameter extraction, offering a scalable alternative for automated melissopalynology and environmental monitoring.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "This study presents a robust methodology for the 3D volumetric reconstruction of native Chileanpollen grains, specifically Gevuina avellana (hazel),Conium maculatum (hemloc) and Anthemis cotula (chamomile). Using a lens-free Digital In-line Holographic Microscopy (DLHM) system, we capture complex interference patterns that are numerically reconstructed using the Kirchhoff-Helmholtz transform. Our results demonstrate that this label-free approach provides high-fidelity morphological characterization and nanometric precision in biophysical parameter extraction, offering a scalable alternative for automated melissopalynology and environmental monitoring."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.bio-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "q-bio.QM",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-20T18:07:32Z",
            "published_parsed": [
                2026,
                1,
                20,
                18,
                7,
                32,
                1,
                20,
                0
            ],
            "arxiv_comment": "5 pages, pre-print article",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "J. Staforelli-Vivanco"
                },
                {
                    "name": "V. Salamanca-Levi"
                },
                {
                    "name": "R. Jofré-Cerda"
                },
                {
                    "name": "M. Rondanelli-Reyes"
                },
                {
                    "name": "I. Lamas"
                }
            ],
            "author_detail": {
                "name": "I. Lamas"
            },
            "author": "I. Lamas",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "通过无透镜数字在线全息显微镜对智利本土花粉进行三维体积重建",
            "abstract_cn": "这项研究提出了一种对本地智利花粉颗粒进行 3D 体积重建的可靠方法，特别是 Gevuina avellana（榛子）、Conium maculatum（铁杉）和 Anthemis cotula（洋甘菊）。使用无透镜数字在线全息显微镜 (DLHM) 系统，我们捕获复杂的干涉图案，并使用基尔霍夫-亥姆霍兹变换进行数值重建。我们的结果表明，这种无标记方法在生物物理参数提取中提供了高保真形态表征和纳米精度，为自动化蜜蜂孢粉学和环境监测提供了可扩展的替代方案。"
        },
        {
            "id": "http://arxiv.org/abs/2601.14766v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.14766v1",
            "title": "PAColorHolo: A Perceptually-Aware Color Management Framework for Holographic Displays",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "PAColorHolo: A Perceptually-Aware Color Management Framework for Holographic Displays"
            },
            "updated": "2026-01-21T08:43:28Z",
            "updated_parsed": [
                2026,
                1,
                21,
                8,
                43,
                28,
                2,
                21,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.14766v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.14766v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Holographic displays offer significant potential for augmented and virtual reality applications by reconstructing wavefronts that enable continuous depth cues and natural parallax without vergence-accommodation conflict. However, despite advances in pixel-level image quality, current systems struggle to achieve perceptually accurate color reproduction--an essential component of visual realism. These challenges arise from complex system-level distortions caused by coherent laser illumination, spatial light modulator imperfections, chromatic aberrations, and camera-induced color biases. In this work, we propose a perceptually-aware color management framework for holographic displays that jointly addresses input-output color inconsistencies through color space transformation, adaptive illumination control, and neural network-based perceptual modeling of the camera's color response. We validate the effectiveness of our approach through numerical simulations, optical experiments, and a controlled user study. The results demonstrate substantial improvements in perceptual color fidelity, laying the groundwork for perceptually driven holographic rendering in future systems.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Holographic displays offer significant potential for augmented and virtual reality applications by reconstructing wavefronts that enable continuous depth cues and natural parallax without vergence-accommodation conflict. However, despite advances in pixel-level image quality, current systems struggle to achieve perceptually accurate color reproduction--an essential component of visual realism. These challenges arise from complex system-level distortions caused by coherent laser illumination, spatial light modulator imperfections, chromatic aberrations, and camera-induced color biases. In this work, we propose a perceptually-aware color management framework for holographic displays that jointly addresses input-output color inconsistencies through color space transformation, adaptive illumination control, and neural network-based perceptual modeling of the camera's color response. We validate the effectiveness of our approach through numerical simulations, optical experiments, and a controlled user study. The results demonstrate substantial improvements in perceptual color fidelity, laying the groundwork for perceptually driven holographic rendering in future systems."
            },
            "tags": [
                {
                    "term": "cs.GR",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-21T08:43:28Z",
            "published_parsed": [
                2026,
                1,
                21,
                8,
                43,
                28,
                2,
                21,
                0
            ],
            "arxiv_comment": "Preprint (accepted to ACM TOG), 34 pages, 32 figures",
            "arxiv_primary_category": {
                "term": "cs.GR"
            },
            "authors": [
                {
                    "name": "Chun Chen"
                },
                {
                    "name": "Minseok Chae"
                },
                {
                    "name": "Seung-Woo Nam"
                },
                {
                    "name": "Myeong-Ho Choi"
                },
                {
                    "name": "Minseong Kim"
                },
                {
                    "name": "Eunbi Lee"
                },
                {
                    "name": "Yoonchan Jeong"
                },
                {
                    "name": "Jae-Hyeung Park"
                }
            ],
            "author_detail": {
                "name": "Jae-Hyeung Park"
            },
            "author": "Jae-Hyeung Park",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "PAColorHolo：全息显示器的感知色彩管理框架",
            "abstract_cn": "全息显示器通过重建波前，实现连续的深度线索和自然视差，而不会产生聚散调节冲突，从而为增强现实和虚拟现实应用提供了巨大的潜力。然而，尽管像素级图像质量取得了进步，当前的系统仍难以实现感知上准确的色彩再现——视觉真实感的重要组成部分。这些挑战源于相干激光照明、空间光调制器缺陷、色差和相机引起的颜色偏差引起的复杂系统级失真。在这项工作中，我们提出了一种用于全息显示器的感知感知色彩管理框架，通过色彩空间变换、自适应照明控制和基于神经网络的相机颜色响应感知建模来共同解决输入输出颜色不一致的问题。我们通过数值模拟、光学实验和受控用户研究验证了我们方法的有效性。结果表明，感知色彩保真度有了显着改善，为未来系统中感知驱动的全息渲染奠定了基础。"
        },
        {
            "id": "http://arxiv.org/abs/2601.15581v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.15581v1",
            "title": "Head-wearable Holographic Head-mounted Display with 6 Degrees of Freedom",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Head-wearable Holographic Head-mounted Display with 6 Degrees of Freedom"
            },
            "updated": "2026-01-22T02:02:53Z",
            "updated_parsed": [
                2026,
                1,
                22,
                2,
                2,
                53,
                3,
                22,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.15581v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.15581v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "A head-mounted display (HMD) using holography technology (holo-HMD) is expected to be the next generation of HMDs capable of reducing three-dimensional sickness. In HMDs, it is important to generate images that respond to head movement in real time. However, in holo-HMDs, generation of hologram data in real time is difficult due to the large computational resources required. This paper proposes a fast calculation algorithm for generating hologram data for holo-HMDs, which requires low computational power. A holo-HMD supporting six degrees of freedom was also developed using this algorithm and it was confirmed that it obtained reconstructed images with six degrees of freedom in real time (30 fps or more).",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "A head-mounted display (HMD) using holography technology (holo-HMD) is expected to be the next generation of HMDs capable of reducing three-dimensional sickness. In HMDs, it is important to generate images that respond to head movement in real time. However, in holo-HMDs, generation of hologram data in real time is difficult due to the large computational resources required. This paper proposes a fast calculation algorithm for generating hologram data for holo-HMDs, which requires low computational power. A holo-HMD supporting six degrees of freedom was also developed using this algorithm and it was confirmed that it obtained reconstructed images with six degrees of freedom in real time (30 fps or more)."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-22T02:02:53Z",
            "published_parsed": [
                2026,
                1,
                22,
                2,
                2,
                53,
                3,
                22,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Taichi Sakakihara"
                },
                {
                    "name": "Teppei Jodo"
                },
                {
                    "name": "Seok Kang"
                },
                {
                    "name": "Yuji Sakamoto"
                }
            ],
            "author_detail": {
                "name": "Yuji Sakamoto"
            },
            "author": "Yuji Sakamoto",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "6 自由度头戴式全息头戴显示器",
            "abstract_cn": "采用全息技术的头戴式显示器（HMD）（holo-HMD）有望成为能够减少三维眩晕的下一代头戴式显示器。在 HMD 中，生成实时响应头部运动的图像非常重要。然而，在全息头显中，由于需要大量的计算资源，实时生成全息图数据很困难。本文提出了一种为全息头戴式显示器生成全息图数据的快速计算算法，该算法需要较低的计算能力。利用该算法还开发了支持六自由度的holo-HMD，并证实其实时获得了六自由度的重建图像（30 fps或更高）。"
        },
        {
            "id": "http://arxiv.org/abs/2601.15769v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.15769v1",
            "title": "Explainable deep-learning detection of microplastic fibers via polarization-resolved holographic microscopy",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Explainable deep-learning detection of microplastic fibers via polarization-resolved holographic microscopy"
            },
            "updated": "2026-01-22T08:59:55Z",
            "updated_parsed": [
                2026,
                1,
                22,
                8,
                59,
                55,
                3,
                22,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.15769v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.15769v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Reliable identification of microplastic fibers is crucial for environmental monitoring but remains analytically challenging. We report an explainable deep-learning framework for classifying microplastic and natural microfibers using polarization-resolved digital holographic microscopy. From multiplexed holograms, the complex Jones matrix of each fiber was reconstructed to extract polarization eigen-parameters describing optical anisotropy. Statistical descriptors of nine polarization characteristics formed a 72-dimensional feature vector for a total of 296 fibers spanning six material classes, including polyamide 6, polyethylene terephthalate, polyamide 6.6, polypropylene, cotton and wool. The designed fully connected deep neural network achieved an accuracy of 96.7 % on the validation data, surpassing that of common machine-learning classifiers. Explainable artificial intelligence analysis with Shapley additive explanations identified eigenvalue-ratio quantities as dominant predictors, revealing the physical basis for classification. An additional reduced-feature model with the preserved architecture exploiting only these most significant eigenvalue-based characteristics retained high accuracy (93.3 %), thereby confirming their dominant role while still outperforming common machine-learning classifiers. These results establish polarization-based features as distinctive optical fingerprints and demonstrate the first explainable deep-learning approach for automated microplastic fiber identification.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Reliable identification of microplastic fibers is crucial for environmental monitoring but remains analytically challenging. We report an explainable deep-learning framework for classifying microplastic and natural microfibers using polarization-resolved digital holographic microscopy. From multiplexed holograms, the complex Jones matrix of each fiber was reconstructed to extract polarization eigen-parameters describing optical anisotropy. Statistical descriptors of nine polarization characteristics formed a 72-dimensional feature vector for a total of 296 fibers spanning six material classes, including polyamide 6, polyethylene terephthalate, polyamide 6.6, polypropylene, cotton and wool. The designed fully connected deep neural network achieved an accuracy of 96.7 % on the validation data, surpassing that of common machine-learning classifiers. Explainable artificial intelligence analysis with Shapley additive explanations identified eigenvalue-ratio quantities as dominant predictors, revealing the physical basis for classification. An additional reduced-feature model with the preserved architecture exploiting only these most significant eigenvalue-based characteristics retained high accuracy (93.3 %), thereby confirming their dominant role while still outperforming common machine-learning classifiers. These results establish polarization-based features as distinctive optical fingerprints and demonstrate the first explainable deep-learning approach for automated microplastic fiber identification."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.data-an",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-22T08:59:55Z",
            "published_parsed": [
                2026,
                1,
                22,
                8,
                59,
                55,
                3,
                22,
                0
            ],
            "arxiv_comment": "14 pages, 5 figures, 1 table",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Jan Appel"
                },
                {
                    "name": "Marika Valentino"
                },
                {
                    "name": "Lisa Miccio"
                },
                {
                    "name": "Vittorio Bianco"
                },
                {
                    "name": "Raffaella Mossotti"
                },
                {
                    "name": "Giulia Dalla Fontana"
                },
                {
                    "name": "Miroslav Ježek"
                },
                {
                    "name": "Pietro Ferraro"
                },
                {
                    "name": "Jaromír Běhal"
                }
            ],
            "author_detail": {
                "name": "Jaromír Běhal"
            },
            "author": "Jaromír Běhal",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "通过偏振分辨全息显微镜对微塑料纤维进行可解释的深度学习检测",
            "abstract_cn": "可靠地识别微塑料纤维对于环境监测至关重要，但在分析上仍然具有挑战性。我们报告了一种可解释的深度学习框架，用于使用偏振分辨数字全息显微镜对微塑料和天然微纤维进行分类。从多重全息图中，重建每根光纤的复杂琼斯矩阵，以提取描述光学各向异性的偏振本征参数。九个偏振特性的统计描述符形成了跨越六种材料类别的总共 296 根纤维的 72 维特征向量，包括聚酰胺 6、聚对苯二甲酸乙二醇酯、聚酰胺 6.6、聚丙烯、棉和羊毛。设计的全连接深度神经网络在验证数据上实现了 96.7% 的准确率，超过了常见的机器学习分类器。具有沙普利附加解释的可解释人工智能分析将特征值比量确定为主要预测因子，揭示了分类的物理基础。具有保留架构的附加简化特征模型仅利用这些最重要的基于特征值的特征，保留了高精度（93.3％），从而证实了它们的主导作用，同时仍然优于常见的机器学习分类器。这些结果将基于偏振的特征建立为独特的光学指纹，并展示了第一个可解释的自动微塑料纤维识别的深度学习方法。"
        },
        {
            "id": "http://arxiv.org/abs/2601.16330v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.16330v1",
            "title": "Single-View Holographic Volumetric 3D Printing with Coupled Differentiable Wave-Optical and Photochemical Optimization",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Single-View Holographic Volumetric 3D Printing with Coupled Differentiable Wave-Optical and Photochemical Optimization"
            },
            "updated": "2026-01-22T21:27:56Z",
            "updated_parsed": [
                2026,
                1,
                22,
                21,
                27,
                56,
                3,
                22,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.16330v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.16330v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Volumetric additive manufacturing promises near-instantaneous fabrication of 3D objects, yet achieving high fidelity at the micro-scale remains challenging due to the complex interplay between optical diffraction and chemical effects. We present \\emph{Single-View Holographic Volumetric Additive Manufacturing} (SHVAM), a mechanically static system that shapes volumetric dose distributions using time-multiplexed, phase-only holograms projected from a single optical axis. To achieve high resolution with SHVAM, we formulate hologram synthesis as a coupled inverse problem, integrating a differentiable wave-optical forward model with a simplified photochemical model that explicitly captures inhibitor diffusion and non-linear dose response. Optimizing hologram sequences under these coupled constraints allows us to pre-compensate for chemical blur, yielding higher print fidelity than optical-only optimization. We demonstrate the efficacy of SHVAM by fabricating simple 2D and 3D structures with lateral feature sizes of approximately \\SI{10}{\\micro\\meter} within a $\\SI{0.8}{\\milli\\meter} \\times \\SI{0.8}{\\milli\\meter} \\times \\SI{3}{\\milli\\meter}$ volume in seconds.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Volumetric additive manufacturing promises near-instantaneous fabrication of 3D objects, yet achieving high fidelity at the micro-scale remains challenging due to the complex interplay between optical diffraction and chemical effects. We present \\emph{Single-View Holographic Volumetric Additive Manufacturing} (SHVAM), a mechanically static system that shapes volumetric dose distributions using time-multiplexed, phase-only holograms projected from a single optical axis. To achieve high resolution with SHVAM, we formulate hologram synthesis as a coupled inverse problem, integrating a differentiable wave-optical forward model with a simplified photochemical model that explicitly captures inhibitor diffusion and non-linear dose response. Optimizing hologram sequences under these coupled constraints allows us to pre-compensate for chemical blur, yielding higher print fidelity than optical-only optimization. We demonstrate the efficacy of SHVAM by fabricating simple 2D and 3D structures with lateral feature sizes of approximately \\SI{10}{\\micro\\meter} within a $\\SI{0.8}{\\milli\\meter} \\times \\SI{0.8}{\\milli\\meter} \\times \\SI{3}{\\milli\\meter}$ volume in seconds."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-22T21:27:56Z",
            "published_parsed": [
                2026,
                1,
                22,
                21,
                27,
                56,
                3,
                22,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Felix Wechsler"
                },
                {
                    "name": "Riccardo Rizzo"
                },
                {
                    "name": "Christophe Moser"
                }
            ],
            "author_detail": {
                "name": "Christophe Moser"
            },
            "author": "Christophe Moser",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "结合可微分波光和光化学优化的单视图全息体积 3D 打印",
            "abstract_cn": "体积增材制造有望近乎瞬时地制造 3D 物体，但由于光学衍射和化学效应之间复杂的相互作用，在微观尺度上实现高保真度仍然具有挑战性。我们提出了 \\emph{单视图全息体积增材制造} (SHVAM)，这是一种机械静态系统，它使用从单个光轴投影的时分复用、纯相位全息图来塑造体积剂量分布。为了利用 SHVAM 实现高分辨率，我们将全息图合成表述为耦合逆问题，将可微分的波光正向模型与简化的光化学模型相结合，该模型明确捕获抑制剂扩散和非线性剂量响应。在这些耦合约束下优化全息图序列使我们能够预先补偿化学模糊，从而比仅光学优化产生更高的打印保真度。我们通过在几秒内的 $\\SI{0.8}{\\milli\\meter} \\times \\SI{0.8}{\\milli\\meter} \\times \\SI{3}{\\milli\\meter}$ 体积内制造横向特征尺寸约为 \\SI{10}{\\micro\\meter} 的简单 2D 和 3D 结构来证明 SHVAM 的功效。"
        },
        {
            "id": "http://arxiv.org/abs/2601.17816v2",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.17816v2",
            "title": "High-Repetition-Rate Projection Multiphoton Lithography for Large-Area Sub-Micron 3D Printing",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "High-Repetition-Rate Projection Multiphoton Lithography for Large-Area Sub-Micron 3D Printing"
            },
            "updated": "2026-01-27T02:55:33Z",
            "updated_parsed": [
                2026,
                1,
                27,
                2,
                55,
                33,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.17816v2",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.17816v2",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "High-resolution lithographic techniques are often limited by low volumetric throughput, since there is no universal and scalable manufacturing process that can produce 3D metasurfaces. In this work, we demonstrate a high-speed holographic 3D printing platform based on spatiotemporal beam shaping, exceeding the repetition rate while keeping the resolution high. The system integrates a femtosecond laser source with a spectral pulse compressor and a beam shaper to project uniform, axially confined light fields to project patterns directly on the advanced photoresists using a Digital Micromirror Device DMD. We investigate the process window for rapid polymerization, optimizing the photoinitiator choice to eliminate thermal crosstalk at high repetition rates. Using this setup, we achieve a production throughput of more than a million voxels per second with sub-micron resolution below 400 nm. The system's reliability is validated through the fabrication of large-area woodpile-like lattices and uniform micropillar arrays, establishing a workflow for scalable manufacturing of micro-optical components.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "High-resolution lithographic techniques are often limited by low volumetric throughput, since there is no universal and scalable manufacturing process that can produce 3D metasurfaces. In this work, we demonstrate a high-speed holographic 3D printing platform based on spatiotemporal beam shaping, exceeding the repetition rate while keeping the resolution high. The system integrates a femtosecond laser source with a spectral pulse compressor and a beam shaper to project uniform, axially confined light fields to project patterns directly on the advanced photoresists using a Digital Micromirror Device DMD. We investigate the process window for rapid polymerization, optimizing the photoinitiator choice to eliminate thermal crosstalk at high repetition rates. Using this setup, we achieve a production throughput of more than a million voxels per second with sub-micron resolution below 400 nm. The system's reliability is validated through the fabrication of large-area woodpile-like lattices and uniform micropillar arrays, establishing a workflow for scalable manufacturing of micro-optical components."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-25T12:45:14Z",
            "published_parsed": [
                2026,
                1,
                25,
                12,
                45,
                14,
                6,
                25,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Savvas Papamakarios"
                },
                {
                    "name": "Maria Manousidaki"
                },
                {
                    "name": "Michalis Stavrou"
                },
                {
                    "name": "David Gray"
                },
                {
                    "name": "Maria Farsari"
                }
            ],
            "author_detail": {
                "name": "Maria Farsari"
            },
            "arxiv_affiliation": "Institute of Electronic Structure and Laser, Foundation for Research and Technology-Hellas",
            "author": "Maria Farsari",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "用于大面积亚微米 3D 打印的高重复率投影多光子光刻",
            "abstract_cn": "高分辨率光刻技术通常受到低体积吞吐量的限制，因为没有可以生产 3D 超表面的通用且可扩展的制造工艺。在这项工作中，我们展示了一种基于时空光束整形的高速全息3D打印平台，在保持高分辨率的同时超越了重复率。该系统将飞秒激光源与光谱脉冲压缩器和光束整形器集成在一起，可投射均匀、轴向受限的光场，从而使用数字微镜器件 DMD 将图案直接投射到先进的光刻胶上。我们研究了快速聚合的工艺窗口，优化了光引发剂的选择，以消除高重复率下的热串扰。使用此设置，我们实现了每秒超过一百万体素的生产吞吐量，且亚微米分辨率低于 400 nm。该系统的可靠性通过大面积木桩状晶格和均匀微柱阵列的制造得到验证，建立了微光学元件可扩展制造的工作流程。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19486v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19486v1",
            "title": "Engineering Spatial Dispersion to Synthesize Arbitrary Spatial Filters Based on Metagratings",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Engineering Spatial Dispersion to Synthesize Arbitrary Spatial Filters Based on Metagratings"
            },
            "updated": "2026-01-27T11:18:59Z",
            "updated_parsed": [
                2026,
                1,
                27,
                11,
                18,
                59,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19486v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19486v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "This paper presents a design framework for synthesizing angularly selective spatial filters using non-uniform metagratings. While traditional metagratings focus on channeling energy into higher-order Floquet modes for a fixed incidence angle, we leverage the fundamental mode as a versatile degree of freedom to engineer spatial dispersion over a continuous angular spectrum. By strategically distributing non-uniformly loaded metallic wires and rigorously modeling their mutual interactions through an impedance-matrix formulation, we realize prescribed angular transfer functions with high efficiency. In particular, the framework is validated at 3.5 GHz through full-wave simulations of (i) low-pass, (ii) high-pass, and (iii) all-pass spatial filters. The results demonstrate that fundamental-mode engineering in non-uniform metagratins offers a highly efficient platform for advanced spatial wave manipulation.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "This paper presents a design framework for synthesizing angularly selective spatial filters using non-uniform metagratings. While traditional metagratings focus on channeling energy into higher-order Floquet modes for a fixed incidence angle, we leverage the fundamental mode as a versatile degree of freedom to engineer spatial dispersion over a continuous angular spectrum. By strategically distributing non-uniformly loaded metallic wires and rigorously modeling their mutual interactions through an impedance-matrix formulation, we realize prescribed angular transfer functions with high efficiency. In particular, the framework is validated at 3.5 GHz through full-wave simulations of (i) low-pass, (ii) high-pass, and (iii) all-pass spatial filters. The results demonstrate that fundamental-mode engineering in non-uniform metagratins offers a highly efficient platform for advanced spatial wave manipulation."
            },
            "tags": [
                {
                    "term": "physics.app-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T11:18:59Z",
            "published_parsed": [
                2026,
                1,
                27,
                11,
                18,
                59,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.app-ph"
            },
            "authors": [
                {
                    "name": "Jinyong Kim"
                },
                {
                    "name": "Minseok Kim"
                }
            ],
            "author_detail": {
                "name": "Minseok Kim"
            },
            "author": "Minseok Kim",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "基于元光栅的空间色散工程合成任意空间滤波器",
            "abstract_cn": "本文提出了一种使用非均匀元光栅合成角度选择性空间滤波器的设计框架。虽然传统的元光栅专注于将能量引导到固定入射角的高阶 Floquet 模式中，但我们利用基本模式作为通用自由度来设计连续角谱上的空间色散。通过策略性地分布非均匀负载的金属线并通过阻抗矩阵公式严格模拟它们的相互作用，我们高效地实现了规定的角度传递函数。特别是，该框架在 3.5 GHz 下通过 (i) 低通、(ii) 高通和 (iii) 全通空间滤波器的全波模拟进行了验证。结果表明，非均匀宏晶中的基模工程为先进的空间波操纵提供了一个高效的平台。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19632v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19632v1",
            "title": "Self-locking non-volatile coding metasurfaces via origami-based mechanical bits",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Self-locking non-volatile coding metasurfaces via origami-based mechanical bits"
            },
            "updated": "2026-01-27T14:09:29Z",
            "updated_parsed": [
                2026,
                1,
                27,
                14,
                9,
                29,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19632v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19632v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Digital coding metasurfaces have revolutionized electromagnetic (EM) manipulation, yet typical tunable approaches based on active components suffer from the \"volatility\" bottleneck. While mechanical modulation provides a potential solution, current implementations generally lack inherent state-locking capability, rendering them vulnerable to environmental disturbances and actuation errors. Inspired by the concept of mechanical bits (MBs), this paper presents a self-locking non-volatile coding metasurface platform enabled by Kresling origami-based MBs, where the continuous mechanical deformation of individual meta-atoms is discretized into robust binary geometric states protected by intrinsic energy barriers. The bistable states are strictly mapped to 1-bit EM coding phases via tailored metallic patterns integrated onto a multimaterial 3D printed Kresling origami array. Building upon this concept, both transmission- and reflection-type prototypes are proposed and experimentally demonstrated, exhibiting exceptional wavefront manipulation capabilities through near-field holographic imaging and far-field beam steering. In addition, the lightweight origami unit (1.5 g) exhibits an exceptional load-bearing capacity, supporting over 100 times its own weight. These results bridge mechanical logic with EM information processing, establishing a universal physical paradigm for constructing low-power, highly robust coding metasurfaces resilient to extreme environments.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Digital coding metasurfaces have revolutionized electromagnetic (EM) manipulation, yet typical tunable approaches based on active components suffer from the \"volatility\" bottleneck. While mechanical modulation provides a potential solution, current implementations generally lack inherent state-locking capability, rendering them vulnerable to environmental disturbances and actuation errors. Inspired by the concept of mechanical bits (MBs), this paper presents a self-locking non-volatile coding metasurface platform enabled by Kresling origami-based MBs, where the continuous mechanical deformation of individual meta-atoms is discretized into robust binary geometric states protected by intrinsic energy barriers. The bistable states are strictly mapped to 1-bit EM coding phases via tailored metallic patterns integrated onto a multimaterial 3D printed Kresling origami array. Building upon this concept, both transmission- and reflection-type prototypes are proposed and experimentally demonstrated, exhibiting exceptional wavefront manipulation capabilities through near-field holographic imaging and far-field beam steering. In addition, the lightweight origami unit (1.5 g) exhibits an exceptional load-bearing capacity, supporting over 100 times its own weight. These results bridge mechanical logic with EM information processing, establishing a universal physical paradigm for constructing low-power, highly robust coding metasurfaces resilient to extreme environments."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T14:09:29Z",
            "published_parsed": [
                2026,
                1,
                27,
                14,
                9,
                29,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Ding Zhang"
                },
                {
                    "name": "Peng Tang"
                },
                {
                    "name": "Liqiao Jing"
                },
                {
                    "name": "Xincheng Yao"
                },
                {
                    "name": "Bo Zhou"
                },
                {
                    "name": "Enzong Wu"
                },
                {
                    "name": "Ying Li"
                },
                {
                    "name": "Evgueni Filipov"
                },
                {
                    "name": "Hongsheng Chen"
                },
                {
                    "name": "Zuojia Wang"
                }
            ],
            "author_detail": {
                "name": "Zuojia Wang"
            },
            "author": "Zuojia Wang",
            "journal": "arXiv: Holography & CGH",
            "title_cn": "通过基于折纸的机械钻头自锁非易失性编码超表面",
            "abstract_cn": "数字编码超表面彻底改变了电磁（EM）操纵，但基于有源组件的典型可调方法却遭遇“波动性”瓶颈。虽然机械调制提供了一种潜在的解决方案，但当前的实现通常缺乏固有的状态锁定能力，使得它们容易受到环境干扰和驱动错误的影响。受机械位（MB）概念的启发，本文提出了一种由基于 Kresling 折纸的 MB 实现的自锁非易失性编码超表面平台，其中单个元原子的连续机械变形被离散化为受内在能量势垒保护的鲁棒二元几何状态。通过集成到多材料 3D 打印 Kresling 折纸阵列上的定制金属图案，双稳态严格映射到 1 位 EM 编码相位。在此概念的基础上，提出了透射型和反射型原型并进行了实验演示，通过近场全息成像和远场光束控制展现了卓越的波前操纵能力。此外，轻质折纸单元（1.5克）具有卓越的承重能力，可支撑其自身重量的100倍以上。这些结果将机械逻辑与电磁信息处理联系起来，建立了一个通用的物理范例，用于构建能够适应极端环境的低功耗、高度鲁棒的编码超表面。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18911v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18911v1",
            "title": "Twisting Kelvin Cells for Enhanced Vibration Control",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Twisting Kelvin Cells for Enhanced Vibration Control"
            },
            "updated": "2026-01-26T19:19:23Z",
            "updated_parsed": [
                2026,
                1,
                26,
                19,
                19,
                23,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18911v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18911v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "This work investigates the propagation of elastic waves in periodic Kelvin-cell chains, focusing on symmetry-breaking geometric modifications induced by twisting the cell's faces. By imposing such twists, the original lattice topology is preserved, while mirror symmetries are strategically broken through modifying a single geometric parameter, allowing wave characteristics to be adjusted without additional resonators or mass augmentation. The complex-valued Bloch-Floquet analysis reveals that twisting activates two distinct wave attenuation mechanisms: Bragg-type band gaps associated with periodicity-induced scattering, and polarization-dependent band gaps arising from longitudinal-torsional mode coupling and avoided crossings. To obtain qualitative and quantitative insight into these mechanisms, a simplified analytical model with coupled translational and rotational degrees of freedom is considered. The finite-element wave transmission calculations are experimentally validated on SLA-printed three-cell specimens, for which wave attenuation reaches up to 20 dB within the predicted band-gap frequencies. Note that high prediction accuracy requires accounting for viscoelastic material behavior, underscoring the importance of material behavior on the wave propagation characteristics. Overall, the findings show that modest geometric modifications to a classical Kelvin-cell lattice can enhance wave-filtering behavior, offering a tractable design strategy for vibration control in lightweight architected lattices.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "This work investigates the propagation of elastic waves in periodic Kelvin-cell chains, focusing on symmetry-breaking geometric modifications induced by twisting the cell's faces. By imposing such twists, the original lattice topology is preserved, while mirror symmetries are strategically broken through modifying a single geometric parameter, allowing wave characteristics to be adjusted without additional resonators or mass augmentation. The complex-valued Bloch-Floquet analysis reveals that twisting activates two distinct wave attenuation mechanisms: Bragg-type band gaps associated with periodicity-induced scattering, and polarization-dependent band gaps arising from longitudinal-torsional mode coupling and avoided crossings. To obtain qualitative and quantitative insight into these mechanisms, a simplified analytical model with coupled translational and rotational degrees of freedom is considered. The finite-element wave transmission calculations are experimentally validated on SLA-printed three-cell specimens, for which wave attenuation reaches up to 20 dB within the predicted band-gap frequencies. Note that high prediction accuracy requires accounting for viscoelastic material behavior, underscoring the importance of material behavior on the wave propagation characteristics. Overall, the findings show that modest geometric modifications to a classical Kelvin-cell lattice can enhance wave-filtering behavior, offering a tractable design strategy for vibration control in lightweight architected lattices."
            },
            "tags": [
                {
                    "term": "physics.app-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cond-mat.mtrl-sci",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T19:19:23Z",
            "published_parsed": [
                2026,
                1,
                26,
                19,
                19,
                23,
                0,
                26,
                0
            ],
            "arxiv_comment": "32 pages including supplementary material, 12 figures, submitted to the Journal of Mechanical Systems and Signal Processing",
            "arxiv_primary_category": {
                "term": "physics.app-ph"
            },
            "authors": [
                {
                    "name": "Lukas Kleine-Wächter"
                },
                {
                    "name": "Anastasiia O. Krushysnka"
                },
                {
                    "name": "Romain Rumpler"
                },
                {
                    "name": "Gerhard Müller"
                }
            ],
            "author_detail": {
                "name": "Gerhard Müller"
            },
            "author": "Gerhard Müller",
            "journal": "arXiv: Wave & Ray Optics",
            "title_cn": "扭转开尔文单元以增强振动控制",
            "abstract_cn": "这项工作研究了弹性波在周期性开尔文细胞链中的传播，重点关注由扭转细胞表面引起的对称性破坏的几何变化。通过施加这种扭曲，原始的晶格拓扑得以保留，同时通过修改单个几何参数策略性地打破了镜像对称性，从而无需额外的谐振器或质量增强即可调整波特性。复值 Bloch-Floquet 分析表明，扭转会激活两种不同的波衰减机制：与周期性引起的散射相关的布拉格型带隙，以及由纵向扭转模式耦合和避免交叉引起的偏振相关带隙。为了获得对这些机制的定性和定量洞察，考虑了具有耦合平移和旋转自由度的简化分析模型。有限元波传输计算在 SLA 打印的三单元样本上进行了实验验证，在预测的带隙频率内，波衰减高达 20 dB。请注意，高预测精度需要考虑粘弹性材料行为，强调材料行为对波传播特性的重要性。总体而言，研究结果表明，对经典开尔文晶胞晶格进行适度的几何修改可以增强滤波行为，为轻质架构晶格中的振动控制提供易于处理的设计策略。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19188v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19188v1",
            "title": "Development of Electroformed X-ray Optics Bridging Synchrotron Technology and Space Astronomy",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Development of Electroformed X-ray Optics Bridging Synchrotron Technology and Space Astronomy"
            },
            "updated": "2026-01-27T04:42:58Z",
            "updated_parsed": [
                2026,
                1,
                27,
                4,
                42,
                58,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19188v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19188v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We have developed X-ray telescope mirrors using an original electroforming replication technique established through the fabrication of millimeter-aperture, ultra-short-focal-length nanofocusing mirrors for synchrotron X-ray microscopy. This paper presents detailed results of X-ray illumination tests of a 60-mm-diameter, full-circumference, double-reflection monolithic electroformed nickel mirror and its Mirror Module Assembly (MMA). The experiments were conducted at the 1-km beamline BL29XUL at SPring-8. To simulate a parallel X-ray beam from celestial sources, we constructed a dedicated evaluation system, the High-Brilliance X-ray Kilometer-long Large-Area Expanded-beam Evaluation System (HBX-KLAEES). Owing to the high photon flux and the quasi-point-like source with a small divergence provided by HBX-KLAEES, the imaging performance was evaluated with high fidelity, resolving both the sharp core and large-angle components of the Point Spread Function (PSF). The results show an extremely sharp core with a Full Width at Half Maximum (FWHM) of 0.7 arcsec and a Half Power Diameter (HPD) of 14 arcsec, even after integration into the MMA. In addition, a positive correlation was found between angular resolution and axial figure error in both the primary and secondary mirror sections, indicating that axial figure errors contribute to image degradation. Based on these results, the MMA was selected as one of the hard X-ray optics for the FOXSI-4 sounding rocket experiment, which performs high-resolution soft and hard X-ray imaging spectroscopy of solar flares and was successfully launched. These results demonstrate the potential for further improvements in angular resolution and the development of high-resolution, ultra-short focal length X-ray optics for small satellites, including CubeSats.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We have developed X-ray telescope mirrors using an original electroforming replication technique established through the fabrication of millimeter-aperture, ultra-short-focal-length nanofocusing mirrors for synchrotron X-ray microscopy. This paper presents detailed results of X-ray illumination tests of a 60-mm-diameter, full-circumference, double-reflection monolithic electroformed nickel mirror and its Mirror Module Assembly (MMA). The experiments were conducted at the 1-km beamline BL29XUL at SPring-8. To simulate a parallel X-ray beam from celestial sources, we constructed a dedicated evaluation system, the High-Brilliance X-ray Kilometer-long Large-Area Expanded-beam Evaluation System (HBX-KLAEES). Owing to the high photon flux and the quasi-point-like source with a small divergence provided by HBX-KLAEES, the imaging performance was evaluated with high fidelity, resolving both the sharp core and large-angle components of the Point Spread Function (PSF). The results show an extremely sharp core with a Full Width at Half Maximum (FWHM) of 0.7 arcsec and a Half Power Diameter (HPD) of 14 arcsec, even after integration into the MMA. In addition, a positive correlation was found between angular resolution and axial figure error in both the primary and secondary mirror sections, indicating that axial figure errors contribute to image degradation. Based on these results, the MMA was selected as one of the hard X-ray optics for the FOXSI-4 sounding rocket experiment, which performs high-resolution soft and hard X-ray imaging spectroscopy of solar flares and was successfully launched. These results demonstrate the potential for further improvements in angular resolution and the development of high-resolution, ultra-short focal length X-ray optics for small satellites, including CubeSats."
            },
            "tags": [
                {
                    "term": "astro-ph.IM",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "astro-ph.SR",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.ins-det",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.space-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T04:42:58Z",
            "published_parsed": [
                2026,
                1,
                27,
                4,
                42,
                58,
                1,
                27,
                0
            ],
            "arxiv_comment": "13 paegs, 9 figures, accepted for publication in Publications of the Astronomical Society of the Pacific (PASP)",
            "arxiv_primary_category": {
                "term": "astro-ph.IM"
            },
            "authors": [
                {
                    "name": "Ryuto Fujii"
                },
                {
                    "name": "Koki Sakuta"
                },
                {
                    "name": "Kazuki Ampuku"
                },
                {
                    "name": "Yusuke Yoshida"
                },
                {
                    "name": "Makoto Yoshihara"
                },
                {
                    "name": "Ayumu Takigawa"
                },
                {
                    "name": "Keitoku Yoshihira"
                },
                {
                    "name": "Tetsuo Kano"
                },
                {
                    "name": "Naoki Ishida"
                },
                {
                    "name": "Noriyuki Narukage"
                },
                {
                    "name": "Keisuke Tamura"
                },
                {
                    "name": "Kikuko Miyata"
                },
                {
                    "name": "Gota Yamaguchi"
                },
                {
                    "name": "Hidekazu Takano"
                },
                {
                    "name": "Yoshiki Kohmura"
                },
                {
                    "name": "Shutaro Mohri"
                },
                {
                    "name": "Takehiro Kume"
                },
                {
                    "name": "Yusuke Matsuzawa"
                },
                {
                    "name": "Yoichi Imamura"
                },
                {
                    "name": "Takahiro Saito"
                },
                {
                    "name": "Kentaro Hiraguri"
                },
                {
                    "name": "Hirokazu Hashizume"
                },
                {
                    "name": "Hidekazu Mimura"
                },
                {
                    "name": "Ikuyuki Mitsuishi"
                }
            ],
            "author_detail": {
                "name": "Ikuyuki Mitsuishi"
            },
            "author": "Ikuyuki Mitsuishi",
            "journal": "arXiv: Wave & Ray Optics",
            "title_cn": "电铸X射线光学桥接同步加速器技术与空间天文学的发展",
            "abstract_cn": "我们使用原始电铸复制技术开发了 X 射线望远镜镜，该技术是通过制造用于同步加速器 X 射线显微镜的毫米孔径、超短焦距纳米聚焦镜而建立的。本文介绍了直径 60 毫米、全圆周、双反射整体电铸镍镜及其镜模块组件 (MMA) 的 X 射线照明测试的详细结果。实验在 SPring-8 的 1 公里光束线 BL29XUL 上进行。为了模拟来自天体源的平行X射线束，我们构建了一个专用的评估系统，即高亮度X射线千米长大面积扩展光束评估系统（HBX-KLAEES）。由于HBX-KLAEES提供的高光子通量和小发散的准点状源，以高保真度评估成像性能，解析了点扩散函数（PSF）的锐核和大角度分量。结果显示，即使在集成到 MMA 中后，核心也极其锋利，半高全宽 (FWHM) 为 0.7 角秒，半功率直径 (HPD) 为 14 角秒。此外，在主镜部分和次镜部分中都发现角分辨率和轴向图形误差之间存在正相关，这表明轴向图形误差会导致图像质量下降。基于这些结果，MMA被选为FOXSI-4探空火箭实验的硬X射线光学器件之一，对太阳耀斑进行高分辨率软和硬X射线成像光谱并成功发射。这些结果证明了进一步提高角分辨率以及为包括 CubeSat 在内的小型卫星开发高分辨率、超短焦距 X 射线光学器件的潜力。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19420v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19420v1",
            "title": "Engineering Quantum Emission with Mie Voids",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Engineering Quantum Emission with Mie Voids"
            },
            "updated": "2026-01-27T09:59:35Z",
            "updated_parsed": [
                2026,
                1,
                27,
                9,
                59,
                35,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19420v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19420v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Spontaneous emission, as a fundamental radiative process and a versatile information carrier, plays a vital role in light-emitting devices, optical information modulation and encryption, super-resolution fluorescence imaging and nano sensing. Engineering the photonic environment surrounding quantum emitters can enhance their emission characteristics. However, simultaneously achieving precise control over both excitation enhancement and quantum-yield modulation at the nanoscale remains elusive, highlighting substantial room for advancing the precised engineering of quantum emission. Here, we introduce silicon Mie voids - air-defined cavities that invert the conventional solid-particle geometry - to achieve independent tuning of quantum emission within an individual subwavelength structure, while minimizing optical losses. Full-wave simulations and experiments on both gradient and uniform Mie-void arrays jointly validate this quantitative framework for emission tuning, which disentangles excitation enhancement arising from local field confinement in air and quantum-yield enhancement resulting from strengthened emitter-resonator coupling, while confirming the accelerated radiative decay enabled by the void configuration. Leveraging this flexible mechanism, we realize a bimodal nanophotonic pattern with near-diffraction-limited pixels that encode the EPFL logo in the bright field and the SJTU logo in both dark field and photoluminescence micrographs. These results establish Mie voids as a powerful platform for programmable, high-density multimodal displays and open new avenues for advancing state-of-the-art nanophotonic devices.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Spontaneous emission, as a fundamental radiative process and a versatile information carrier, plays a vital role in light-emitting devices, optical information modulation and encryption, super-resolution fluorescence imaging and nano sensing. Engineering the photonic environment surrounding quantum emitters can enhance their emission characteristics. However, simultaneously achieving precise control over both excitation enhancement and quantum-yield modulation at the nanoscale remains elusive, highlighting substantial room for advancing the precised engineering of quantum emission. Here, we introduce silicon Mie voids - air-defined cavities that invert the conventional solid-particle geometry - to achieve independent tuning of quantum emission within an individual subwavelength structure, while minimizing optical losses. Full-wave simulations and experiments on both gradient and uniform Mie-void arrays jointly validate this quantitative framework for emission tuning, which disentangles excitation enhancement arising from local field confinement in air and quantum-yield enhancement resulting from strengthened emitter-resonator coupling, while confirming the accelerated radiative decay enabled by the void configuration. Leveraging this flexible mechanism, we realize a bimodal nanophotonic pattern with near-diffraction-limited pixels that encode the EPFL logo in the bright field and the SJTU logo in both dark field and photoluminescence micrographs. These results establish Mie voids as a powerful platform for programmable, high-density multimodal displays and open new avenues for advancing state-of-the-art nanophotonic devices."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cond-mat.mes-hall",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T09:59:35Z",
            "published_parsed": [
                2026,
                1,
                27,
                9,
                59,
                35,
                1,
                27,
                0
            ],
            "arxiv_comment": "29 pages, 6 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Yuchao Fu"
                },
                {
                    "name": "Ilia Lykov"
                },
                {
                    "name": "Sergejs Boroviks"
                },
                {
                    "name": "Nai-Quan Zhu"
                },
                {
                    "name": "Tianyue Li"
                },
                {
                    "name": "Siarhei Zavatski"
                },
                {
                    "name": "Makhlad Chahid"
                },
                {
                    "name": "Olivier J. F. Martin"
                }
            ],
            "author_detail": {
                "name": "Olivier J. F. Martin"
            },
            "author": "Olivier J. F. Martin",
            "journal": "arXiv: Wave & Ray Optics",
            "title_cn": "利用米氏空隙工程量子发射",
            "abstract_cn": "自发发射作为一种基本的辐射过程和一种多功能的信息载体，在发光器件、光信息调制和加密、超分辨率荧光成像和纳米传感等方面发挥着至关重要的作用。设计量子发射器周围的光子环境可以增强其发射特性。然而，在纳米尺度上同时实现对激发增强和量子产率调制的精确控制仍然难以实现，这凸显了推进量子发射精确工程的巨大空间。在这里，我们引入了硅米氏空隙（空气定义的空腔，它反转了传统的固体颗粒几何形状），以在单个亚波长结构内实现量子发射的独立调谐，同时最大限度地减少光学损耗。梯度和均匀米氏空洞阵列的全波模拟和实验共同验证了这种发射调谐的定量框架，该框架解开了空气中局部场限制引起的激发增强和增强的发射极-谐振器耦合引起的量子产率增强，同时确认了空洞配置实现的加速辐射衰减。利用这种灵活的机制，我们实现了具有近衍射极限像素的双峰纳米光子图案，该图案在明场中编码 EPFL 徽标，在暗场和光致发光显微照片中编码 SJTU 徽标。这些结果使米氏空隙成为可编程、高密度多模态显示器的强大平台，并为先进的纳米光子器件开辟了新途径。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18826v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18826v1",
            "title": "OCTA-Based Biomarker Characterization in nAMD",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "OCTA-Based Biomarker Characterization in nAMD"
            },
            "updated": "2026-01-25T11:16:07Z",
            "updated_parsed": [
                2026,
                1,
                25,
                11,
                16,
                7,
                6,
                25,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18826v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18826v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                },
                {
                    "rel": "related",
                    "href": "https://doi.org/10.1109/IPAS63548.2025.10924557",
                    "title": "doi",
                    "type": "text/html"
                }
            ],
            "summary": "We aim to enhance ophthalmologists' decision-making when diagnosing the Neovascular Age-Related Macular Degeneration (nAMD). We developed three tools to analyze Optical Coherence Tomography Angiography images: (1) extracting biomarkers such as mCNV area and vessel density using image processing; (2) generating a 3D visualization of the neovascularization for a better view of the affected regions; and (3) applying an ensemble of three white box machine learning algorithms (decision tree, support vector machines and DL-Learner) for nAMD diagnosis. The learned expressions reached 100% accuracy for the training data and 68% accuracy in testing. The main advantage is that all the learned models white-box, which ensures explainability and transparency, allowing clinicians to better understand the decision-making process.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We aim to enhance ophthalmologists' decision-making when diagnosing the Neovascular Age-Related Macular Degeneration (nAMD). We developed three tools to analyze Optical Coherence Tomography Angiography images: (1) extracting biomarkers such as mCNV area and vessel density using image processing; (2) generating a 3D visualization of the neovascularization for a better view of the affected regions; and (3) applying an ensemble of three white box machine learning algorithms (decision tree, support vector machines and DL-Learner) for nAMD diagnosis. The learned expressions reached 100% accuracy for the training data and 68% accuracy in testing. The main advantage is that all the learned models white-box, which ensures explainability and transparency, allowing clinicians to better understand the decision-making process."
            },
            "tags": [
                {
                    "term": "eess.IV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.med-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-25T11:16:07Z",
            "published_parsed": [
                2026,
                1,
                25,
                11,
                16,
                7,
                6,
                25,
                0
            ],
            "arxiv_primary_category": {
                "term": "eess.IV"
            },
            "arxiv_journal_ref": "2025 IEEE 6th International Conference on Image Processing, Applications and Systems (IPAS)",
            "authors": [
                {
                    "name": "MAria Simona Tivadar"
                },
                {
                    "name": "Ioana Damian"
                },
                {
                    "name": "Adrian Groza"
                },
                {
                    "name": "Simona Delia Nicoara"
                }
            ],
            "author_detail": {
                "name": "Simona Delia Nicoara"
            },
            "author": "Simona Delia Nicoara",
            "arxiv_doi": "10.1109/IPAS63548.2025.10924557",
            "journal": "arXiv: Ptychography & Microscopy",
            "title_cn": "nAMD 中基于 OCTA 的生物标志物表征",
            "abstract_cn": "我们的目标是提高眼科医生在诊断新生血管性年龄相关性黄斑变性 (nAMD) 时的决策能力。我们开发了三种工具来分析光学相干断层扫描血管造影图像：（1）使用图像处理提取生物标志物，例如 mCNV 面积和血管密度； (2) 生成新血管形成的 3D 可视化，以便更好地观察受影响区域； (3) 应用三种白盒机器学习算法（决策树、支持向量机和 DL-Learner）的集合进行 nAMD 诊断。学习到的表达式在训练数据中达到 100% 的准确率，在测试中达到 68% 的准确率。主要优点是所有学习模型都是白盒的，这确保了可解释性和透明度，使临床医生能够更好地理解决策过程。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18915v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18915v1",
            "title": "On-Axis Optical Trapping with Vortex Beams: The Role of the Multipolar Decomposition",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "On-Axis Optical Trapping with Vortex Beams: The Role of the Multipolar Decomposition"
            },
            "updated": "2026-01-26T19:26:08Z",
            "updated_parsed": [
                2026,
                1,
                26,
                19,
                26,
                8,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18915v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18915v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                },
                {
                    "rel": "related",
                    "href": "https://doi.org/10.1021/acsphotonics.3c01499",
                    "title": "doi",
                    "type": "text/html"
                }
            ],
            "summary": "Optical trapping is a well_established, decades old technology with applications in several fields of research. The most common scenario deals with particles that tend to be centered on the brightest part of the optical trap. Consequently, the optical forces keep the particle away from the dark zones of the beam. However, this is not the case when a focused doughnut_shaped beam generates on_axis trapping. In this system, the particle is centered on the intensity minima of the laser beam and the bright annular part lies on the periphery of the particle. Researchers have shown great interest in this phenomenon due to its advantage of reducing light interaction with trapped particles and the intriguing increase in the trapping strength. This work presents experimental and theoretical results that extend the analysis of on_axis trapping with light vortex beams. Specifically, in our experiments, we trap micron_sized spherical silica (SiO2) particles in water and we measure, through the power spectrum density method, the trap stiffness constant \\k{appa} generated by vortex beams with different topological charge orders. The optical forces are calculated from the exact solutions of the electromagnetic fields provided by the generalized Lorentz_Mie theory. We show a remarkable agreement between the theoretical prediction and the experimental measurements of \\k{appa}. Moreover, our numerical model gives us information about the electromagnetic fields inside the particle, offering valuable insights into the influence of the electromagnetic fields present in the vortex beam trapping scenario.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Optical trapping is a well_established, decades old technology with applications in several fields of research. The most common scenario deals with particles that tend to be centered on the brightest part of the optical trap. Consequently, the optical forces keep the particle away from the dark zones of the beam. However, this is not the case when a focused doughnut_shaped beam generates on_axis trapping. In this system, the particle is centered on the intensity minima of the laser beam and the bright annular part lies on the periphery of the particle. Researchers have shown great interest in this phenomenon due to its advantage of reducing light interaction with trapped particles and the intriguing increase in the trapping strength. This work presents experimental and theoretical results that extend the analysis of on_axis trapping with light vortex beams. Specifically, in our experiments, we trap micron_sized spherical silica (SiO2) particles in water and we measure, through the power spectrum density method, the trap stiffness constant \\k{appa} generated by vortex beams with different topological charge orders. The optical forces are calculated from the exact solutions of the electromagnetic fields provided by the generalized Lorentz_Mie theory. We show a remarkable agreement between the theoretical prediction and the experimental measurements of \\k{appa}. Moreover, our numerical model gives us information about the electromagnetic fields inside the particle, offering valuable insights into the influence of the electromagnetic fields present in the vortex beam trapping scenario."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T19:26:08Z",
            "published_parsed": [
                2026,
                1,
                26,
                19,
                26,
                8,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "arxiv_journal_ref": "ACS Photonics 2024, 11, 626_633",
            "authors": [
                {
                    "name": "Iker Gómez-Viloria"
                },
                {
                    "name": "Álvaro Nodar"
                },
                {
                    "name": "Martín Molezuelas-Ferreras"
                },
                {
                    "name": "Jorge Olmos-Trigo"
                },
                {
                    "name": "Ángel Cifuentes"
                },
                {
                    "name": "Miriam Martínez"
                },
                {
                    "name": "Miguel Varga"
                },
                {
                    "name": "Gabriel Molina-Terriza"
                }
            ],
            "author_detail": {
                "name": "Gabriel Molina-Terriza"
            },
            "author": "Gabriel Molina-Terriza",
            "arxiv_doi": "10.1021/acsphotonics.3c01499",
            "journal": "arXiv: Physics - Optics",
            "title_cn": "涡旋光束的同轴光学捕获：多极分解的作用",
            "abstract_cn": "光捕获是一项成熟的、已有数十年历史的技术，应用于多个研究领域。最常见的情况是粒子往往集中在光阱最亮的部分。因此，光学力使粒子远离光束的暗区。然而，当聚焦的环形光束产生轴上捕获时，情况并非如此。在该系统中，粒子以激光束强度最小值为中心，明亮的环形部分位于粒子的外围。研究人员对这种现象表现出了极大的兴趣，因为它具有减少光与被捕获粒子相互作用的优点以及捕获强度的有趣增加。这项工作提出了实验和理论结果，扩展了光涡旋光束轴上捕获的分析。具体来说，在我们的实验中，我们捕获水中微米级的球形二氧化硅（SiO2）颗粒，并通过功率谱密度法测量由不同拓扑电荷序的涡旋束产生的陷阱刚度常数\\k{appa}。光学力是根据广义洛伦兹米理论提供的电磁场的精确解来计算的。我们证明了 \\k{appa} 的理论预测和实验测量之间存在显着的一致性。此外，我们的数值模型为我们提供了有关粒子内部电磁场的信息，为了解涡旋束捕获场景中存在的电磁场的影响提供了有价值的见解。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18937v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18937v1",
            "title": "Complete transparency with three active-passive-coupled optical resonators",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Complete transparency with three active-passive-coupled optical resonators"
            },
            "updated": "2026-01-26T20:17:18Z",
            "updated_parsed": [
                2026,
                1,
                26,
                20,
                17,
                18,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18937v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18937v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "The phenomena of induced transparency, with the typical examples of electromagnetically induced transparency (EIT) in atomic media and coupled optical resonators, have attracted tremendous interest since their discoveries. Due to the limitations of the involved elements, however, near-100\\% transmissions were reported under highly demanding experimental conditions for atomic and other media. Based on a structure of three linearly coupled optical resonators, an active one carrying a possibly arbitrary optical gain and two passive ones simply with dissipation, we demonstrate that a transmitted light field can become completely transparent through the structure, which displays all properties similar to those of EIT. Manifested by a destructive interference to annihilate the intracavity field in the resonator directly coupled to the input, this complete transparency exists for any feasible power of the transmitted field and all realizable coupling strengths of the dark resonator with the input and the neighboring resonator, as long as the inter-cavity coupling for two other resonators is adjustable over a suitable range. A free control on the transparency window size and output field intensity can be realized by tuning two inter-cavity couplings without modifying the built-in system parameters.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "The phenomena of induced transparency, with the typical examples of electromagnetically induced transparency (EIT) in atomic media and coupled optical resonators, have attracted tremendous interest since their discoveries. Due to the limitations of the involved elements, however, near-100\\% transmissions were reported under highly demanding experimental conditions for atomic and other media. Based on a structure of three linearly coupled optical resonators, an active one carrying a possibly arbitrary optical gain and two passive ones simply with dissipation, we demonstrate that a transmitted light field can become completely transparent through the structure, which displays all properties similar to those of EIT. Manifested by a destructive interference to annihilate the intracavity field in the resonator directly coupled to the input, this complete transparency exists for any feasible power of the transmitted field and all realizable coupling strengths of the dark resonator with the input and the neighboring resonator, as long as the inter-cavity coupling for two other resonators is adjustable over a suitable range. A free control on the transparency window size and output field intensity can be realized by tuning two inter-cavity couplings without modifying the built-in system parameters."
            },
            "tags": [
                {
                    "term": "quant-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T20:17:18Z",
            "published_parsed": [
                2026,
                1,
                26,
                20,
                17,
                18,
                0,
                26,
                0
            ],
            "arxiv_comment": "13 pages, 6 figures",
            "arxiv_primary_category": {
                "term": "quant-ph"
            },
            "authors": [
                {
                    "name": "Xiao-Bo Yan"
                },
                {
                    "name": "Liu Yang"
                },
                {
                    "name": "Bing He"
                }
            ],
            "author_detail": {
                "name": "Bing He"
            },
            "author": "Bing He",
            "journal": "arXiv: Physics - Optics",
            "title_cn": "通过三个主动-被动耦合光学谐振器实现完全透明",
            "abstract_cn": "诱导透明现象，以原子介质和耦合光学谐振器中的电磁诱导透明（EIT）为典型例子，自被发现以来就引起了人们的极大兴趣。然而，由于所涉及元素的限制，在原子和其他介质的高要求实验条件下，报告显示接近 100% 的传输率。基于三个线性耦合光学谐振器的结构，一个有源谐振器可能具有任意光学增益，两个无源谐振器仅具有耗散，我们证明透射光场可以通过该结构变得完全透明，从而显示出与 EIT 类似的所有属性。表现为消除直接耦合到输入的谐振器中的腔内场的相消干涉，这种完全透明对于传输场的任何可行功率以及暗谐振器与输入和相邻谐振器的所有可实现的耦合强度都存在，只要两个其他谐振器的腔间耦合在合适的范围内可调。通过调节两个腔间耦合，可以实现对透明窗口尺寸和输出场强的自由控制，而无需修改内置系统参数。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19028v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19028v1",
            "title": "Quantized non-Abelian helicity of flat bands in 2D Floquet topological photonic insulators",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Quantized non-Abelian helicity of flat bands in 2D Floquet topological photonic insulators"
            },
            "updated": "2026-01-26T23:27:00Z",
            "updated_parsed": [
                2026,
                1,
                26,
                23,
                27,
                0,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19028v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19028v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Flat-band states in topological systems provide a unique platform for investigating strongly correlated phenomena and many body physics. However, in 2D static tight-binding systems, perfectly flat bands can only exist in the topologically trivial phase, as characterized by a zero Chern number. Here we show that by introducing periodic driving into a 2D photonic Lieb lattice composed of coupled microring resonators, the resulting Floquet topological insulator can host perfectly flat bands with nontrivial topology. In particular, by tracking the evolution of the flat-band modes over each cycle, we show that the non-Abelian displacements of the flat-band modes are characterized by a nontrivial quantized helicity even though the quasi-energy bands have zero Chern number. The helical motion of the flat-band modes can be described by a braiding of the world lines of their trajectories, with a nontrivial winding number directly connected to the helicity. We also propose a scheme to experimentally measure the quantized non-Abelian helicity in a microring lattice subject to a synthetic magnetic field. These results suggest that Floquet topological photonic insulators based on coupled microring resonators can provide a versatile platform for investigating non-Abelian topological physics and strongly correlated phenomena in photonic flat-band systems.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Flat-band states in topological systems provide a unique platform for investigating strongly correlated phenomena and many body physics. However, in 2D static tight-binding systems, perfectly flat bands can only exist in the topologically trivial phase, as characterized by a zero Chern number. Here we show that by introducing periodic driving into a 2D photonic Lieb lattice composed of coupled microring resonators, the resulting Floquet topological insulator can host perfectly flat bands with nontrivial topology. In particular, by tracking the evolution of the flat-band modes over each cycle, we show that the non-Abelian displacements of the flat-band modes are characterized by a nontrivial quantized helicity even though the quasi-energy bands have zero Chern number. The helical motion of the flat-band modes can be described by a braiding of the world lines of their trajectories, with a nontrivial winding number directly connected to the helicity. We also propose a scheme to experimentally measure the quantized non-Abelian helicity in a microring lattice subject to a synthetic magnetic field. These results suggest that Floquet topological photonic insulators based on coupled microring resonators can provide a versatile platform for investigating non-Abelian topological physics and strongly correlated phenomena in photonic flat-band systems."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T23:27:00Z",
            "published_parsed": [
                2026,
                1,
                26,
                23,
                27,
                0,
                0,
                26,
                0
            ],
            "arxiv_comment": "17 pages, 6 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Bo Leng"
                },
                {
                    "name": "Vien Van"
                }
            ],
            "author_detail": {
                "name": "Vien Van"
            },
            "author": "Vien Van",
            "journal": "arXiv: Physics - Optics",
            "title_cn": "二维 Floquet 拓扑光子绝缘体中平带的量子化非阿贝尔螺旋度",
            "abstract_cn": "拓扑系统中的平带态为研究强相关现象和许多身体物理提供了独特的平台。然而，在二维静态紧束缚系统中，完全平坦的能带只能存在于拓扑平凡相中，其特征是陈数为零。在这里，我们展示了通过将周期性驱动引入由耦合微环谐振器组成的 2D 光子 Lieb 晶格中，所得的 Floquet 拓扑绝缘体可以拥有具有非平凡拓扑的完美平坦能带。特别是，通过跟踪平带模式在每个周期的演化，我们表明，即使准能带的陈数为零，平带模式的非阿贝尔位移也具有非平凡的量子化螺旋性特征。平带模式的螺旋运动可以通过其轨迹的世界线的编织来描述，其中不平凡的缠绕数与螺旋度直接相关。我们还提出了一种方案，通过实验测量合成磁场下微环晶格中的量子化非阿贝尔螺旋度。这些结果表明，基于耦合微环谐振器的 Floquet 拓扑光子绝缘体可以为研究非阿贝尔拓扑物理和光子平带系统中的强相关现象提供一个通用平台。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19116v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19116v1",
            "title": "Passive Daytime Radiative Cooling Enabled by Bio-Derived Ceramic-Polymer Coatings on Rapid-Curing Fiberglass Casts",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Passive Daytime Radiative Cooling Enabled by Bio-Derived Ceramic-Polymer Coatings on Rapid-Curing Fiberglass Casts"
            },
            "updated": "2026-01-27T02:40:05Z",
            "updated_parsed": [
                2026,
                1,
                27,
                2,
                40,
                5,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19116v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19116v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Passive daytime radiative cooling (PDRC) provides an energy-free approach to suppress surface temperatures by reflecting solar irradiation while emitting thermal radiation through the mid-infrared atmospheric window. Despite rapid progress in optical performance, most PDRC systems remain limited by rigid, fragile, or planar substrates, restricting their use on flexible, curved, or wearable surfaces. Here, we report a biocompatible and structurally robust PDRC system integrated onto a commercial rapid-curing fiberglass cast, a conformal substrate widely used in orthopedic and industrial applications. The cooling architecture adopts a bilayer polymer design consisting of a polyvinyl alcohol (PVA) adhesion layer and a polymethyl methacrylate (PMMA) protective layer, both embedded with calcium pyrophosphate (CPP) ceramic particles derived from processed animal bone waste. The bio-derived CPP simultaneously enables broadband solar scattering and high mid-infrared emittance, while offering sustainability and biocompatibility advantages. The resulting composite exhibits over 90% solar reflectance and achieves up to 15 C sub-ambient cooling under direct outdoor sunlight.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Passive daytime radiative cooling (PDRC) provides an energy-free approach to suppress surface temperatures by reflecting solar irradiation while emitting thermal radiation through the mid-infrared atmospheric window. Despite rapid progress in optical performance, most PDRC systems remain limited by rigid, fragile, or planar substrates, restricting their use on flexible, curved, or wearable surfaces. Here, we report a biocompatible and structurally robust PDRC system integrated onto a commercial rapid-curing fiberglass cast, a conformal substrate widely used in orthopedic and industrial applications. The cooling architecture adopts a bilayer polymer design consisting of a polyvinyl alcohol (PVA) adhesion layer and a polymethyl methacrylate (PMMA) protective layer, both embedded with calcium pyrophosphate (CPP) ceramic particles derived from processed animal bone waste. The bio-derived CPP simultaneously enables broadband solar scattering and high mid-infrared emittance, while offering sustainability and biocompatibility advantages. The resulting composite exhibits over 90% solar reflectance and achieves up to 15 C sub-ambient cooling under direct outdoor sunlight."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "eess.SY",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T02:40:05Z",
            "published_parsed": [
                2026,
                1,
                27,
                2,
                40,
                5,
                1,
                27,
                0
            ],
            "arxiv_comment": "20 pages, 5 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Xuguang Zhang"
                },
                {
                    "name": "Hexiang Zhang"
                },
                {
                    "name": "Hanqing Liu"
                },
                {
                    "name": "Xiaoli Li"
                },
                {
                    "name": "Mu Ying"
                },
                {
                    "name": "Yutian Yang"
                },
                {
                    "name": "Marilyn L. Minus"
                },
                {
                    "name": "Ming Su"
                },
                {
                    "name": "Yi Zheng"
                }
            ],
            "author_detail": {
                "name": "Yi Zheng"
            },
            "author": "Yi Zheng",
            "journal": "arXiv: Physics - Optics",
            "title_cn": "快速固化玻璃纤维铸件上的生物衍生陶瓷聚合物涂层实现被动日间辐射冷却",
            "abstract_cn": "被动日间辐射冷却（PDRC）提供了一种无能量的方法，通过反射太阳辐射同时通过中红外大气窗口发射热辐射来抑制表面温度。尽管光学性能取得了快速进步，但大多数 PDRC 系统仍然受到刚性、易碎或平面基材的限制，限制了它们在柔性、弯曲或耐磨表面上的使用。在这里，我们报告了一种生物相容性且结构坚固的 PDRC 系统，该系统集成到商业快速固化玻璃纤维铸件上，这是一种广泛用于骨科和工业应用的保形基材。该冷却架构采用双层聚合物设计，由聚乙烯醇（PVA）粘合层和聚甲基丙烯酸甲酯（PMMA）保护层组成，两者均嵌入来自加工动物骨废料的焦磷酸钙（CPP）陶瓷颗粒。生物衍生的 CPP 同时实现宽带太阳散射和高中红外发射率，同时提供可持续性和生物相容性优势。由此产生的复合材料具有超过 90% 的太阳光反射率，并在室外阳光直射下实现高达 15°C 的低于环境温度的冷却。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19201v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19201v1",
            "title": "Electrically pumped AlGaN edge-emitting UV-B laser diodes grown by molecular beam epitaxy",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Electrically pumped AlGaN edge-emitting UV-B laser diodes grown by molecular beam epitaxy"
            },
            "updated": "2026-01-27T05:04:08Z",
            "updated_parsed": [
                2026,
                1,
                27,
                5,
                4,
                8,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19201v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19201v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Mid and deep ultraviolet (UV) laser diodes remain among the least explored devices in semiconductor optoelectronics, despite their importance for spectroscopy, biochemical sensing, disinfection, and emerging quantum photonics. Here, we demonstrate an electrically pumped AlGaN-based laser diode operating in the UV-B band (280-315 nm). The device is grown by molecular beam epitaxy (MBE) on single-crystal AlN substrate and fabricated in a ridge-waveguide geometry. The laser diode operates at 298.5 nm and exhibits a relatively low threshold current density of 3.4 kA/cm$^2$. Clear nonlinear light-current characteristics and pronounced spectral narrowing with a full-width-at-half-maximum (FWHM) of 0.2 nm are measured above threshold.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Mid and deep ultraviolet (UV) laser diodes remain among the least explored devices in semiconductor optoelectronics, despite their importance for spectroscopy, biochemical sensing, disinfection, and emerging quantum photonics. Here, we demonstrate an electrically pumped AlGaN-based laser diode operating in the UV-B band (280-315 nm). The device is grown by molecular beam epitaxy (MBE) on single-crystal AlN substrate and fabricated in a ridge-waveguide geometry. The laser diode operates at 298.5 nm and exhibits a relatively low threshold current density of 3.4 kA/cm$^2$. Clear nonlinear light-current characteristics and pronounced spectral narrowing with a full-width-at-half-maximum (FWHM) of 0.2 nm are measured above threshold."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.app-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T05:04:08Z",
            "published_parsed": [
                2026,
                1,
                27,
                5,
                4,
                8,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Huabin Yu"
                },
                {
                    "name": "Shubham Mondal"
                },
                {
                    "name": "Rui Shen"
                },
                {
                    "name": "Md Tanvir Hasan"
                },
                {
                    "name": "David He"
                },
                {
                    "name": "Jiangnan Liu"
                },
                {
                    "name": "Samuel Yang"
                },
                {
                    "name": "Minming He"
                },
                {
                    "name": "Omar Alkhazragi"
                },
                {
                    "name": "Danhao Wang"
                },
                {
                    "name": "Mackillo Kira"
                },
                {
                    "name": "Parag Deotare"
                },
                {
                    "name": "Di Liang"
                },
                {
                    "name": "Zetian Mi"
                }
            ],
            "author_detail": {
                "name": "Zetian Mi"
            },
            "author": "Zetian Mi",
            "journal": "arXiv: Physics - Optics",
            "title_cn": "通过分子束外延生长的电泵浦 AlGaN 边发射 UV-B 激光二极管",
            "abstract_cn": "尽管中深紫外 (UV) 激光二极管对于光谱学、生化传感、消毒和新兴量子光子学非常重要，但它们仍然是半导体光电子学中研究最少的器件之一。在这里，我们展示了一种工作在 UV-B 波段（280-315 nm）的电泵浦 AlGaN 激光二极管。该器件通过分子束外延 (MBE) 在单晶 AlN 基板上生长，并以脊形波导几何形状制造。该激光二极管的工作波长为 298.5 nm，并具有 3.4 kA/cm$^2$ 的相对较低的阈值电流密度。在阈值以上测量到清晰的非线性光电流特性和明显的光谱变窄，半峰全宽 (FWHM) 为 0.2 nm。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19292v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19292v1",
            "title": "Ultrastrong light-matter coupling in near-field coupled split-ring resonators revealed by photocurrent spectroscopy",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Ultrastrong light-matter coupling in near-field coupled split-ring resonators revealed by photocurrent spectroscopy"
            },
            "updated": "2026-01-27T07:28:12Z",
            "updated_parsed": [
                2026,
                1,
                27,
                7,
                28,
                12,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19292v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19292v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Landau polaritons arising from the coupling between cyclotron resonance and terahertz split-ring resonators (SRRs) have served as a central platform for exploring ultrastrong light-matter interaction for more than a decade. Over this period, a wide variety of SRR architectures, differing in size, geometry, and even material composition, have been investigated. However, the regime of near-field coupled SRRs has remained largely unexplored. Here, we demonstrate ultrastrong coupling using photocurrent spectroscopy in two prototypical near-field configurations: a SRR dimer and a topological SRR chain. The measurements reveal hybridization not only with bright resonant modes but also with optically dark modes and topological edge modes, highlighting the exceptional sensitivity of the photocurrent spectroscopy. Moreover, the engineered near-field interactions allow the study of multi-mode ultrastrong coupling and the interplay between topological band structure and cavity quantum electrodynamics.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Landau polaritons arising from the coupling between cyclotron resonance and terahertz split-ring resonators (SRRs) have served as a central platform for exploring ultrastrong light-matter interaction for more than a decade. Over this period, a wide variety of SRR architectures, differing in size, geometry, and even material composition, have been investigated. However, the regime of near-field coupled SRRs has remained largely unexplored. Here, we demonstrate ultrastrong coupling using photocurrent spectroscopy in two prototypical near-field configurations: a SRR dimer and a topological SRR chain. The measurements reveal hybridization not only with bright resonant modes but also with optically dark modes and topological edge modes, highlighting the exceptional sensitivity of the photocurrent spectroscopy. Moreover, the engineered near-field interactions allow the study of multi-mode ultrastrong coupling and the interplay between topological band structure and cavity quantum electrodynamics."
            },
            "tags": [
                {
                    "term": "cond-mat.mes-hall",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T07:28:12Z",
            "published_parsed": [
                2026,
                1,
                27,
                7,
                28,
                12,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cond-mat.mes-hall"
            },
            "authors": [
                {
                    "name": "Jing Huang"
                },
                {
                    "name": "Jinkwan Kwoen"
                },
                {
                    "name": "Yasuhiko Arakawa"
                },
                {
                    "name": "Kazuhiko Hirakawa"
                },
                {
                    "name": "Kazuyuki Kuroyama"
                }
            ],
            "author_detail": {
                "name": "Kazuyuki Kuroyama"
            },
            "author": "Kazuyuki Kuroyama",
            "journal": "arXiv: Physics - Optics",
            "title_cn": "光电流光谱揭示近场耦合开环谐振器中的超强光-物质耦合",
            "abstract_cn": "十多年来，由回旋加速器共振和太赫兹开环谐振器（SRR）耦合产生的朗道极化激元一直是探索超强光与物质相互作用的中心平台。在此期间，人们对各种不同尺寸、几何形状甚至材料成分的 SRR 架构进行了研究。然而，近场耦合 SRR 的机制在很大程度上仍未得到探索。在这里，我们使用光电流光谱法在两种典型的近场配置中展示了超强耦合：SRR 二聚体和拓扑 SRR 链。测量结果揭示了不仅与亮共振模式杂交，而且与光学暗模式和拓扑边缘模式杂交，凸显了光电流光谱的卓越灵敏度。此外，工程近场相互作用允许研究多模超强耦合以及拓扑能带结构和腔量子电动力学之间的相互作用。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19361v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19361v1",
            "title": "Scaling of broadband Ho:CALGO regenerative amplifier to multi-mJ pulse energy",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Scaling of broadband Ho:CALGO regenerative amplifier to multi-mJ pulse energy"
            },
            "updated": "2026-01-27T08:44:00Z",
            "updated_parsed": [
                2026,
                1,
                27,
                8,
                44,
                0,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19361v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19361v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We report on energy scaling of a 2.08-μm wavelength regenerative amplifier (RA) system based on the broadband gain material Ho:CaAlGdO4 (CALGO) to multi-mJ pulse energy at kHz repetition rates. Compared to previous reports, energy scaling was enabled thanks to an upgraded seed laser with a higher fluence and better spectral overlap to the gain spectrum of Ho:CALGO, which increased amplification efficiency. Bifurcation-free energy extraction was investigated experimentally and numerically for various repetition rates. A stable output was obtained at 10 W average power for repetition rates of 30 kHz and above. In addition, stable 3.4-mJ energy extraction was achieved at a 1-kHz repetition rate. We discuss the further scaling potential of pulse energy and pulse duration.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We report on energy scaling of a 2.08-μm wavelength regenerative amplifier (RA) system based on the broadband gain material Ho:CaAlGdO4 (CALGO) to multi-mJ pulse energy at kHz repetition rates. Compared to previous reports, energy scaling was enabled thanks to an upgraded seed laser with a higher fluence and better spectral overlap to the gain spectrum of Ho:CALGO, which increased amplification efficiency. Bifurcation-free energy extraction was investigated experimentally and numerically for various repetition rates. A stable output was obtained at 10 W average power for repetition rates of 30 kHz and above. In addition, stable 3.4-mJ energy extraction was achieved at a 1-kHz repetition rate. We discuss the further scaling potential of pulse energy and pulse duration."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T08:44:00Z",
            "published_parsed": [
                2026,
                1,
                27,
                8,
                44,
                0,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Anna Suzuki"
                },
                {
                    "name": "Michael Müller"
                },
                {
                    "name": "Sergei Tomilov"
                },
                {
                    "name": "Clara J. Saraceno"
                }
            ],
            "author_detail": {
                "name": "Clara J. Saraceno"
            },
            "author": "Clara J. Saraceno",
            "journal": "arXiv: Physics - Optics",
            "title_cn": "将宽带 Ho:CALGO 再生放大器缩放至多 mJ 脉冲能量",
            "abstract_cn": "我们报告了基于宽带增益材料 Ho:CaAlGdO4 (CALGO) 的 2.08 μm 波长再生放大器 (RA) 系统在 kHz 重复频率下的能量缩放至多 mJ 脉冲能量。与之前的报告相比，由于升级的种子激光器具有更高的能量密度和与 Ho:CALGO 增益光谱更好的光谱重叠，从而提高了放大效率，从而实现了能量缩放。针对不同的重复率，对无分叉能量提取进行了实验和数值研究。在 30 kHz 及以上的重复频率下，平均功率为 10 W 时可获得稳定的输出。此外，在 1 kHz 重复率下实现了稳定的 3.4 mJ 能量提取。我们讨论了脉冲能量和脉冲持续时间的进一步扩展潜力。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19403v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19403v1",
            "title": "Learned split-spectrum metalens for obstruction-free broadband imaging in the visible",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Learned split-spectrum metalens for obstruction-free broadband imaging in the visible"
            },
            "updated": "2026-01-27T09:38:26Z",
            "updated_parsed": [
                2026,
                1,
                27,
                9,
                38,
                26,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19403v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19403v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Obstructions such as raindrops, fences, or dust degrade captured images, especially when mechanical cleaning is infeasible. Conventional solutions to obstructions rely on a bulky compound optics array or computational inpainting, which compromise compactness or fidelity. Metalenses composed of subwavelength meta-atoms promise compact imaging, but simultaneous achievement of broadband and obstruction-free imaging remains a challenge, since a metalens that images distant scenes across a broadband spectrum cannot properly defocus near-depth occlusions. Here, we introduce a learned split-spectrum metalens that enables broadband obstruction-free imaging. Our approach divides the spectrum of each RGB channel into pass and stop bands with multi-band spectral filtering and learns the metalens to focus light from far objects through pass bands, while filtering focused near-depth light through stop bands. This optical signal is further enhanced using a neural network. Our learned split-spectrum metalens achieves broadband and obstruction-free imaging with relative PSNR gains of 32.29% and improves object detection and semantic segmentation accuracies with absolute gains of +13.54% mAP, +48.45% IoU, and +20.35% mIoU over a conventional hyperbolic design. This promises robust obstruction-free sensing and vision for space-constrained systems, such as mobile robots, drones, and endoscopes.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Obstructions such as raindrops, fences, or dust degrade captured images, especially when mechanical cleaning is infeasible. Conventional solutions to obstructions rely on a bulky compound optics array or computational inpainting, which compromise compactness or fidelity. Metalenses composed of subwavelength meta-atoms promise compact imaging, but simultaneous achievement of broadband and obstruction-free imaging remains a challenge, since a metalens that images distant scenes across a broadband spectrum cannot properly defocus near-depth occlusions. Here, we introduce a learned split-spectrum metalens that enables broadband obstruction-free imaging. Our approach divides the spectrum of each RGB channel into pass and stop bands with multi-band spectral filtering and learns the metalens to focus light from far objects through pass bands, while filtering focused near-depth light through stop bands. This optical signal is further enhanced using a neural network. Our learned split-spectrum metalens achieves broadband and obstruction-free imaging with relative PSNR gains of 32.29% and improves object detection and semantic segmentation accuracies with absolute gains of +13.54% mAP, +48.45% IoU, and +20.35% mIoU over a conventional hyperbolic design. This promises robust obstruction-free sensing and vision for space-constrained systems, such as mobile robots, drones, and endoscopes."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.app-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T09:38:26Z",
            "published_parsed": [
                2026,
                1,
                27,
                9,
                38,
                26,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Seungwoo Yoon"
                },
                {
                    "name": "Dohyun Kang"
                },
                {
                    "name": "Eunsue Choi"
                },
                {
                    "name": "Sohyun Lee"
                },
                {
                    "name": "Seoyeon Kim"
                },
                {
                    "name": "Minho Choi"
                },
                {
                    "name": "Hyeonsu Heo"
                },
                {
                    "name": "Dong-ha Shin"
                },
                {
                    "name": "Suha Kwak"
                },
                {
                    "name": "Arka Majumdar"
                },
                {
                    "name": "Junsuk Rho"
                },
                {
                    "name": "Seung-Hwan Baek"
                }
            ],
            "author_detail": {
                "name": "Seung-Hwan Baek"
            },
            "author": "Seung-Hwan Baek",
            "journal": "arXiv: Physics - Optics",
            "title_cn": "学习了用于可见光中无障碍宽带成像的分谱超透镜",
            "abstract_cn": "雨滴、栅栏或灰尘等障碍物会降低捕获的图像质量，尤其是在无法进行机械清洁的情况下。传统的障碍物解决方案依赖于笨重的复合光学阵列或计算修复，这会损害紧凑性或保真度。由亚波长元原子组成的超透镜有望实现紧凑成像，但同时实现宽带和无遮挡成像仍然是一个挑战，因为跨宽带光谱对远处场景进行成像的超透镜无法正确散焦近深度遮挡。在这里，我们介绍了一种学习的分谱超透镜，可以实现宽带无阻碍成像。我们的方法通过多频带光谱滤波将每个 RGB 通道的光谱分为通带和阻带，并学习元透镜通过通带聚焦来自远处物体的光，同时通过阻带过滤聚焦的近深度光。使用神经网络进一步增强该光信号。我们学习的分谱超透镜实现了宽带和无遮挡成像，相对 PSNR 增益为 32.29%，并提高了目标检测和语义分割精度，与传统双曲设计相比，绝对增益为 +13.54% mAP、+48.45% IoU 和 +20.35% mIoU。这为移动机器人、无人机和内窥镜等空间受限的系统提供了强大的无障碍传感和视觉功能。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19528v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19528v1",
            "title": "High-sensitivity silicon nitride microring resonator opto-fluidic sensor",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "High-sensitivity silicon nitride microring resonator opto-fluidic sensor"
            },
            "updated": "2026-01-27T12:10:45Z",
            "updated_parsed": [
                2026,
                1,
                27,
                12,
                10,
                45,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19528v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19528v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Photonic integrated circuit devices can be used as refractometric opto-fluidic sensors to detect the presence of analytes in solution at low concentrations. In this work, we investigate the refractive index sensitivity of silicon nitride microring resonator based photonic integrated circuit fluidic sensors. The performance of a foundry fabricated sensor is measured over the C-band in the presence of liquid samples achieving a mean sensitivity of 579 nanometres per refractive index unit. This demonstration of a scalable, high-sensitivity opto-fluidic sensor, compatible with recognition marker surface functionalisation, opens the way to applications in environmental and bio-sensing.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Photonic integrated circuit devices can be used as refractometric opto-fluidic sensors to detect the presence of analytes in solution at low concentrations. In this work, we investigate the refractive index sensitivity of silicon nitride microring resonator based photonic integrated circuit fluidic sensors. The performance of a foundry fabricated sensor is measured over the C-band in the presence of liquid samples achieving a mean sensitivity of 579 nanometres per refractive index unit. This demonstration of a scalable, high-sensitivity opto-fluidic sensor, compatible with recognition marker surface functionalisation, opens the way to applications in environmental and bio-sensing."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T12:10:45Z",
            "published_parsed": [
                2026,
                1,
                27,
                12,
                10,
                45,
                1,
                27,
                0
            ],
            "arxiv_comment": "5 pages, 3 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Davey O. Armstrong"
                },
                {
                    "name": "Sherif Ibrahim"
                },
                {
                    "name": "Shirin Naserikarimvand"
                },
                {
                    "name": "Simon Whelan"
                },
                {
                    "name": "Owen J. Guy"
                },
                {
                    "name": "Anthony J. Bennett"
                },
                {
                    "name": "John P. Hadden"
                }
            ],
            "author_detail": {
                "name": "John P. Hadden"
            },
            "author": "John P. Hadden",
            "journal": "arXiv: Physics - Optics",
            "title_cn": "高灵敏度氮化硅微环谐振器光流传感器",
            "abstract_cn": "光子集成电路器件可用作折射光流传感器来检测溶液中低浓度分析物的存在。在这项工作中，我们研究了基于氮化硅微环谐振器的光子集成电路流体传感器的折射率灵敏度。铸造厂制造的传感器的性能是在液体样品存在的情况下在 C 波段上测量的，平均灵敏度为每折射率单位 579 纳米。此次演示的可扩展、高灵敏度光流体传感器与识别标记表面功能化兼容，为环境和生物传感领域的应用开辟了道路。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19534v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19534v1",
            "title": "Near-field effects on cathodoluminescence outcoupling in perovskite thin films",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Near-field effects on cathodoluminescence outcoupling in perovskite thin films"
            },
            "updated": "2026-01-27T12:23:27Z",
            "updated_parsed": [
                2026,
                1,
                27,
                12,
                23,
                27,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19534v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19534v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Halide perovskite semiconductors are a promising material for high-efficiency solar cells. Their optical properties can vary within and between crystallographic grains. We present spatially-resolved cathodoluminescence (CL) spectroscopy at 2 keV and 5 keV on polycrystalline CsPbBr3 perovskite films to study these variations at the nanoscale. The CL maps show a strongly reduced intensity near the polycrystalline grain boundaries. We perform numerical simulations of the far-field emission of the electron beam-generated optical near fields using the surface profiles from AFM as input. We find that near grain boundaries the light outcoupling is strongly reduced due to enhanced internal reflection and light trapping at the curved surfaces. Lateral variations in CL intensity inside grains are due to Fabry-Perot-like resonances in the film, with the substrate acting as a back reflector. Our results show that near-field coupling and interference effects can dominate nanoscale luminescence maps of halide perovskite films. The results are broadly relevant for the analysis of cathodoluminescence and photoluminescence of corrugated thin films.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Halide perovskite semiconductors are a promising material for high-efficiency solar cells. Their optical properties can vary within and between crystallographic grains. We present spatially-resolved cathodoluminescence (CL) spectroscopy at 2 keV and 5 keV on polycrystalline CsPbBr3 perovskite films to study these variations at the nanoscale. The CL maps show a strongly reduced intensity near the polycrystalline grain boundaries. We perform numerical simulations of the far-field emission of the electron beam-generated optical near fields using the surface profiles from AFM as input. We find that near grain boundaries the light outcoupling is strongly reduced due to enhanced internal reflection and light trapping at the curved surfaces. Lateral variations in CL intensity inside grains are due to Fabry-Perot-like resonances in the film, with the substrate acting as a back reflector. Our results show that near-field coupling and interference effects can dominate nanoscale luminescence maps of halide perovskite films. The results are broadly relevant for the analysis of cathodoluminescence and photoluminescence of corrugated thin films."
            },
            "tags": [
                {
                    "term": "cond-mat.mtrl-sci",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cond-mat.mes-hall",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T12:23:27Z",
            "published_parsed": [
                2026,
                1,
                27,
                12,
                23,
                27,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cond-mat.mtrl-sci"
            },
            "authors": [
                {
                    "name": "Robin Schot"
                },
                {
                    "name": "Imme Schuringa"
                },
                {
                    "name": "Álvaro Rodríguez Echarri"
                },
                {
                    "name": "Lars Sonneveld"
                },
                {
                    "name": "Tom Veeken"
                },
                {
                    "name": "Yang Lu"
                },
                {
                    "name": "Samuel D. Stranks"
                },
                {
                    "name": "Albert Polman"
                },
                {
                    "name": "Bruno Ehrler"
                },
                {
                    "name": "Saskia Fiedler"
                }
            ],
            "author_detail": {
                "name": "Saskia Fiedler"
            },
            "author": "Saskia Fiedler",
            "journal": "arXiv: Physics - Optics",
            "title_cn": "钙钛矿薄膜中阴极发光耦合的近场效应",
            "abstract_cn": "卤化物钙钛矿半导体是一种有前途的高效太阳能电池材料。它们的光学特性在晶粒内部和晶粒之间可能有所不同。我们在多晶 CsPbBr3 钙钛矿薄膜上提出了 2 keV 和 5 keV 的空间分辨阴极发光 (CL) 光谱，以研究纳米尺度的这些变化。 CL 图显示多晶晶界附近的强度大大降低。我们使用 AFM 的表面轮廓作为输入，对电子束产生的光学近场的远场发射进行数值模拟。我们发现，在晶界附近，由于弯曲表面处的内反射和光捕获增强，光输出耦合大大减少。晶粒内 CL 强度的横向变化是由于薄膜中的类法布里-珀罗共振所致，其中基底充当背反射器。我们的结果表明，近场耦合和干涉效应可以主导卤化物钙钛矿薄膜的纳米级发光图。结果与波纹薄膜的阴极发光和光致发光分析广泛相关。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19574v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19574v1",
            "title": "Automatic Classification of Laser Peening Quality Using Acoustic Signals",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Automatic Classification of Laser Peening Quality Using Acoustic Signals"
            },
            "updated": "2026-01-27T13:03:01Z",
            "updated_parsed": [
                2026,
                1,
                27,
                13,
                3,
                1,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19574v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19574v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Laser Shock Peening increases the fatigue life of metallic components by introducing beneficial compressive residual stresses. To achieve the desired effect, each individual laser pulse must be delivered correctly. Laser Shock Peening quality is typically verified by destructive and time-consuming residual stress measurements or by subjective operator judgement, which is non-objective and unsuitable for continuous in-line control. We propose a simple, low-cost and robust method based on the analysis of the acoustic response that automatically classifies individual laser pulses as defect-free or defective. We show that the acoustic response captured by a low-cost microphone carries sufficiently informative signatures to reliably distinguish correct from incorrect impacts and enables quality control at the level of single pulses. The method provides a non-destructive and objective route to real-time monitoring of Laser Shock Peening, with the potential to increase process reliability and support industrial deployment of this technology without the need for subsequent destructive measurements.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Laser Shock Peening increases the fatigue life of metallic components by introducing beneficial compressive residual stresses. To achieve the desired effect, each individual laser pulse must be delivered correctly. Laser Shock Peening quality is typically verified by destructive and time-consuming residual stress measurements or by subjective operator judgement, which is non-objective and unsuitable for continuous in-line control. We propose a simple, low-cost and robust method based on the analysis of the acoustic response that automatically classifies individual laser pulses as defect-free or defective. We show that the acoustic response captured by a low-cost microphone carries sufficiently informative signatures to reliably distinguish correct from incorrect impacts and enables quality control at the level of single pulses. The method provides a non-destructive and objective route to real-time monitoring of Laser Shock Peening, with the potential to increase process reliability and support industrial deployment of this technology without the need for subsequent destructive measurements."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T13:03:01Z",
            "published_parsed": [
                2026,
                1,
                27,
                13,
                3,
                1,
                1,
                27,
                0
            ],
            "arxiv_comment": "9 pages, 7 figures, 2 tables. Under review in JEOS",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Bohumil Kolář"
                },
                {
                    "name": "Jan Kočí"
                },
                {
                    "name": "Michal Kotek"
                },
                {
                    "name": "Tomáš Martinec"
                },
                {
                    "name": "Ivan Mašín"
                }
            ],
            "author_detail": {
                "name": "Ivan Mašín"
            },
            "author": "Ivan Mašín",
            "journal": "arXiv: Physics - Optics",
            "title_cn": "使用声学信号对激光喷丸质量进行自动分类",
            "abstract_cn": "激光冲击强化通过引入有益的残余压应力来延长金属部件的疲劳寿命。为了达到预期的效果，必须正确传送每个单独的激光脉冲。激光冲击强化质量通常通过破坏性且耗时的残余应力测量或操作员的主观判断来验证，这是非客观的，不适合连续在线控制。我们提出了一种基于声学响应分析的简单、低成本且稳健的方法，该方法自动将单个激光脉冲分类为无缺陷或有缺陷。我们证明，低成本麦克风捕获的声学响应带有足够的信息特征，可以可靠地区分正确和不正确的影响，并实现单脉冲水平的质量控制。该方法提供了一种实时监测激光冲击强化的非破坏性客观途径，有可能提高工艺可靠性并支持该技术的工业部署，而无需进行后续破坏性测量。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19646v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19646v1",
            "title": "Design Principles for Tailoring Heat Transport via Iris-Gated Core-Double-Shell Nanoparticles in the Context of Photothermal Therapies",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Design Principles for Tailoring Heat Transport via Iris-Gated Core-Double-Shell Nanoparticles in the Context of Photothermal Therapies"
            },
            "updated": "2026-01-27T14:21:52Z",
            "updated_parsed": [
                2026,
                1,
                27,
                14,
                21,
                52,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19646v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19646v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "The rational design of Janus nanostructures that combine efficient optical absorption with controlled thermal transport is essential for advancing plasmonic photothermal therapies and related applications. Here, we introduce a theoretical and computational framework to investigate core-double-shell nanoparticles and their asymmetric version, the iris-gated core-double-shell architecture. The optical response of the structures is first evaluated using generalized Mie theory and subsequently validated through FEM and FDTD simulations, ensuring a consistent description of their electromagnetic and thermal behavior. To systematically map the space of variables, we defined a multi-objective figure of merit that integrates absorption efficiency, absorption cross section, and polymer-layer thickness. Furthermore, we define a thermal gain parameter that quantifies energy densification and complements the analysis of thermal directionality. Our results reveal a near-optimal configuration with parameters ($r_c$, $δ_{Au}$, $δ_p$, $θ$)=(36 nm, 5 nm, 40 nm, 70$°$), capable of producing a temperature rise of 20-23 $°$C, with 67% of the thermal fluz directed toward the upper hemispace and yielding 50% focusing enhancement relative to the symmetric case. This design preserves geometric simplicity and high symmetry while delivering robust thermal asymmetry, thereby facilitating experimental implementation. Beyond photothermal therapies, the proposed methodology constitutes a versatile platform for the rapid screening and optimization of layered nanostructures, adaptable to diverse materials, excitation wavelengths, and functional objectives in nanophotonics.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "The rational design of Janus nanostructures that combine efficient optical absorption with controlled thermal transport is essential for advancing plasmonic photothermal therapies and related applications. Here, we introduce a theoretical and computational framework to investigate core-double-shell nanoparticles and their asymmetric version, the iris-gated core-double-shell architecture. The optical response of the structures is first evaluated using generalized Mie theory and subsequently validated through FEM and FDTD simulations, ensuring a consistent description of their electromagnetic and thermal behavior. To systematically map the space of variables, we defined a multi-objective figure of merit that integrates absorption efficiency, absorption cross section, and polymer-layer thickness. Furthermore, we define a thermal gain parameter that quantifies energy densification and complements the analysis of thermal directionality. Our results reveal a near-optimal configuration with parameters ($r_c$, $δ_{Au}$, $δ_p$, $θ$)=(36 nm, 5 nm, 40 nm, 70$°$), capable of producing a temperature rise of 20-23 $°$C, with 67% of the thermal fluz directed toward the upper hemispace and yielding 50% focusing enhancement relative to the symmetric case. This design preserves geometric simplicity and high symmetry while delivering robust thermal asymmetry, thereby facilitating experimental implementation. Beyond photothermal therapies, the proposed methodology constitutes a versatile platform for the rapid screening and optimization of layered nanostructures, adaptable to diverse materials, excitation wavelengths, and functional objectives in nanophotonics."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.app-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T14:21:52Z",
            "published_parsed": [
                2026,
                1,
                27,
                14,
                21,
                52,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Javier González-Colsa"
                },
                {
                    "name": "Fernando Bresme"
                },
                {
                    "name": "Pablo Albella"
                }
            ],
            "author_detail": {
                "name": "Pablo Albella"
            },
            "author": "Pablo Albella",
            "journal": "arXiv: Physics - Optics",
            "title_cn": "光热疗法背景下通过虹膜门控核双壳纳米粒子定制热传输的设计原理",
            "abstract_cn": "Janus 纳米结构的合理设计将高效的光吸收与受控的热传输相结合，对于推进等离子体光热疗法和相关应用至关重要。在这里，我们介绍了一个理论和计算框架来研究核双壳纳米颗粒及其不对称版本，即虹膜门控核双壳结构。首先使用广义米氏理论评估结构的光学响应，然后通过 FEM 和 FDTD 模拟进行验证，确保对其电磁和热行为的描述一致。为了系统地绘制变量空间，我们定义了一个多目标品质因数，其中集成了吸收效率、吸收截面和聚合物层厚度。此外，我们定义了一个热增益参数，该参数可量化能量致密化并补充热方向性的分析。我们的结果揭示了参数 ($r_c$, $δ_{Au}$, $δ_p$, $θ$)=(36 nm, 5 nm, 40 nm, 70$°$) 的近乎最佳配置，能够产生 20-23 $°$C 的温升，67% 的热通量指向上半空间，相对于对称情况产生 50% 的聚焦增强。该设计保留了几何简单性和高度对称性，同时提供强大的热不对称性，从而促进实验实施。除了光热疗法之外，所提出的方法还构成了一个多功能平台，用于快速筛选和优化层状纳米结构，适用于纳米光子学中的不同材料、激发波长和功能目标。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19669v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19669v1",
            "title": "Microring Resonator Dispersion Metrology with Neural Networks",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Microring Resonator Dispersion Metrology with Neural Networks"
            },
            "updated": "2026-01-27T14:49:08Z",
            "updated_parsed": [
                2026,
                1,
                27,
                14,
                49,
                8,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19669v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19669v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Precise knowledge of resonator dispersion, from both geometric and material contributions, is essential for reliable high-performance nonlinear integrated photonics devices, such as optical parametric oscillators, frequency doublers, and integrated optical frequency combs. However, direct measurements at the fabrication level provide limited knowledge, whether through destructive cross-section imaging or non-destructive ellipsometry, while complete optical characterization that enables precise dispersion metrology is time-consuming and poorly suited for mass-scale foundry fabrication. In this work, we develop a machine learning framework to solve three complementary problems: (i) predicting resonator geometric dimensions, (ii) identifying the correct material dispersion, and last, but not least, (iii) precisely reconstructing the integrated dispersion spectrum directly from ring dimensions. These three neural networks together enable both inverse and forward characterization of microring resonators. Using numerically generated datasets based on Sellmeier-type material models, we demonstrate <1 nm ring dimension prediction accuracy without noise, <8 nm prediction accuracy with ~45 dispersion samples under a realistic frequency measurement noise level (50 MHz), and ~16 nm prediction accuracy at a higher noise level (200 MHz). The Sellmeier model classification exceeds 99% accuracy in all cases. Importantly, dispersion sampled far from the pump resonances proves most informative, reducing full-spectrum characterization requirements. The forward-prediction network reconstructs dispersion spectra from the ring dimensions with high accuracy. Our results highlight the potential of machine learning applied to dispersion data as a rapid, non-destructive tool for wafer-scale quality control and process monitoring in photonic foundries.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Precise knowledge of resonator dispersion, from both geometric and material contributions, is essential for reliable high-performance nonlinear integrated photonics devices, such as optical parametric oscillators, frequency doublers, and integrated optical frequency combs. However, direct measurements at the fabrication level provide limited knowledge, whether through destructive cross-section imaging or non-destructive ellipsometry, while complete optical characterization that enables precise dispersion metrology is time-consuming and poorly suited for mass-scale foundry fabrication. In this work, we develop a machine learning framework to solve three complementary problems: (i) predicting resonator geometric dimensions, (ii) identifying the correct material dispersion, and last, but not least, (iii) precisely reconstructing the integrated dispersion spectrum directly from ring dimensions. These three neural networks together enable both inverse and forward characterization of microring resonators. Using numerically generated datasets based on Sellmeier-type material models, we demonstrate <1 nm ring dimension prediction accuracy without noise, <8 nm prediction accuracy with ~45 dispersion samples under a realistic frequency measurement noise level (50 MHz), and ~16 nm prediction accuracy at a higher noise level (200 MHz). The Sellmeier model classification exceeds 99% accuracy in all cases. Importantly, dispersion sampled far from the pump resonances proves most informative, reducing full-spectrum characterization requirements. The forward-prediction network reconstructs dispersion spectra from the ring dimensions with high accuracy. Our results highlight the potential of machine learning applied to dispersion data as a rapid, non-destructive tool for wafer-scale quality control and process monitoring in photonic foundries."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T14:49:08Z",
            "published_parsed": [
                2026,
                1,
                27,
                14,
                49,
                8,
                1,
                27,
                0
            ],
            "arxiv_comment": "16 pages, 11 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Ergun Simsek"
                },
                {
                    "name": "Shao-Chien Ou"
                },
                {
                    "name": "Gregory Moille"
                },
                {
                    "name": "Kartik Srinivasan"
                }
            ],
            "author_detail": {
                "name": "Kartik Srinivasan"
            },
            "author": "Kartik Srinivasan",
            "journal": "arXiv: Physics - Optics",
            "title_cn": "使用神经网络的微环谐振器色散计量",
            "abstract_cn": "从几何和材料方面准确了解谐振器色散对于可靠的高性能非线性集成光子器件（例如光学参量振荡器、倍频器和集成光学频率梳）至关重要。然而，无论是通过破坏性截面成像还是非破坏性椭圆测量，在制造层面的直接测量提供的知识有限，而实现精确色散计量的完整光学表征非常耗时，并且不太适合大规模铸造制造。在这项工作中，我们开发了一个机器学习框架来解决三个互补的问题：（i）预测谐振器几何尺寸，（ii）识别正确的材料色散，最后但并非最不重要的，（iii）直接从环尺寸精确重建积分色散谱。这三个神经网络共同实现了微环谐振器的逆向和正向表征。使用基于 Sellmeier 型材料模型的数值生成数据集，我们证明了在无噪声的情况下 <1 nm 环尺寸预测精度，在实际频率测量噪声水平 (50 MHz) 下约 45 个色散样本的预测精度 <8 nm，以及在较高噪声水平 (200 MHz) 下约 16 nm 的预测精度。 Sellmeier 模型分类在所有情况下的准确率均超过 99%。重要的是，远离泵浦共振采样的色散被证明最具信息性，降低了全谱表征要求。前向预测网络以高精度从环维度重建色散谱。我们的结果凸显了机器学习应用于色散数据的潜力，作为光子铸造厂晶圆级质量控制和工艺监控的快速、无损工具。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19676v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19676v1",
            "title": "Optical steering of a large ring laser",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Optical steering of a large ring laser"
            },
            "updated": "2026-01-27T14:56:35Z",
            "updated_parsed": [
                2026,
                1,
                27,
                14,
                56,
                35,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19676v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19676v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "A common approach to reduce the linewidth of a laser is an increase of its resonator length. In large gas lasers, however, the frequency spacing between longitudinal modes of the resonator easily becomes significantly smaller than the Doppler-broadened width of the gain profile. As a consequence, the laser might operate on a multitude of modes simultaneously, or jump between modes. Such unstable operation cannot be tolerated in metrological or sensing applications, such as ring laser gyroscopes. Here, we propose and demonstrate a method to establish stable operation on a chosen mode index by optically steering the ring laser to a desired mode index through injection locking with an external laser. The injected mode reliably follows the external steering. Intra-cavity backscattering can even cause the counter-propagating, non-injected mode to follow the external steering as well.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "A common approach to reduce the linewidth of a laser is an increase of its resonator length. In large gas lasers, however, the frequency spacing between longitudinal modes of the resonator easily becomes significantly smaller than the Doppler-broadened width of the gain profile. As a consequence, the laser might operate on a multitude of modes simultaneously, or jump between modes. Such unstable operation cannot be tolerated in metrological or sensing applications, such as ring laser gyroscopes. Here, we propose and demonstrate a method to establish stable operation on a chosen mode index by optically steering the ring laser to a desired mode index through injection locking with an external laser. The injected mode reliably follows the external steering. Intra-cavity backscattering can even cause the counter-propagating, non-injected mode to follow the external steering as well."
            },
            "tags": [
                {
                    "term": "physics.optics",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T14:56:35Z",
            "published_parsed": [
                2026,
                1,
                27,
                14,
                56,
                35,
                1,
                27,
                0
            ],
            "arxiv_comment": "5 pages, 3 figures",
            "arxiv_primary_category": {
                "term": "physics.optics"
            },
            "authors": [
                {
                    "name": "Jannik Zenner"
                },
                {
                    "name": "Karl Ulrich Schreiber"
                },
                {
                    "name": "Simon Stellmer"
                }
            ],
            "author_detail": {
                "name": "Simon Stellmer"
            },
            "author": "Simon Stellmer",
            "journal": "arXiv: Physics - Optics",
            "title_cn": "大环形激光器的光控",
            "abstract_cn": "减少激光器线宽的常见方法是增加其谐振器长度。然而，在大型气体激光器中，谐振器纵向模式之间的频率间隔很容易变得明显小于增益分布的多普勒展宽宽度。因此，激光器可能会同时在多种模式下运行，或者在模式之间跳跃。这种不稳定的操作在计量或传感应用中是不能容忍的，例如环形激光陀螺仪。在这里，我们提出并演示了一种方法，通过使用外部激光器注入锁定，以光学方式将环形激光器转向所需的模式指数，从而在选定的模式指数上建立稳定的操作。注入模式可靠地遵循外部转向。腔内反向散射甚至可以导致反向传播的非注入模式也跟随外部转向。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18932v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18932v1",
            "title": "Advances in Diffusion-Based Generative Compression",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Advances in Diffusion-Based Generative Compression"
            },
            "updated": "2026-01-26T20:10:29Z",
            "updated_parsed": [
                2026,
                1,
                26,
                20,
                10,
                29,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18932v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18932v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Popularized by their strong image generation performance, diffusion and related methods for generative modeling have found widespread success in visual media applications. In particular, diffusion methods have enabled new approaches to data compression, where realistic reconstructions can be generated at extremely low bit-rates. This article provides a unifying review of recent diffusion-based methods for generative lossy compression, with a focus on image compression. These methods generally encode the source into an embedding and employ a diffusion model to iteratively refine it in the decoding procedure, such that the final reconstruction approximately follows the ground truth data distribution. The embedding can take various forms and is typically transmitted via an auxiliary entropy model, and recent methods also explore the use of diffusion models themselves for information transmission via channel simulation. We review representative approaches through the lens of rate-distortion-perception theory, highlighting the role of common randomness and connections to inverse problems, and identify open challenges.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Popularized by their strong image generation performance, diffusion and related methods for generative modeling have found widespread success in visual media applications. In particular, diffusion methods have enabled new approaches to data compression, where realistic reconstructions can be generated at extremely low bit-rates. This article provides a unifying review of recent diffusion-based methods for generative lossy compression, with a focus on image compression. These methods generally encode the source into an embedding and employ a diffusion model to iteratively refine it in the decoding procedure, such that the final reconstruction approximately follows the ground truth data distribution. The embedding can take various forms and is typically transmitted via an auxiliary entropy model, and recent methods also explore the use of diffusion models themselves for information transmission via channel simulation. We review representative approaches through the lens of rate-distortion-perception theory, highlighting the role of common randomness and connections to inverse problems, and identify open challenges."
            },
            "tags": [
                {
                    "term": "eess.IV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.IT",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.LG",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "stat.ML",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T20:10:29Z",
            "published_parsed": [
                2026,
                1,
                26,
                20,
                10,
                29,
                0,
                26,
                0
            ],
            "arxiv_comment": "Preprint",
            "arxiv_primary_category": {
                "term": "eess.IV"
            },
            "authors": [
                {
                    "name": "Yibo Yang"
                },
                {
                    "name": "Stephan Mandt"
                }
            ],
            "author_detail": {
                "name": "Stephan Mandt"
            },
            "author": "Stephan Mandt",
            "journal": "arXiv: Computational Imaging",
            "title_cn": "基于扩散的生成压缩的进展",
            "abstract_cn": "扩散和生成建模的相关方法因其强大的图像生成性能而受到欢迎，在视觉媒体应用中取得了广泛的成功。特别是，扩散方法启用了新的数据压缩方法，可以以极低的比特率生成真实的重建。本文对最近基于扩散的生成有损压缩方法进行了统一回顾，重点关注图像压缩。这些方法通常将源编码为嵌入，并采用扩散模型在解码过程中迭代地细化它，使得最终的重建大致遵循地面实况数据分布。嵌入可以采取多种形式，通常通过辅助熵模型传输，最近的方法还探索使用扩散模型本身通过信道模拟进行信息传输。我们通过率失真感知理论的视角回顾了代表性方法，强调了常见随机性的作用以及与逆问题的联系，并确定了开放的挑战。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19117v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19117v1",
            "title": "Optimized $k$-means color quantization of digital images in machine-based and human perception-based colorspaces",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Optimized $k$-means color quantization of digital images in machine-based and human perception-based colorspaces"
            },
            "updated": "2026-01-27T02:42:11Z",
            "updated_parsed": [
                2026,
                1,
                27,
                2,
                42,
                11,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19117v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19117v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Color quantization represents an image using a fraction of its original number of colors while only minimally losing its visual quality. The $k$-means algorithm is commonly used in this context, but has mostly been applied in the machine-based RGB colorspace composed of the three primary colors. However, some recent studies have indicated its improved performance in human perception-based colorspaces. We investigated the performance of $k$-means color quantization at four quantization levels in the RGB, CIE-XYZ, and CIE-LUV/CIE-HCL colorspaces, on 148 varied digital images spanning a wide range of scenes, subjects and settings. The Visual Information Fidelity (VIF) measure numerically assessed the quality of the quantized images, and showed that in about half of the cases, $k$-means color quantization is best in the RGB space, while at other times, and especially for higher quantization levels ($k$), the CIE-XYZ colorspace is where it usually does better. There are also some cases, especially at lower $k$, where the best performance is obtained in the CIE-LUV colorspace. Further analysis of the performances in terms of the distributions of the hue, chromaticity and luminance in an image presents a nuanced perspective and characterization of the images for which each colorspace is better for $k$-means color quantization.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Color quantization represents an image using a fraction of its original number of colors while only minimally losing its visual quality. The $k$-means algorithm is commonly used in this context, but has mostly been applied in the machine-based RGB colorspace composed of the three primary colors. However, some recent studies have indicated its improved performance in human perception-based colorspaces. We investigated the performance of $k$-means color quantization at four quantization levels in the RGB, CIE-XYZ, and CIE-LUV/CIE-HCL colorspaces, on 148 varied digital images spanning a wide range of scenes, subjects and settings. The Visual Information Fidelity (VIF) measure numerically assessed the quality of the quantized images, and showed that in about half of the cases, $k$-means color quantization is best in the RGB space, while at other times, and especially for higher quantization levels ($k$), the CIE-XYZ colorspace is where it usually does better. There are also some cases, especially at lower $k$, where the best performance is obtained in the CIE-LUV colorspace. Further analysis of the performances in terms of the distributions of the hue, chromaticity and luminance in an image presents a nuanced perspective and characterization of the images for which each colorspace is better for $k$-means color quantization."
            },
            "tags": [
                {
                    "term": "eess.IV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "stat.AP",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T02:42:11Z",
            "published_parsed": [
                2026,
                1,
                27,
                2,
                42,
                11,
                1,
                27,
                0
            ],
            "arxiv_comment": "25 pages, 11 figures, 5 tables, accepted in the Journal of Electronic Imaging",
            "arxiv_primary_category": {
                "term": "eess.IV"
            },
            "authors": [
                {
                    "name": "Ranjan Maitra"
                }
            ],
            "author_detail": {
                "name": "Ranjan Maitra"
            },
            "author": "Ranjan Maitra",
            "journal": "arXiv: Computational Imaging",
            "title_cn": "优化的 $k$ - 意味着基于机器和基于人类感知的色彩空间中数字图像的色彩量化",
            "abstract_cn": "颜色量化使用原始颜色数量的一小部分来表示图像，同时仅最小程度地损失其视觉质量。 $k$-means 算法通常在这种情况下使用，但主要应用于由三基色组成的基于机器的 RGB 色彩空间。然而，最近的一些研究表明它在基于人类感知的色彩空间中的性能得到了改善。我们研究了 RGB、CIE-XYZ 和 CIE-LUV/CIE-HCL 颜色空间中四个量化级别的 $k$-means 颜色量化在涵盖各种场景、主题和设置的 148 张不同数字图像上的性能。视觉信息保真度 (VIF) 测量以数字方式评估量化图像的质量，结果表明，在大约一半的情况下，$k$ 表示颜色量化在 RGB 空间中效果最佳，而在其他时候，尤其是对于更高的量化级别 ($k$)，CIE-XYZ 颜色空间通常表现更好。还有一些情况，特别是在较低的 $k$ 下，在 CIE-LUV 色彩空间中获得最佳性能。对图像中色调、色度和亮度分布的性能进行进一步分析，呈现出图像的细致入微的视角和特征，其中每个颜色空间更适合 $k$ 均值颜色量化。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19169v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19169v1",
            "title": "Recover Cell Tensor: Diffusion-Equivalent Tensor Completion for Fluorescence Microscopy Imaging",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Recover Cell Tensor: Diffusion-Equivalent Tensor Completion for Fluorescence Microscopy Imaging"
            },
            "updated": "2026-01-27T04:00:39Z",
            "updated_parsed": [
                2026,
                1,
                27,
                4,
                0,
                39,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19169v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19169v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Fluorescence microscopy (FM) imaging is a fundamental technique for observing live cell division, one of the most essential processes in the cycle of life and death. Observing 3D live cells requires scanning through the cell volume while minimizing lethal phototoxicity. That limits acquisition time and results in sparsely sampled volumes with anisotropic resolution and high noise. Existing image restoration methods, primarily based on inverse problem modeling, assume known and stable degradation processes and struggle under such conditions, especially in the absence of high-quality reference volumes. In this paper, from a new perspective, we propose a novel tensor completion framework tailored to the nature of FM imaging, which inherently involves nonlinear signal degradation and incomplete observations. Specifically, FM imaging with equidistant Z-axis sampling is essentially a tensor completion task under a uniformly random sampling condition. On one hand, we derive the theoretical lower bound for exact cell tensor completion, validating the feasibility of accurately recovering 3D cell tensor. On the other hand, we reformulate the tensor completion problem as a mathematically equivalent score-based generative model. By incorporating structural consistency priors, the generative trajectory is effectively guided toward denoised and geometrically coherent reconstructions. Our method demonstrates state-of-the-art performance on SR-CACO-2 and three real \\textit{in vivo} cellular datasets, showing substantial improvements in both signal-to-noise ratio and structural fidelity.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Fluorescence microscopy (FM) imaging is a fundamental technique for observing live cell division, one of the most essential processes in the cycle of life and death. Observing 3D live cells requires scanning through the cell volume while minimizing lethal phototoxicity. That limits acquisition time and results in sparsely sampled volumes with anisotropic resolution and high noise. Existing image restoration methods, primarily based on inverse problem modeling, assume known and stable degradation processes and struggle under such conditions, especially in the absence of high-quality reference volumes. In this paper, from a new perspective, we propose a novel tensor completion framework tailored to the nature of FM imaging, which inherently involves nonlinear signal degradation and incomplete observations. Specifically, FM imaging with equidistant Z-axis sampling is essentially a tensor completion task under a uniformly random sampling condition. On one hand, we derive the theoretical lower bound for exact cell tensor completion, validating the feasibility of accurately recovering 3D cell tensor. On the other hand, we reformulate the tensor completion problem as a mathematically equivalent score-based generative model. By incorporating structural consistency priors, the generative trajectory is effectively guided toward denoised and geometrically coherent reconstructions. Our method demonstrates state-of-the-art performance on SR-CACO-2 and three real \\textit{in vivo} cellular datasets, showing substantial improvements in both signal-to-noise ratio and structural fidelity."
            },
            "tags": [
                {
                    "term": "eess.IV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "eess.SP",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T04:00:39Z",
            "published_parsed": [
                2026,
                1,
                27,
                4,
                0,
                39,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "eess.IV"
            },
            "authors": [
                {
                    "name": "Chenwei Wang"
                },
                {
                    "name": "Zhaoke Huang"
                },
                {
                    "name": "Zelin Li"
                },
                {
                    "name": "Wenqi Zhu"
                }
            ],
            "author_detail": {
                "name": "Wenqi Zhu"
            },
            "author": "Wenqi Zhu",
            "journal": "arXiv: Computational Imaging",
            "title_cn": "恢复细胞张量：荧光显微镜成像的扩散等效张量完成",
            "abstract_cn": "荧光显微镜 (FM) 成像是观察活细胞分裂的基本技术，活细胞分裂是生命和死亡周期中最重要的过程之一。观察 3D 活细胞需要扫描细胞体积，同时最大限度地减少致命的光毒性。这限制了采集时间，并导致稀疏采样体积，具有各向异性分辨率和高噪声。现有的图像恢复方法主要基于逆问题建模，假设已知且稳定的退化过程，并且在这种条件下陷入困境，特别是在缺乏高质量参考体积的情况下。在本文中，我们从一个新的角度提出了一种针对调频成像本质的新颖的张量完成框架，该框架本质上涉及非线性信号衰减和不完整的观测。具体来说，Z轴等距采样的FM成像本质上是均匀随机采样条件下的张量补全任务。一方面，我们推导了精确细胞张量完成的理论下界，验证了精确恢复 3D 细胞张量的可行性。另一方面，我们将张量完成问题重新表述为数学上等效的基于分数的生成模型。通过结合结构一致性先验，生成轨迹可以有效地引导去噪和几何相干重建。我们的方法在 SR-CACO-2 和三个真实的 \\textit{in vivo} 细胞数据集上展示了最先进的性能，显示出信噪比和结构保真度的显着改善。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19246v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19246v1",
            "title": "Magnetic Resonance Simulation of Effective Transverse Relaxation (T2*)",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Magnetic Resonance Simulation of Effective Transverse Relaxation (T2*)"
            },
            "updated": "2026-01-27T06:28:52Z",
            "updated_parsed": [
                2026,
                1,
                27,
                6,
                28,
                52,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19246v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19246v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Purpose: To simulate effective transverse relaxation ($T_2^*$) as a part of MR simulation. $T_2^*$ consists of reversible ($T_2^{\\prime}$) and irreversible ($T_2$) components. Whereas simulations of $T_2$ are easy, $T_2^{\\prime}$ is not easily simulated if only magnetizations of individual isochromats are simulated.\n  Theory and Methods: Efficient methods for simulating $T_2^{\\prime}$ were proposed. To approximate the Lorentzian function of $T_2^{\\prime}$ realistically, conventional simulators require 100+ isochromats. This approximation can be avoided by utilizing a linear phase model for simulating an entire Lorentzian function directly. To represent the linear phase model, the partial derivatives of the magnetizations with respect to the frequency axis were also simulated. To accelerate the simulations with these partial derivatives, the proposed methods introduced two techniques: analytic solutions, and combined transitions. For understanding the fundamental mechanism of the proposed method, a simple one-isochromat simulation was performed. For evaluating realistic cases, several pulse sequences were simulated using two phantoms with and without $T_2^{\\prime}$ simulations.\n  Results: The one-isochromat simulation demonstrated that $T_2^{\\prime}$ simulations were possible. In the realistic cases, $T_2^{\\prime}$ was recovered as expected without using 100+ isochromats for each point. The computational times with $T_2^{\\prime}$ simulations were only 2.0 to 2.7 times longer than those without $T_2^{\\prime}$ simulations. When the above-mentioned two techniques were utilized, the analytic solutions accelerated 19 times, and the combined transitions accelerated up to 17 times.\n  Conclusion: Both theory and results showed that the proposed methods simulated $T_2^{\\prime}$ efficiently by utilizing a linear model with a Lorentzian function, analytic solutions, and combined transitions.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Purpose: To simulate effective transverse relaxation ($T_2^*$) as a part of MR simulation. $T_2^*$ consists of reversible ($T_2^{\\prime}$) and irreversible ($T_2$) components. Whereas simulations of $T_2$ are easy, $T_2^{\\prime}$ is not easily simulated if only magnetizations of individual isochromats are simulated.\n  Theory and Methods: Efficient methods for simulating $T_2^{\\prime}$ were proposed. To approximate the Lorentzian function of $T_2^{\\prime}$ realistically, conventional simulators require 100+ isochromats. This approximation can be avoided by utilizing a linear phase model for simulating an entire Lorentzian function directly. To represent the linear phase model, the partial derivatives of the magnetizations with respect to the frequency axis were also simulated. To accelerate the simulations with these partial derivatives, the proposed methods introduced two techniques: analytic solutions, and combined transitions. For understanding the fundamental mechanism of the proposed method, a simple one-isochromat simulation was performed. For evaluating realistic cases, several pulse sequences were simulated using two phantoms with and without $T_2^{\\prime}$ simulations.\n  Results: The one-isochromat simulation demonstrated that $T_2^{\\prime}$ simulations were possible. In the realistic cases, $T_2^{\\prime}$ was recovered as expected without using 100+ isochromats for each point. The computational times with $T_2^{\\prime}$ simulations were only 2.0 to 2.7 times longer than those without $T_2^{\\prime}$ simulations. When the above-mentioned two techniques were utilized, the analytic solutions accelerated 19 times, and the combined transitions accelerated up to 17 times.\n  Conclusion: Both theory and results showed that the proposed methods simulated $T_2^{\\prime}$ efficiently by utilizing a linear model with a Lorentzian function, analytic solutions, and combined transitions."
            },
            "tags": [
                {
                    "term": "eess.IV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "physics.med-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T06:28:52Z",
            "published_parsed": [
                2026,
                1,
                27,
                6,
                28,
                52,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "eess.IV"
            },
            "authors": [
                {
                    "name": "Hidenori Takeshima"
                }
            ],
            "author_detail": {
                "name": "Hidenori Takeshima"
            },
            "author": "Hidenori Takeshima",
            "journal": "arXiv: Computational Imaging",
            "title_cn": "有效横向弛豫 (T2*) 的磁共振模拟",
            "abstract_cn": "目的：模拟有效横向弛豫 ($T_2^*$)，作为 MR 模拟的一部分。 $T_2^*$ 由可逆 ($T_2^{\\prime}$) 和不可逆 ($T_2$) 组成。尽管 $T_2$ 的模拟很容易，但如果仅模拟单个等色体的磁化强度，则不容易模拟 $T_2^{\\prime}$ 。\n  理论与方法：提出了模拟$T_2^{\\prime}$的有效方法。为了真实地近似 $T_2^{\\prime}$ 的洛伦兹函数，传统模拟器需要 100 多个等色镜。通过利用线性相位模型直接模拟整个洛伦兹函数可以避免这种近似。为了表示线性相位模型，还模拟了磁化强度相对于频率轴的偏导数。为了加速这些偏导数的模拟，所提出的方法引入了两种技术：解析解和组合转换。为了理解该方法的基本机制，进行了简单的单等色镜模拟。为了评估实际情况，使用带有和不带有 $T_2^{\\prime}$ 模拟的两个模型来模拟多个脉冲序列。\n  结果：单等色镜模拟证明 $T_2^{\\prime}$ 模拟是可能的。在实际情况下，$T_2^{\\prime}$ 按预期恢复，无需为每个点使用 100 多个等色图。使用 $T_2^{\\prime}$ 模拟的计算时间仅比不使用 $T_2^{\\prime}$ 模拟的计算时间长 2.0 到 2.7 倍。当使用上述两种技术时，解析解加速了 19 倍，组合转换加速了 17 倍。\n  结论：理论和结果都表明，所提出的方法通过利用具有洛伦兹函数、解析解和组合转换的线性模型有效地模拟了 $T_2^{\\prime}$。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19293v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19293v1",
            "title": "Reinforced Rate Control for Neural Video Compression via Inter-Frame Rate-Distortion Awareness",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Reinforced Rate Control for Neural Video Compression via Inter-Frame Rate-Distortion Awareness"
            },
            "updated": "2026-01-27T07:30:37Z",
            "updated_parsed": [
                2026,
                1,
                27,
                7,
                30,
                37,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19293v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19293v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Neural video compression (NVC) has demonstrated superior compression efficiency, yet effective rate control remains a significant challenge due to complex temporal dependencies. Existing rate control schemes typically leverage frame content to capture distortion interactions, overlooking inter-frame rate dependencies arising from shifts in per-frame coding parameters. This often leads to suboptimal bitrate allocation and cascading parameter decisions. To address this, we propose a reinforcement-learning (RL)-based rate control framework that formulates the task as a frame-by-frame sequential decision process. At each frame, an RL agent observes a spatiotemporal state and selects coding parameters to optimize a long-term reward that reflects rate-distortion (R-D) performance and bitrate adherence. Unlike prior methods, our approach jointly determines bitrate allocation and coding parameters in a single step, independent of group of pictures (GOP) structure. Extensive experiments across diverse NVC architectures show that our method reduces the average relative bitrate error to 1.20% and achieves up to 13.45% bitrate savings at typical GOP sizes, outperforming existing approaches. In addition, our framework demonstrates improved robustness to content variation and bandwidth fluctuations with lower coding overhead, making it highly suitable for practical deployment.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Neural video compression (NVC) has demonstrated superior compression efficiency, yet effective rate control remains a significant challenge due to complex temporal dependencies. Existing rate control schemes typically leverage frame content to capture distortion interactions, overlooking inter-frame rate dependencies arising from shifts in per-frame coding parameters. This often leads to suboptimal bitrate allocation and cascading parameter decisions. To address this, we propose a reinforcement-learning (RL)-based rate control framework that formulates the task as a frame-by-frame sequential decision process. At each frame, an RL agent observes a spatiotemporal state and selects coding parameters to optimize a long-term reward that reflects rate-distortion (R-D) performance and bitrate adherence. Unlike prior methods, our approach jointly determines bitrate allocation and coding parameters in a single step, independent of group of pictures (GOP) structure. Extensive experiments across diverse NVC architectures show that our method reduces the average relative bitrate error to 1.20% and achieves up to 13.45% bitrate savings at typical GOP sizes, outperforming existing approaches. In addition, our framework demonstrates improved robustness to content variation and bandwidth fluctuations with lower coding overhead, making it highly suitable for practical deployment."
            },
            "tags": [
                {
                    "term": "eess.IV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T07:30:37Z",
            "published_parsed": [
                2026,
                1,
                27,
                7,
                30,
                37,
                1,
                27,
                0
            ],
            "arxiv_comment": "Accepted by AAAI 2026",
            "arxiv_primary_category": {
                "term": "eess.IV"
            },
            "authors": [
                {
                    "name": "Wuyang Cong"
                },
                {
                    "name": "Junqi Shi"
                },
                {
                    "name": "Lizhong Wang"
                },
                {
                    "name": "Weijing Shi"
                },
                {
                    "name": "Ming Lu"
                },
                {
                    "name": "Hao Chen"
                },
                {
                    "name": "Zhan Ma"
                }
            ],
            "author_detail": {
                "name": "Zhan Ma"
            },
            "author": "Zhan Ma",
            "journal": "arXiv: Computational Imaging",
            "title_cn": "通过帧间速率失真感知增强神经视频压缩的速率控制",
            "abstract_cn": "神经视频压缩 (NVC) 已展现出卓越的压缩效率，但由于复杂的时间依赖性，有效的速率控制仍然是一个重大挑战。现有的速率控制方案通常利用帧内容来捕获失真交互，而忽略了因每帧编码参数的变化而产生的帧间速率依赖性。这通常会导致比特率分配和级联参数决策不理想。为了解决这个问题，我们提出了一种基于强化学习（RL）的速率控制框架，该框架将任务制定为逐帧顺序决策过程。在每一帧中，强化学习代理都会观察时空状态并选择编码参数来优化反映率失真 (R-D) 性能和比特率遵守情况的长期奖励。与之前的方法不同，我们的方法在一个步骤中联合确定比特率分配和编码参数，独立于图像组（GOP）结构。跨不同 NVC 架构的大量实验表明，我们的方法将平均相对比特率误差降低至 1.20%，并在典型 GOP 大小下实现高达 13.45% 的比特率节省，优于现有方法。此外，我们的框架表现出对内容变化和带宽波动的鲁棒性提高，编码开销更低，使其非常适合实际部署。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19349v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19349v1",
            "title": "AMGFormer: Adaptive Multi-Granular Transformer for Brain Tumor Segmentation with Missing Modalities",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "AMGFormer: Adaptive Multi-Granular Transformer for Brain Tumor Segmentation with Missing Modalities"
            },
            "updated": "2026-01-27T08:29:02Z",
            "updated_parsed": [
                2026,
                1,
                27,
                8,
                29,
                2,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19349v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19349v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Multimodal MRI is essential for brain tumor segmentation, yet missing modalities in clinical practice cause existing methods to exhibit >40% performance variance across modality combinations, rendering them clinically unreliable. We propose AMGFormer, achieving significantly improved stability through three synergistic modules: (1) QuadIntegrator Bridge (QIB) enabling spatially adaptive fusion maintaining consistent predictions regardless of available modalities, (2) Multi-Granular Attention Orchestrator (MGAO) focusing on pathological regions to reduce background sensitivity, and (3) Modality Quality-Aware Enhancement (MQAE) preventing error propagation from corrupted sequences. On BraTS 2018, our method achieves 89.33% WT, 82.70% TC, 67.23% ET Dice scores with <0.5% variance across 15 modality combinations, solving the stability crisis. Single-modality ET segmentation shows 40-81% relative improvements over state-of-the-art methods. The method generalizes to BraTS 2020/2021, achieving up to 92.44% WT, 89.91% TC, 84.57% ET. The model demonstrates potential for clinical deployment with 1.2s inference. Code: https://github.com/guochengxiangives/AMGFormer.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Multimodal MRI is essential for brain tumor segmentation, yet missing modalities in clinical practice cause existing methods to exhibit >40% performance variance across modality combinations, rendering them clinically unreliable. We propose AMGFormer, achieving significantly improved stability through three synergistic modules: (1) QuadIntegrator Bridge (QIB) enabling spatially adaptive fusion maintaining consistent predictions regardless of available modalities, (2) Multi-Granular Attention Orchestrator (MGAO) focusing on pathological regions to reduce background sensitivity, and (3) Modality Quality-Aware Enhancement (MQAE) preventing error propagation from corrupted sequences. On BraTS 2018, our method achieves 89.33% WT, 82.70% TC, 67.23% ET Dice scores with <0.5% variance across 15 modality combinations, solving the stability crisis. Single-modality ET segmentation shows 40-81% relative improvements over state-of-the-art methods. The method generalizes to BraTS 2020/2021, achieving up to 92.44% WT, 89.91% TC, 84.57% ET. The model demonstrates potential for clinical deployment with 1.2s inference. Code: https://github.com/guochengxiangives/AMGFormer."
            },
            "tags": [
                {
                    "term": "eess.IV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T08:29:02Z",
            "published_parsed": [
                2026,
                1,
                27,
                8,
                29,
                2,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "eess.IV"
            },
            "authors": [
                {
                    "name": "Chengxiang Guo"
                },
                {
                    "name": "Jian Wang"
                },
                {
                    "name": "Junhua Fei"
                },
                {
                    "name": "Xiao Li"
                },
                {
                    "name": "Chunling Chen"
                },
                {
                    "name": "Yun Jin"
                }
            ],
            "author_detail": {
                "name": "Yun Jin"
            },
            "author": "Yun Jin",
            "journal": "arXiv: Computational Imaging",
            "title_cn": "AMGFormer：用于缺失模态的脑肿瘤分割的自适应多粒度 Transformer",
            "abstract_cn": "多模态 MRI 对于脑肿瘤分割至关重要，但临床实践中缺少模态导致现有方法在模态组合之间表现出 > 40% 的性能差异，从而导致它们在临床上不可靠。我们提出 AMGFormer，通过三个协同模块显着提高稳定性：（1）QuadIntegrator Bridge（QIB）实现空间自适应融合，无论可用模态如何都保持一致的预测，（2）多粒度注意力协调器（MGAO）专注于病理区域以降低背景敏感性，以及（3）模态质量感知增强（MQAE）防止损坏序列的错误传播。在 BraTS 2018 上，我们的方法在 15 种模态组合中实现了 89.33% WT、82.70% TC、67.23% ET Dice 分数，方差 <0.5%，解决了稳定性危机。单模态 ET 分割比最先进的方法有 40-81% 的相对改进。该方法推广到 BraTS 2020/2021，实现高达 92.44% WT、89.91% TC、84.57% ET。该模型展示了 1.2 秒推理的临床部署潜力。代码：https://github.com/guo Chengxiangives/AMGFormer。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19461v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19461v1",
            "title": "Towards Gold-Standard Depth Estimation for Tree Branches in UAV Forestry: Benchmarking Deep Stereo Matching Methods",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Towards Gold-Standard Depth Estimation for Tree Branches in UAV Forestry: Benchmarking Deep Stereo Matching Methods"
            },
            "updated": "2026-01-27T10:45:29Z",
            "updated_parsed": [
                2026,
                1,
                27,
                10,
                45,
                29,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19461v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19461v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Autonomous UAV forestry operations require robust depth estimation with strong cross-domain generalization, yet existing evaluations focus on urban and indoor scenarios, leaving a critical gap for vegetation-dense environments. We present the first systematic zero-shot evaluation of eight stereo methods spanning iterative refinement, foundation model, diffusion-based, and 3D CNN paradigms. All methods use officially released pretrained weights (trained on Scene Flow) and are evaluated on four standard benchmarks (ETH3D, KITTI 2012/2015, Middlebury) plus a novel 5,313-pair Canterbury Tree Branches dataset ($1920 \\times 1080$). Results reveal scene-dependent patterns: foundation models excel on structured scenes (BridgeDepth: 0.23 px on ETH3D; DEFOM: 4.65 px on Middlebury), while iterative methods show variable cross-benchmark performance (IGEV++: 0.36 px on ETH3D but 6.77 px on Middlebury; IGEV: 0.33 px on ETH3D but 4.99 px on Middlebury). Qualitative evaluation on the Tree Branches dataset establishes DEFOM as the gold-standard baseline for vegetation depth estimation, with superior cross-domain consistency (consistently ranking 1st-2nd across benchmarks, average rank 1.75). DEFOM predictions will serve as pseudo-ground-truth for future benchmarking.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Autonomous UAV forestry operations require robust depth estimation with strong cross-domain generalization, yet existing evaluations focus on urban and indoor scenarios, leaving a critical gap for vegetation-dense environments. We present the first systematic zero-shot evaluation of eight stereo methods spanning iterative refinement, foundation model, diffusion-based, and 3D CNN paradigms. All methods use officially released pretrained weights (trained on Scene Flow) and are evaluated on four standard benchmarks (ETH3D, KITTI 2012/2015, Middlebury) plus a novel 5,313-pair Canterbury Tree Branches dataset ($1920 \\times 1080$). Results reveal scene-dependent patterns: foundation models excel on structured scenes (BridgeDepth: 0.23 px on ETH3D; DEFOM: 4.65 px on Middlebury), while iterative methods show variable cross-benchmark performance (IGEV++: 0.36 px on ETH3D but 6.77 px on Middlebury; IGEV: 0.33 px on ETH3D but 4.99 px on Middlebury). Qualitative evaluation on the Tree Branches dataset establishes DEFOM as the gold-standard baseline for vegetation depth estimation, with superior cross-domain consistency (consistently ranking 1st-2nd across benchmarks, average rank 1.75). DEFOM predictions will serve as pseudo-ground-truth for future benchmarking."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.RO",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "eess.IV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T10:45:29Z",
            "published_parsed": [
                2026,
                1,
                27,
                10,
                45,
                29,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Yida Lin"
                },
                {
                    "name": "Bing Xue"
                },
                {
                    "name": "Mengjie Zhang"
                },
                {
                    "name": "Sam Schofield"
                },
                {
                    "name": "Richard Green"
                }
            ],
            "author_detail": {
                "name": "Richard Green"
            },
            "author": "Richard Green",
            "journal": "arXiv: Computational Imaging",
            "title_cn": "迈向无人机林业中树枝深度估计的黄金标准：深度立体匹配方法基准测试",
            "abstract_cn": "自主无人机林业作业需要强大的深度估计和强大的跨域泛化能力，但现有的评估侧重于城市和室内场景，为植被密集的环境留下了关键的空白。我们首次对八种立体方法进行系统性零样本评估，涵盖迭代细化、基础模型、基于扩散和 3D CNN 范式。所有方法均使用官方发布的预训练权重（在 Scene Flow 上训练），并根据四个标准基准（ETH3D、KITTI 2012/2015、Middlebury）以及新颖的 5,313 对坎特伯雷树枝数据集（1920 美元×1080 美元）进行评估。结果揭示了场景相关模式：基础模型在结构化场景上表现出色（BridgeDepth：在 ETH3D 上为 0.23 px；DEFOM：在 Middlebury 上为 4.65 px），而迭代方法则显示出可变的跨基准性能（IGEV++：在 ETH3D 上为 0.36 px，但在 Middlebury 上为 6.77 px；IGEV：在 ETH3D 上为 0.33 px，但在 Middlebury 上为 4.99 px米德尔伯里）。对 Tree Branches 数据集的定性评估将 DEFOM 确立为植被深度估计的黄金标准基线，具有卓越的跨域一致性（在基准中始终排名第一至第二，平均排名 1.75）。 DEFOM 预测将作为未来基准测试的伪地面事实。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18045v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18045v1",
            "title": "Leveraging Persistence Image to Enhance Robustness and Performance in Curvilinear Structure Segmentation",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Leveraging Persistence Image to Enhance Robustness and Performance in Curvilinear Structure Segmentation"
            },
            "updated": "2026-01-25T23:51:45Z",
            "updated_parsed": [
                2026,
                1,
                25,
                23,
                51,
                45,
                6,
                25,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18045v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18045v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Segmenting curvilinear structures in medical images is essential for analyzing morphological patterns in clinical applications. Integrating topological properties, such as connectivity, improves segmentation accuracy and consistency. However, extracting and embedding such properties - especially from Persistence Diagrams (PD) - is challenging due to their non-differentiability and computational cost. Existing approaches mostly encode topology through handcrafted loss functions, which generalize poorly across tasks. In this paper, we propose PIs-Regressor, a simple yet effective module that learns persistence image (PI) - finite, differentiable representations of topological features - directly from data. Together with Topology SegNet, which fuses these features in both downsampling and upsampling stages, our framework integrates topology into the network architecture itself rather than auxiliary losses. Unlike existing methods that depend heavily on handcrafted loss functions, our approach directly incorporates topological information into the network structure, leading to more robust segmentation. Our design is flexible and can be seamlessly combined with other topology-based methods to further enhance segmentation performance. Experimental results show that integrating topological features enhances model robustness, effectively handling challenges like overexposure and blurring in medical imaging. Our approach on three curvilinear benchmarks demonstrate state-of-the-art performance in both pixel-level accuracy and topological fidelity.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Segmenting curvilinear structures in medical images is essential for analyzing morphological patterns in clinical applications. Integrating topological properties, such as connectivity, improves segmentation accuracy and consistency. However, extracting and embedding such properties - especially from Persistence Diagrams (PD) - is challenging due to their non-differentiability and computational cost. Existing approaches mostly encode topology through handcrafted loss functions, which generalize poorly across tasks. In this paper, we propose PIs-Regressor, a simple yet effective module that learns persistence image (PI) - finite, differentiable representations of topological features - directly from data. Together with Topology SegNet, which fuses these features in both downsampling and upsampling stages, our framework integrates topology into the network architecture itself rather than auxiliary losses. Unlike existing methods that depend heavily on handcrafted loss functions, our approach directly incorporates topological information into the network structure, leading to more robust segmentation. Our design is flexible and can be seamlessly combined with other topology-based methods to further enhance segmentation performance. Experimental results show that integrating topological features enhances model robustness, effectively handling challenges like overexposure and blurring in medical imaging. Our approach on three curvilinear benchmarks demonstrate state-of-the-art performance in both pixel-level accuracy and topological fidelity."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-25T23:51:45Z",
            "published_parsed": [
                2026,
                1,
                25,
                23,
                51,
                45,
                6,
                25,
                0
            ],
            "arxiv_comment": "Accepted by IEEE International Symposium on Biomedical Imaging (ISBI) 2026. 5 pages, 3 figures",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Zhuangzhi Gao"
                },
                {
                    "name": "Feixiang Zhou"
                },
                {
                    "name": "He Zhao"
                },
                {
                    "name": "Xiuju Chen"
                },
                {
                    "name": "Xiaoxin Li"
                },
                {
                    "name": "Qinkai Yu"
                },
                {
                    "name": "Yitian Zhao"
                },
                {
                    "name": "Alena Shantsila"
                },
                {
                    "name": "Gregory Y. H. Lip"
                },
                {
                    "name": "Eduard Shantsila"
                },
                {
                    "name": "Yalin Zheng"
                }
            ],
            "author_detail": {
                "name": "Yalin Zheng"
            },
            "author": "Yalin Zheng",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "利用余辉图像增强曲线结构分割的鲁棒性和性能",
            "abstract_cn": "分割医学图像中的曲线结构对于分析临床应用中的形态模式至关重要。集成拓扑属性（例如连通性）可以提高分割的准确性和一致性。然而，由于其不可微性和计算成本，提取和嵌入这些属性（尤其是从持久性图 (PD) 中）具有挑战性。现有的方法主要通过手工设计的损失函数来编码拓扑，这在任务中泛化性很差。在本文中，我们提出了 PIs-Regressor，这是一个简单而有效的模块，可以直接从数据中学习持久性图像（PI）——拓扑特征的有限、可微的表示。与在下采样和上采样阶段融合这些功能的 Topology SegNet 一起，我们的框架将拓扑集成到网络架构本身中，而不是辅助损失。与严重依赖手工损失函数的现有方法不同，我们的方法直接将拓扑信息合并到网络结构中，从而实现更稳健的分割。我们的设计非常灵活，可以与其他基于拓扑的方法无缝结合，以进一步增强分割性能。实验结果表明，集成拓扑特征可以增强模型的鲁棒性，有效应对医学成像中的过度曝光和模糊等挑战。我们在三个曲线基准上的方法在像素级精度和拓扑保真度方面展示了最先进的性能。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18049v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18049v1",
            "title": "Semi-Supervised Hyperspectral Image Classification with Edge-Aware Superpixel Label Propagation and Adaptive Pseudo-Labeling",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Semi-Supervised Hyperspectral Image Classification with Edge-Aware Superpixel Label Propagation and Adaptive Pseudo-Labeling"
            },
            "updated": "2026-01-26T00:31:08Z",
            "updated_parsed": [
                2026,
                1,
                26,
                0,
                31,
                8,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18049v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18049v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Significant progress has been made in semi-supervised hyperspectral image (HSI) classification regarding feature extraction and classification performance. However, due to high annotation costs and limited sample availability, semi-supervised learning still faces challenges such as boundary label diffusion and pseudo-label instability. To address these issues, this paper proposes a novel semi-supervised hyperspectral classification framework integrating spatial prior information with a dynamic learning mechanism. First, we design an Edge-Aware Superpixel Label Propagation (EASLP) module. By integrating edge intensity penalty with neighborhood correction strategy, it mitigates label diffusion from superpixel segmentation while enhancing classification robustness in boundary regions. Second, we introduce a Dynamic History-Fused Prediction (DHP) method. By maintaining historical predictions and dynamically weighting them with current results, DHP smoothens pseudo-label fluctuations and improves temporal consistency and noise resistance. Concurrently, incorporating condifence and consistency measures, the Adaptive Tripartite Sample Categorization (ATSC) strategy implements hierarchical utilization of easy, ambiguous, and hard samples, leading to enhanced pseudo-label quality and learning efficiency. The Dynamic Reliability-Enhanced Pseudo-Label Framework (DREPL), composed of DHP and ATSC, strengthens pseudo-label stability across temporal and sample domains. Through synergizes operation with EASLP, it achieves spatio-temporal consistency optimization. Evaluations on four benchmark datasets demonstrate its capability to maintain superior classification performance.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Significant progress has been made in semi-supervised hyperspectral image (HSI) classification regarding feature extraction and classification performance. However, due to high annotation costs and limited sample availability, semi-supervised learning still faces challenges such as boundary label diffusion and pseudo-label instability. To address these issues, this paper proposes a novel semi-supervised hyperspectral classification framework integrating spatial prior information with a dynamic learning mechanism. First, we design an Edge-Aware Superpixel Label Propagation (EASLP) module. By integrating edge intensity penalty with neighborhood correction strategy, it mitigates label diffusion from superpixel segmentation while enhancing classification robustness in boundary regions. Second, we introduce a Dynamic History-Fused Prediction (DHP) method. By maintaining historical predictions and dynamically weighting them with current results, DHP smoothens pseudo-label fluctuations and improves temporal consistency and noise resistance. Concurrently, incorporating condifence and consistency measures, the Adaptive Tripartite Sample Categorization (ATSC) strategy implements hierarchical utilization of easy, ambiguous, and hard samples, leading to enhanced pseudo-label quality and learning efficiency. The Dynamic Reliability-Enhanced Pseudo-Label Framework (DREPL), composed of DHP and ATSC, strengthens pseudo-label stability across temporal and sample domains. Through synergizes operation with EASLP, it achieves spatio-temporal consistency optimization. Evaluations on four benchmark datasets demonstrate its capability to maintain superior classification performance."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T00:31:08Z",
            "published_parsed": [
                2026,
                1,
                26,
                0,
                31,
                8,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Yunfei Qiu"
                },
                {
                    "name": "Qiqiong Ma"
                },
                {
                    "name": "Tianhua Lv"
                },
                {
                    "name": "Li Fang"
                },
                {
                    "name": "Shudong Zhou"
                },
                {
                    "name": "Wei Yao"
                }
            ],
            "author_detail": {
                "name": "Wei Yao"
            },
            "author": "Wei Yao",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "具有边缘感知超像素标签传播和自适应伪标签的半监督高光谱图像分类",
            "abstract_cn": "半监督高光谱图像（HSI）分类在特征提取和分类性能方面取得了重大进展。然而，由于标注成本较高和样本可用性有限，半监督学习仍然面临边界标签扩散和伪标签不稳定等挑战。为了解决这些问题，本文提出了一种新颖的半监督高光谱分类框架，将空间先验信息与动态学习机制相结合。首先，我们设计了边缘感知超像素标签传播（EASLP）模块。通过将边缘强度惩罚与邻域校正策略相结合，它可以减轻超像素分割的标签扩散，同时增强边界区域的分类鲁棒性。其次，我们介绍动态历史融合预测（DHP）方法。通过维护历史预测并用当前结果对其进行动态加权，DHP 可以平滑伪标签波动并提高时间一致性和抗噪声能力。同时，结合置信度和一致性度量，自适应三方样本分类（ATSC）策略实现了简单样本、模糊样本和困难样本的分层利用，从而提高了伪标签质量和学习效率。动态可靠性增强伪标签框架 (DREPL) 由 DHP 和 ATSC 组成，增强了跨时间域和样本域的伪标签稳定性。通过与EASLP的协同操作，实现时空一致性优化。对四个基准数据集的评估证明了其保持卓越分类性能的能力。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18099v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18099v1",
            "title": "Computational Framework for Estimating Relative Gaussian Blur Kernels between Image Pairs",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Computational Framework for Estimating Relative Gaussian Blur Kernels between Image Pairs"
            },
            "updated": "2026-01-26T03:21:26Z",
            "updated_parsed": [
                2026,
                1,
                26,
                3,
                21,
                26,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18099v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18099v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Following the earlier verification for Gaussian model in \\cite{ASaa2026}, this paper introduces a zero training forward computational framework for the model to realize it in real time applications. The framework is based on discrete calculation of the analytic expression of the defocused image from the sharper one for the application range of the standard deviation of the Gaussian kernels and selecting the best matches. The analytic expression yields multiple solutions at certain image points, but is filtered down to a single solution using similarity measures over neighboring points.The framework is structured to handle cases where two given images are partial blurred versions of each other. Experimental evaluations on real images demonstrate that the proposed framework achieves a mean absolute error (MAE) below $1.7\\%$ in estimating synthetic blur values. Furthermore, the discrepancy between actual blurred image intensities and their corresponding estimates remains under $2\\%$, obtained by applying the extracted defocus filters to less blurred images.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Following the earlier verification for Gaussian model in \\cite{ASaa2026}, this paper introduces a zero training forward computational framework for the model to realize it in real time applications. The framework is based on discrete calculation of the analytic expression of the defocused image from the sharper one for the application range of the standard deviation of the Gaussian kernels and selecting the best matches. The analytic expression yields multiple solutions at certain image points, but is filtered down to a single solution using similarity measures over neighboring points.The framework is structured to handle cases where two given images are partial blurred versions of each other. Experimental evaluations on real images demonstrate that the proposed framework achieves a mean absolute error (MAE) below $1.7\\%$ in estimating synthetic blur values. Furthermore, the discrepancy between actual blurred image intensities and their corresponding estimates remains under $2\\%$, obtained by applying the extracted defocus filters to less blurred images."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T03:21:26Z",
            "published_parsed": [
                2026,
                1,
                26,
                3,
                21,
                26,
                0,
                26,
                0
            ],
            "arxiv_comment": "9 pages, 14 input images, 3 TikZ images. arXiv admin note: substantial text overlap with arXiv:2601.04779. substantial text overlap with arXiv:2601.04779. substantial text overlap with arXiv:2601.04779. substantial text overlap with arXiv:2601.04779",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Akbar Saadat"
                }
            ],
            "author_detail": {
                "name": "Akbar Saadat"
            },
            "author": "Akbar Saadat",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "用于估计图像对之间相对高斯模糊核的计算框架",
            "abstract_cn": "继\\cite{ASaa2026}中对高斯模型的早期验证之后，本文引入了模型的零训练前向计算框架以在实时应用中实现它。该框架基于针对高斯核的标准差的应用范围从较清晰的图像离散计算散焦图像的解析表达式并选择最佳匹配。分析表达式在某些图像点处产生多个解决方案，但使用相邻点的相似性度量将其过滤为单个解决方案。该框架的结构旨在处理两个给定图像彼此部分模糊版本的情况。对真实图像的实验评估表明，所提出的框架在估计合成模糊值时实现了低于 1.7\\%$ 的平均绝对误差 (MAE)。此外，实际模糊图像强度与其相应估计值之间的差异保持在 $2\\%$ 以下，这是通过将提取的散焦滤波器应用于不太模糊的图像而获得的。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18100v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18100v1",
            "title": "Spatial-Conditioned Reasoning in Long-Egocentric Videos",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Spatial-Conditioned Reasoning in Long-Egocentric Videos"
            },
            "updated": "2026-01-26T03:21:35Z",
            "updated_parsed": [
                2026,
                1,
                26,
                3,
                21,
                35,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18100v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18100v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Long-horizon egocentric video presents significant challenges for visual navigation due to viewpoint drift and the absence of persistent geometric context. Although recent vision-language models perform well on image and short-video reasoning, their spatial reasoning capability in long egocentric sequences remains limited. In this work, we study how explicit spatial signals influence VLM-based video understanding without modifying model architectures or inference procedures. We introduce Sanpo-D, a fine-grained re-annotation of the Google Sanpo dataset, and benchmark multiple VLMs on navigation-oriented spatial queries. To examine input-level inductive bias, we further fuse depth maps with RGB frames and evaluate their impact on spatial reasoning. Our results reveal a trade-off between general-purpose accuracy and spatial specialization, showing that depth-aware and spatially grounded representations can improve performance on safety-critical tasks such as pedestrian and obstruction detection.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Long-horizon egocentric video presents significant challenges for visual navigation due to viewpoint drift and the absence of persistent geometric context. Although recent vision-language models perform well on image and short-video reasoning, their spatial reasoning capability in long egocentric sequences remains limited. In this work, we study how explicit spatial signals influence VLM-based video understanding without modifying model architectures or inference procedures. We introduce Sanpo-D, a fine-grained re-annotation of the Google Sanpo dataset, and benchmark multiple VLMs on navigation-oriented spatial queries. To examine input-level inductive bias, we further fuse depth maps with RGB frames and evaluate their impact on spatial reasoning. Our results reveal a trade-off between general-purpose accuracy and spatial specialization, showing that depth-aware and spatially grounded representations can improve performance on safety-critical tasks such as pedestrian and obstruction detection."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T03:21:35Z",
            "published_parsed": [
                2026,
                1,
                26,
                3,
                21,
                35,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "James Tribble"
                },
                {
                    "name": "Hao Wang"
                },
                {
                    "name": "Si-En Hong"
                },
                {
                    "name": "Chaoyi Zhou"
                },
                {
                    "name": "Ashish Bastola"
                },
                {
                    "name": "Siyu Huang"
                },
                {
                    "name": "Abolfazl Razi"
                }
            ],
            "author_detail": {
                "name": "Abolfazl Razi"
            },
            "author": "Abolfazl Razi",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "以自我为中心的长视频中的空间条件推理",
            "abstract_cn": "由于视点漂移和缺乏持续的几何背景，长视距自我中心视频对视觉导航提出了重大挑战。尽管最近的视觉语言模型在图像和短视频推理方面表现良好，但它们在长自我中心序列中的空间推理能力仍然有限。在这项工作中，我们研究了显式空间信号如何影响基于 VLM 的视频理解，而无需修改模型架构或推理程序。我们引入了 Sanpo-D，这是 Google Sanpo 数据集的细粒度重新注释，并对面向导航的空间查询的多个 VLM 进行了基准测试。为了检查输入级归纳偏差，我们进一步将深度图与 RGB 帧融合并评估它们对空间推理的影响。我们的结果揭示了通用精度和空间专业化之间的权衡，表明深度感知和空间接地表示可以提高行人和障碍物检测等安全关键任务的性能。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18118v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18118v1",
            "title": "LungCRCT: Causal Representation based Lung CT Processing for Lung Cancer Treatment",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "LungCRCT: Causal Representation based Lung CT Processing for Lung Cancer Treatment"
            },
            "updated": "2026-01-26T04:03:50Z",
            "updated_parsed": [
                2026,
                1,
                26,
                4,
                3,
                50,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18118v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18118v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Due to silence in early stages, lung cancer has been one of the most leading causes of mortality in cancer patients world-wide. Moreover, major symptoms of lung cancer are hard to differentiate with other respiratory disease symptoms such as COPD, further leading patients to overlook cancer progression in early stages. Thus, to enhance survival rates in lung cancer, early detection from consistent proactive respiratory system monitoring becomes crucial. One of the most prevalent and effective methods for lung cancer monitoring would be low-dose computed tomography(LDCT) chest scans, which led to remarkable enhancements in lung cancer detection or tumor classification tasks under rapid advancements and applications of computer vision based AI models such as EfficientNet or ResNet in image processing. However, though advanced CNN models under transfer learning or ViT based models led to high performing lung cancer detections, due to its intrinsic limitations in terms of correlation dependence and low interpretability due to complexity, expansions of deep learning models to lung cancer treatment analysis or causal intervention analysis simulations are still limited. Therefore, this research introduced LungCRCT: a latent causal representation learning based lung cancer analysis framework that retrieves causal representations of factors within the physical causal mechanism of lung cancer progression. With the use of advanced graph autoencoder based causal discovery algorithms with distance Correlation disentanglement and entropy-based image reconstruction refinement, LungCRCT not only enables causal intervention analysis for lung cancer treatments, but also leads to robust, yet extremely light downstream models in malignant tumor classification tasks with an AUC score of 93.91%.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Due to silence in early stages, lung cancer has been one of the most leading causes of mortality in cancer patients world-wide. Moreover, major symptoms of lung cancer are hard to differentiate with other respiratory disease symptoms such as COPD, further leading patients to overlook cancer progression in early stages. Thus, to enhance survival rates in lung cancer, early detection from consistent proactive respiratory system monitoring becomes crucial. One of the most prevalent and effective methods for lung cancer monitoring would be low-dose computed tomography(LDCT) chest scans, which led to remarkable enhancements in lung cancer detection or tumor classification tasks under rapid advancements and applications of computer vision based AI models such as EfficientNet or ResNet in image processing. However, though advanced CNN models under transfer learning or ViT based models led to high performing lung cancer detections, due to its intrinsic limitations in terms of correlation dependence and low interpretability due to complexity, expansions of deep learning models to lung cancer treatment analysis or causal intervention analysis simulations are still limited. Therefore, this research introduced LungCRCT: a latent causal representation learning based lung cancer analysis framework that retrieves causal representations of factors within the physical causal mechanism of lung cancer progression. With the use of advanced graph autoencoder based causal discovery algorithms with distance Correlation disentanglement and entropy-based image reconstruction refinement, LungCRCT not only enables causal intervention analysis for lung cancer treatments, but also leads to robust, yet extremely light downstream models in malignant tumor classification tasks with an AUC score of 93.91%."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T04:03:50Z",
            "published_parsed": [
                2026,
                1,
                26,
                4,
                3,
                50,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Daeyoung Kim"
                }
            ],
            "author_detail": {
                "name": "Daeyoung Kim"
            },
            "author": "Daeyoung Kim",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "LungCRCT：基于因果表示的肺部 CT 处理用于肺癌治疗",
            "abstract_cn": "由于早期阶段的沉默，肺癌已成为全世界癌症患者死亡的主要原因之一。此外，肺癌的主要症状很难与慢性阻塞性肺病等其他呼吸道疾病症状区分开来，进一步导致患者忽视早期癌症的进展。因此，为了提高肺癌的生存率，持续主动呼吸系统监测的早期发现变得至关重要。低剂量计算机断层扫描（LDCT）胸部扫描是肺癌监测最普遍、最有效的方法之一，随着基于计算机视觉的人工智能模型（例如 EfficientNet 或 ResNet）在图像处理中的快速发展和应用，低剂量计算机断层扫描（LDCT）胸部扫描显着增强了肺癌检测或肿瘤分类任务。然而，尽管转移学习下的先进 CNN 模型或基于 ViT 的模型可以实现高性能的肺癌检测，但由于其在相关性依赖性方面的内在局限性以及由于复杂性导致的可解释性较低，深度学习模型在肺癌治疗分析或因果干预分析模拟中的扩展仍然受到限制。因此，本研究引入了 LungCRCT：一种基于潜在因果表征学习的肺癌分析框架，可检索肺癌进展的物理因果机制中因素的因果表征。通过使用基于先进图自动编码器的因果发现算法以及距离相关性解缠和基于熵的图像重建细化，LungCRCT不仅能够对肺癌治疗进行因果干预分析，而且还可以在恶性肿瘤分类任务中产生稳健且极其轻量的下游模型，AUC得分为93.91%。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18190v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18190v1",
            "title": "Multi-Perspective Subimage CLIP with Keyword Guidance for Remote Sensing Image-Text Retrieval",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Multi-Perspective Subimage CLIP with Keyword Guidance for Remote Sensing Image-Text Retrieval"
            },
            "updated": "2026-01-26T06:16:53Z",
            "updated_parsed": [
                2026,
                1,
                26,
                6,
                16,
                53,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18190v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18190v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Vision-Language Pre-training (VLP) models like CLIP have significantly advanced Remote Sensing Image-Text Retrieval (RSITR). However, existing methods predominantly rely on coarse-grained global alignment, which often overlooks the dense, multi-scale semantics inherent in overhead imagery. Moreover, adapting these heavy models via full fine-tuning incurs prohibitive computational costs and risks catastrophic forgetting. To address these challenges, we propose MPS-CLIP, a parameter-efficient framework designed to shift the retrieval paradigm from global matching to keyword-guided fine-grained alignment. Specifically, we leverage a Large Language Model (LLM) to extract core semantic keywords, guiding the Segment Anything Model (SamGeo) to generate semantically relevant sub-perspectives. To efficiently adapt the frozen backbone, we introduce a Gated Global Attention (G^2A) adapter, which captures global context and long-range dependencies with minimal overhead. Furthermore, a Multi-Perspective Representation (MPR) module aggregates these local cues into robust multi-perspective embeddings. The framework is optimized via a hybrid objective combining multi-perspective contrastive and weighted triplet losses, which dynamically selects maximum-response perspectives to suppress noise and enforce precise semantic matching. Extensive experiments on the RSICD and RSITMD benchmarks demonstrate that MPS-CLIP achieves state-of-the-art performance with 35.18% and 48.40% mean Recall (mR), respectively, significantly outperforming full fine-tuning baselines and recent competitive methods. Code is available at https://github.com/Lcrucial1f/MPS-CLIP.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Vision-Language Pre-training (VLP) models like CLIP have significantly advanced Remote Sensing Image-Text Retrieval (RSITR). However, existing methods predominantly rely on coarse-grained global alignment, which often overlooks the dense, multi-scale semantics inherent in overhead imagery. Moreover, adapting these heavy models via full fine-tuning incurs prohibitive computational costs and risks catastrophic forgetting. To address these challenges, we propose MPS-CLIP, a parameter-efficient framework designed to shift the retrieval paradigm from global matching to keyword-guided fine-grained alignment. Specifically, we leverage a Large Language Model (LLM) to extract core semantic keywords, guiding the Segment Anything Model (SamGeo) to generate semantically relevant sub-perspectives. To efficiently adapt the frozen backbone, we introduce a Gated Global Attention (G^2A) adapter, which captures global context and long-range dependencies with minimal overhead. Furthermore, a Multi-Perspective Representation (MPR) module aggregates these local cues into robust multi-perspective embeddings. The framework is optimized via a hybrid objective combining multi-perspective contrastive and weighted triplet losses, which dynamically selects maximum-response perspectives to suppress noise and enforce precise semantic matching. Extensive experiments on the RSICD and RSITMD benchmarks demonstrate that MPS-CLIP achieves state-of-the-art performance with 35.18% and 48.40% mean Recall (mR), respectively, significantly outperforming full fine-tuning baselines and recent competitive methods. Code is available at https://github.com/Lcrucial1f/MPS-CLIP."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T06:16:53Z",
            "published_parsed": [
                2026,
                1,
                26,
                6,
                16,
                53,
                0,
                26,
                0
            ],
            "arxiv_comment": "7 pages, 3 figures. Code: https://github.com/Lcrucial1f/MPS-CLIP",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Yifan Li"
                },
                {
                    "name": "Shiying Wang"
                },
                {
                    "name": "Jianqiang Huang"
                }
            ],
            "author_detail": {
                "name": "Jianqiang Huang"
            },
            "author": "Jianqiang Huang",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "关键词引导的多视角子图像CLIP遥感图文检索",
            "abstract_cn": "像 CLIP 这样的视觉语言预训练 (VLP) 模型具有显着先进的遥感图像文本检索 (RSITR)。然而，现有的方法主要依赖于粗粒度的全局对齐，这常常忽视了俯视图像固有的密集的、多尺度的语义。此外，通过全面微调来适应这些重型模型会带来高昂的计算成本，并可能导致灾难性遗忘。为了应对这些挑战，我们提出了 MPS-CLIP，这是一种参数高效的框架，旨在将检索范式从全局匹配转变为关键字引导的细粒度对齐。具体来说，我们利用大型语言模型（LLM）来提取核心语义关键词，指导分段任何模型（SamGeo）生成语义相关的子视角。为了有效地适应冻结的骨干网，我们引入了门控全局注意力（G^2A）适配器，它以最小的开销捕获全局上下文和远程依赖关系。此外，多视角表示（MPR）模块将这些本地线索聚合成强大的多视角嵌入。该框架通过结合多视角对比和加权三元组损失的混合目标进行优化，动态选择最大响应视角来抑制噪声并强制执行精确的语义匹配。 RSICD 和 RSITMD 基准的大量实验表明，MPS-CLIP 实现了最先进的性能，平均召回率 (mR) 分别为 35.18% 和 48.40%，显着优于完全微调基线和最近的竞争方法。代码可在 https://github.com/Lcrucial1f/MPS-CLIP 获取。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18219v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18219v1",
            "title": "Automated HER2 scoring with uncertainty quantification using lensfree holography and deep learning",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Automated HER2 scoring with uncertainty quantification using lensfree holography and deep learning"
            },
            "updated": "2026-01-26T07:09:08Z",
            "updated_parsed": [
                2026,
                1,
                26,
                7,
                9,
                8,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18219v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18219v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Accurate assessment of human epidermal growth factor receptor 2 (HER2) expression is critical for breast cancer diagnosis, prognosis, and therapy selection; yet, most existing digital HER2 scoring methods rely on bulky and expensive optical systems. Here, we present a compact and cost-effective lensfree holography platform integrated with deep learning for automated HER2 scoring of immunohistochemically stained breast tissue sections. The system captures lensfree diffraction patterns of stained HER2 tissue sections under RGB laser illumination and acquires complex field information over a sample area of ~1,250 mm^2 at an effective throughput of ~84 mm^2 per minute. To enhance diagnostic reliability, we incorporated an uncertainty quantification strategy based on Bayesian Monte Carlo dropout, which provides autonomous uncertainty estimates for each prediction and supports reliable, robust HER2 scoring, with an overall correction rate of 30.4%. Using a blinded test set of 412 unique tissue samples, our approach achieved a testing accuracy of 84.9% for 4-class (0, 1+, 2+, 3+) HER2 classification and 94.8% for binary (0/1+ vs. 2+/3+) HER2 scoring with uncertainty quantification. Overall, this lensfree holography approach provides a practical pathway toward portable, high-throughput, and cost-effective HER2 scoring, particularly suited for resource-limited settings, where traditional digital pathology infrastructure is unavailable.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Accurate assessment of human epidermal growth factor receptor 2 (HER2) expression is critical for breast cancer diagnosis, prognosis, and therapy selection; yet, most existing digital HER2 scoring methods rely on bulky and expensive optical systems. Here, we present a compact and cost-effective lensfree holography platform integrated with deep learning for automated HER2 scoring of immunohistochemically stained breast tissue sections. The system captures lensfree diffraction patterns of stained HER2 tissue sections under RGB laser illumination and acquires complex field information over a sample area of ~1,250 mm^2 at an effective throughput of ~84 mm^2 per minute. To enhance diagnostic reliability, we incorporated an uncertainty quantification strategy based on Bayesian Monte Carlo dropout, which provides autonomous uncertainty estimates for each prediction and supports reliable, robust HER2 scoring, with an overall correction rate of 30.4%. Using a blinded test set of 412 unique tissue samples, our approach achieved a testing accuracy of 84.9% for 4-class (0, 1+, 2+, 3+) HER2 classification and 94.8% for binary (0/1+ vs. 2+/3+) HER2 scoring with uncertainty quantification. Overall, this lensfree holography approach provides a practical pathway toward portable, high-throughput, and cost-effective HER2 scoring, particularly suited for resource-limited settings, where traditional digital pathology infrastructure is unavailable."
            },
            "tags": [
                {
                    "term": "physics.med-ph",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.LG",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T07:09:08Z",
            "published_parsed": [
                2026,
                1,
                26,
                7,
                9,
                8,
                0,
                26,
                0
            ],
            "arxiv_comment": "23 Pages, 6 Figures, 1 Table",
            "arxiv_primary_category": {
                "term": "physics.med-ph"
            },
            "authors": [
                {
                    "name": "Che-Yung Shen"
                },
                {
                    "name": "Xilin Yang"
                },
                {
                    "name": "Yuzhu Li"
                },
                {
                    "name": "Leon Lenk"
                },
                {
                    "name": "Aydogan Ozcan"
                }
            ],
            "author_detail": {
                "name": "Aydogan Ozcan"
            },
            "author": "Aydogan Ozcan",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "使用无透镜全息术和深度学习进行不确定性量化的自动化 HER2 评分",
            "abstract_cn": "准确评估人表皮生长因子受体2（HER2）表达对于乳腺癌的诊断、预后和治疗选择至关重要；然而，大多数现有的数字 HER2 评分方法依赖于笨重且昂贵的光学系统。在这里，我们提出了一个紧凑且经济高效的无透镜全息平台，该平台与深度学习集成，用于对免疫组织化学染色的乳腺组织切片进行自动 HER2 评分。该系统在 RGB 激光照明下捕获染色 HER2 组织切片的无透镜衍射图案，并以每分钟约 84 mm^2 的有效吞吐量在约 1,250 mm^2 的样本区域内获取复杂的场信息。为了提高诊断可靠性，我们采用了基于贝叶斯蒙特卡罗 dropout 的不确定性量化策略，该策略为每个预测提供自主不确定性估计，并支持可靠、稳健的 HER2 评分，总体校正率为 30.4%。使用包含 412 个独特组织样本的盲法测试集，我们的方法在 4 级（0、1+、2+、3+）HER2 分类中实现了 84.9% 的测试准确度，在不确定性量化的二元（0/1+ 与 2+/3+）HER2 评分中实现了 94.8% 的测试准确度。总体而言，这种无透镜全息方法为便携式、高通量和经济高效的 HER2 评分提供了一条实用途径，特别适合资源有限、传统数字病理学基础设施不可用的环境。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18228v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18228v1",
            "title": "Facial Emotion Recognition on FER-2013 using an EfficientNetB2-Based Approach",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Facial Emotion Recognition on FER-2013 using an EfficientNetB2-Based Approach"
            },
            "updated": "2026-01-26T07:29:50Z",
            "updated_parsed": [
                2026,
                1,
                26,
                7,
                29,
                50,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18228v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18228v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Detection of human emotions based on facial images in real-world scenarios is a difficult task due to low image quality, variations in lighting, pose changes, background distractions, small inter-class variations, noisy crowd-sourced labels, and severe class imbalance, as observed in the FER-2013 dataset of 48x48 grayscale images. Although recent approaches using large CNNs such as VGG and ResNet achieve reasonable accuracy, they are computationally expensive and memory-intensive, limiting their practicality for real-time applications. We address these challenges using a lightweight and efficient facial emotion recognition pipeline based on EfficientNetB2, trained using a two-stage warm-up and fine-tuning strategy. The model is enhanced with AdamW optimization, decoupled weight decay, label smoothing (epsilon = 0.06) to reduce annotation noise, and clipped class weights to mitigate class imbalance, along with dropout, mixed-precision training, and extensive real-time data augmentation. The model is trained using a stratified 87.5%/12.5% train-validation split while keeping the official test set intact, achieving a test accuracy of 68.78% with nearly ten times fewer parameters than VGG16-based baselines. Experimental results, including per-class metrics and learning dynamics, demonstrate stable training and strong generalization, making the proposed approach suitable for real-time and edge-based applications.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Detection of human emotions based on facial images in real-world scenarios is a difficult task due to low image quality, variations in lighting, pose changes, background distractions, small inter-class variations, noisy crowd-sourced labels, and severe class imbalance, as observed in the FER-2013 dataset of 48x48 grayscale images. Although recent approaches using large CNNs such as VGG and ResNet achieve reasonable accuracy, they are computationally expensive and memory-intensive, limiting their practicality for real-time applications. We address these challenges using a lightweight and efficient facial emotion recognition pipeline based on EfficientNetB2, trained using a two-stage warm-up and fine-tuning strategy. The model is enhanced with AdamW optimization, decoupled weight decay, label smoothing (epsilon = 0.06) to reduce annotation noise, and clipped class weights to mitigate class imbalance, along with dropout, mixed-precision training, and extensive real-time data augmentation. The model is trained using a stratified 87.5%/12.5% train-validation split while keeping the official test set intact, achieving a test accuracy of 68.78% with nearly ten times fewer parameters than VGG16-based baselines. Experimental results, including per-class metrics and learning dynamics, demonstrate stable training and strong generalization, making the proposed approach suitable for real-time and edge-based applications."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.LG",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T07:29:50Z",
            "published_parsed": [
                2026,
                1,
                26,
                7,
                29,
                50,
                0,
                26,
                0
            ],
            "arxiv_comment": "6 pages, 4 figures",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Sahil Naik"
                },
                {
                    "name": "Soham Bagayatkar"
                },
                {
                    "name": "Pavankumar Singh"
                }
            ],
            "author_detail": {
                "name": "Pavankumar Singh"
            },
            "author": "Pavankumar Singh",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "使用基于 EfficientNetB2 的方法在 FER-2013 上进行面部情绪识别",
            "abstract_cn": "正如在 48x48 灰度图像的 FER-2013 数据集中观察到的那样，由于图像质量低、光照变化、姿势变化、背景干扰、类间变化小、众包噪声标签和严重的类不平衡，在现实场景中基于面部图像检测人类情绪是一项艰巨的任务。尽管最近使用 VGG 和 ResNet 等大型 CNN 的方法实现了合理的精度，但它们的计算成本高昂且内存密集，限制了它们在实时应用中的实用性。我们使用基于 EfficientNetB2 的轻量级且高效的面部情绪识别管道来应对这些挑战，并使用两阶段预热和微调策略进行训练。该模型通过 AdamW 优化、解耦权重衰减、标签平滑 (epsilon = 0.06) 来增强，以减少注释噪声，并通过剪裁类权重来减轻类不平衡，以及 dropout、混合精度训练和广泛的实时数据增强。该模型使用分层的 87.5%/12.5% 训练验证分割进行训练，同时保持官方测试集完整，实现了 68.78% 的测试准确率，参数比基于 VGG16 的基线少了近十倍。实验结果，包括每类指标和学习动态，证明了稳定的训练和强大的泛化能力，使得所提出的方法适合实时和基于边缘的应用。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18238v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18238v1",
            "title": "TechING: Towards Real World Technical Image Understanding via VLMs",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "TechING: Towards Real World Technical Image Understanding via VLMs"
            },
            "updated": "2026-01-26T07:43:55Z",
            "updated_parsed": [
                2026,
                1,
                26,
                7,
                43,
                55,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18238v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18238v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Professionals working in technical domain typically hand-draw (on whiteboard, paper, etc.) technical diagrams (e.g., flowcharts, block diagrams, etc.) during discussions; however, if they want to edit these later, it needs to be drawn from scratch. Modern day VLMs have made tremendous progress in image understanding but they struggle when it comes to understanding technical diagrams. One way to overcome this problem is to fine-tune on real world hand-drawn images, but it is not practically possible to generate large number of such images. In this paper, we introduce a large synthetically generated corpus (reflective of real world images) for training VLMs and subsequently evaluate VLMs on a smaller corpus of hand-drawn images (with the help of humans). We introduce several new self-supervision tasks for training and perform extensive experiments with various baseline models and fine-tune Llama 3.2 11B-instruct model on synthetic images on these tasks to obtain LLama-VL-TUG, which significantly improves the ROUGE-L performance of Llama 3.2 11B-instruct by 2.14x and achieves the best all-round performance across all baseline models. On real-world images, human evaluation reveals that we achieve minimum compilation errors across all baselines in 7 out of 8 diagram types and improve the average F1 score of Llama 3.2 11B-instruct by 6.97x.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Professionals working in technical domain typically hand-draw (on whiteboard, paper, etc.) technical diagrams (e.g., flowcharts, block diagrams, etc.) during discussions; however, if they want to edit these later, it needs to be drawn from scratch. Modern day VLMs have made tremendous progress in image understanding but they struggle when it comes to understanding technical diagrams. One way to overcome this problem is to fine-tune on real world hand-drawn images, but it is not practically possible to generate large number of such images. In this paper, we introduce a large synthetically generated corpus (reflective of real world images) for training VLMs and subsequently evaluate VLMs on a smaller corpus of hand-drawn images (with the help of humans). We introduce several new self-supervision tasks for training and perform extensive experiments with various baseline models and fine-tune Llama 3.2 11B-instruct model on synthetic images on these tasks to obtain LLama-VL-TUG, which significantly improves the ROUGE-L performance of Llama 3.2 11B-instruct by 2.14x and achieves the best all-round performance across all baseline models. On real-world images, human evaluation reveals that we achieve minimum compilation errors across all baselines in 7 out of 8 diagram types and improve the average F1 score of Llama 3.2 11B-instruct by 6.97x."
            },
            "tags": [
                {
                    "term": "cs.CL",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.LG",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T07:43:55Z",
            "published_parsed": [
                2026,
                1,
                26,
                7,
                43,
                55,
                0,
                26,
                0
            ],
            "arxiv_comment": "Accepted at Findings of EACL 2026, 30 Pages (9 Pages main paper + 4 pages references + 17 pages appendix)",
            "arxiv_primary_category": {
                "term": "cs.CL"
            },
            "authors": [
                {
                    "name": "Tafazzul Nadeem"
                },
                {
                    "name": "Bhavik Shangari"
                },
                {
                    "name": "Manish Rai"
                },
                {
                    "name": "Gagan Raj Gupta"
                },
                {
                    "name": "Ashutosh Modi"
                }
            ],
            "author_detail": {
                "name": "Ashutosh Modi"
            },
            "author": "Ashutosh Modi",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "TechING：通过 VLM 实现现实世界的技术图像理解",
            "abstract_cn": "技术领域的专业人员在讨论过程中通常会手绘（在白板、纸张等上）技术图表（例如流程图、框图等）；但是，如果他们想稍后编辑这些，则需要从头开始绘制。现代 VLM 在图像理解方面取得了巨大进步，但在理解技术图表方面却遇到了困难。克服这个问题的一种方法是对现实世界的手绘图像进行微调，但实际上不可能生成大量此类图像。在本文中，我们引入了一个大型综合生成的语料库（反映现实世界图像）用于训练 VLM，并随后在较小的手绘图像语料库上评估 VLM（在人类的帮助下）。我们引入了几个新的自监督任务进行训练，并使用各种基线模型进行了广泛的实验，并在这些任务上对合成图像上的 Llama 3.2 11B-instruct 模型进行了微调，以获得 LLama-VL-TUG，这将 Llama 3.2 11B-instruct 的 ROUGE-L 性能显着提高了 2.14 倍，并在所有基线模型中实现了最佳的全面性能。在真实图像上，人工评估表明，我们在 8 种图表类型中的 7 种中实现了所有基线的最小编译错误，并将 Llama 3.2 11B-instruct 的平均 F1 分数提高了 6.97 倍。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18240v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18240v1",
            "title": "V-Loop: Visual Logical Loop Verification for Hallucination Detection in Medical Visual Question Answering",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "V-Loop: Visual Logical Loop Verification for Hallucination Detection in Medical Visual Question Answering"
            },
            "updated": "2026-01-26T07:46:41Z",
            "updated_parsed": [
                2026,
                1,
                26,
                7,
                46,
                41,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18240v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18240v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Multimodal Large Language Models (MLLMs) have shown remarkable capability in assisting disease diagnosis in medical visual question answering (VQA). However, their outputs remain vulnerable to hallucinations (i.e., responses that contradict visual facts), posing significant risks in high-stakes medical scenarios. Recent introspective detection methods, particularly uncertainty-based approaches, offer computational efficiency but are fundamentally indirect, as they estimate predictive uncertainty for an image-question pair rather than verifying the factual correctness of a specific answer. To address this limitation, we propose Visual Logical Loop Verification (V-Loop), a training-free and plug-and-play framework for hallucination detection in medical VQA. V-Loop introduces a bidirectional reasoning process that forms a visually grounded logical loop to verify factual correctness. Given an input, the MLLM produces an answer for the primary input pair. V-Loop extracts semantic units from the primary QA pair, generates a verification question by conditioning on the answer unit to re-query the question unit, and enforces visual attention consistency to ensure answering both primary question and verification question rely on the same image evidence. If the verification answer matches the expected semantic content, the logical loop closes, indicating factual grounding; otherwise, the primary answer is flagged as hallucinated. Extensive experiments on multiple medical VQA benchmarks and MLLMs show that V-Loop consistently outperforms existing introspective methods, remains highly efficient, and further boosts uncertainty-based approaches when used in combination.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Multimodal Large Language Models (MLLMs) have shown remarkable capability in assisting disease diagnosis in medical visual question answering (VQA). However, their outputs remain vulnerable to hallucinations (i.e., responses that contradict visual facts), posing significant risks in high-stakes medical scenarios. Recent introspective detection methods, particularly uncertainty-based approaches, offer computational efficiency but are fundamentally indirect, as they estimate predictive uncertainty for an image-question pair rather than verifying the factual correctness of a specific answer. To address this limitation, we propose Visual Logical Loop Verification (V-Loop), a training-free and plug-and-play framework for hallucination detection in medical VQA. V-Loop introduces a bidirectional reasoning process that forms a visually grounded logical loop to verify factual correctness. Given an input, the MLLM produces an answer for the primary input pair. V-Loop extracts semantic units from the primary QA pair, generates a verification question by conditioning on the answer unit to re-query the question unit, and enforces visual attention consistency to ensure answering both primary question and verification question rely on the same image evidence. If the verification answer matches the expected semantic content, the logical loop closes, indicating factual grounding; otherwise, the primary answer is flagged as hallucinated. Extensive experiments on multiple medical VQA benchmarks and MLLMs show that V-Loop consistently outperforms existing introspective methods, remains highly efficient, and further boosts uncertainty-based approaches when used in combination."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T07:46:41Z",
            "published_parsed": [
                2026,
                1,
                26,
                7,
                46,
                41,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Mengyuan Jin"
                },
                {
                    "name": "Zehui Liao"
                },
                {
                    "name": "Yong Xia"
                }
            ],
            "author_detail": {
                "name": "Yong Xia"
            },
            "author": "Yong Xia",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "V-Loop：医学视觉问答中幻觉检测的视觉逻辑循环验证",
            "abstract_cn": "多模态大语言模型（MLLM）在医学视觉问答（VQA）中辅助疾病诊断方面表现出了卓越的能力。然而，他们的输出仍然容易产生幻觉（即与视觉事实相矛盾的反应），在高风险的医疗场景中构成重大风险。最近的内省检测方法，特别是基于不确定性的方法，提供了计算效率，但基本上是间接的，因为它们估计图像-问题对的预测不确定性，而不是验证特定答案的事实正确性。为了解决这一限制，我们提出了视觉逻辑循环验证（V-Loop），这是一种用于医学 VQA 中幻觉检测的免训练且即插即用的框架。 V-Loop 引入了双向推理过程，形成视觉基础的逻辑循环来验证事实的正确性。给定一个输入，MLLM 会生成主要输入对的答案。 V-Loop 从主要 QA 对中提取语义单元，通过以答案单元为条件重新查询问题单元来生成验证问题，并强制视觉注意一致性以确保回答主要问题和验证问题都依赖于相同的图像证据。如果验证答案与预期的语义内容相匹配，则逻辑循环关闭，表明有事实依据；否则，主要答案将被标记为幻觉。对多个医学 VQA 基准和 MLLM 的大量实验表明，V-Loop 始终优于现有的内省方法，保持高效，并在组合使用时进一步增强基于不确定性的方法。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18242v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18242v1",
            "title": "Vision-Language-Model-Guided Differentiable Ray Tracing for Fast and Accurate Multi-Material RF Parameter Estimation",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Vision-Language-Model-Guided Differentiable Ray Tracing for Fast and Accurate Multi-Material RF Parameter Estimation"
            },
            "updated": "2026-01-26T07:54:53Z",
            "updated_parsed": [
                2026,
                1,
                26,
                7,
                54,
                53,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18242v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18242v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Accurate radio-frequency (RF) material parameters are essential for electromagnetic digital twins in 6G systems, yet gradient-based inverse ray tracing (RT) remains sensitive to initialization and costly under limited measurements. This paper proposes a vision-language-model (VLM) guided framework that accelerates and stabilizes multi-material parameter estimation in a differentiable RT (DRT) engine. A VLM parses scene images to infer material categories and maps them to quantitative priors via an ITU-R material table, yielding informed conductivity initializations. The VLM further selects informative transmitter/receiver placements that promote diverse, material-discriminative paths. Starting from these priors, the DRT performs gradient-based refinement using measured received signal strengths. Experiments in NVIDIA Sionna on indoor scenes show 2-4$\\times$ faster convergence and 10-100$\\times$ lower final parameter error compared with uniform or random initialization and random placement baselines, achieving sub-0.1\\% mean relative error with only a few receivers. Complexity analyses indicate per-iteration time scales near-linearly with the number of materials and measurement setups, while VLM-guided placement reduces the measurements required for accurate recovery. Ablations over RT depth and ray counts confirm further accuracy gains without significant per-iteration overhead. Results demonstrate that semantic priors from VLMs effectively guide physics-based optimization for fast and reliable RF material estimation.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Accurate radio-frequency (RF) material parameters are essential for electromagnetic digital twins in 6G systems, yet gradient-based inverse ray tracing (RT) remains sensitive to initialization and costly under limited measurements. This paper proposes a vision-language-model (VLM) guided framework that accelerates and stabilizes multi-material parameter estimation in a differentiable RT (DRT) engine. A VLM parses scene images to infer material categories and maps them to quantitative priors via an ITU-R material table, yielding informed conductivity initializations. The VLM further selects informative transmitter/receiver placements that promote diverse, material-discriminative paths. Starting from these priors, the DRT performs gradient-based refinement using measured received signal strengths. Experiments in NVIDIA Sionna on indoor scenes show 2-4$\\times$ faster convergence and 10-100$\\times$ lower final parameter error compared with uniform or random initialization and random placement baselines, achieving sub-0.1\\% mean relative error with only a few receivers. Complexity analyses indicate per-iteration time scales near-linearly with the number of materials and measurement setups, while VLM-guided placement reduces the measurements required for accurate recovery. Ablations over RT depth and ray counts confirm further accuracy gains without significant per-iteration overhead. Results demonstrate that semantic priors from VLMs effectively guide physics-based optimization for fast and reliable RF material estimation."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.NI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T07:54:53Z",
            "published_parsed": [
                2026,
                1,
                26,
                7,
                54,
                53,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Zerui Kang"
                },
                {
                    "name": "Yishen Lim"
                },
                {
                    "name": "Zhouyou Gu"
                },
                {
                    "name": "Seung-Woo Ko"
                },
                {
                    "name": "Tony Q. S. Quek"
                },
                {
                    "name": "Jihong Park"
                }
            ],
            "author_detail": {
                "name": "Jihong Park"
            },
            "author": "Jihong Park",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "视觉语言模型引导的可微分射线追踪，用于快速准确的多材料射频参数估计",
            "abstract_cn": "准确的射频 (RF) 材料参数对于 6G 系统中的电磁数字孪生至关重要，但基于梯度的逆射线追踪 (RT) 仍然对初始化敏感，并且在测量有限的情况下成本高昂。本文提出了一种视觉语言模型 (VLM) 引导框架，可加速和稳定可微 RT (DRT) 引擎中的多材料参数估计。 VLM 解析场景图像以推断材料类别，并通过 ITU-R 材料表将它们映射到定量先验，从而产生知情的电导率初始化。 VLM 进一步选择信息丰富的发射器/接收器放置，以促进多样化、材料区分的路径。从这些先验开始，DRT 使用测量的接收信号强度执行基于梯度的细化。在 NVIDIA Sionna 上进行的室内场景实验表明，与均匀或随机初始化和随机放置基线相比，收敛速度提高了 2-4$\\times$，最终参数误差降低了 10-100$\\times$，仅用少数接收器即可实现低于 0.1\\% 的平均相对误差。复杂性分析表明每次迭代的时间尺度与材料和测量设置的数量几乎呈线性关系，而 VLM 引导的放置减少了精确恢复所需的测量。 RT 深度和光线计数的消融证实了精度的进一步提高，而无需显着的每次迭代开销。结果表明，VLM 的语义先验有效指导基于物理的优化，以实现快速可靠的射频材料估计。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18250v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18250v1",
            "title": "A multimodal vision foundation model for generalizable knee pathology",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "A multimodal vision foundation model for generalizable knee pathology"
            },
            "updated": "2026-01-26T08:14:51Z",
            "updated_parsed": [
                2026,
                1,
                26,
                8,
                14,
                51,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18250v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18250v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Musculoskeletal disorders represent a leading cause of global disability, creating an urgent demand for precise interpretation of medical imaging. Current artificial intelligence (AI) approaches in orthopedics predominantly rely on task-specific, supervised learning paradigms. These methods are inherently fragmented, require extensive annotated datasets, and often lack generalizability across different modalities and clinical scenarios. The development of foundation models in this field has been constrained by the scarcity of large-scale, curated, and open-source musculoskeletal datasets. To address these challenges, we introduce OrthoFoundation, a multimodal vision foundation model optimized for musculoskeletal pathology. We constructed a pre-training dataset of 1.2 million unlabeled knee X-ray and MRI images from internal and public databases. Utilizing a Dinov3 backbone, the model was trained via self-supervised contrastive learning to capture robust radiological representations. OrthoFoundation achieves state-of-the-art (SOTA) performance across 14 downstream tasks. It attained superior accuracy in X-ray osteoarthritis diagnosis and ranked first in MRI structural injury detection. The model demonstrated remarkable label efficiency, matching supervised baselines using only 50% of labeled data. Furthermore, despite being pre-trained on knee images, OrthoFoundation exhibited exceptional cross-anatomy generalization to the hip, shoulder, and ankle. OrthoFoundation represents a significant advancement toward general-purpose AI for musculoskeletal imaging. By learning fundamental, joint-agnostic radiological semantics from large-scale multimodal data, it overcomes the limitations of conventional models, which provides a robust framework for reducing annotation burdens and enhancing diagnostic accuracy in clinical practice.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Musculoskeletal disorders represent a leading cause of global disability, creating an urgent demand for precise interpretation of medical imaging. Current artificial intelligence (AI) approaches in orthopedics predominantly rely on task-specific, supervised learning paradigms. These methods are inherently fragmented, require extensive annotated datasets, and often lack generalizability across different modalities and clinical scenarios. The development of foundation models in this field has been constrained by the scarcity of large-scale, curated, and open-source musculoskeletal datasets. To address these challenges, we introduce OrthoFoundation, a multimodal vision foundation model optimized for musculoskeletal pathology. We constructed a pre-training dataset of 1.2 million unlabeled knee X-ray and MRI images from internal and public databases. Utilizing a Dinov3 backbone, the model was trained via self-supervised contrastive learning to capture robust radiological representations. OrthoFoundation achieves state-of-the-art (SOTA) performance across 14 downstream tasks. It attained superior accuracy in X-ray osteoarthritis diagnosis and ranked first in MRI structural injury detection. The model demonstrated remarkable label efficiency, matching supervised baselines using only 50% of labeled data. Furthermore, despite being pre-trained on knee images, OrthoFoundation exhibited exceptional cross-anatomy generalization to the hip, shoulder, and ankle. OrthoFoundation represents a significant advancement toward general-purpose AI for musculoskeletal imaging. By learning fundamental, joint-agnostic radiological semantics from large-scale multimodal data, it overcomes the limitations of conventional models, which provides a robust framework for reducing annotation burdens and enhancing diagnostic accuracy in clinical practice."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T08:14:51Z",
            "published_parsed": [
                2026,
                1,
                26,
                8,
                14,
                51,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Kang Yu"
                },
                {
                    "name": "Dingyu Wang"
                },
                {
                    "name": "Zimu Yuan"
                },
                {
                    "name": "Nan Zhou"
                },
                {
                    "name": "Jiajun Liu"
                },
                {
                    "name": "Jiaxin Liu"
                },
                {
                    "name": "Shanggui Liu"
                },
                {
                    "name": "Yaoyan Zheng"
                },
                {
                    "name": "Huishu Yuan"
                },
                {
                    "name": "Di Huang"
                },
                {
                    "name": "Dong Jiang"
                }
            ],
            "author_detail": {
                "name": "Dong Jiang"
            },
            "author": "Dong Jiang",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "通用膝关节病理学的多模态视觉基础模型",
            "abstract_cn": "肌肉骨骼疾病是全球残疾的主要原因，迫切需要精确解释医学成像。当前骨科领域的人工智能 (AI) 方法主要依赖于特定任务的监督学习范式。这些方法本质上是分散的，需要大量带注释的数据集，并且通常缺乏跨不同模式和临床场景的通用性。该领域基础模型的发展受到大规模、精选和开源肌肉骨骼数据集稀缺的限制。为了应对这些挑战，我们引入了 OrthoFoundation，这是一种针对肌肉骨骼病理学优化的多模态视觉基础模型。我们构建了一个预训练数据集，其中包含来自内部和公共数据库的 120 万张未标记的膝盖 X 射线和 MRI 图像。该模型利用 Dinov3 主干网络，通过自我监督对比学习进行训练，以捕获稳健的放射学表征。 OrthoFoundation 在 14 个下游任务中实现了最先进的 (SOTA) 性能。它在X射线骨关节炎诊断中取得了优异的准确率，在MRI结构损伤检测中排名第一。该模型展示了卓越的标签效率，仅使用 50% 的标签数据即可匹配监督基线。此外，尽管在膝盖图像上进行了预先训练，OrthoFoundation 仍表现出了对臀部、肩部和脚踝的出色的跨解剖学概括。 OrthoFoundation 代表了肌肉骨骼成像通用人工智能的重大进步。通过从大规模多模态数据中学习基本的、与关节无关的放射学语义，它克服了传统模型的局限性，为减少注释负担和提高临床实践中的诊断准确性提供了一个强大的框架。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18260v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18260v1",
            "title": "Depth to Anatomy: Learning Internal Organ Locations from Surface Depth Images",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Depth to Anatomy: Learning Internal Organ Locations from Surface Depth Images"
            },
            "updated": "2026-01-26T08:33:11Z",
            "updated_parsed": [
                2026,
                1,
                26,
                8,
                33,
                11,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18260v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18260v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Automated patient positioning plays an important role in optimizing scanning procedure and improving patient throughput. Leveraging depth information captured by RGB-D cameras presents a promising approach for estimating internal organ positions, thereby enabling more accurate and efficient positioning. In this work, we propose a learning-based framework that directly predicts the 3D locations and shapes of multiple internal organs from single 2D depth images of the body surface. Utilizing a large-scale dataset of full-body MRI scans, we synthesize depth images paired with corresponding anatomical segmentations to train a unified convolutional neural network architecture. Our method accurately localizes a diverse set of anatomical structures, including bones and soft tissues, without requiring explicit surface reconstruction. Experimental results demonstrate the potential of integrating depth sensors into radiology workflows to streamline scanning procedures and enhance patient experience through automated patient positioning.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Automated patient positioning plays an important role in optimizing scanning procedure and improving patient throughput. Leveraging depth information captured by RGB-D cameras presents a promising approach for estimating internal organ positions, thereby enabling more accurate and efficient positioning. In this work, we propose a learning-based framework that directly predicts the 3D locations and shapes of multiple internal organs from single 2D depth images of the body surface. Utilizing a large-scale dataset of full-body MRI scans, we synthesize depth images paired with corresponding anatomical segmentations to train a unified convolutional neural network architecture. Our method accurately localizes a diverse set of anatomical structures, including bones and soft tissues, without requiring explicit surface reconstruction. Experimental results demonstrate the potential of integrating depth sensors into radiology workflows to streamline scanning procedures and enhance patient experience through automated patient positioning."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T08:33:11Z",
            "published_parsed": [
                2026,
                1,
                26,
                8,
                33,
                11,
                0,
                26,
                0
            ],
            "arxiv_comment": "preprint",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Eytan Kats"
                },
                {
                    "name": "Kai Geissler"
                },
                {
                    "name": "Daniel Mensing"
                },
                {
                    "name": "Jochen G. Hirsch"
                },
                {
                    "name": "Stefan Heldman"
                },
                {
                    "name": "Mattias P. Heinrich"
                }
            ],
            "author_detail": {
                "name": "Mattias P. Heinrich"
            },
            "author": "Mattias P. Heinrich",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "深度解剖：从表面深度图像学习内脏器官位置",
            "abstract_cn": "自动患者定位在优化扫描程序和提高患者吞吐量方面发挥着重要作用。利用 RGB-D 相机捕获的深度信息为估计内部器官位置提供了一种有前景的方法，从而实现更准确、更高效的定位。在这项工作中，我们提出了一个基于学习的框架，可以根据身体表面的单个 2D 深度图像直接预测多个内脏器官的 3D 位置和形状。利用全身 MRI 扫描的大规模数据集，我们合成与相应解剖分割配对的深度图像，以训练统一的卷积神经网络架构。我们的方法可以准确定位多种解剖结构，包括骨骼和软组织，而不需要显式的表面重建。实验结果证明了将深度传感器集成到放射学工作流程中的潜力，可以简化扫描程序并通过自动患者定位增强患者体验。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18263v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18263v1",
            "title": "Revisiting Aerial Scene Classification on the AID Benchmark",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Revisiting Aerial Scene Classification on the AID Benchmark"
            },
            "updated": "2026-01-26T08:39:02Z",
            "updated_parsed": [
                2026,
                1,
                26,
                8,
                39,
                2,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18263v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18263v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Aerial images play a vital role in urban planning and environmental preservation, as they consist of various structures, representing different types of buildings, forests, mountains, and unoccupied lands. Due to its heterogeneous nature, developing robust models for scene classification remains a challenge. In this study, we conduct a literature review of various machine learning methods for aerial image classification. Our survey covers a range of approaches from handcrafted features (e.g., SIFT, LBP) to traditional CNNs (e.g., VGG, GoogLeNet), and advanced deep hybrid networks. In this connection, we have also designed Aerial-Y-Net, a spatial attention-enhanced CNN with multi-scale feature fusion mechanism, which acts as an attention-based model and helps us to better understand the complexities of aerial images. Evaluated on the AID dataset, our model achieves 91.72% accuracy, outperforming several baseline architectures.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Aerial images play a vital role in urban planning and environmental preservation, as they consist of various structures, representing different types of buildings, forests, mountains, and unoccupied lands. Due to its heterogeneous nature, developing robust models for scene classification remains a challenge. In this study, we conduct a literature review of various machine learning methods for aerial image classification. Our survey covers a range of approaches from handcrafted features (e.g., SIFT, LBP) to traditional CNNs (e.g., VGG, GoogLeNet), and advanced deep hybrid networks. In this connection, we have also designed Aerial-Y-Net, a spatial attention-enhanced CNN with multi-scale feature fusion mechanism, which acts as an attention-based model and helps us to better understand the complexities of aerial images. Evaluated on the AID dataset, our model achieves 91.72% accuracy, outperforming several baseline architectures."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T08:39:02Z",
            "published_parsed": [
                2026,
                1,
                26,
                8,
                39,
                2,
                0,
                26,
                0
            ],
            "arxiv_comment": "Presented at the IEEE India Geoscience and Remote Sensing Symposium 2025 and accepted for publication in IEEE Xplore",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Subhajeet Das"
                },
                {
                    "name": "Susmita Ghosh"
                },
                {
                    "name": "Abhiroop Chatterjee"
                }
            ],
            "author_detail": {
                "name": "Abhiroop Chatterjee"
            },
            "author": "Abhiroop Chatterjee",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "重新审视 AID 基准上的空中场景分类",
            "abstract_cn": "航空图像在城市规划和环境保护中发挥着至关重要的作用，因为它们由各种结构组成，代表不同类型的建筑物、森林、山脉和无人居住的土地。由于其异构性，开发强大的场景分类模型仍然是一个挑战。在本研究中，我们对航空图像分类的各种机器学习方法进行了文献综述。我们的调查涵盖了从手工特征（例如 SIFT、LBP）到传统 CNN（例如 VGG、GoogLeNet）以及先进的深度混合网络的一系列方法。在这方面，我们还设计了Aerial-Y-Net，一种具有多尺度特征融合机制的空间注意力增强CNN，它作为基于注意力的模型，帮助我们更好地理解航空图像的复杂性。在 AID 数据集上进行评估，我们的模型达到了 91.72% 的准确率，优于多个基线架构。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18301v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18301v1",
            "title": "Contextual Range-View Projection for 3D LiDAR Point Clouds",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Contextual Range-View Projection for 3D LiDAR Point Clouds"
            },
            "updated": "2026-01-26T09:30:43Z",
            "updated_parsed": [
                2026,
                1,
                26,
                9,
                30,
                43,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18301v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18301v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Range-view projection provides an efficient method for transforming 3D LiDAR point clouds into 2D range image representations, enabling effective processing with 2D deep learning models. However, a major challenge in this projection is the many-to-one conflict, where multiple 3D points are mapped onto the same pixel in the range image, requiring a selection strategy. Existing approaches typically retain the point with the smallest depth (closest to the LiDAR), disregarding semantic relevance and object structure, which leads to the loss of important contextual information. In this paper, we extend the depth-based selection rule by incorporating contextual information from both instance centers and class labels, introducing two mechanisms: \\textit{Centerness-Aware Projection (CAP)} and \\textit{Class-Weighted-Aware Projection (CWAP)}. In CAP, point depths are adjusted according to their distance from the instance center, thereby prioritizing central instance points over noisy boundary and background points. In CWAP, object classes are prioritized through user-defined weights, offering flexibility in the projection strategy. Our evaluations on the SemanticKITTI dataset show that CAP preserves more instance points during projection, achieving up to a 3.1\\% mIoU improvement compared to the baseline. Furthermore, CWAP enhances the performance of targeted classes while having a negligible impact on the performance of other classes",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Range-view projection provides an efficient method for transforming 3D LiDAR point clouds into 2D range image representations, enabling effective processing with 2D deep learning models. However, a major challenge in this projection is the many-to-one conflict, where multiple 3D points are mapped onto the same pixel in the range image, requiring a selection strategy. Existing approaches typically retain the point with the smallest depth (closest to the LiDAR), disregarding semantic relevance and object structure, which leads to the loss of important contextual information. In this paper, we extend the depth-based selection rule by incorporating contextual information from both instance centers and class labels, introducing two mechanisms: \\textit{Centerness-Aware Projection (CAP)} and \\textit{Class-Weighted-Aware Projection (CWAP)}. In CAP, point depths are adjusted according to their distance from the instance center, thereby prioritizing central instance points over noisy boundary and background points. In CWAP, object classes are prioritized through user-defined weights, offering flexibility in the projection strategy. Our evaluations on the SemanticKITTI dataset show that CAP preserves more instance points during projection, achieving up to a 3.1\\% mIoU improvement compared to the baseline. Furthermore, CWAP enhances the performance of targeted classes while having a negligible impact on the performance of other classes"
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T09:30:43Z",
            "published_parsed": [
                2026,
                1,
                26,
                9,
                30,
                43,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Seyedali Mousavi"
                },
                {
                    "name": "Seyedhamidreza Mousavi"
                },
                {
                    "name": "Masoud Daneshtalab"
                }
            ],
            "author_detail": {
                "name": "Masoud Daneshtalab"
            },
            "author": "Masoud Daneshtalab",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "3D LiDAR 点云的上下文距离视图投影",
            "abstract_cn": "范围视图投影提供了一种将 3D LiDAR 点云转换为 2D 范围图像表示的有效方法，从而能够使用 2D 深度学习模型进行有效处理。然而，该投影的一个主要挑战是多对一冲突，其中多个 3D 点被映射到距离图像中的同一像素上，需要一种选择策略。现有的方法通常保留最小深度的点（最接近激光雷达），而忽略语义相关性和对象结构，这会导致重要上下文信息的丢失。在本文中，我们通过合并来自实例中心和类标签的上下文信息来扩展基于深度的选择规则，引入两种机制：\\textit{中心感知投影（CAP）}和\\textit{类加权感知投影（CWAP）}。在 CAP 中，点深度根据距实例中心的距离进行调整，从而优先考虑中心实例点而不是噪声边界和背景点。在 CWAP 中，对象类通过用户定义的权重确定优先级，从而提供投影策略的灵活性。我们对 SemanticKITTI 数据集的评估表明，CAP 在投影过程中保留了更多实例点，与基线相比，实现了高达 3.1\\% mIoU 的改进。此外，CWAP 提高了目标类别的性能，同时对其他类别的性能影响可以忽略不计"
        },
        {
            "id": "http://arxiv.org/abs/2601.18330v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18330v1",
            "title": "A Tumor Aware DenseNet Swin Hybrid Learning with Boosted and Hierarchical Feature Spaces for Large-Scale Brain MRI Classification",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "A Tumor Aware DenseNet Swin Hybrid Learning with Boosted and Hierarchical Feature Spaces for Large-Scale Brain MRI Classification"
            },
            "updated": "2026-01-26T10:14:57Z",
            "updated_parsed": [
                2026,
                1,
                26,
                10,
                14,
                57,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18330v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18330v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "This study proposes an efficient Densely Swin Hybrid (EDSH) framework for brain tumor MRI analysis, designed to jointly capture fine grained texture patterns and long range contextual dependencies. Two tumor aware experimental setups are introduced to address class-specific diagnostic challenges. The first setup employs a Boosted Feature Space (BFS), where independently customized DenseNet and Swint branches learn complementary local and global representations that are dimension aligned, fused, and boosted, enabling highly sensitive detection of diffuse glioma patterns by successfully learning the features of irregular shape, poorly defined mass, and heterogeneous texture. The second setup adopts a hierarchical DenseNet Swint architecture with Deep Feature Extraction have Dual Residual connections (DFE and DR), in which DenseNet serves as a stem CNN for structured local feature learning, while Swin_t models global tumor morphology, effectively suppressing false negatives in meningioma and pituitary tumor classification by learning the features of well defined mass, location (outside brain) and enlargments in tumors (dural tail or upward extension). DenseNet is customized at the input level to match MRI spatial characteristics, leveraging dense residual connectivity to preserve texture information and mitigate vanishing-gradient effects. In parallel, Swint is tailored through task aligned patch embedding and shifted-window self attention to efficiently capture hierarchical global dependencies. Extensive evaluation on a large-scale MRI dataset (stringent 40,260 images across four tumor classes) demonstrates consistent superiority over standalone CNNs, Vision Transformers, and hybrids, achieving 98.50 accuracy and recall on the test unseen dataset.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "This study proposes an efficient Densely Swin Hybrid (EDSH) framework for brain tumor MRI analysis, designed to jointly capture fine grained texture patterns and long range contextual dependencies. Two tumor aware experimental setups are introduced to address class-specific diagnostic challenges. The first setup employs a Boosted Feature Space (BFS), where independently customized DenseNet and Swint branches learn complementary local and global representations that are dimension aligned, fused, and boosted, enabling highly sensitive detection of diffuse glioma patterns by successfully learning the features of irregular shape, poorly defined mass, and heterogeneous texture. The second setup adopts a hierarchical DenseNet Swint architecture with Deep Feature Extraction have Dual Residual connections (DFE and DR), in which DenseNet serves as a stem CNN for structured local feature learning, while Swin_t models global tumor morphology, effectively suppressing false negatives in meningioma and pituitary tumor classification by learning the features of well defined mass, location (outside brain) and enlargments in tumors (dural tail or upward extension). DenseNet is customized at the input level to match MRI spatial characteristics, leveraging dense residual connectivity to preserve texture information and mitigate vanishing-gradient effects. In parallel, Swint is tailored through task aligned patch embedding and shifted-window self attention to efficiently capture hierarchical global dependencies. Extensive evaluation on a large-scale MRI dataset (stringent 40,260 images across four tumor classes) demonstrates consistent superiority over standalone CNNs, Vision Transformers, and hybrids, achieving 98.50 accuracy and recall on the test unseen dataset."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.LG",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T10:14:57Z",
            "published_parsed": [
                2026,
                1,
                26,
                10,
                14,
                57,
                0,
                26,
                0
            ],
            "arxiv_comment": "33 Pages, 8 Tables, Figures 16",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Muhammad Ali Shah"
                },
                {
                    "name": "Muhammad Mansoor Alam"
                },
                {
                    "name": "Saddam Hussain Khan"
                }
            ],
            "author_detail": {
                "name": "Saddam Hussain Khan"
            },
            "arxiv_affiliation": "University of Engineering and Applied Sciences, Swat, Kanju Township, Pakistan",
            "author": "Saddam Hussain Khan",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "具有增强和分层特征空间的肿瘤感知 DenseNet Swin 混合学习，用于大规模脑 MRI 分类",
            "abstract_cn": "本研究提出了一种用于脑肿瘤 MRI 分析的高效 Densely Swin Hybrid (EDSH) 框架，旨在联合捕获细粒度纹理模式和长范围上下文依赖性。引入了两种肿瘤感知实验装置来解决特定类别的诊断挑战。第一个设置采用增强特征空间（BFS），其中独立定制的 DenseNet 和 Swint 分支学习维度对齐、融合和增强的互补局部和全局表示，通过成功学习不规则形状、定义不明确的质量和异质纹理的特征，实现弥漫性神经胶质瘤模式的高灵敏度检测。第二种设置采用具有深度特征提取的分层 DenseNet Swint 架构，具有双残差连接（DFE 和 DR），其中 DenseNet 用作结构化局部特征学习的干 CNN，而 Swin_t 建模全局肿瘤形态，通过学习明确定义的肿块、位置（脑外）和肿瘤增大（硬脑膜尾或向上延伸）的特征，有效抑制脑膜瘤和垂体瘤分类中的假阴性。 DenseNet 在输入级别进行定制，以匹配 MRI 空间特征，利用密集残差连接来保留纹理信息并减轻梯度消失效应。同时，Swint 通过任务对齐补丁嵌入和移动窗口自注意力进行定制，以有效捕获分层全局依赖关系。对大规模 MRI 数据集（涵盖四个肿瘤类别的严格 40,260 个图像）的广泛评估表明，与独立 CNN、Vision Transformers 和混合数据集相比，其具有一致的优越性，在测试未见过的数据集上实现了 98.50 的准确率和召回率。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18336v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18336v1",
            "title": "PPISP: Physically-Plausible Compensation and Control of Photometric Variations in Radiance Field Reconstruction",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "PPISP: Physically-Plausible Compensation and Control of Photometric Variations in Radiance Field Reconstruction"
            },
            "updated": "2026-01-26T10:23:43Z",
            "updated_parsed": [
                2026,
                1,
                26,
                10,
                23,
                43,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18336v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18336v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Multi-view 3D reconstruction methods remain highly sensitive to photometric inconsistencies arising from camera optical characteristics and variations in image signal processing (ISP). Existing mitigation strategies such as per-frame latent variables or affine color corrections lack physical grounding and generalize poorly to novel views. We propose the Physically-Plausible ISP (PPISP) correction module, which disentangles camera-intrinsic and capture-dependent effects through physically based and interpretable transformations. A dedicated PPISP controller, trained on the input views, predicts ISP parameters for novel viewpoints, analogous to auto exposure and auto white balance in real cameras. This design enables realistic and fair evaluation on novel views without access to ground-truth images. PPISP achieves SoTA performance on standard benchmarks, while providing intuitive control and supporting the integration of metadata when available. The source code is available at: https://github.com/nv-tlabs/ppisp",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Multi-view 3D reconstruction methods remain highly sensitive to photometric inconsistencies arising from camera optical characteristics and variations in image signal processing (ISP). Existing mitigation strategies such as per-frame latent variables or affine color corrections lack physical grounding and generalize poorly to novel views. We propose the Physically-Plausible ISP (PPISP) correction module, which disentangles camera-intrinsic and capture-dependent effects through physically based and interpretable transformations. A dedicated PPISP controller, trained on the input views, predicts ISP parameters for novel viewpoints, analogous to auto exposure and auto white balance in real cameras. This design enables realistic and fair evaluation on novel views without access to ground-truth images. PPISP achieves SoTA performance on standard benchmarks, while providing intuitive control and supporting the integration of metadata when available. The source code is available at: https://github.com/nv-tlabs/ppisp"
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.GR",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T10:23:43Z",
            "published_parsed": [
                2026,
                1,
                26,
                10,
                23,
                43,
                0,
                26,
                0
            ],
            "arxiv_comment": "For more details and updates, please visit our project website: https://research.nvidia.com/labs/sil/projects/ppisp/",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Isaac Deutsch"
                },
                {
                    "name": "Nicolas Moënne-Loccoz"
                },
                {
                    "name": "Gavriel State"
                },
                {
                    "name": "Zan Gojcic"
                }
            ],
            "author_detail": {
                "name": "Zan Gojcic"
            },
            "author": "Zan Gojcic",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "PPISP：辐射场重建中光度变化的物理合理补偿和控制",
            "abstract_cn": "多视图 3D 重建方法对相机光学特性和图像信号处理 (ISP) 变化引起的光度不一致仍然高度敏感。现有的缓解策略（例如每帧潜在变量或仿射颜色校正）缺乏物理基础，并且很难推广到新颖的视图。我们提出了物理上合理的 ISP (PPISP)​​ 校正模块，该模块通过基于物理和可解释的转换来解开相机固有的和与捕获相关的效果。专用 PPISP 控制器根据输入视图进行训练，预测新视点的 ISP 参数，类似于真实相机中的自动曝光和自动白平衡。这种设计可以在不访问真实图像的情况下对新颖的视图进行现实和公平的评估。 PPISP 在标准基准上实现了 SoTA 性能，同时提供直观的控制并支持元数据的集成（如果可用）。源代码位于：https://github.com/nv-tlabs/ppisp"
        },
        {
            "id": "http://arxiv.org/abs/2601.18346v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18346v1",
            "title": "Q-Bench-Portrait: Benchmarking Multimodal Large Language Models on Portrait Image Quality Perception",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Q-Bench-Portrait: Benchmarking Multimodal Large Language Models on Portrait Image Quality Perception"
            },
            "updated": "2026-01-26T10:37:20Z",
            "updated_parsed": [
                2026,
                1,
                26,
                10,
                37,
                20,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18346v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18346v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Recent advances in multimodal large language models (MLLMs) have demonstrated impressive performance on existing low-level vision benchmarks, which primarily focus on generic images. However, their capabilities to perceive and assess portrait images, a domain characterized by distinct structural and perceptual properties, remain largely underexplored. To this end, we introduce Q-Bench-Portrait, the first holistic benchmark specifically designed for portrait image quality perception, comprising 2,765 image-question-answer triplets and featuring (1) diverse portrait image sources, including natural, synthetic distortion, AI-generated, artistic, and computer graphics images; (2) comprehensive quality dimensions, covering technical distortions, AIGC-specific distortions, and aesthetics; and (3) a range of question formats, including single-choice, multiple-choice, true/false, and open-ended questions, at both global and local levels. Based on Q-Bench-Portrait, we evaluate 20 open-source and 5 closed-source MLLMs, revealing that although current models demonstrate some competence in portrait image perception, their performance remains limited and imprecise, with a clear gap relative to human judgments. We hope that the proposed benchmark will foster further research into enhancing the portrait image perception capabilities of both general-purpose and domain-specific MLLMs.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Recent advances in multimodal large language models (MLLMs) have demonstrated impressive performance on existing low-level vision benchmarks, which primarily focus on generic images. However, their capabilities to perceive and assess portrait images, a domain characterized by distinct structural and perceptual properties, remain largely underexplored. To this end, we introduce Q-Bench-Portrait, the first holistic benchmark specifically designed for portrait image quality perception, comprising 2,765 image-question-answer triplets and featuring (1) diverse portrait image sources, including natural, synthetic distortion, AI-generated, artistic, and computer graphics images; (2) comprehensive quality dimensions, covering technical distortions, AIGC-specific distortions, and aesthetics; and (3) a range of question formats, including single-choice, multiple-choice, true/false, and open-ended questions, at both global and local levels. Based on Q-Bench-Portrait, we evaluate 20 open-source and 5 closed-source MLLMs, revealing that although current models demonstrate some competence in portrait image perception, their performance remains limited and imprecise, with a clear gap relative to human judgments. We hope that the proposed benchmark will foster further research into enhancing the portrait image perception capabilities of both general-purpose and domain-specific MLLMs."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T10:37:20Z",
            "published_parsed": [
                2026,
                1,
                26,
                10,
                37,
                20,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Sijing Wu"
                },
                {
                    "name": "Yunhao Li"
                },
                {
                    "name": "Zicheng Zhang"
                },
                {
                    "name": "Qi Jia"
                },
                {
                    "name": "Xinyue Li"
                },
                {
                    "name": "Huiyu Duan"
                },
                {
                    "name": "Xiongkuo Min"
                },
                {
                    "name": "Guangtao Zhai"
                }
            ],
            "author_detail": {
                "name": "Guangtao Zhai"
            },
            "author": "Guangtao Zhai",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "Q-Bench-Portrait：对肖像图像质量感知的多模态大语言模型进行基准测试",
            "abstract_cn": "多模态大语言模型 (MLLM) 的最新进展在现有的低级视觉基准上展示了令人印象深刻的性能，这些基准主要关注通用图像。然而，它们感知和评估肖像图像的能力（一个以独特的结构和感知特性为特征的领域）在很大程度上仍未得到充分开发。为此，我们推出了 Q-Bench-Portrait，这是第一个专门针对人像图像质量感知而设计的整体基准测试，由 2,765 个图像-问题-答案三元组组成，并具有以下特点：(1) 多样化的人像图像源，包括自然、合成失真、人工智能生成、艺术和计算机图形图像； (2) 综合质量维度，涵盖技术扭曲、AIGC特有扭曲和美观； (3) 全球和本地层面的一系列问题格式，包括单选题、多项选择题、对错题和开放式问题。基于 Q-Bench-Portrait，我们评估了 20 个开源和 5 个闭源 MLLM，结果表明，尽管当前模型在肖像图像感知方面表现出一定的能力，但它们的性能仍然有限且不精确，与人类判断相比存在明显差距。我们希望所提出的基准能够促进进一步研究，以增强通用和特定领域 MLLM 的肖像图像感知能力。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18368v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18368v1",
            "title": "OREHAS: A fully automated deep-learning pipeline for volumetric endolymphatic hydrops quantification in MRI",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "OREHAS: A fully automated deep-learning pipeline for volumetric endolymphatic hydrops quantification in MRI"
            },
            "updated": "2026-01-26T11:19:21Z",
            "updated_parsed": [
                2026,
                1,
                26,
                11,
                19,
                21,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18368v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18368v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We present OREHAS (Optimized Recognition & Evaluation of volumetric Hydrops in the Auditory System), the first fully automatic pipeline for volumetric quantification of endolymphatic hydrops (EH) from routine 3D-SPACE-MRC and 3D-REAL-IR MRI. The system integrates three components -- slice classification, inner ear localization, and sequence-specific segmentation -- into a single workflow that computes per-ear endolymphatic-to-vestibular volume ratios (ELR) directly from whole MRI volumes, eliminating the need for manual intervention.\n  Trained with only 3 to 6 annotated slices per patient, OREHAS generalized effectively to full 3D volumes, achieving Dice scores of 0.90 for SPACE-MRC and 0.75 for REAL-IR. In an external validation cohort with complete manual annotations, OREHAS closely matched expert ground truth (VSI = 74.3%) and substantially outperformed the clinical syngo.via software (VSI = 42.5%), which tended to overestimate endolymphatic volumes. Across 19 test patients, vestibular measurements from OREHAS were consistent with syngo.via, while endolymphatic volumes were systematically smaller and more physiologically realistic.\n  These results show that reliable and reproducible EH quantification can be achieved from standard MRI using limited supervision. By combining efficient deep-learning-based segmentation with a clinically aligned volumetric workflow, OREHAS reduces operator dependence, ensures methodological consistency. Besides, the results are compatible with established imaging protocols. The approach provides a robust foundation for large-scale studies and for recalibrating clinical diagnostic thresholds based on accurate volumetric measurements of the inner ear.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We present OREHAS (Optimized Recognition & Evaluation of volumetric Hydrops in the Auditory System), the first fully automatic pipeline for volumetric quantification of endolymphatic hydrops (EH) from routine 3D-SPACE-MRC and 3D-REAL-IR MRI. The system integrates three components -- slice classification, inner ear localization, and sequence-specific segmentation -- into a single workflow that computes per-ear endolymphatic-to-vestibular volume ratios (ELR) directly from whole MRI volumes, eliminating the need for manual intervention.\n  Trained with only 3 to 6 annotated slices per patient, OREHAS generalized effectively to full 3D volumes, achieving Dice scores of 0.90 for SPACE-MRC and 0.75 for REAL-IR. In an external validation cohort with complete manual annotations, OREHAS closely matched expert ground truth (VSI = 74.3%) and substantially outperformed the clinical syngo.via software (VSI = 42.5%), which tended to overestimate endolymphatic volumes. Across 19 test patients, vestibular measurements from OREHAS were consistent with syngo.via, while endolymphatic volumes were systematically smaller and more physiologically realistic.\n  These results show that reliable and reproducible EH quantification can be achieved from standard MRI using limited supervision. By combining efficient deep-learning-based segmentation with a clinically aligned volumetric workflow, OREHAS reduces operator dependence, ensures methodological consistency. Besides, the results are compatible with established imaging protocols. The approach provides a robust foundation for large-scale studies and for recalibrating clinical diagnostic thresholds based on accurate volumetric measurements of the inner ear."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T11:19:21Z",
            "published_parsed": [
                2026,
                1,
                26,
                11,
                19,
                21,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Caterina Fuster-Barceló"
                },
                {
                    "name": "Claudia Castrillón"
                },
                {
                    "name": "Laura Rodrigo-Muñoz"
                },
                {
                    "name": "Victor Manuel Vega-Suárez"
                },
                {
                    "name": "Nicolás Pérez-Fernández"
                },
                {
                    "name": "Gorka Bastarrika"
                },
                {
                    "name": "Arrate Muñoz-Barrutia"
                }
            ],
            "author_detail": {
                "name": "Arrate Muñoz-Barrutia"
            },
            "author": "Arrate Muñoz-Barrutia",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "OREHAS：用于 MRI 中体积内淋巴积水定量的全自动深度学习管道",
            "abstract_cn": "我们推出了 OREHAS（听觉系统体积积水的优化识别和评估），这是第一个通过常规 3D-SPACE-MRC 和 3D-REAL-IR MRI 对内淋巴积水 (EH) 进行体积量化的全自动管道。该系统将切片分类、内耳定位和序列特定分割这三个组件集成到一个工作流程中，直接根据整个 MRI 体积计算每耳内淋巴与前庭体积比率 (ELR)，从而无需手动干预。\n  每个患者仅使用 3 到 6 个带注释的切片进行训练，OREHAS 可以有效地推广到完整的 3D 体积，SPACE-MRC 的 Dice 分数为 0.90，REAL-IR 的 Dice 分数为 0.75。在具有完整手动注释的外部验证队列中，OREHAS 与专家的基本事实密切匹配 (VSI = 74.3%)，并且大大优于临床 syngo.via 软件 (VSI = 42.5%)，该软件往往会高估内淋巴体积。在 19 名测试患者中，OREHAS 的前庭测量结果与 syngo.via 一致，而内淋巴体积更小且更符合生理学现实。\n  这些结果表明，使用有限的监督，可以通过标准 MRI 实现可靠且可重复的 EH 量化。通过将基于深度学习的高效分割与临床一致的体积工作流程相结合，OREHAS 减少了操作员依赖，确保方法的一致性。此外，结果与既定的成像协议兼容。该方法为大规模研究和基于内耳精确体积测量重新校准临床诊断阈值提供了坚​​实的基础。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18385v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18385v1",
            "title": "Estimation of geometric transformation matrices using grid-shaped pilot signals",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Estimation of geometric transformation matrices using grid-shaped pilot signals"
            },
            "updated": "2026-01-26T11:33:01Z",
            "updated_parsed": [
                2026,
                1,
                26,
                11,
                33,
                1,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18385v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18385v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                },
                {
                    "rel": "related",
                    "href": "https://doi.org/10.1561/116.20250067",
                    "title": "doi",
                    "type": "text/html"
                }
            ],
            "summary": "Digital watermarking techniques are essential to prevent unauthorized use of images. Since pirated images are often geometrically distorted by operations such as scaling and cropping, accurate synchronization - detecting the embedding position of the watermark - is critical for proper extraction. In particular, cropping changes the origin of the image, making synchronization difficult. However, few existing methods are robust against cropping. To address this issue, we propose a watermarking method that estimates geometric transformations applied to a stego image using a pilot signal, allowing synchronization even after cropping. A grid-shaped pilot signal with distinct horizontal and vertical values is embedded in the image. When the image is transformed, the grid is also distorted. By analyzing this distortion, the transformation matrix can be estimated. Applying the Radon transform to the distorted image allows estimation of the grid angles and intervals. In addition, since the horizontal and vertical grid lines are encoded differently, the grid orientation can be determined, which reduces ambiguity. To validate our method, we performed simulations with anisotropic scaling, rotation, shearing, and cropping. The results show that the proposed method accurately estimates transformation matrices with low error under both single and composite attacks.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Digital watermarking techniques are essential to prevent unauthorized use of images. Since pirated images are often geometrically distorted by operations such as scaling and cropping, accurate synchronization - detecting the embedding position of the watermark - is critical for proper extraction. In particular, cropping changes the origin of the image, making synchronization difficult. However, few existing methods are robust against cropping. To address this issue, we propose a watermarking method that estimates geometric transformations applied to a stego image using a pilot signal, allowing synchronization even after cropping. A grid-shaped pilot signal with distinct horizontal and vertical values is embedded in the image. When the image is transformed, the grid is also distorted. By analyzing this distortion, the transformation matrix can be estimated. Applying the Radon transform to the distorted image allows estimation of the grid angles and intervals. In addition, since the horizontal and vertical grid lines are encoded differently, the grid orientation can be determined, which reduces ambiguity. To validate our method, we performed simulations with anisotropic scaling, rotation, shearing, and cropping. The results show that the proposed method accurately estimates transformation matrices with low error under both single and composite attacks."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T11:33:01Z",
            "published_parsed": [
                2026,
                1,
                26,
                11,
                33,
                1,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "arxiv_journal_ref": "APSIPA Transactions on Signal and Information Processing (2025) 14 (1)",
            "authors": [
                {
                    "name": "Rinka Kawano"
                },
                {
                    "name": "Masaki Kawamura"
                }
            ],
            "author_detail": {
                "name": "Masaki Kawamura"
            },
            "author": "Masaki Kawamura",
            "arxiv_doi": "10.1561/116.20250067",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "使用网格状导频信号估计几何变换矩阵",
            "abstract_cn": "数字水印技术对于防止未经授权使用图像至关重要。由于盗版图像通常会因缩放和裁剪等操作而产生几何扭曲，因此准确的同步（检测水印的嵌入位置）对于正确提取至关重要。特别是，裁剪会改变图像的来源，使同步变得困难。然而，现有的方法很少对裁剪具有鲁棒性。为了解决这个问题，我们提出了一种水印方法，该方法使用导频信号估计应用于隐写图像的几何变换，即使在裁剪后也允许同步。图像中嵌入了具有不同水平和垂直值的网格状导频信号。当图像变换时，网格也会变形。通过分析这种失真，可以估计变换矩阵。将氡变换应用于扭曲图像可以估计网格角度和间隔。此外，由于水平和垂直网格线的编码不同，因此可以确定网格方向，从而减少模糊性。为了验证我们的方法，我们通过各向异性缩放、旋转、剪切和裁剪进行了模拟。结果表明，该方法在单一攻击和复合攻击下都能准确估计变换矩阵，且误差较低。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18386v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18386v1",
            "title": "ARMOR: Agentic Reasoning for Methods Orchestration and Reparameterization for Robust Adversarial Attacks",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "ARMOR: Agentic Reasoning for Methods Orchestration and Reparameterization for Robust Adversarial Attacks"
            },
            "updated": "2026-01-26T11:36:34Z",
            "updated_parsed": [
                2026,
                1,
                26,
                11,
                36,
                34,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18386v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18386v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Existing automated attack suites operate as static ensembles with fixed sequences, lacking strategic adaptation and semantic awareness. This paper introduces the Agentic Reasoning for Methods Orchestration and Reparameterization (ARMOR) framework to address these limitations. ARMOR orchestrates three canonical adversarial primitives, Carlini-Wagner (CW), Jacobian-based Saliency Map Attack (JSMA), and Spatially Transformed Attacks (STA) via Vision Language Models (VLM)-guided agents that collaboratively generate and synthesize perturbations through a shared ``Mixing Desk\". Large Language Models (LLMs) adaptively tune and reparameterize parallel attack agents in a real-time, closed-loop system that exploits image-specific semantic vulnerabilities. On standard benchmarks, ARMOR achieves improved cross-architecture transfer and reliably fools both settings, delivering a blended output for blind targets and selecting the best attack or blended attacks for white-box targets using a confidence-and-SSIM score.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Existing automated attack suites operate as static ensembles with fixed sequences, lacking strategic adaptation and semantic awareness. This paper introduces the Agentic Reasoning for Methods Orchestration and Reparameterization (ARMOR) framework to address these limitations. ARMOR orchestrates three canonical adversarial primitives, Carlini-Wagner (CW), Jacobian-based Saliency Map Attack (JSMA), and Spatially Transformed Attacks (STA) via Vision Language Models (VLM)-guided agents that collaboratively generate and synthesize perturbations through a shared ``Mixing Desk\". Large Language Models (LLMs) adaptively tune and reparameterize parallel attack agents in a real-time, closed-loop system that exploits image-specific semantic vulnerabilities. On standard benchmarks, ARMOR achieves improved cross-architecture transfer and reliably fools both settings, delivering a blended output for blind targets and selecting the best attack or blended attacks for white-box targets using a confidence-and-SSIM score."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T11:36:34Z",
            "published_parsed": [
                2026,
                1,
                26,
                11,
                36,
                34,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Gabriel Lee Jun Rong"
                },
                {
                    "name": "Christos Korgialas"
                },
                {
                    "name": "Dion Jia Xu Ho"
                },
                {
                    "name": "Pai Chet Ng"
                },
                {
                    "name": "Xiaoxiao Miao"
                },
                {
                    "name": "Konstantinos N. Plataniotis"
                }
            ],
            "author_detail": {
                "name": "Konstantinos N. Plataniotis"
            },
            "author": "Konstantinos N. Plataniotis",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "ARMOR：用于鲁棒对抗攻击的方法编排和重新参数化的代理推理",
            "abstract_cn": "现有的自动化攻击套件作为具有固定序列的静态整体运行，缺乏策略适应和语义意识。本文介绍了方法编排和重新参数化的代理推理 (ARMOR) 框架来解决这些限制。 ARMOR 通过视觉语言模型 (VLM) 引导的代理协调三个规范的对抗原语：Carlini-Wagner (CW)、基于雅可比的显着图攻击 (JSMA) 和空间转换攻击 (STA)，这些代理通过共享的“混合台”协作生成和合成扰动。大型语言模型 (LLM) 在实时、闭环中自适应地调整和重新参数化并行攻击代理在标准基准测试中，ARMOR 实现了改进的跨架构传输并可靠地愚弄了这两种设置，为盲目标提供混合输出，并使用置信度和 SSIM 分数为白盒目标选择最佳攻击或混合攻击。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18392v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18392v1",
            "title": "Efficient Complex-Valued Vision Transformers for MRI Classification Directly from k-Space",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Efficient Complex-Valued Vision Transformers for MRI Classification Directly from k-Space"
            },
            "updated": "2026-01-26T11:50:52Z",
            "updated_parsed": [
                2026,
                1,
                26,
                11,
                50,
                52,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18392v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18392v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Deep learning applications in Magnetic Resonance Imaging (MRI) predominantly operate on reconstructed magnitude images, a process that discards phase information and requires computationally expensive transforms. Standard neural network architectures rely on local operations (convolutions or grid-patches) that are ill-suited for the global, non-local nature of raw frequency-domain (k-Space) data. In this work, we propose a novel complex-valued Vision Transformer (kViT) designed to perform classification directly on k-Space data. To bridge the geometric disconnect between current architectures and MRI physics, we introduce a radial k-Space patching strategy that respects the spectral energy distribution of the frequency-domain. Extensive experiments on the fastMRI and in-house datasets demonstrate that our approach achieves classification performance competitive with state-of-the-art image-domain baselines (ResNet, EfficientNet, ViT). Crucially, kViT exhibits superior robustness to high acceleration factors and offers a paradigm shift in computational efficiency, reducing VRAM consumption during training by up to 68$\\times$ compared to standard methods. This establishes a pathway for resource-efficient, direct-from-scanner AI analysis.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Deep learning applications in Magnetic Resonance Imaging (MRI) predominantly operate on reconstructed magnitude images, a process that discards phase information and requires computationally expensive transforms. Standard neural network architectures rely on local operations (convolutions or grid-patches) that are ill-suited for the global, non-local nature of raw frequency-domain (k-Space) data. In this work, we propose a novel complex-valued Vision Transformer (kViT) designed to perform classification directly on k-Space data. To bridge the geometric disconnect between current architectures and MRI physics, we introduce a radial k-Space patching strategy that respects the spectral energy distribution of the frequency-domain. Extensive experiments on the fastMRI and in-house datasets demonstrate that our approach achieves classification performance competitive with state-of-the-art image-domain baselines (ResNet, EfficientNet, ViT). Crucially, kViT exhibits superior robustness to high acceleration factors and offers a paradigm shift in computational efficiency, reducing VRAM consumption during training by up to 68$\\times$ compared to standard methods. This establishes a pathway for resource-efficient, direct-from-scanner AI analysis."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T11:50:52Z",
            "published_parsed": [
                2026,
                1,
                26,
                11,
                50,
                52,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Moritz Rempe"
                },
                {
                    "name": "Lukas T. Rotkopf"
                },
                {
                    "name": "Marco Schlimbach"
                },
                {
                    "name": "Helmut Becker"
                },
                {
                    "name": "Fabian Hörst"
                },
                {
                    "name": "Johannes Haubold"
                },
                {
                    "name": "Philipp Dammann"
                },
                {
                    "name": "Kevin Kröninger"
                },
                {
                    "name": "Jens Kleesiek"
                }
            ],
            "author_detail": {
                "name": "Jens Kleesiek"
            },
            "author": "Jens Kleesiek",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "直接从 k 空间进行 MRI 分类的高效复值视觉转换器",
            "abstract_cn": "磁共振成像 (MRI) 中的深度学习应用主要对重建的震级图像进行操作，该过程会丢弃相位信息并需要计算成本高昂的变换。标准神经网络架构依赖于局部操作（卷积或网格补丁），这些操作不适合原始频域（k 空间）数据的全局、非局部性质。在这项工作中，我们提出了一种新颖的复值视觉变换器（kViT），旨在直接对 k 空间数据执行分类。为了弥合当前架构和 MRI 物理之间的几何脱节，我们引入了一种尊重频域频谱能量分布的径向 k 空间修补策略。在 fastMRI 和内部数据集上进行的大量实验表明，我们的方法实现了与最先进的图像域基线（ResNet、EfficientNet、ViT）相媲美的分类性能。至关重要的是，kViT 对高加速因子表现出卓越的鲁棒性，并提供计算效率的范式转变，与标准方法相比，训练期间的 VRAM 消耗减少高达 68 美元\\倍$。这为资源高效、直接来自扫描仪的人工智能分析建立了一条途径。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18407v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18407v1",
            "title": "Larger than memory image processing",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Larger than memory image processing"
            },
            "updated": "2026-01-26T12:02:41Z",
            "updated_parsed": [
                2026,
                1,
                26,
                12,
                2,
                41,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18407v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18407v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "This report addresses larger-than-memory image analysis for petascale datasets such as 1.4 PB electron-microscopy volumes and 150 TB human-organ atlases. We argue that performance is fundamentally I/O-bound. We show that structuring analysis as streaming passes over data is crucial. For 3D volumes, two representations are popular: stacks of 2D slices (e.g., directories or multi-page TIFF) and 3D chunked layouts (e.g., Zarr/HDF5). While for a few algorithms, chunked layout on disk is crucial to keep disk I/O at a minimum, we show how the slice-based streaming architecture can be built on top of either image representation in a manner that minimizes disk I/O. This is in particular advantageous for algorithms relying on neighbouring values, since the slicing streaming architecture is 1D, which implies that there are only 2 possible sweeping orders, both of which are aligned with the order in which images are read from the disk. This is in contrast to 3D chunks, in which any sweep cannot be done without accessing each chunk at least 9 times. We formalize this with sweep-based execution (natural 2D/3D orders), windowed operations, and overlap-aware tiling to minimize redundant access. Building on these principles, we introduce a domain-specific language (DSL) that encodes algorithms with intrinsic knowledge of their optimal streaming and memory use; the DSL performs compile-time and run-time pipeline analyses to automatically select window sizes, fuse stages, tee and zip streams, and schedule passes for limited-RAM machines, yielding near-linear I/O scans and predictable memory footprints. The approach integrates with existing tooling for segmentation and morphology but reframes pre/post-processing as pipelines that privilege sequential read/write patterns, delivering substantial throughput gains for extremely large images without requiring full-volume residency in memory.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "This report addresses larger-than-memory image analysis for petascale datasets such as 1.4 PB electron-microscopy volumes and 150 TB human-organ atlases. We argue that performance is fundamentally I/O-bound. We show that structuring analysis as streaming passes over data is crucial. For 3D volumes, two representations are popular: stacks of 2D slices (e.g., directories or multi-page TIFF) and 3D chunked layouts (e.g., Zarr/HDF5). While for a few algorithms, chunked layout on disk is crucial to keep disk I/O at a minimum, we show how the slice-based streaming architecture can be built on top of either image representation in a manner that minimizes disk I/O. This is in particular advantageous for algorithms relying on neighbouring values, since the slicing streaming architecture is 1D, which implies that there are only 2 possible sweeping orders, both of which are aligned with the order in which images are read from the disk. This is in contrast to 3D chunks, in which any sweep cannot be done without accessing each chunk at least 9 times. We formalize this with sweep-based execution (natural 2D/3D orders), windowed operations, and overlap-aware tiling to minimize redundant access. Building on these principles, we introduce a domain-specific language (DSL) that encodes algorithms with intrinsic knowledge of their optimal streaming and memory use; the DSL performs compile-time and run-time pipeline analyses to automatically select window sizes, fuse stages, tee and zip streams, and schedule passes for limited-RAM machines, yielding near-linear I/O scans and predictable memory footprints. The approach integrates with existing tooling for segmentation and morphology but reframes pre/post-processing as pipelines that privilege sequential read/write patterns, delivering substantial throughput gains for extremely large images without requiring full-volume residency in memory."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T12:02:41Z",
            "published_parsed": [
                2026,
                1,
                26,
                12,
                2,
                41,
                0,
                26,
                0
            ],
            "arxiv_comment": "10 pages",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Jon Sporring"
                },
                {
                    "name": "David Stansby"
                }
            ],
            "author_detail": {
                "name": "David Stansby"
            },
            "author": "David Stansby",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "大于内存的图像处理",
            "abstract_cn": "该报告针对千万亿级数据集（例如 1.4 PB 电子显微镜体积和 150 TB 人体器官图集）进行大于内存的图像分析。我们认为性能从根本上来说是受 I/O 限制的。我们表明，流式传输数据时的结构化分析至关重要。对于 3D 体积，两种表示形式很流行：2D 切片堆栈（例如目录或多页 TIFF）和 3D 分块布局（例如 Zarr/HDF5）。虽然对于一些算法来说，磁盘上的分块布局对于将磁盘 I/O 保持在最低水平至关重要，但我们展示了如何以最小化磁盘 I/O 的方式在任一图像表示之上构建基于切片的流架构。这对于依赖于相邻值的算法特别有利，因为切片流架构是一维的，这意味着只有 2 个可能的扫描顺序，这两个顺序都与从磁盘读取图像的顺序对齐。这与 3D 块形成对比，在 3D 块中，如果不访问每个块至少 9 次，就无法完成任何扫描。我们通过基于扫描的执行（自然 2D/3D 顺序）、窗口操作和重叠感知平铺将其形式化，以最大限度地减少冗余访问。基于这些原则，我们引入了一种特定领域语言（DSL），该语言使用其最佳流和内存使用的内在知识对算法进行编码； DSL 执行编译时和运行时管道分析，以自动选择窗口大小、熔断阶段、tee 和 zip 流以及有限 RAM 机器的调度通道，从而产生近线性 I/O 扫描和可预测的内存占用。该方法与现有的分割和形态学工具集成，但将预处理/后处理重新构建为优先顺序读/写模式的管道，为极大的图像提供可观的吞吐量增益，而不需要在内存中全卷驻留。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18845v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18845v1",
            "title": "Dynamic Mask-Based Backdoor Attack Against Vision AI Models: A Case Study on Mushroom Detection",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Dynamic Mask-Based Backdoor Attack Against Vision AI Models: A Case Study on Mushroom Detection"
            },
            "updated": "2026-01-26T12:25:16Z",
            "updated_parsed": [
                2026,
                1,
                26,
                12,
                25,
                16,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18845v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18845v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Deep learning has revolutionized numerous tasks within the computer vision field, including image classification, image segmentation, and object detection. However, the increasing deployment of deep learning models has exposed them to various adversarial attacks, including backdoor attacks. This paper presents a novel dynamic mask-based backdoor attack method, specifically designed for object detection models. We exploit a dataset poisoning technique to embed a malicious trigger, rendering any models trained on this compromised dataset vulnerable to our backdoor attack. We particularly focus on a mushroom detection dataset to demonstrate the practical risks posed by such attacks on critical real-life domains. Our work also emphasizes the importance of creating a detailed backdoor attack scenario to illustrate the significant risks associated with the outsourcing practice. Our approach leverages SAM, a recent and powerful image segmentation AI model, to create masks for dynamic trigger placement, introducing a new and stealthy attack method. Through extensive experimentation, we show that our sophisticated attack scenario maintains high accuracy on clean data with the YOLOv7 object detection model while achieving high attack success rates on poisoned samples. Our approach surpasses traditional methods for backdoor injection, which are based on static and consistent patterns. Our findings underscore the urgent need for robust countermeasures to protect deep learning models from these evolving adversarial threats.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Deep learning has revolutionized numerous tasks within the computer vision field, including image classification, image segmentation, and object detection. However, the increasing deployment of deep learning models has exposed them to various adversarial attacks, including backdoor attacks. This paper presents a novel dynamic mask-based backdoor attack method, specifically designed for object detection models. We exploit a dataset poisoning technique to embed a malicious trigger, rendering any models trained on this compromised dataset vulnerable to our backdoor attack. We particularly focus on a mushroom detection dataset to demonstrate the practical risks posed by such attacks on critical real-life domains. Our work also emphasizes the importance of creating a detailed backdoor attack scenario to illustrate the significant risks associated with the outsourcing practice. Our approach leverages SAM, a recent and powerful image segmentation AI model, to create masks for dynamic trigger placement, introducing a new and stealthy attack method. Through extensive experimentation, we show that our sophisticated attack scenario maintains high accuracy on clean data with the YOLOv7 object detection model while achieving high attack success rates on poisoned samples. Our approach surpasses traditional methods for backdoor injection, which are based on static and consistent patterns. Our findings underscore the urgent need for robust countermeasures to protect deep learning models from these evolving adversarial threats."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T12:25:16Z",
            "published_parsed": [
                2026,
                1,
                26,
                12,
                25,
                16,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Zeineb Dridi"
                },
                {
                    "name": "Jihen Bennaceur"
                },
                {
                    "name": "Amine Ben Hassouna"
                }
            ],
            "author_detail": {
                "name": "Amine Ben Hassouna"
            },
            "author": "Amine Ben Hassouna",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "针对视觉 AI 模型的基于动态掩码的后门攻击：蘑菇检测案例研究",
            "abstract_cn": "深度学习彻底改变了计算机视觉领域的众多任务，包括图像分类、图像分割和目标检测。然而，深度学习模型的日益部署使其面临各种对抗性攻击，包括后门攻击。本文提出了一种新颖的基于动态掩码的后门攻击方法，专为目标检测模型设计。我们利用数据集中毒技术嵌入恶意触发器，使在此受损数据集上训练的任何模型都容易受到后门攻击。我们特别关注蘑菇检测数据集，以展示此类攻击对关键现实生活领域造成的实际风险。我们的工作还强调了创建详细的后门攻击场景的重要性，以说明与外包实践相关的重大风险。我们的方法利用 SAM（一种最新且强大的图像分割 AI 模型）来创建用于动态触发放置的掩码，从而引入一种新的隐秘攻击方法。通过大量的实验，我们表明，我们复杂的攻击场景使用 YOLOv7 对象检测模型在干净数据上保持了高精度，同时对中毒样本实现了高攻击成功率。我们的方法超越了基于静态和一致模式的传统后门注入方法。我们的研究结果强调，迫切需要采取强有力的对策来保护深度学习模型免受这些不断变化的对抗性威胁的影响。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18464v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18464v1",
            "title": "Fair-Eye Net: A Fair, Trustworthy, Multimodal Integrated Glaucoma Full Chain AI System",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Fair-Eye Net: A Fair, Trustworthy, Multimodal Integrated Glaucoma Full Chain AI System"
            },
            "updated": "2026-01-26T13:12:24Z",
            "updated_parsed": [
                2026,
                1,
                26,
                13,
                12,
                24,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18464v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18464v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Glaucoma is a top cause of irreversible blindness globally, making early detection and longitudinal follow-up pivotal to preventing permanent vision loss. Current screening and progression assessment, however, rely on single tests or loosely linked examinations, introducing subjectivity and fragmented care. Limited access to high-quality imaging tools and specialist expertise further compromises consistency and equity in real-world use. To address these gaps, we developed Fair-Eye Net, a fair, reliable multimodal AI system closing the clinical loop from glaucoma screening to follow-up and risk alerting. It integrates fundus photos, OCT structural metrics, VF functional indices, and demographic factors via a dual-stream heterogeneous fusion architecture, with an uncertainty-aware hierarchical gating strategy for selective prediction and safe referral. A fairness constraint reduces missed diagnoses in disadvantaged subgroups. Experimental results show it achieved an AUC of 0.912 (96.7% specificity), cut racial false-negativity disparity by 73.4% (12.31% to 3.28%), maintained stable cross-domain performance, and enabled 3-12 months of early risk alerts (92% sensitivity, 88% specificity). Unlike post hoc fairness adjustments, Fair-Eye Net optimizes fairness as a primary goal with clinical reliability via multitask learning, offering a reproducible path for clinical translation and large-scale deployment to advance global eye health equity.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Glaucoma is a top cause of irreversible blindness globally, making early detection and longitudinal follow-up pivotal to preventing permanent vision loss. Current screening and progression assessment, however, rely on single tests or loosely linked examinations, introducing subjectivity and fragmented care. Limited access to high-quality imaging tools and specialist expertise further compromises consistency and equity in real-world use. To address these gaps, we developed Fair-Eye Net, a fair, reliable multimodal AI system closing the clinical loop from glaucoma screening to follow-up and risk alerting. It integrates fundus photos, OCT structural metrics, VF functional indices, and demographic factors via a dual-stream heterogeneous fusion architecture, with an uncertainty-aware hierarchical gating strategy for selective prediction and safe referral. A fairness constraint reduces missed diagnoses in disadvantaged subgroups. Experimental results show it achieved an AUC of 0.912 (96.7% specificity), cut racial false-negativity disparity by 73.4% (12.31% to 3.28%), maintained stable cross-domain performance, and enabled 3-12 months of early risk alerts (92% sensitivity, 88% specificity). Unlike post hoc fairness adjustments, Fair-Eye Net optimizes fairness as a primary goal with clinical reliability via multitask learning, offering a reproducible path for clinical translation and large-scale deployment to advance global eye health equity."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T13:12:24Z",
            "published_parsed": [
                2026,
                1,
                26,
                13,
                12,
                24,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Wenbin Wei"
                },
                {
                    "name": "Suyuan Yao"
                },
                {
                    "name": "Cheng Huang"
                },
                {
                    "name": "Xiangyu Gao"
                }
            ],
            "author_detail": {
                "name": "Xiangyu Gao"
            },
            "author": "Xiangyu Gao",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "慧眼网：公平、可信、多模态一体化的青光眼全链人工智能系统",
            "abstract_cn": "青光眼是全球不可逆失明的首要原因，因此早期发现和纵向随访对于预防永久性视力丧失至关重要。然而，目前的筛查和进展评估依赖于单一测试或松散联系的检查，引入了主观性和分散的护理。获得高质量成像工具和专业知识的机会有限，进一步损害了实际使用中的一致性和公平性。为了弥补这些差距，我们开发了 Fair-Eye Net，这是一个公平、可靠的多模式人工智能系统，关闭了从青光眼筛查到随访和风险警报的临床循环。它通过双流异构融合架构集成了眼底照片、OCT 结构指标、VF 功能指数和人口统计因素，以及用于选择性预测和安全转诊的不确定性感知分层门控策略。公平约束减少了弱势群体的漏诊。实验结果显示，其 AUC 为 0.912（特异性为 96.7%），种族假阴性差异缩小了 73.4%（12.31% 至 3.28%），保持了稳定的跨域性能，并实现了 3-12 个月的早期风险警报（敏感性为 92%，特异性为 88%）。与事后公平性调整不同，Fair-Eye Net 通过多任务学习以临床可靠性优化公平性作为主要目标，为临床转化和大规模部署提供可重复的路径，以促进全球眼健康公平性。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18493v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18493v1",
            "title": "DisasterInsight: A Multimodal Benchmark for Function-Aware and Grounded Disaster Assessment",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "DisasterInsight: A Multimodal Benchmark for Function-Aware and Grounded Disaster Assessment"
            },
            "updated": "2026-01-26T13:48:11Z",
            "updated_parsed": [
                2026,
                1,
                26,
                13,
                48,
                11,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18493v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18493v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Timely interpretation of satellite imagery is critical for disaster response, yet existing vision-language benchmarks for remote sensing largely focus on coarse labels and image-level recognition, overlooking the functional understanding and instruction robustness required in real humanitarian workflows. We introduce DisasterInsight, a multimodal benchmark designed to evaluate vision-language models (VLMs) on realistic disaster analysis tasks. DisasterInsight restructures the xBD dataset into approximately 112K building-centered instances and supports instruction-diverse evaluation across multiple tasks, including building-function classification, damage-level and disaster-type classification, counting, and structured report generation aligned with humanitarian assessment guidelines.\n  To establish domain-adapted baselines, we propose DI-Chat, obtained by fine-tuning existing VLM backbones on disaster-specific instruction data using parameter-efficient Low-Rank Adaptation (LoRA). Extensive experiments on state-of-the-art generic and remote-sensing VLMs reveal substantial performance gaps across tasks, particularly in damage understanding and structured report generation. DI-Chat achieves significant improvements on damage-level and disaster-type classification as well as report generation quality, while building-function classification remains challenging for all evaluated models. DisasterInsight provides a unified benchmark for studying grounded multimodal reasoning in disaster imagery.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Timely interpretation of satellite imagery is critical for disaster response, yet existing vision-language benchmarks for remote sensing largely focus on coarse labels and image-level recognition, overlooking the functional understanding and instruction robustness required in real humanitarian workflows. We introduce DisasterInsight, a multimodal benchmark designed to evaluate vision-language models (VLMs) on realistic disaster analysis tasks. DisasterInsight restructures the xBD dataset into approximately 112K building-centered instances and supports instruction-diverse evaluation across multiple tasks, including building-function classification, damage-level and disaster-type classification, counting, and structured report generation aligned with humanitarian assessment guidelines.\n  To establish domain-adapted baselines, we propose DI-Chat, obtained by fine-tuning existing VLM backbones on disaster-specific instruction data using parameter-efficient Low-Rank Adaptation (LoRA). Extensive experiments on state-of-the-art generic and remote-sensing VLMs reveal substantial performance gaps across tasks, particularly in damage understanding and structured report generation. DI-Chat achieves significant improvements on damage-level and disaster-type classification as well as report generation quality, while building-function classification remains challenging for all evaluated models. DisasterInsight provides a unified benchmark for studying grounded multimodal reasoning in disaster imagery."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T13:48:11Z",
            "published_parsed": [
                2026,
                1,
                26,
                13,
                48,
                11,
                0,
                26,
                0
            ],
            "arxiv_comment": "Under review at ICPR 2026",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Sara Tehrani"
                },
                {
                    "name": "Yonghao Xu"
                },
                {
                    "name": "Leif Haglund"
                },
                {
                    "name": "Amanda Berg"
                },
                {
                    "name": "Michael Felsberg"
                }
            ],
            "author_detail": {
                "name": "Michael Felsberg"
            },
            "author": "Michael Felsberg",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "DisasterInsight：功能感知和扎根灾害评估的多模式基准",
            "abstract_cn": "卫星图像的及时解释对于灾难响应至关重要，但现有的遥感视觉语言基准主要集中在粗略标签和图像级识别上，忽视了实际人道主义工作流程中所需的功能理解和指令稳健性。我们推出了 DisasterInsight，这是一个多模式基准测试，旨在评估现实灾难分析任务的视觉语言模型 (VLM)。 DisasterInsight 将 xBD 数据集重组为大约 112K 以建筑为中心的实例，并支持跨多个任务的指令多样化评估，包括建筑功能分类、损坏级别和灾难类型分类、计数以及符合人道主义评估指南的结构化报告生成。\n  为了建立域适应基线，我们提出了 DI-Chat，它是通过使用参数高效的低阶适应 (LoRA) 对灾难特定指令数据上的现有 VLM 主干进行微调而获得的。对最先进的通用和遥感 VLM 进行的广泛实验揭示了任务之间的巨大性能差距，特别是在损伤理解和结构化报告生成方面。 DI-Chat 在损害级别和灾害类型分类以及报告生成质量方面取得了显着改进，而建筑功能分类对于所有评估模型来说仍然具有挑战性。 DisasterInsight 为研究灾难图像中的扎根多模态推理提供了统一的基准。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18851v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18851v1",
            "title": "SelfieAvatar: Real-time Head Avatar reenactment from a Selfie Video",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "SelfieAvatar: Real-time Head Avatar reenactment from a Selfie Video"
            },
            "updated": "2026-01-26T14:26:16Z",
            "updated_parsed": [
                2026,
                1,
                26,
                14,
                26,
                16,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18851v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18851v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Head avatar reenactment focuses on creating animatable personal avatars from monocular videos, serving as a foundational element for applications like social signal understanding, gaming, human-machine interaction, and computer vision. Recent advances in 3D Morphable Model (3DMM)-based facial reconstruction methods have achieved remarkable high-fidelity face estimation. However, on the one hand, they struggle to capture the entire head, including non-facial regions and background details in real time, which is an essential aspect for producing realistic, high-fidelity head avatars. On the other hand, recent approaches leveraging generative adversarial networks (GANs) for head avatar generation from videos can achieve high-quality reenactments but encounter limitations in reproducing fine-grained head details, such as wrinkles and hair textures. In addition, existing methods generally rely on a large amount of training data, and rarely focus on using only a simple selfie video to achieve avatar reenactment. To address these challenges, this study introduces a method for detailed head avatar reenactment using a selfie video. The approach combines 3DMMs with a StyleGAN-based generator. A detailed reconstruction model is proposed, incorporating mixed loss functions for foreground reconstruction and avatar image generation during adversarial training to recover high-frequency details. Qualitative and quantitative evaluations on self-reenactment and cross-reenactment tasks demonstrate that the proposed method achieves superior head avatar reconstruction with rich and intricate textures compared to existing approaches.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Head avatar reenactment focuses on creating animatable personal avatars from monocular videos, serving as a foundational element for applications like social signal understanding, gaming, human-machine interaction, and computer vision. Recent advances in 3D Morphable Model (3DMM)-based facial reconstruction methods have achieved remarkable high-fidelity face estimation. However, on the one hand, they struggle to capture the entire head, including non-facial regions and background details in real time, which is an essential aspect for producing realistic, high-fidelity head avatars. On the other hand, recent approaches leveraging generative adversarial networks (GANs) for head avatar generation from videos can achieve high-quality reenactments but encounter limitations in reproducing fine-grained head details, such as wrinkles and hair textures. In addition, existing methods generally rely on a large amount of training data, and rarely focus on using only a simple selfie video to achieve avatar reenactment. To address these challenges, this study introduces a method for detailed head avatar reenactment using a selfie video. The approach combines 3DMMs with a StyleGAN-based generator. A detailed reconstruction model is proposed, incorporating mixed loss functions for foreground reconstruction and avatar image generation during adversarial training to recover high-frequency details. Qualitative and quantitative evaluations on self-reenactment and cross-reenactment tasks demonstrate that the proposed method achieves superior head avatar reconstruction with rich and intricate textures compared to existing approaches."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T14:26:16Z",
            "published_parsed": [
                2026,
                1,
                26,
                14,
                26,
                16,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Wei Liang"
                },
                {
                    "name": "Hui Yu"
                },
                {
                    "name": "Derui Ding"
                },
                {
                    "name": "Rachael E. Jack"
                },
                {
                    "name": "Philippe G. Schyns"
                }
            ],
            "author_detail": {
                "name": "Philippe G. Schyns"
            },
            "author": "Philippe G. Schyns",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "SelfieAvatar：自拍视频中的实时头像重演",
            "abstract_cn": "头部头像重现专注于从单眼视频创建可动画的个人头像，作为社交信号理解、游戏、人机交互和计算机视觉等应用的基础元素。基于 3D Morphable Model (3DMM) 的面部重建方法的最新进展已经实现了显着的高保真面部估计。然而，一方面，他们很难实时捕捉整个头部，包括非面部区域和背景细节，这是制作逼真、高保真头部头像的重要方面。另一方面，最近利用生成对抗网络（GAN）从视频生成头部头像的方法可以实现高质量的重演，但在再现细粒度头部细节（例如皱纹和头发纹理）方面遇到限制。此外，现有的方法一般依赖于大量的训练数据，很少专注于仅使用简单的自拍视频来实现头像重演。为了解决这些挑战，本研究介绍了一种使用自拍视频详细重现头部头像的方法。该方法将 3DMM 与基于 StyleGAN 的生成器相结合。提出了一种详细的重建模型，在对抗训练期间结合用于前景重建和头像图像生成的混合损失函数来恢复高频细节。对自我重演和交叉重演任务的定性和定量评估表明，与现有方法相比，所提出的方法可以实现具有丰富且复杂纹理的优质头部头像重建。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18543v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18543v1",
            "title": "GenAgent: Scaling Text-to-Image Generation via Agentic Multimodal Reasoning",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "GenAgent: Scaling Text-to-Image Generation via Agentic Multimodal Reasoning"
            },
            "updated": "2026-01-26T14:49:04Z",
            "updated_parsed": [
                2026,
                1,
                26,
                14,
                49,
                4,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18543v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18543v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We introduce GenAgent, unifying visual understanding and generation through an agentic multimodal model. Unlike unified models that face expensive training costs and understanding-generation trade-offs, GenAgent decouples these capabilities through an agentic framework: understanding is handled by the multimodal model itself, while generation is achieved by treating image generation models as invokable tools. Crucially, unlike existing modular systems constrained by static pipelines, this design enables autonomous multi-turn interactions where the agent generates multimodal chains-of-thought encompassing reasoning, tool invocation, judgment, and reflection to iteratively refine outputs. We employ a two-stage training strategy: first, cold-start with supervised fine-tuning on high-quality tool invocation and reflection data to bootstrap agent behaviors; second, end-to-end agentic reinforcement learning combining pointwise rewards (final image quality) and pairwise rewards (reflection accuracy), with trajectory resampling for enhanced multi-turn exploration. GenAgent significantly boosts base generator(FLUX.1-dev) performance on GenEval++ (+23.6\\%) and WISE (+14\\%). Beyond performance gains, our framework demonstrates three key properties: 1) cross-tool generalization to generators with varying capabilities, 2) test-time scaling with consistent improvements across interaction rounds, and 3) task-adaptive reasoning that automatically adjusts to different tasks. Our code will be available at \\href{https://github.com/deep-kaixun/GenAgent}{this url}.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We introduce GenAgent, unifying visual understanding and generation through an agentic multimodal model. Unlike unified models that face expensive training costs and understanding-generation trade-offs, GenAgent decouples these capabilities through an agentic framework: understanding is handled by the multimodal model itself, while generation is achieved by treating image generation models as invokable tools. Crucially, unlike existing modular systems constrained by static pipelines, this design enables autonomous multi-turn interactions where the agent generates multimodal chains-of-thought encompassing reasoning, tool invocation, judgment, and reflection to iteratively refine outputs. We employ a two-stage training strategy: first, cold-start with supervised fine-tuning on high-quality tool invocation and reflection data to bootstrap agent behaviors; second, end-to-end agentic reinforcement learning combining pointwise rewards (final image quality) and pairwise rewards (reflection accuracy), with trajectory resampling for enhanced multi-turn exploration. GenAgent significantly boosts base generator(FLUX.1-dev) performance on GenEval++ (+23.6\\%) and WISE (+14\\%). Beyond performance gains, our framework demonstrates three key properties: 1) cross-tool generalization to generators with varying capabilities, 2) test-time scaling with consistent improvements across interaction rounds, and 3) task-adaptive reasoning that automatically adjusts to different tasks. Our code will be available at \\href{https://github.com/deep-kaixun/GenAgent}{this url}."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T14:49:04Z",
            "published_parsed": [
                2026,
                1,
                26,
                14,
                49,
                4,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Kaixun Jiang"
                },
                {
                    "name": "Yuzheng Wang"
                },
                {
                    "name": "Junjie Zhou"
                },
                {
                    "name": "Pandeng Li"
                },
                {
                    "name": "Zhihang Liu"
                },
                {
                    "name": "Chen-Wei Xie"
                },
                {
                    "name": "Zhaoyu Chen"
                },
                {
                    "name": "Yun Zheng"
                },
                {
                    "name": "Wenqiang Zhang"
                }
            ],
            "author_detail": {
                "name": "Wenqiang Zhang"
            },
            "author": "Wenqiang Zhang",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "GenAgent：通过代理多模态推理扩展文本到图像的生成",
            "abstract_cn": "我们引入 GenAgent，通过代理多模态模型统一视觉理解和生成。与面临昂贵的训练成本和理解生成权衡的统一模型不同，GenAgent 通过代理框架将这些功能解耦：理解由多模态模型本身处理，而生成是通过将图像生成模型视为可调用工具来实现的。至关重要的是，与受静态管道约束的现有模块化系统不同，这种设计可以实现自主多轮交互，其中代理生成包含推理、工具调用、判断和反射的多模式思想链，以迭代地完善输出。我们采用两阶段训练策略：首先，冷启动，对高质量工具调用和反射数据进行监督微调，以引导代理行为；其次，端到端代理强化学习结合了点式奖励（最终图像质量）和成对奖励（反射准确性），并通过轨迹重采样来增强多轮探索。 GenAgent 显着提高了 GenEval++ (+23.6\\%) 和 WISE (+14\\%) 上的基本生成器 (FLUX.1-dev) 性能。除了性能提升之外，我们的框架还展示了三个关键属性：1）对具有不同功能的生成器的跨工具泛化，2）测试时间扩展，在交互轮次中具有一致的改进，以及3）自动调整以适应不同任务的任务自适应推理。我们的代码可以在 \\href{https://github.com/deep-kaixun/GenAgent}{this url} 获取。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18547v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18547v1",
            "title": "REMAC: Reference-Based Martian Asymmetrical Image Compression",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "REMAC: Reference-Based Martian Asymmetrical Image Compression"
            },
            "updated": "2026-01-26T14:55:17Z",
            "updated_parsed": [
                2026,
                1,
                26,
                14,
                55,
                17,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18547v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18547v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                },
                {
                    "rel": "related",
                    "href": "https://doi.org/10.1109/TGRS.2025.3649222",
                    "title": "doi",
                    "type": "text/html"
                }
            ],
            "summary": "To expedite space exploration on Mars, it is indispensable to develop an efficient Martian image compression method for transmitting images through the constrained Mars-to-Earth communication channel. Although the existing learned compression methods have achieved promising results for natural images from earth, there remain two critical issues that hinder their effectiveness for Martian image compression: 1) They overlook the highly-limited computational resources on Mars; 2) They do not utilize the strong \\textit{inter-image} similarities across Martian images to advance image compression performance. Motivated by our empirical analysis of the strong \\textit{intra-} and \\textit{inter-image} similarities from the perspective of texture, color, and semantics, we propose a reference-based Martian asymmetrical image compression (REMAC) approach, which shifts computational complexity from the encoder to the resource-rich decoder and simultaneously improves compression performance. To leverage \\textit{inter-image} similarities, we propose a reference-guided entropy module and a ref-decoder that utilize useful information from reference images, reducing redundant operations at the encoder and achieving superior compression performance. To exploit \\textit{intra-image} similarities, the ref-decoder adopts a deep, multi-scale architecture with enlarged receptive field size to model long-range spatial dependencies. Additionally, we develop a latent feature recycling mechanism to further alleviate the extreme computational constraints on Mars. Experimental results show that REMAC reduces encoder complexity by 43.51\\% compared to the state-of-the-art method, while achieving a BD-PSNR gain of 0.2664 dB.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "To expedite space exploration on Mars, it is indispensable to develop an efficient Martian image compression method for transmitting images through the constrained Mars-to-Earth communication channel. Although the existing learned compression methods have achieved promising results for natural images from earth, there remain two critical issues that hinder their effectiveness for Martian image compression: 1) They overlook the highly-limited computational resources on Mars; 2) They do not utilize the strong \\textit{inter-image} similarities across Martian images to advance image compression performance. Motivated by our empirical analysis of the strong \\textit{intra-} and \\textit{inter-image} similarities from the perspective of texture, color, and semantics, we propose a reference-based Martian asymmetrical image compression (REMAC) approach, which shifts computational complexity from the encoder to the resource-rich decoder and simultaneously improves compression performance. To leverage \\textit{inter-image} similarities, we propose a reference-guided entropy module and a ref-decoder that utilize useful information from reference images, reducing redundant operations at the encoder and achieving superior compression performance. To exploit \\textit{intra-image} similarities, the ref-decoder adopts a deep, multi-scale architecture with enlarged receptive field size to model long-range spatial dependencies. Additionally, we develop a latent feature recycling mechanism to further alleviate the extreme computational constraints on Mars. Experimental results show that REMAC reduces encoder complexity by 43.51\\% compared to the state-of-the-art method, while achieving a BD-PSNR gain of 0.2664 dB."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.MM",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T14:55:17Z",
            "published_parsed": [
                2026,
                1,
                26,
                14,
                55,
                17,
                0,
                26,
                0
            ],
            "arxiv_comment": "Accepted for publication in IEEE Transactions on Geoscience and Remote Sensing (TGRS). 2025 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. 18 pages, 20 figures",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "arxiv_journal_ref": "Year: 2025, Volume: 64, Article Sequence Number: 5601018",
            "authors": [
                {
                    "name": "Qing Ding"
                },
                {
                    "name": "Mai Xu"
                },
                {
                    "name": "Shengxi Li"
                },
                {
                    "name": "Xin Deng"
                },
                {
                    "name": "Xin Zou"
                }
            ],
            "author_detail": {
                "name": "Xin Zou"
            },
            "author": "Xin Zou",
            "arxiv_doi": "10.1109/TGRS.2025.3649222",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "REMAC：基于参考的火星非对称图像压缩",
            "abstract_cn": "为了加快火星太空探索，必须开发一种有效的火星图像压缩方法，通过受限的火星地地通信通道传输图像。尽管现有的学习压缩方法在处理来自地球的自然图像方面取得了可喜的结果，但仍然存在两个阻碍其在火星图像压缩方面的有效性的关键问题：1）它们忽视了火星上高度有限的计算资源； 2）他们没有利用火星图像之间强大的\\textit{图像间}相似性来提高图像压缩性能。受我们从纹理、颜色和语义的角度对 \\textit{intra-} 和 \\textit{inter-image} 相似性进行实证分析的启发，我们提出了一种基于参考的火星非对称图像压缩（REMAC）方法，该方法将计算复杂性从编码器转移到资源丰富的解码器，同时提高了压缩性能。为了利用 \\textit{图像间} 相似性，我们提出了一个参考引导熵模块和一个参考解码器，它利用参考图像中的有用信息，减少编码器的冗余操作并实现卓越的压缩性能。为了利用 \\textit{图像内} 相似性，参考解码器采用了具有扩大感受野大小的深度、多尺度架构来建模远程空间依赖性。此外，我们开发了一种潜在特征回收机制，以进一步缓解火星上的极端计算限制。实验结果表明，与最先进的方法相比，REMAC 将编码器复杂度降低了 43.51%，同时实现了 0.2664 dB 的 BD-PSNR 增益。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18556v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18556v1",
            "title": "Generative Diffusion Augmentation with Quantum-Enhanced Discrimination for Medical Image Diagnosis",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Generative Diffusion Augmentation with Quantum-Enhanced Discrimination for Medical Image Diagnosis"
            },
            "updated": "2026-01-26T15:05:19Z",
            "updated_parsed": [
                2026,
                1,
                26,
                15,
                5,
                19,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18556v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18556v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "In biomedical engineering, artificial intelligence has become a pivotal tool for enhancing medical diagnostics, particularly in medical image classification tasks such as detecting pneumonia from chest X-rays and breast cancer screening. However, real-world medical datasets frequently exhibit severe class imbalance, where positive samples substantially outnumber negative samples, leading to biased models with low recall rates for minority classes. This imbalance not only compromises diagnostic accuracy but also poses clinical misdiagnosis risks. To address this challenge, we propose SDA-QEC (Simplified Diffusion Augmentation with Quantum-Enhanced Classification), an innovative framework that integrates simplified diffusion-based data augmentation with quantum-enhanced feature discrimination. Our approach employs a lightweight diffusion augmentor to generate high-quality synthetic samples for minority classes, rebalancing the training distribution. Subsequently, a quantum feature layer embedded within MobileNetV2 architecture enhances the model's discriminative capability through high-dimensional feature mapping in Hilbert space. Comprehensive experiments on coronary angiography image classification demonstrate that SDA-QEC achieves 98.33% accuracy, 98.78% AUC, and 98.33% F1-score, significantly outperforming classical baselines including ResNet18, MobileNetV2, DenseNet121, and VGG16. Notably, our framework simultaneously attains 98.33% sensitivity and 98.33% specificity, achieving a balanced performance critical for clinical deployment. The proposed method validates the feasibility of integrating generative augmentation with quantum-enhanced modeling in real-world medical imaging tasks, offering a novel research pathway for developing highly reliable medical AI systems in small-sample, highly imbalanced, and high-risk diagnostic scenarios.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "In biomedical engineering, artificial intelligence has become a pivotal tool for enhancing medical diagnostics, particularly in medical image classification tasks such as detecting pneumonia from chest X-rays and breast cancer screening. However, real-world medical datasets frequently exhibit severe class imbalance, where positive samples substantially outnumber negative samples, leading to biased models with low recall rates for minority classes. This imbalance not only compromises diagnostic accuracy but also poses clinical misdiagnosis risks. To address this challenge, we propose SDA-QEC (Simplified Diffusion Augmentation with Quantum-Enhanced Classification), an innovative framework that integrates simplified diffusion-based data augmentation with quantum-enhanced feature discrimination. Our approach employs a lightweight diffusion augmentor to generate high-quality synthetic samples for minority classes, rebalancing the training distribution. Subsequently, a quantum feature layer embedded within MobileNetV2 architecture enhances the model's discriminative capability through high-dimensional feature mapping in Hilbert space. Comprehensive experiments on coronary angiography image classification demonstrate that SDA-QEC achieves 98.33% accuracy, 98.78% AUC, and 98.33% F1-score, significantly outperforming classical baselines including ResNet18, MobileNetV2, DenseNet121, and VGG16. Notably, our framework simultaneously attains 98.33% sensitivity and 98.33% specificity, achieving a balanced performance critical for clinical deployment. The proposed method validates the feasibility of integrating generative augmentation with quantum-enhanced modeling in real-world medical imaging tasks, offering a novel research pathway for developing highly reliable medical AI systems in small-sample, highly imbalanced, and high-risk diagnostic scenarios."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.LG",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T15:05:19Z",
            "published_parsed": [
                2026,
                1,
                26,
                15,
                5,
                19,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Jingsong Xia"
                },
                {
                    "name": "Siqi Wang"
                }
            ],
            "author_detail": {
                "name": "Siqi Wang"
            },
            "author": "Siqi Wang",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "用于医学图像诊断的量子增强辨别生成扩散增强",
            "abstract_cn": "在生物医学工程中，人工智能已成为增强医疗诊断的关键工具，特别是在医学图像分类任务中，例如通过胸部 X 光检测肺炎和乳腺癌筛查。然而，现实世界的医学数据集经常表现出严重的类别不平衡，其中正样本大大超过负样本，导致少数类别的召回率较低的有偏差模型。这种不平衡不仅会影响诊断准确性，还会带来临床误诊风险。为了应对这一挑战，我们提出了 SDA-QEC（具有量子增强分类的简化扩散增强），这是一种创新框架，它将基于简化扩散的数据增强与量子增强特征辨别相结合。我们的方法采用轻量级扩散增强器为少数类别生成高质量的合成样本，重新平衡训练分布。随后，MobileNetV2 架构中嵌入的量子特征层通过希尔伯特空间中的高维特征映射增强了模型的判别能力。冠状动脉造影图像分类的综合实验表明，SDA-QEC 的准确率达到 98.33%，AUC 达到 98.78%，F1 分数达到 98.33%，显着优于 ResNet18、MobileNetV2、DenseNet121 和 VGG16 等经典基线。值得注意的是，我们的框架同时达到了 98.33% 的敏感性和 98.33% 的特异性，实现了对临床部署至关重要的平衡性能。该方法验证了在现实世界的医学成像任务中将生成增强与量子增强建模相结合的可行性，为在小样本、高度不平衡和高风险的诊断场景中开发高可靠的医疗人工智能系统提供了一种新的研究途径。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18560v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18560v1",
            "title": "AI-enabled Satellite Edge Computing: A Single-Pixel Feature based Shallow Classification Model for Hyperspectral Imaging",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "AI-enabled Satellite Edge Computing: A Single-Pixel Feature based Shallow Classification Model for Hyperspectral Imaging"
            },
            "updated": "2026-01-26T15:07:31Z",
            "updated_parsed": [
                2026,
                1,
                26,
                15,
                7,
                31,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18560v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18560v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "As the important component of the Earth observation system, hyperspectral imaging satellites provide high-fidelity and enriched information for the formulation of related policies due to the powerful spectral measurement capabilities. However, the transmission speed of the satellite downlink has become a major bottleneck in certain applications, such as disaster monitoring and emergency mapping, which demand a fast response ability. We propose an efficient AI-enabled Satellite Edge Computing paradigm for hyperspectral image classification, facilitating the satellites to attain autonomous decision-making. To accommodate the resource constraints of satellite platforms, the proposed method adopts a lightweight, non-deep learning framework integrated with a few-shot learning strategy. Moreover, onboard processing on satellites could be faced with sensor failure and scan pattern errors, which result in degraded image quality with bad/misaligned pixels and mixed noise. To address these challenges, we develop a novel two-stage pixel-wise label propagation scheme that utilizes only intrinsic spectral features at the single pixel level without the necessity to consider spatial structural information as requested by deep neural networks. In the first stage, initial pixel labels are obtained by propagating selected anchor labels through the constructed anchor-pixel affinity matrix. Subsequently, a top-k pruned sparse graph is generated by directly computing pixel-level similarities. In the second stage, a closed-form solution derived from the sparse graph is employed to replace iterative computations. Furthermore, we developed a rank constraint-based graph clustering algorithm to determine the anchor labels.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "As the important component of the Earth observation system, hyperspectral imaging satellites provide high-fidelity and enriched information for the formulation of related policies due to the powerful spectral measurement capabilities. However, the transmission speed of the satellite downlink has become a major bottleneck in certain applications, such as disaster monitoring and emergency mapping, which demand a fast response ability. We propose an efficient AI-enabled Satellite Edge Computing paradigm for hyperspectral image classification, facilitating the satellites to attain autonomous decision-making. To accommodate the resource constraints of satellite platforms, the proposed method adopts a lightweight, non-deep learning framework integrated with a few-shot learning strategy. Moreover, onboard processing on satellites could be faced with sensor failure and scan pattern errors, which result in degraded image quality with bad/misaligned pixels and mixed noise. To address these challenges, we develop a novel two-stage pixel-wise label propagation scheme that utilizes only intrinsic spectral features at the single pixel level without the necessity to consider spatial structural information as requested by deep neural networks. In the first stage, initial pixel labels are obtained by propagating selected anchor labels through the constructed anchor-pixel affinity matrix. Subsequently, a top-k pruned sparse graph is generated by directly computing pixel-level similarities. In the second stage, a closed-form solution derived from the sparse graph is employed to replace iterative computations. Furthermore, we developed a rank constraint-based graph clustering algorithm to determine the anchor labels."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T15:07:31Z",
            "published_parsed": [
                2026,
                1,
                26,
                15,
                7,
                31,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Li Fang"
                },
                {
                    "name": "Tianyu Li"
                },
                {
                    "name": "Yanghong Lin"
                },
                {
                    "name": "Shudong Zhou"
                },
                {
                    "name": "Wei Yao"
                }
            ],
            "author_detail": {
                "name": "Wei Yao"
            },
            "author": "Wei Yao",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "支持人工智能的卫星边缘计算：基于单像素特征的高光谱成像浅层分类模型",
            "abstract_cn": "高光谱成像卫星作为对地观测系统的重要组成部分，凭借强大的光谱测量能力，为相关政策的制定提供高保真、丰富的信息。然而，在灾害监测、应急测绘等需要快速响应能力的应用中，卫星下行链路的传输速度已成为主要瓶颈。我们提出了一种高效的人工智能卫星边缘计算范例，用于高光谱图像分类，促进卫星实现自主决策。为了适应卫星平台的资源限制，该方法采用了轻量级的非深度学习框架，并结合了少量学习策略。此外，卫星上的机载处理可能会面临传感器故障和扫描模式错误，从而导致图像质量下降、像素不良/未对齐和混合噪声。为了解决这些挑战，我们开发了一种新颖的两阶段像素级标签传播方案，该方案仅利用单像素级别的固有光谱特征，而无需考虑深度神经网络所要求的空间结构信息。在第一阶段，通过构建的锚像素亲和力矩阵传播选定的锚标签来获得初始像素标签。随后，通过直接计算像素级相似度来生成 top-k 剪枝稀疏图。在第二阶段，采用从稀疏图导出的封闭式解来代替迭代计算。此外，我们开发了一种基于排序约束的图聚类算法来确定锚标签。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18585v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18585v1",
            "title": "GimmBO: Interactive Generative Image Model Merging via Bayesian Optimization",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "GimmBO: Interactive Generative Image Model Merging via Bayesian Optimization"
            },
            "updated": "2026-01-26T15:32:16Z",
            "updated_parsed": [
                2026,
                1,
                26,
                15,
                32,
                16,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18585v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18585v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Fine-tuning-based adaptation is widely used to customize diffusion-based image generation, leading to large collections of community-created adapters that capture diverse subjects and styles. Adapters derived from the same base model can be merged with weights, enabling the synthesis of new visual results within a vast and continuous design space. To explore this space, current workflows rely on manual slider-based tuning, an approach that scales poorly and makes weight selection difficult, even when the candidate set is limited to 20-30 adapters. We propose GimmBO to support interactive exploration of adapter merging for image generation through Preferential Bayesian Optimization (PBO). Motivated by observations from real-world usage, including sparsity and constrained weight ranges, we introduce a two-stage BO backend that improves sampling efficiency and convergence in high-dimensional spaces. We evaluate our approach with simulated users and a user study, demonstrating improved convergence, high success rates, and consistent gains over BO and line-search baselines, and further show the flexibility of the framework through several extensions.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Fine-tuning-based adaptation is widely used to customize diffusion-based image generation, leading to large collections of community-created adapters that capture diverse subjects and styles. Adapters derived from the same base model can be merged with weights, enabling the synthesis of new visual results within a vast and continuous design space. To explore this space, current workflows rely on manual slider-based tuning, an approach that scales poorly and makes weight selection difficult, even when the candidate set is limited to 20-30 adapters. We propose GimmBO to support interactive exploration of adapter merging for image generation through Preferential Bayesian Optimization (PBO). Motivated by observations from real-world usage, including sparsity and constrained weight ranges, we introduce a two-stage BO backend that improves sampling efficiency and convergence in high-dimensional spaces. We evaluate our approach with simulated users and a user study, demonstrating improved convergence, high success rates, and consistent gains over BO and line-search baselines, and further show the flexibility of the framework through several extensions."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.GR",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T15:32:16Z",
            "published_parsed": [
                2026,
                1,
                26,
                15,
                32,
                16,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Chenxi Liu"
                },
                {
                    "name": "Selena Ling"
                },
                {
                    "name": "Alec Jacobson"
                }
            ],
            "author_detail": {
                "name": "Alec Jacobson"
            },
            "author": "Alec Jacobson",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "GimmBO：通过贝叶斯优化的交互式生成图像模型合并",
            "abstract_cn": "基于微调的适应广泛用于定制基于扩散的图像生成，从而产生了大量社区创建的适配器，可以捕捉不同的主题和风格。来自同一基本模型的适配器可以与权重合并，从而能够在广阔且连续的设计空间中合成新的视觉结果。为了探索这个空间，当前的工作流程依赖于基于滑块的手动调整，这种方法扩展性很差，并且使得权重选择变得困难，即使候选集仅限于 20-30 个适配器也是如此。我们建议 GimmBO 通过优先贝叶斯优化（PBO）支持适配器合并的交互式探索，以生成图像。受现实世界使用观察（包括稀疏性和约束权重范围）的启发，我们引入了两阶段 BO 后端，可以提高高维空间中的采样效率和收敛性。我们通过模拟用户和用户研究来评估我们的方法，证明了改进的收敛性、高成功率以及相对于 BO 和线搜索基线的一致增益，并通过多个扩展进一步展示了该框架的灵活性。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18589v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18589v1",
            "title": "AGSP-DSA: An Adaptive Graph Signal Processing Framework for Robust Multimodal Fusion with Dynamic Semantic Alignment",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "AGSP-DSA: An Adaptive Graph Signal Processing Framework for Robust Multimodal Fusion with Dynamic Semantic Alignment"
            },
            "updated": "2026-01-26T15:35:03Z",
            "updated_parsed": [
                2026,
                1,
                26,
                15,
                35,
                3,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18589v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18589v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "In this paper, we introduce an Adaptive Graph Signal Processing with Dynamic Semantic Alignment (AGSP DSA) framework to perform robust multimodal data fusion over heterogeneous sources, including text, audio, and images. The requested approach uses a dual-graph construction to learn both intra-modal and inter-modal relations, spectral graph filtering to boost the informative signals, and effective node embedding with Multi-scale Graph Convolutional Networks (GCNs). Semantic aware attention mechanism: each modality may dynamically contribute to the context with respect to contextual relevance. The experimental outcomes on three benchmark datasets, including CMU-MOSEI, AVE, and MM-IMDB, show that AGSP-DSA performs as the state of the art. More precisely, it achieves 95.3% accuracy, 0.936 F1-score, and 0.924 mAP on CMU-MOSEI, improving MM-GNN by 2.6 percent in accuracy. It gets 93.4% accuracy and 0.911 F1-score on AVE and 91.8% accuracy and 0.886 F1-score on MM-IMDB, which demonstrate good generalization and robustness in the missing modality setting. These findings verify the efficiency of AGSP-DSA in promoting multimodal learning in sentiment analysis, event recognition and multimedia classification.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "In this paper, we introduce an Adaptive Graph Signal Processing with Dynamic Semantic Alignment (AGSP DSA) framework to perform robust multimodal data fusion over heterogeneous sources, including text, audio, and images. The requested approach uses a dual-graph construction to learn both intra-modal and inter-modal relations, spectral graph filtering to boost the informative signals, and effective node embedding with Multi-scale Graph Convolutional Networks (GCNs). Semantic aware attention mechanism: each modality may dynamically contribute to the context with respect to contextual relevance. The experimental outcomes on three benchmark datasets, including CMU-MOSEI, AVE, and MM-IMDB, show that AGSP-DSA performs as the state of the art. More precisely, it achieves 95.3% accuracy, 0.936 F1-score, and 0.924 mAP on CMU-MOSEI, improving MM-GNN by 2.6 percent in accuracy. It gets 93.4% accuracy and 0.911 F1-score on AVE and 91.8% accuracy and 0.886 F1-score on MM-IMDB, which demonstrate good generalization and robustness in the missing modality setting. These findings verify the efficiency of AGSP-DSA in promoting multimodal learning in sentiment analysis, event recognition and multimedia classification."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.MM",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T15:35:03Z",
            "published_parsed": [
                2026,
                1,
                26,
                15,
                35,
                3,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "KV Karthikeya"
                },
                {
                    "name": "Ashok Kumar Das"
                },
                {
                    "name": "Shantanu Pal"
                },
                {
                    "name": "Vivekananda Bhat K"
                },
                {
                    "name": "Arun Sekar Rajasekaran"
                }
            ],
            "author_detail": {
                "name": "Arun Sekar Rajasekaran"
            },
            "author": "Arun Sekar Rajasekaran",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "AGSP-DSA：具有动态语义对齐的鲁棒多模态融合的自适应图形信号处理框架",
            "abstract_cn": "在本文中，我们介绍了一种具有动态语义对齐的自适应图信号处理（AGSP DSA）框架，用于对文本、音频和图像等异构源执行鲁棒的多模态数据融合。所请求的方法使用双图构造来学习模内和模间关系，使用谱图过滤来增强信息信号，以及使用多尺度图卷积网络（GCN）进行有效的节点嵌入。语义感知注意机制：每种模态都可以动态地对上下文相关性做出贡献。三个基准数据集（包括 CMU-MOSEI、AVE 和 MM-IMDB）上的实验结果表明 AGSP-DSA 的性能达到了最先进的水平。更准确地说，它在 CMU-MOSEI 上实现了 95.3% 的准确率、0.936 F1 分数和 0.924 mAP，将 MM-GNN 的准确率提高了 2.6%。它在 AVE 上获得了 93.4% 的准确率和 0.911 F1 分数，在 MM-IMDB 上获得了 91.8% 的准确率和 0.886 F1 分数，这在缺失模态设置中表现出了良好的泛化性和鲁棒性。这些发现验证了 AGSP-DSA 在促进情感分析、事件识别和多媒体分类等多模态学习方面的效率。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18619v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18619v1",
            "title": "Scale-Aware Self-Supervised Learning for Segmentation of Small and Sparse Structures",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Scale-Aware Self-Supervised Learning for Segmentation of Small and Sparse Structures"
            },
            "updated": "2026-01-26T15:58:04Z",
            "updated_parsed": [
                2026,
                1,
                26,
                15,
                58,
                4,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18619v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18619v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Self-supervised learning (SSL) has emerged as a powerful strategy for representation learning under limited annotation regimes, yet its effectiveness remains highly sensitive to many factors, especially the nature of the target task. In segmentation, existing pipelines are typically tuned to large, homogeneous regions, but their performance drops when objects are small, sparse, or locally irregular. In this work, we propose a scale-aware SSL adaptation that integrates small-window cropping into the augmentation pipeline, zooming in on fine-scale structures during pretraining. We evaluate this approach across two domains with markedly different data modalities: seismic imaging, where the goal is to segment sparse faults, and neuroimaging, where the task is to delineate small cellular structures. In both settings, our method yields consistent improvements over standard and state-of-the-art baselines under label constraints, improving accuracy by up to 13% for fault segmentation and 5% for cell delineation. In contrast, large-scale features such as seismic facies or tissue regions see little benefit, underscoring that the value of SSL depends critically on the scale of the target objects. Our findings highlight the need to align SSL design with object size and sparsity, offering a general principle for buil ding more effective representation learning pipelines across scientific imaging domains.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Self-supervised learning (SSL) has emerged as a powerful strategy for representation learning under limited annotation regimes, yet its effectiveness remains highly sensitive to many factors, especially the nature of the target task. In segmentation, existing pipelines are typically tuned to large, homogeneous regions, but their performance drops when objects are small, sparse, or locally irregular. In this work, we propose a scale-aware SSL adaptation that integrates small-window cropping into the augmentation pipeline, zooming in on fine-scale structures during pretraining. We evaluate this approach across two domains with markedly different data modalities: seismic imaging, where the goal is to segment sparse faults, and neuroimaging, where the task is to delineate small cellular structures. In both settings, our method yields consistent improvements over standard and state-of-the-art baselines under label constraints, improving accuracy by up to 13% for fault segmentation and 5% for cell delineation. In contrast, large-scale features such as seismic facies or tissue regions see little benefit, underscoring that the value of SSL depends critically on the scale of the target objects. Our findings highlight the need to align SSL design with object size and sparsity, offering a general principle for buil ding more effective representation learning pipelines across scientific imaging domains."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T15:58:04Z",
            "published_parsed": [
                2026,
                1,
                26,
                15,
                58,
                4,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Jorge Quesada"
                },
                {
                    "name": "Ghassan AlRegib"
                }
            ],
            "author_detail": {
                "name": "Ghassan AlRegib"
            },
            "author": "Ghassan AlRegib",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "用于分割小型稀疏结构的尺度感知自监督学习",
            "abstract_cn": "自监督学习（SSL）已成为有限注释机制下表示学习的强大策略，但其有效性对许多因素仍然高度敏感，尤其是目标任务的性质。在分割中，现有的管道通常调整为大的、均匀的区域，但当对象小、稀疏或局部不规则时，它们的性能会下降。在这项工作中，我们提出了一种尺度感知 SSL 适配，它将小窗口裁剪集成到增强管道中，在预训练期间放大精细尺度结构。我们在两个具有明显不同数据模式的领域评估这种方法：地震成像，其目标是分割稀疏断层，以及神经成像，其任务是描绘小细胞结构。在这两种设置中，我们的方法在标签约束下比标准和最先进的基线产生了一致的改进，将故障分割的准确性提高了 13%，将细胞描绘的准确性提高了 5%。相比之下，地震相或组织区域等大尺度特征几乎没有什么好处，这强调了 SSL 的价值关键取决于目标物体的规模。我们的研究结果强调了将 SSL 设计与对象大小和稀疏性保持一致的必要性，为跨科学成像领域构建更有效的表示学习管道提供了一般原则。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18623v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18623v1",
            "title": "Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation"
            },
            "updated": "2026-01-26T16:00:36Z",
            "updated_parsed": [
                2026,
                1,
                26,
                16,
                0,
                36,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18623v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18623v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Cross-modal image translation remains brittle and inefficient. Standard diffusion approaches often rely on a single, global linear transfer between domains. We find that this shortcut forces the sampler to traverse off-manifold, high-cost regions, inflating the correction burden and inviting semantic drift. We refer to this shared failure mode as fixed-schedule domain transfer. In this paper, we embed domain-shift dynamics directly into the generative process. Our model predicts a spatially varying mixing field at every reverse step and injects an explicit, target-consistent restoration term into the drift. This in-step guidance keeps large updates on-manifold and shifts the model's role from global alignment to local residual correction. We provide a continuous-time formulation with an exact solution form and derive a practical first-order sampler that preserves marginal consistency. Empirically, across translation tasks in medical imaging, remote sensing, and electroluminescence semantic mapping, our framework improves structural fidelity and semantic consistency while converging in fewer denoising steps.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Cross-modal image translation remains brittle and inefficient. Standard diffusion approaches often rely on a single, global linear transfer between domains. We find that this shortcut forces the sampler to traverse off-manifold, high-cost regions, inflating the correction burden and inviting semantic drift. We refer to this shared failure mode as fixed-schedule domain transfer. In this paper, we embed domain-shift dynamics directly into the generative process. Our model predicts a spatially varying mixing field at every reverse step and injects an explicit, target-consistent restoration term into the drift. This in-step guidance keeps large updates on-manifold and shifts the model's role from global alignment to local residual correction. We provide a continuous-time formulation with an exact solution form and derive a practical first-order sampler that preserves marginal consistency. Empirically, across translation tasks in medical imaging, remote sensing, and electroluminescence semantic mapping, our framework improves structural fidelity and semantic consistency while converging in fewer denoising steps."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T16:00:36Z",
            "published_parsed": [
                2026,
                1,
                26,
                16,
                0,
                36,
                0,
                26,
                0
            ],
            "arxiv_comment": "Paper accepted as a conference paper at ICLR 2026",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Zihao Wang"
                },
                {
                    "name": "Yuzhou Chen"
                },
                {
                    "name": "Shaogang Ren"
                }
            ],
            "author_detail": {
                "name": "Shaogang Ren"
            },
            "author": "Shaogang Ren",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "跨模态图像翻译扩散模型中的自适应域转移",
            "abstract_cn": "跨模式图像翻译仍然脆弱且低效。标准扩散方法通常依赖于域之间的单一全局线性传输。我们发现这种捷径迫使采样器遍历非流形的高成本区域，增加了校正负担并引发语义漂移。我们将这种共享故障模式称为固定计划域传输。在本文中，我们将域转移动力学直接嵌入到生成过程中。我们的模型预测每个反向步骤中空间变化的混合场，并将一个明确的、目标一致的恢复项注入到漂移中。这种逐步指导使流形上保持大量更新，并将模型的角色从全局对齐转变为局部残差校正。我们提供了具有精确解形式的连续时间公式，并导出了保持边际一致性的实用一阶采样器。根据经验，在医学成像、遥感和电致发光语义映射的翻译任务中，我们的框架提高了结构保真度和语义一致性，同时以更少的去噪步骤收敛。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18625v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18625v1",
            "title": "CONQUER: Context-Aware Representation with Query Enhancement for Text-Based Person Search",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "CONQUER: Context-Aware Representation with Query Enhancement for Text-Based Person Search"
            },
            "updated": "2026-01-26T16:01:33Z",
            "updated_parsed": [
                2026,
                1,
                26,
                16,
                1,
                33,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18625v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18625v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Text-Based Person Search (TBPS) aims to retrieve pedestrian images from large galleries using natural language descriptions. This task, essential for public safety applications, is hindered by cross-modal discrepancies and ambiguous user queries. We introduce CONQUER, a two-stage framework designed to address these challenges by enhancing cross-modal alignment during training and adaptively refining queries at inference. During training, CONQUER employs multi-granularity encoding, complementary pair mining, and context-guided optimal matching based on Optimal Transport to learn robust embeddings. At inference, a plug-and-play query enhancement module refines vague or incomplete queries via anchor selection and attribute-driven enrichment, without requiring retraining of the backbone. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that CONQUER consistently outperforms strong baselines in both Rank-1 accuracy and mAP, yielding notable improvements in cross-domain and incomplete-query scenarios. These results highlight CONQUER as a practical and effective solution for real-world TBPS deployment. Source code is available at https://github.com/zqxie77/CONQUER.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Text-Based Person Search (TBPS) aims to retrieve pedestrian images from large galleries using natural language descriptions. This task, essential for public safety applications, is hindered by cross-modal discrepancies and ambiguous user queries. We introduce CONQUER, a two-stage framework designed to address these challenges by enhancing cross-modal alignment during training and adaptively refining queries at inference. During training, CONQUER employs multi-granularity encoding, complementary pair mining, and context-guided optimal matching based on Optimal Transport to learn robust embeddings. At inference, a plug-and-play query enhancement module refines vague or incomplete queries via anchor selection and attribute-driven enrichment, without requiring retraining of the backbone. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that CONQUER consistently outperforms strong baselines in both Rank-1 accuracy and mAP, yielding notable improvements in cross-domain and incomplete-query scenarios. These results highlight CONQUER as a practical and effective solution for real-world TBPS deployment. Source code is available at https://github.com/zqxie77/CONQUER."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T16:01:33Z",
            "published_parsed": [
                2026,
                1,
                26,
                16,
                1,
                33,
                0,
                26,
                0
            ],
            "arxiv_comment": "Accepted by ICASSP 2026",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Zequn Xie"
                }
            ],
            "author_detail": {
                "name": "Zequn Xie"
            },
            "author": "Zequn Xie",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "CONQUER：具有基于文本人员搜索的查询增强功能的上下文感知表示",
            "abstract_cn": "基于文本的人物搜索（TBPS）旨在使用自然语言描述从大型画廊中检索行人图像。这项对于公共安全应用至关重要的任务受到跨模式差异和模糊用户查询的阻碍。我们引入了 CONQUER，这是一个两阶段框架，旨在通过增强训练期间的跨模式对齐和在推理时自适应地细化查询来应对这些挑战。在训练过程中，CONQUER 采用多粒度编码、互补对挖掘和基于最佳传输的上下文引导最佳匹配来学习稳健的嵌入。在推理时，即插即用查询增强模块通过锚点选择和属性驱动的丰富来细化模糊或不完整的查询，而不需要重新训练主干网。在 CUHK-PEDES、ICFG-PEDES 和 RSTPReid 上进行的大量实验表明，CONQUER 在 Rank-1 准确率和 mAP 方面始终优于强大的基线，在跨域和不完整查询场景中产生了显着的改进。这些结果凸显了 CONQUER 作为现实世界 TBPS 部署的实用且有效的解决方案。源代码可在 https://github.com/zqxie77/CONQUER 获取。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18633v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18633v1",
            "title": "Splat-Portrait: Generalizing Talking Heads with Gaussian Splatting",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Splat-Portrait: Generalizing Talking Heads with Gaussian Splatting"
            },
            "updated": "2026-01-26T16:06:57Z",
            "updated_parsed": [
                2026,
                1,
                26,
                16,
                6,
                57,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18633v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18633v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Talking Head Generation aims at synthesizing natural-looking talking videos from speech and a single portrait image. Previous 3D talking head generation methods have relied on domain-specific heuristics such as warping-based facial motion representation priors to animate talking motions, yet still produce inaccurate 3D avatar reconstructions, thus undermining the realism of generated animations. We introduce Splat-Portrait, a Gaussian-splatting-based method that addresses the challenges of 3D head reconstruction and lip motion synthesis. Our approach automatically learns to disentangle a single portrait image into a static 3D reconstruction represented as static Gaussian Splatting, and a predicted whole-image 2D background. It then generates natural lip motion conditioned on input audio, without any motion driven priors. Training is driven purely by 2D reconstruction and score-distillation losses, without 3D supervision nor landmarks. Experimental results demonstrate that Splat-Portrait exhibits superior performance on talking head generation and novel view synthesis, achieving better visual quality compared to previous works. Our project code and supplementary documents are public available at https://github.com/stonewalking/Splat-portrait.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Talking Head Generation aims at synthesizing natural-looking talking videos from speech and a single portrait image. Previous 3D talking head generation methods have relied on domain-specific heuristics such as warping-based facial motion representation priors to animate talking motions, yet still produce inaccurate 3D avatar reconstructions, thus undermining the realism of generated animations. We introduce Splat-Portrait, a Gaussian-splatting-based method that addresses the challenges of 3D head reconstruction and lip motion synthesis. Our approach automatically learns to disentangle a single portrait image into a static 3D reconstruction represented as static Gaussian Splatting, and a predicted whole-image 2D background. It then generates natural lip motion conditioned on input audio, without any motion driven priors. Training is driven purely by 2D reconstruction and score-distillation losses, without 3D supervision nor landmarks. Experimental results demonstrate that Splat-Portrait exhibits superior performance on talking head generation and novel view synthesis, achieving better visual quality compared to previous works. Our project code and supplementary documents are public available at https://github.com/stonewalking/Splat-portrait."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T16:06:57Z",
            "published_parsed": [
                2026,
                1,
                26,
                16,
                6,
                57,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Tong Shi"
                },
                {
                    "name": "Melonie de Almeida"
                },
                {
                    "name": "Daniela Ivanova"
                },
                {
                    "name": "Nicolas Pugeault"
                },
                {
                    "name": "Paul Henderson"
                }
            ],
            "author_detail": {
                "name": "Paul Henderson"
            },
            "author": "Paul Henderson",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "Splat-Portrait：用高斯泼溅概括说话的头像",
            "abstract_cn": "Talking Head Generation 旨在从语音和单个肖像图像合成看起来自然的谈话视频。以前的 3D 头部说话生成方法依赖于特定领域的启发法，例如在动画说话动作之前基于扭曲的面部运动表示，但仍然会产生不准确的 3D 头像重建，从而破坏了生成动画的真实感。我们引入了 Splat-Portrait，这是一种基于高斯分布的方法，可解决 3D 头部重建和嘴唇运动合成的挑战。我们的方法自动学习将单个肖像图像分解为静态 3D 重建（表示为静态高斯分布）和预测的整个图像 2D 背景。然后，它会根据输入音频生成自然的嘴唇运动，而无需任何运动驱动的先验。训练纯粹由 2D 重建和分数蒸馏损失驱动，没有 3D 监督或地标。实验结果表明，Splat-Portrait 在头像生成和新颖的视图合成方面表现出优越的性能，与之前的作品相比，实现了更好的视觉质量。我们的项目代码和补充文档可在 https://github.com/stonewalking/Splat-portrait 上公开获取。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18739v2",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18739v2",
            "title": "SeNeDiF-OOD: Semantic Nested Dichotomy Fusion for Out-of-Distribution Detection Methodology in Open-World Classification. A Case Study on Monument Style Classification",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "SeNeDiF-OOD: Semantic Nested Dichotomy Fusion for Out-of-Distribution Detection Methodology in Open-World Classification. A Case Study on Monument Style Classification"
            },
            "updated": "2026-01-27T09:40:10Z",
            "updated_parsed": [
                2026,
                1,
                27,
                9,
                40,
                10,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18739v2",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18739v2",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Out-of-distribution (OOD) detection is a fundamental requirement for the reliable deployment of artificial intelligence applications in open-world environments. However, addressing the heterogeneous nature of OOD data, ranging from low-level corruption to semantic shifts, remains a complex challenge that single-stage detectors often fail to resolve. To address this issue, we propose SeNeDiF-OOD, a novel methodology based on Semantic Nested Dichotomy Fusion. This framework decomposes the detection task into a hierarchical structure of binary fusion nodes, where each layer is designed to integrate decision boundaries aligned with specific levels of semantic abstraction. To validate the proposed framework, we present a comprehensive case study using MonuMAI, a real-world architectural style recognition system exposed to an open environment. This application faces a diverse range of inputs, including non-monument images, unknown architectural styles, and adversarial attacks, making it an ideal testbed for our proposal. Through extensive experimental evaluation in this domain, results demonstrate that our hierarchical fusion methodology significantly outperforms traditional baselines, effectively filtering these diverse OOD categories while preserving in-distribution performance.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Out-of-distribution (OOD) detection is a fundamental requirement for the reliable deployment of artificial intelligence applications in open-world environments. However, addressing the heterogeneous nature of OOD data, ranging from low-level corruption to semantic shifts, remains a complex challenge that single-stage detectors often fail to resolve. To address this issue, we propose SeNeDiF-OOD, a novel methodology based on Semantic Nested Dichotomy Fusion. This framework decomposes the detection task into a hierarchical structure of binary fusion nodes, where each layer is designed to integrate decision boundaries aligned with specific levels of semantic abstraction. To validate the proposed framework, we present a comprehensive case study using MonuMAI, a real-world architectural style recognition system exposed to an open environment. This application faces a diverse range of inputs, including non-monument images, unknown architectural styles, and adversarial attacks, making it an ideal testbed for our proposal. Through extensive experimental evaluation in this domain, results demonstrate that our hierarchical fusion methodology significantly outperforms traditional baselines, effectively filtering these diverse OOD categories while preserving in-distribution performance."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T18:01:46Z",
            "published_parsed": [
                2026,
                1,
                26,
                18,
                1,
                46,
                0,
                26,
                0
            ],
            "arxiv_comment": "28 pages",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Ignacio Antequera-Sánchez"
                },
                {
                    "name": "Juan Luis Suárez-Díaz"
                },
                {
                    "name": "Rosana Montes"
                },
                {
                    "name": "Francisco Herrera"
                }
            ],
            "author_detail": {
                "name": "Francisco Herrera"
            },
            "author": "Francisco Herrera",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "SeNeDiF-OOD：开放世界分类中分布外检测方法的语义嵌套二分法融合。纪念碑风格分类案例研究",
            "abstract_cn": "分布外 (OOD) 检测是在开放世界环境中可靠部署人工智能应用程序的基本要求。然而，解决 OOD 数据的异构性质（从低级损坏到语义转换）仍然是单级检测器通常无法解决的复杂挑战。为了解决这个问题，我们提出了 SeNeDiF-OOD，一种基于语义嵌套二分法融合的新颖方法。该框架将检测任务分解为二进制融合节点的层次结构，其中每一层都旨在集成与特定语义抽象级别对齐的决策边界。为了验证所提出的框架，我们使用 MonuMAI 进行了全面的案例研究，MonuMAI 是一个暴露在开放环境中的真实建筑风格识别系统。该应用程序面临各种输入，包括非纪念碑图像、未知的建筑风格和对抗性攻击，使其成为我们提案的理想测试平台。通过该领域的广泛实验评估，结果表明我们的分层融合方法显着优于传统基线，有效过滤这些不同的 OOD 类别，同时保持分布内性能。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18891v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18891v1",
            "title": "Weakly supervised framework for wildlife detection and counting in challenging Arctic environments: a case study on caribou (Rangifer tarandus)",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Weakly supervised framework for wildlife detection and counting in challenging Arctic environments: a case study on caribou (Rangifer tarandus)"
            },
            "updated": "2026-01-26T19:02:18Z",
            "updated_parsed": [
                2026,
                1,
                26,
                19,
                2,
                18,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18891v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18891v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Caribou across the Arctic has declined in recent decades, motivating scalable and accurate monitoring approaches to guide evidence-based conservation actions and policy decisions. Manual interpretation from this imagery is labor-intensive and error-prone, underscoring the need for automatic and reliable detection across varying scenes. Yet, such automatic detection is challenging due to severe background heterogeneity, dominant empty terrain (class imbalance), small or occluded targets, and wide variation in density and scale. To make the detection model (HerdNet) more robust to these challenges, a weakly supervised patch-level pretraining based on a detection network's architecture is proposed. The detection dataset includes five caribou herds distributed across Alaska. By learning from empty vs. non-empty labels in this dataset, the approach produces early weakly supervised knowledge for enhanced detection compared to HerdNet, which is initialized from generic weights. Accordingly, the patch-based pretrain network attained high accuracy on multi-herd imagery (2017) and on an independent year's (2019) test sets (F1: 93.7%/92.6%, respectively), enabling reliable mapping of regions containing animals to facilitate manual counting on large aerial imagery. Transferred to detection, initialization from weakly supervised pretraining yielded consistent gains over ImageNet weights on both positive patches (F1: 92.6%/93.5% vs. 89.3%/88.6%), and full-image counting (F1: 95.5%/93.3% vs. 91.5%/90.4%). Remaining limitations are false positives from animal-like background clutter and false negatives related to low animal density occlusions. Overall, pretraining on coarse labels prior to detection makes it possible to rely on weakly-supervised pretrained weights even when labeled data are limited, achieving results comparable to generic-weight initialization.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Caribou across the Arctic has declined in recent decades, motivating scalable and accurate monitoring approaches to guide evidence-based conservation actions and policy decisions. Manual interpretation from this imagery is labor-intensive and error-prone, underscoring the need for automatic and reliable detection across varying scenes. Yet, such automatic detection is challenging due to severe background heterogeneity, dominant empty terrain (class imbalance), small or occluded targets, and wide variation in density and scale. To make the detection model (HerdNet) more robust to these challenges, a weakly supervised patch-level pretraining based on a detection network's architecture is proposed. The detection dataset includes five caribou herds distributed across Alaska. By learning from empty vs. non-empty labels in this dataset, the approach produces early weakly supervised knowledge for enhanced detection compared to HerdNet, which is initialized from generic weights. Accordingly, the patch-based pretrain network attained high accuracy on multi-herd imagery (2017) and on an independent year's (2019) test sets (F1: 93.7%/92.6%, respectively), enabling reliable mapping of regions containing animals to facilitate manual counting on large aerial imagery. Transferred to detection, initialization from weakly supervised pretraining yielded consistent gains over ImageNet weights on both positive patches (F1: 92.6%/93.5% vs. 89.3%/88.6%), and full-image counting (F1: 95.5%/93.3% vs. 91.5%/90.4%). Remaining limitations are false positives from animal-like background clutter and false negatives related to low animal density occlusions. Overall, pretraining on coarse labels prior to detection makes it possible to rely on weakly-supervised pretrained weights even when labeled data are limited, achieving results comparable to generic-weight initialization."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T19:02:18Z",
            "published_parsed": [
                2026,
                1,
                26,
                19,
                2,
                18,
                0,
                26,
                0
            ],
            "arxiv_comment": "30 pages, 8 figures, submitted to Frontiers in Ecology and Evolution",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Ghazaleh Serati"
                },
                {
                    "name": "Samuel Foucher"
                },
                {
                    "name": "Jerome Theau"
                }
            ],
            "author_detail": {
                "name": "Jerome Theau"
            },
            "author": "Jerome Theau",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "在充满挑战的北极环境中野生动物检测和计数的弱监督框架：驯鹿（Rangifer tarandus）的案例研究",
            "abstract_cn": "近几十年来，北极地区的驯鹿数量有所减少，这促使人们采用可扩展且准确的监测方法来指导基于证据的保护行动和政策决策。对这些图像进行手动解读是一项劳动密集型工作，而且容易出错，这凸显了在不同场景中进行自动、可靠检测的必要性。然而，由于严重的背景异质性、占主导地位的空旷地形（类别不平衡）、小或被遮挡的目标以及密度和规模的广泛变化，这种自动检测具有挑战性。为了使检测模型（HerdNet）对这些挑战更加鲁棒，提出了一种基于检测网络架构的弱监督补丁级预训练。检测数据集包括分布在阿拉斯加各地的五个驯鹿群。与从通用权重初始化的 HerdNet 相比，通过从该数据集中的空标签与非空标签学习，该方法可以产生早期的弱监督知识以增强检测。因此，基于补丁的预训练网络在多群体图像（2017 年）和独立年份（2019 年）测试集上获得了高精度（F1：分别为 93.7%/92.6%），从而能够可靠地绘制包含动物的区域，以便于对大型航空图像进行手动计数。转移到检测中，弱监督预训练的初始化在两个正块上（F1：92.6％/93.5％ vs. 89.3％/88.6％）和全图像计数（F1：95.5％/93.3％ vs. 91.5％/90.4％）上产生了与 ImageNet 权重一致的增益。其余的限制是来自类动物背景杂波的误报和与低动物密度遮挡相关的误报。总体而言，即使标记数据有限，在检测之前对粗标签进行预训练也可以依赖弱监督的预训练权重，从而实现与通用权重初始化相当的结果。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18900v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18900v1",
            "title": "RealStats: A Rigorous Real-Only Statistical Framework for Fake Image Detection",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "RealStats: A Rigorous Real-Only Statistical Framework for Fake Image Detection"
            },
            "updated": "2026-01-26T19:11:31Z",
            "updated_parsed": [
                2026,
                1,
                26,
                19,
                11,
                31,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18900v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18900v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "As generative models continue to evolve, detecting AI-generated images remains a critical challenge. While effective detection methods exist, they often lack formal interpretability and may rely on implicit assumptions about fake content, potentially limiting robustness to distributional shifts. In this work, we introduce a rigorous, statistically grounded framework for fake image detection that focuses on producing a probability score interpretable with respect to the real-image population. Our method leverages the strengths of multiple existing detectors by combining training-free statistics. We compute p-values over a range of test statistics and aggregate them using classical statistical ensembling to assess alignment with the unified real-image distribution. This framework is generic, flexible, and training-free, making it well-suited for robust fake image detection across diverse and evolving settings.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "As generative models continue to evolve, detecting AI-generated images remains a critical challenge. While effective detection methods exist, they often lack formal interpretability and may rely on implicit assumptions about fake content, potentially limiting robustness to distributional shifts. In this work, we introduce a rigorous, statistically grounded framework for fake image detection that focuses on producing a probability score interpretable with respect to the real-image population. Our method leverages the strengths of multiple existing detectors by combining training-free statistics. We compute p-values over a range of test statistics and aggregate them using classical statistical ensembling to assess alignment with the unified real-image distribution. This framework is generic, flexible, and training-free, making it well-suited for robust fake image detection across diverse and evolving settings."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.LG",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "stat.ML",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T19:11:31Z",
            "published_parsed": [
                2026,
                1,
                26,
                19,
                11,
                31,
                0,
                26,
                0
            ],
            "arxiv_comment": "22 pages, 14 figures. Accepted to AISTATS 2026",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Haim Zisman"
                },
                {
                    "name": "Uri Shaham"
                }
            ],
            "author_detail": {
                "name": "Uri Shaham"
            },
            "author": "Uri Shaham",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "RealStats：用于虚假图像检测的严格纯实数统计框架",
            "abstract_cn": "随着生成模型的不断发展，检测人工智能生成的图像仍然是一个严峻的挑战。虽然存在有效的检测方法，但它们通常缺乏正式的可解释性，并且可能依赖于关于虚假内容的隐含假设，从而可能限制分布变化的稳健性。在这项工作中，我们引入了一个严格的、基于统计的虚假图像检测框架，该框架专注于生成可相对于真实图像群体进行解释的概率得分。我们的方法通过结合免训练统计数据来利用多个现有检测器的优势。我们计算一系列测试统计数据的 p 值，并使用经典统计集成来聚合它们，以评估与统一真实图像分布的对齐情况。该框架通用、灵活且无需训练，非常适合在不同和不断变化的环境中进行鲁棒的假图像检测。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18923v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18923v1",
            "title": "DeFM: Learning Foundation Representations from Depth for Robotics",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "DeFM: Learning Foundation Representations from Depth for Robotics"
            },
            "updated": "2026-01-26T19:45:31Z",
            "updated_parsed": [
                2026,
                1,
                26,
                19,
                45,
                31,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18923v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18923v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Depth sensors are widely deployed across robotic platforms, and advances in fast, high-fidelity depth simulation have enabled robotic policies trained on depth observations to achieve robust sim-to-real transfer for a wide range of tasks. Despite this, representation learning for depth modality remains underexplored compared to RGB, where large-scale foundation models now define the state of the art. To address this gap, we present DeFM, a self-supervised foundation model trained entirely on depth images for robotic applications. Using a DINO-style self-distillation objective on a curated dataset of 60M depth images, DeFM learns geometric and semantic representations that generalize to diverse environments, tasks, and sensors. To retain metric awareness across multiple scales, we introduce a novel input normalization strategy. We further distill DeFM into compact models suitable for resource-constrained robotic systems. When evaluated on depth-based classification, segmentation, navigation, locomotion, and manipulation benchmarks, DeFM achieves state-of-the-art performance and demonstrates strong generalization from simulation to real-world environments. We release all our pretrained models, which can be adopted off-the-shelf for depth-based robotic learning without task-specific fine-tuning. Webpage: https://de-fm.github.io/",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Depth sensors are widely deployed across robotic platforms, and advances in fast, high-fidelity depth simulation have enabled robotic policies trained on depth observations to achieve robust sim-to-real transfer for a wide range of tasks. Despite this, representation learning for depth modality remains underexplored compared to RGB, where large-scale foundation models now define the state of the art. To address this gap, we present DeFM, a self-supervised foundation model trained entirely on depth images for robotic applications. Using a DINO-style self-distillation objective on a curated dataset of 60M depth images, DeFM learns geometric and semantic representations that generalize to diverse environments, tasks, and sensors. To retain metric awareness across multiple scales, we introduce a novel input normalization strategy. We further distill DeFM into compact models suitable for resource-constrained robotic systems. When evaluated on depth-based classification, segmentation, navigation, locomotion, and manipulation benchmarks, DeFM achieves state-of-the-art performance and demonstrates strong generalization from simulation to real-world environments. We release all our pretrained models, which can be adopted off-the-shelf for depth-based robotic learning without task-specific fine-tuning. Webpage: https://de-fm.github.io/"
            },
            "tags": [
                {
                    "term": "cs.RO",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T19:45:31Z",
            "published_parsed": [
                2026,
                1,
                26,
                19,
                45,
                31,
                0,
                26,
                0
            ],
            "arxiv_comment": "Under review, 19 pages, 15 Figures, 9 Tables",
            "arxiv_primary_category": {
                "term": "cs.RO"
            },
            "authors": [
                {
                    "name": "Manthan Patel"
                },
                {
                    "name": "Jonas Frey"
                },
                {
                    "name": "Mayank Mittal"
                },
                {
                    "name": "Fan Yang"
                },
                {
                    "name": "Alexander Hansson"
                },
                {
                    "name": "Amir Bar"
                },
                {
                    "name": "Cesar Cadena"
                },
                {
                    "name": "Marco Hutter"
                }
            ],
            "author_detail": {
                "name": "Marco Hutter"
            },
            "author": "Marco Hutter",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "DeFM：机器人深度学习基础表示",
            "abstract_cn": "深度传感器广泛部署在机器人平台上，快速、高保真深度模拟的进步使得基于深度观察训练的机器人策略能够为各种任务实现稳健的模拟到真实的转换。尽管如此，与 RGB 相比，深度模态的表示学习仍然未被充分探索，其中大规模基础模型现在定义了最先进的技术。为了解决这一差距，我们提出了 DeFM，这是一种完全基于机器人应用的深度图像进行训练的自监督基础模型。在 60M 深度图像的精选数据集上使用 DINO 式自蒸馏目标，DeFM 学习可推广到不同环境、任务和传感器的几何和语义表示。为了保持跨多个尺度的度量意识，我们引入了一种新颖的输入标准化策略。我们进一步将 DeFM 提炼成适合资源受限的机器人系统的紧凑模型。在基于深度的分类、分割、导航、运动和操作基准进行评估时，DeFM 实现了最先进的性能，并展示了从模拟到现实环境的强大泛化能力。我们发布了所有预训练模型，这些模型可以现成用于基于深度的机器人学习，无需针对特定任务进行微调。网页：https://de-fm.github.io/"
        },
        {
            "id": "http://arxiv.org/abs/2601.18929v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18929v1",
            "title": "On the Role of Depth in Surgical Vision Foundation Models: An Empirical Study of RGB-D Pre-training",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "On the Role of Depth in Surgical Vision Foundation Models: An Empirical Study of RGB-D Pre-training"
            },
            "updated": "2026-01-26T20:04:57Z",
            "updated_parsed": [
                2026,
                1,
                26,
                20,
                4,
                57,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18929v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18929v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Vision foundation models (VFMs) have emerged as powerful tools for surgical scene understanding. However, current approaches predominantly rely on unimodal RGB pre-training, overlooking the complex 3D geometry inherent to surgical environments. Although several architectures support multimodal or geometry-aware inputs in general computer vision, the benefits of incorporating depth information in surgical settings remain underexplored. We conduct a large-scale empirical study comparing eight ViT-based VFMs that differ in pre-training domain, learning objective, and input modality (RGB vs. RGB-D). For pre-training, we use a curated dataset of 1.4 million robotic surgical images paired with depth maps generated from an off-the-shelf network. We evaluate these models under both frozen-backbone and end-to-end fine-tuning protocols across eight surgical datasets spanning object detection, segmentation, depth estimation, and pose estimation. Our experiments yield several consistent findings. Models incorporating explicit geometric tokenization, such as MultiMAE, substantially outperform unimodal baselines across all tasks. Notably, geometric-aware pre-training enables remarkable data efficiency: models fine-tuned on just 25% of labeled data consistently surpass RGB-only models trained on the full dataset. Importantly, these gains require no architectural or runtime changes at inference; depth is used only during pre-training, making adoption straightforward. These findings suggest that multimodal pre-training offers a viable path towards building more capable surgical vision systems.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Vision foundation models (VFMs) have emerged as powerful tools for surgical scene understanding. However, current approaches predominantly rely on unimodal RGB pre-training, overlooking the complex 3D geometry inherent to surgical environments. Although several architectures support multimodal or geometry-aware inputs in general computer vision, the benefits of incorporating depth information in surgical settings remain underexplored. We conduct a large-scale empirical study comparing eight ViT-based VFMs that differ in pre-training domain, learning objective, and input modality (RGB vs. RGB-D). For pre-training, we use a curated dataset of 1.4 million robotic surgical images paired with depth maps generated from an off-the-shelf network. We evaluate these models under both frozen-backbone and end-to-end fine-tuning protocols across eight surgical datasets spanning object detection, segmentation, depth estimation, and pose estimation. Our experiments yield several consistent findings. Models incorporating explicit geometric tokenization, such as MultiMAE, substantially outperform unimodal baselines across all tasks. Notably, geometric-aware pre-training enables remarkable data efficiency: models fine-tuned on just 25% of labeled data consistently surpass RGB-only models trained on the full dataset. Importantly, these gains require no architectural or runtime changes at inference; depth is used only during pre-training, making adoption straightforward. These findings suggest that multimodal pre-training offers a viable path towards building more capable surgical vision systems."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T20:04:57Z",
            "published_parsed": [
                2026,
                1,
                26,
                20,
                4,
                57,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "John J. Han"
                },
                {
                    "name": "Adam Schmidt"
                },
                {
                    "name": "Muhammad Abdullah Jamal"
                },
                {
                    "name": "Chinedu Nwoye"
                },
                {
                    "name": "Anita Rau"
                },
                {
                    "name": "Jie Ying Wu"
                },
                {
                    "name": "Omid Mohareri"
                }
            ],
            "author_detail": {
                "name": "Omid Mohareri"
            },
            "author": "Omid Mohareri",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "深度在手术视觉基础模型中的作用：RGB-D 预训练的实证研究",
            "abstract_cn": "视觉基础模型 (VFM) 已成为理解手术场景的强大工具。然而，当前的方法主要依赖于单峰 RGB 预训练，忽略了手术环境固有的复杂 3D 几何形状。尽管多种架构支持通用计算机视觉中的多模态或几何感知输入，但在手术环境中整合深度信息的好处仍未得到充分探索。我们进行了一项大规模实证研究，比较了八种基于 ViT 的 VFM，这些 VFM 在预训练领域、学习目标和输入模式（RGB 与 RGB-D）方面有所不同。对于预训练，我们使用由 140 万张机器人手术图像组成的精选数据集，以及由现成网络生成的深度图。我们在涵盖对象检测、分割、深度估计和姿势估计的八个手术数据集的冻结骨干和端到端微调协议下评估这些模型。我们的实验得出了一些一致的发现。包含显式几何标记化的模型（例如 MultiMAE）在所有任务中都远远优于单峰基线。值得注意的是，几何感知预训练可实现显着的数据效率：仅对 25% 的标记数据进行微调的模型始终优于在完整数据集上训练的仅 RGB 模型。重要的是，这些收益不需要在推理时进行架构或运行时更改；深度仅在预训练期间使用，使采用变得简单。这些发现表明，多模式预训练为构建功能更强的手术视觉系统提供了一条可行的途径。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18948v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18948v1",
            "title": "Smart Split-Federated Learning over Noisy Channels for Embryo Image Segmentation",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Smart Split-Federated Learning over Noisy Channels for Embryo Image Segmentation"
            },
            "updated": "2026-01-26T20:40:36Z",
            "updated_parsed": [
                2026,
                1,
                26,
                20,
                40,
                36,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18948v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18948v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Split-Federated (SplitFed) learning is an extension of federated learning that places minimal requirements on the clients computing infrastructure, since only a small portion of the overall model is deployed on the clients hardware. In SplitFed learning, feature values, gradient updates, and model updates are transferred across communication channels. In this paper, we study the effects of noise in the communication channels on the learning process and the quality of the final model. We propose a smart averaging strategy for SplitFed learning with the goal of improving resilience against channel noise. Experiments on a segmentation model for embryo images shows that the proposed smart averaging strategy is able to tolerate two orders of magnitude stronger noise in the communication channels compared to conventional averaging, while still maintaining the accuracy of the final model.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Split-Federated (SplitFed) learning is an extension of federated learning that places minimal requirements on the clients computing infrastructure, since only a small portion of the overall model is deployed on the clients hardware. In SplitFed learning, feature values, gradient updates, and model updates are transferred across communication channels. In this paper, we study the effects of noise in the communication channels on the learning process and the quality of the final model. We propose a smart averaging strategy for SplitFed learning with the goal of improving resilience against channel noise. Experiments on a segmentation model for embryo images shows that the proposed smart averaging strategy is able to tolerate two orders of magnitude stronger noise in the communication channels compared to conventional averaging, while still maintaining the accuracy of the final model."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T20:40:36Z",
            "published_parsed": [
                2026,
                1,
                26,
                20,
                40,
                36,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Zahra Hafezi Kafshgari"
                },
                {
                    "name": "Ivan V. Bajic"
                },
                {
                    "name": "Parvaneh Saeedi"
                }
            ],
            "author_detail": {
                "name": "Parvaneh Saeedi"
            },
            "author": "Parvaneh Saeedi",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "用于胚胎图像分割的噪声通道的智能分割联合学习",
            "abstract_cn": "分割联合 (SplitFed) 学习是联合学习的扩展，它对客户端计算基础设施提出了最低要求，因为整个模型中只有一小部分部署在客户端硬件上。在 SplitFed 学习中，特征值、梯度更新和模型更新通过通信渠道传输。在本文中，我们研究了通信渠道中的噪声对学习过程和最终模型质量的影响。我们提出了一种用于 SplitFed 学习的智能平均策略，其目标是提高针对通道噪声的弹性。对胚胎图像分割模型的实验表明，与传统平均相比，所提出的智能平均策略能够容忍通信通道中强两个数量级的噪声，同时仍然保持最终模型的准确性。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18970v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18970v1",
            "title": "Pay Attention to Where You Look",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Pay Attention to Where You Look"
            },
            "updated": "2026-01-26T21:10:32Z",
            "updated_parsed": [
                2026,
                1,
                26,
                21,
                10,
                32,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18970v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18970v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Novel view synthesis (NVS) has advanced with generative modeling, enabling photorealistic image generation. In few-shot NVS, where only a few input views are available, existing methods often assume equal importance for all input views relative to the target, leading to suboptimal results.\n  We address this limitation by introducing a camera-weighting mechanism that adjusts the importance of source views based on their relevance to the target. We propose two approaches: a deterministic weighting scheme leveraging geometric properties like Euclidean distance and angular differences, and a cross-attention-based learning scheme that optimizes view weighting. Additionally, models can be further trained with our camera-weighting scheme to refine their understanding of view relevance and enhance synthesis quality. This mechanism is adaptable and can be integrated into various NVS algorithms, improving their ability to synthesize high-quality novel views. Our results demonstrate that adaptive view weighting enhances accuracy and realism, offering a promising direction for improving NVS.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Novel view synthesis (NVS) has advanced with generative modeling, enabling photorealistic image generation. In few-shot NVS, where only a few input views are available, existing methods often assume equal importance for all input views relative to the target, leading to suboptimal results.\n  We address this limitation by introducing a camera-weighting mechanism that adjusts the importance of source views based on their relevance to the target. We propose two approaches: a deterministic weighting scheme leveraging geometric properties like Euclidean distance and angular differences, and a cross-attention-based learning scheme that optimizes view weighting. Additionally, models can be further trained with our camera-weighting scheme to refine their understanding of view relevance and enhance synthesis quality. This mechanism is adaptable and can be integrated into various NVS algorithms, improving their ability to synthesize high-quality novel views. Our results demonstrate that adaptive view weighting enhances accuracy and realism, offering a promising direction for improving NVS."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T21:10:32Z",
            "published_parsed": [
                2026,
                1,
                26,
                21,
                10,
                32,
                0,
                26,
                0
            ],
            "arxiv_comment": "ICIP 2025 Workshop on Generative AI for World Simulations and Communications",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "arxiv_journal_ref": "International Conference on Image Processing 2025",
            "authors": [
                {
                    "name": "Alex Beriand"
                },
                {
                    "name": "JhihYang Wu"
                },
                {
                    "name": "Daniel Brignac"
                },
                {
                    "name": "Natnael Daba"
                },
                {
                    "name": "Abhijit Mahalanobis"
                }
            ],
            "author_detail": {
                "name": "Abhijit Mahalanobis"
            },
            "author": "Abhijit Mahalanobis",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "注意你看的地方",
            "abstract_cn": "新颖的视图合成（NVS）在生成建模方面取得了进步，可以生成逼真的图像。在少镜头 NVS 中，只有少数输入视图可用，现有方法通常假设所有输入视图相对于目标具有同等重要性，从而导致次优结果。\n  我们通过引入相机加权机制来解决这一限制，该机制根据源视图与目标的相关性来调整源视图的重要性。我们提出了两种方法：利用欧几里德距离和角度差异等几何特性的确定性加权方案，以及优化视图加权的基于交叉注意力的学习方案。此外，可以使用我们的相机加权方案进一步训练模型，以加深对视图相关性的理解并提高合成质量。该机制适应性强，可以集成到各种 NVS 算法中，提高其合成高质量新颖视图的能力。我们的结果表明，自适应视图加权提高了准确性和真实感，为改进 NVS 提供了一个有希望的方向。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18993v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18993v1",
            "title": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction"
            },
            "updated": "2026-01-26T22:03:46Z",
            "updated_parsed": [
                2026,
                1,
                26,
                22,
                3,
                46,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18993v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18993v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Camera redirection aims to replay a dynamic scene from a single monocular video under a user-specified camera trajectory. However, large-angle redirection is inherently ill-posed: a monocular video captures only a narrow spatio-temporal view of a dynamic 3D scene, providing highly partial observations of the underlying 4D world. The key challenge is therefore to recover a complete and coherent representation from this limited input, with consistent geometry and motion. While recent diffusion-based methods achieve impressive results, they often break down under large-angle viewpoint changes far from the original trajectory, where missing visual grounding leads to severe geometric ambiguity and temporal inconsistency. To address this, we present FreeOrbit4D, an effective training-free framework that tackles this geometric ambiguity by recovering a geometry-complete 4D proxy as structural grounding for video generation. We obtain this proxy by decoupling foreground and background reconstructions: we unproject the monocular video into a static background and geometry-incomplete foreground point clouds in a unified global space, then leverage an object-centric multi-view diffusion model to synthesize multi-view images and reconstruct geometry-complete foreground point clouds in canonical object space. By aligning the canonical foreground point cloud to the global scene space via dense pixel-synchronized 3D--3D correspondences and projecting the geometry-complete 4D proxy onto target camera viewpoints, we provide geometric scaffolds that guide a conditional video diffusion model. Extensive experiments show that FreeOrbit4D produces more faithful redirected videos under challenging large-angle trajectories, and our geometry-complete 4D proxy further opens a potential avenue for practical applications such as edit propagation and 4D data generation. Project page and code will be released soon.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Camera redirection aims to replay a dynamic scene from a single monocular video under a user-specified camera trajectory. However, large-angle redirection is inherently ill-posed: a monocular video captures only a narrow spatio-temporal view of a dynamic 3D scene, providing highly partial observations of the underlying 4D world. The key challenge is therefore to recover a complete and coherent representation from this limited input, with consistent geometry and motion. While recent diffusion-based methods achieve impressive results, they often break down under large-angle viewpoint changes far from the original trajectory, where missing visual grounding leads to severe geometric ambiguity and temporal inconsistency. To address this, we present FreeOrbit4D, an effective training-free framework that tackles this geometric ambiguity by recovering a geometry-complete 4D proxy as structural grounding for video generation. We obtain this proxy by decoupling foreground and background reconstructions: we unproject the monocular video into a static background and geometry-incomplete foreground point clouds in a unified global space, then leverage an object-centric multi-view diffusion model to synthesize multi-view images and reconstruct geometry-complete foreground point clouds in canonical object space. By aligning the canonical foreground point cloud to the global scene space via dense pixel-synchronized 3D--3D correspondences and projecting the geometry-complete 4D proxy onto target camera viewpoints, we provide geometric scaffolds that guide a conditional video diffusion model. Extensive experiments show that FreeOrbit4D produces more faithful redirected videos under challenging large-angle trajectories, and our geometry-complete 4D proxy further opens a potential avenue for practical applications such as edit propagation and 4D data generation. Project page and code will be released soon."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.GR",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T22:03:46Z",
            "published_parsed": [
                2026,
                1,
                26,
                22,
                3,
                46,
                0,
                26,
                0
            ],
            "arxiv_comment": "14 pages, 10 figures",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Wei Cao"
                },
                {
                    "name": "Hao Zhang"
                },
                {
                    "name": "Fengrui Tian"
                },
                {
                    "name": "Yulun Wu"
                },
                {
                    "name": "Yingying Li"
                },
                {
                    "name": "Shenlong Wang"
                },
                {
                    "name": "Ning Yu"
                },
                {
                    "name": "Yaoyao Liu"
                }
            ],
            "author_detail": {
                "name": "Yaoyao Liu"
            },
            "author": "Yaoyao Liu",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "FreeOrbit4D：通过几何完整的 4D 重建对单目视频进行免训练任意相机重定向",
            "abstract_cn": "摄像机重定向旨在在用户指定的摄像机轨迹下重播单个单目视频的动态场景。然而，大角度重定向本质上是不适定的：单目视频仅捕获动态 3D 场景的狭窄时空视图，提供对底层 4D 世界的高度局部观察。因此，关键的挑战是从有限的输入中恢复完整且连贯的表示，并具有一致的几何形状和运动。虽然最近基于扩散的方法取得了令人印象深刻的结果，但它们经常在远离原始轨迹的大角度视点变化下崩溃，缺少视觉基础会导致严重的几何模糊和时间不一致。为了解决这个问题，我们提出了 FreeOrbit4D，这是一个有效的免训练框架，它通过恢复几何完整的 4D 代理作为视频生成的结构基础来解决这种几何模糊性。我们通过解耦前景和背景重建来获得这个代理：我们将单目视频投影到统一的全局空间中的静态背景和几何不完整的前景点云中，然后利用以对象为中心的多视图扩散模型来合成多视图图像并在规范对象空间中重建几何完整的前景点云。通过密集的像素同步 3D--3D 对应将规范前景点云与全局场景空间对齐，并将几何完整的 4D 代理投影到目标摄像机视点上，我们提供了指导条件视频扩散模型的几何支架。大量实验表明，FreeOrbit4D 在具有挑战性的大角度轨迹下产生更忠实的重定向视频，并且我们的几何完整 4D 代理进一步为编辑传播和 4D 数据生成等实际应用开辟了潜在途径。项目页面和代码即将发布。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18997v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18997v1",
            "title": "Anatomically-aware conformal prediction for medical image segmentation with random walks",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Anatomically-aware conformal prediction for medical image segmentation with random walks"
            },
            "updated": "2026-01-26T22:16:07Z",
            "updated_parsed": [
                2026,
                1,
                26,
                22,
                16,
                7,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18997v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18997v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "The reliable deployment of deep learning in medical imaging requires uncertainty quantification that provides rigorous error guarantees while remaining anatomically meaningful. Conformal prediction (CP) is a powerful distribution-free framework for constructing statistically valid prediction intervals. However, standard applications in segmentation often ignore anatomical context, resulting in fragmented, spatially incoherent, and over-segmented prediction sets that limit clinical utility. To bridge this gap, this paper proposes Random-Walk Conformal Prediction (RW-CP), a model-agnostic framework which can be added on top of any segmentation method. RW-CP enforces spatial coherence to generate anatomically valid sets. Our method constructs a k-nearest neighbour graph from pre-trained vision foundation model features and applies a random walk to diffuse uncertainty. The random walk diffusion regularizes the non-conformity scores, making the prediction sets less sensitive to the conformal calibration parameter $λ$, ensuring more stable and continuous anatomical boundaries. RW-CP maintains rigorous marginal coverage while significantly improving segmentation quality. Evaluations on multi-modal public datasets show improvements of up to $35.4\\%$ compared to standard CP baselines, given an allowable error rate of $α=0.1$.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "The reliable deployment of deep learning in medical imaging requires uncertainty quantification that provides rigorous error guarantees while remaining anatomically meaningful. Conformal prediction (CP) is a powerful distribution-free framework for constructing statistically valid prediction intervals. However, standard applications in segmentation often ignore anatomical context, resulting in fragmented, spatially incoherent, and over-segmented prediction sets that limit clinical utility. To bridge this gap, this paper proposes Random-Walk Conformal Prediction (RW-CP), a model-agnostic framework which can be added on top of any segmentation method. RW-CP enforces spatial coherence to generate anatomically valid sets. Our method constructs a k-nearest neighbour graph from pre-trained vision foundation model features and applies a random walk to diffuse uncertainty. The random walk diffusion regularizes the non-conformity scores, making the prediction sets less sensitive to the conformal calibration parameter $λ$, ensuring more stable and continuous anatomical boundaries. RW-CP maintains rigorous marginal coverage while significantly improving segmentation quality. Evaluations on multi-modal public datasets show improvements of up to $35.4\\%$ compared to standard CP baselines, given an allowable error rate of $α=0.1$."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.LG",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T22:16:07Z",
            "published_parsed": [
                2026,
                1,
                26,
                22,
                16,
                7,
                0,
                26,
                0
            ],
            "arxiv_comment": "13 pages",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Mélanie Gaillochet"
                },
                {
                    "name": "Christian Desrosiers"
                },
                {
                    "name": "Hervé Lombaert"
                }
            ],
            "author_detail": {
                "name": "Hervé Lombaert"
            },
            "author": "Hervé Lombaert",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "具有随机游走的医学图像分割的解剖学感知共形预测",
            "abstract_cn": "深度学习在医学成像中的可靠部署需要不确定性量化，以提供严格的错误保证，同时保持解剖学意义。保形预测 (CP) 是一种强大的无分布框架，用于构建统计上有效的预测区间。然而，分割中的标准应用程序经常忽略解剖背景，导致碎片化、空间不连贯和过度分割的预测集，从而限制了临床实用性。为了弥补这一差距，本文提出了随机游走保形预测（RW-CP），这是一种与模型无关的框架，可以添加到任何分割方法之上。 RW-CP 强制空间相干性来生成解剖学上有效的集合。我们的方法根据预先训练的视觉基础模型特征构建 k 最近邻图，并应用随机游走来弥散不确定性。随机游走扩散对不合格分数进行正则化，使预测集对保形校准参数 $λ$ 不太敏感，确保更稳定和连续的解剖边界。 RW-CP 保持严格的边际覆盖率，同时显着提高分割质量。对多模态公共数据集的评估显示，在允许的错误率为 $α=0.1$ 的情况下，与标准 CP 基线相比，改进高达 $35.4\\%$。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19014v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19014v1",
            "title": "Non-Invasive 3D Wound Measurement with RGB-D Imaging",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Non-Invasive 3D Wound Measurement with RGB-D Imaging"
            },
            "updated": "2026-01-26T23:03:24Z",
            "updated_parsed": [
                2026,
                1,
                26,
                23,
                3,
                24,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19014v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19014v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Chronic wound monitoring and management require accurate and efficient wound measurement methods. This paper presents a fast, non-invasive 3D wound measurement algorithm based on RGB-D imaging. The method combines RGB-D odometry with B-spline surface reconstruction to generate detailed 3D wound meshes, enabling automatic computation of clinically relevant wound measurements such as perimeter, surface area, and dimensions. We evaluated our system on realistic silicone wound phantoms and measured sub-millimetre 3D reconstruction accuracy compared with high-resolution ground-truth scans. The extracted measurements demonstrated low variability across repeated captures and strong agreement with manual assessments. The proposed pipeline also outperformed a state-of-the-art object-centric RGB-D reconstruction method while maintaining runtimes suitable for real-time clinical deployment. Our approach offers a promising tool for automated wound assessment in both clinical and remote healthcare settings.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Chronic wound monitoring and management require accurate and efficient wound measurement methods. This paper presents a fast, non-invasive 3D wound measurement algorithm based on RGB-D imaging. The method combines RGB-D odometry with B-spline surface reconstruction to generate detailed 3D wound meshes, enabling automatic computation of clinically relevant wound measurements such as perimeter, surface area, and dimensions. We evaluated our system on realistic silicone wound phantoms and measured sub-millimetre 3D reconstruction accuracy compared with high-resolution ground-truth scans. The extracted measurements demonstrated low variability across repeated captures and strong agreement with manual assessments. The proposed pipeline also outperformed a state-of-the-art object-centric RGB-D reconstruction method while maintaining runtimes suitable for real-time clinical deployment. Our approach offers a promising tool for automated wound assessment in both clinical and remote healthcare settings."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T23:03:24Z",
            "published_parsed": [
                2026,
                1,
                26,
                23,
                3,
                24,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Lena Harkämper"
                },
                {
                    "name": "Leo Lebrat"
                },
                {
                    "name": "David Ahmedt-Aristizabal"
                },
                {
                    "name": "Olivier Salvado"
                },
                {
                    "name": "Mattias Heinrich"
                },
                {
                    "name": "Rodrigo Santa Cruz"
                }
            ],
            "author_detail": {
                "name": "Rodrigo Santa Cruz"
            },
            "author": "Rodrigo Santa Cruz",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "使用 RGB-D 成像进行非侵入式 3D 伤口测量",
            "abstract_cn": "慢性伤口监测和管理需要准确、高效的伤口测量方法。本文提出了一种基于 RGB-D 成像的快速、非侵入性 3D 伤口测量算法。该方法将 RGB-D 里程计与 B 样条表面重建相结合，生成详细的 3D 伤口网格，从而能够自动计算临床相关伤口测量结果，例如周长、表面积和尺寸。我们在真实的硅胶伤口模型上评估了我们的系统，并与高分辨率地面真实扫描相比测量了亚毫米 3D 重建精度。提取的测量结果表明重复捕获的变异性较低，并且与手动评估高度一致。所提出的流程还优于最先进的以对象为中心的 RGB-D 重建方法，同时保持适合实时临床部署的运行时间。我们的方法为临床和远程医疗保健环境中的自动化伤口评估提供了一种很有前途的工具。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19048v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19048v1",
            "title": "NuiWorld: Exploring a Scalable Framework for End-to-End Controllable World Generation",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "NuiWorld: Exploring a Scalable Framework for End-to-End Controllable World Generation"
            },
            "updated": "2026-01-27T00:04:02Z",
            "updated_parsed": [
                2026,
                1,
                27,
                0,
                4,
                2,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19048v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19048v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "World generation is a fundamental capability for applications like video games, simulation, and robotics. However, existing approaches face three main obstacles: controllability, scalability, and efficiency. End-to-end scene generation models have been limited by data scarcity. While object-centric generation approaches rely on fixed resolution representations, degrading fidelity for larger scenes. Training-free approaches, while flexible, are often slow and computationally expensive at inference time. We present NuiWorld, a framework that attempts to address these challenges. To overcome data scarcity, we propose a generative bootstrapping strategy that starts from a few input images. Leveraging recent 3D reconstruction and expandable scene generation techniques, we synthesize scenes of varying sizes and layouts, producing enough data to train an end-to-end model. Furthermore, our framework enables controllability through pseudo sketch labels, and demonstrates a degree of generalization to previously unseen sketches. Our approach represents scenes as a collection of variable scene chunks, which are compressed into a flattened vector-set representation. This significantly reduces the token length for large scenes, enabling consistent geometric fidelity across scenes sizes while improving training and inference efficiency.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "World generation is a fundamental capability for applications like video games, simulation, and robotics. However, existing approaches face three main obstacles: controllability, scalability, and efficiency. End-to-end scene generation models have been limited by data scarcity. While object-centric generation approaches rely on fixed resolution representations, degrading fidelity for larger scenes. Training-free approaches, while flexible, are often slow and computationally expensive at inference time. We present NuiWorld, a framework that attempts to address these challenges. To overcome data scarcity, we propose a generative bootstrapping strategy that starts from a few input images. Leveraging recent 3D reconstruction and expandable scene generation techniques, we synthesize scenes of varying sizes and layouts, producing enough data to train an end-to-end model. Furthermore, our framework enables controllability through pseudo sketch labels, and demonstrates a degree of generalization to previously unseen sketches. Our approach represents scenes as a collection of variable scene chunks, which are compressed into a flattened vector-set representation. This significantly reduces the token length for large scenes, enabling consistent geometric fidelity across scenes sizes while improving training and inference efficiency."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T00:04:02Z",
            "published_parsed": [
                2026,
                1,
                27,
                0,
                4,
                2,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Han-Hung Lee"
                },
                {
                    "name": "Cheng-Yu Yang"
                },
                {
                    "name": "Yu-Lun Liu"
                },
                {
                    "name": "Angel X. Chang"
                }
            ],
            "author_detail": {
                "name": "Angel X. Chang"
            },
            "author": "Angel X. Chang",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "NuiWorld：探索端到端可控世界生成的可扩展框架",
            "abstract_cn": "世界生成是视频游戏、模拟和机器人等应用程序的一项基本功能。然而，现有方法面临三个主要障碍：可控性、可扩展性和效率。端到端场景生成模型受到数据稀缺的限制。虽然以对象为中心的生成方法依赖于固定分辨率表示，但会降低较大场景的保真度。免训练方法虽然灵活，但在推理时通常很慢且计算成本昂贵。我们提出 NuiWorld，一个试图解决这些挑战的框架。为了克服数据稀缺的问题，我们提出了一种从一些输入图像开始的生成引导策略。利用最新的 3D 重建和可扩展场景生成技术，我们合成不同大小和布局的场景，生成足够的数据来训练端到端模型。此外，我们的框架通过伪草图标签实现了可控性，并展示了对以前未见过的草图的一定程度的泛化。我们的方法将场景表示为可变场景块的集合，这些场景块被压缩为扁平化的向量集表示。这显着减少了大型场景的令牌长度，实现了跨场景大小的一致的几何保真度，同时提高了训练和推理效率。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19060v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19060v1",
            "title": "Pixel-Grounded Retrieval for Knowledgeable Large Multimodal Models",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Pixel-Grounded Retrieval for Knowledgeable Large Multimodal Models"
            },
            "updated": "2026-01-27T00:46:08Z",
            "updated_parsed": [
                2026,
                1,
                27,
                0,
                46,
                8,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19060v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19060v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Visual Question Answering (VQA) often requires coupling fine-grained perception with factual knowledge beyond the input image. Prior multimodal Retrieval-Augmented Generation (MM-RAG) systems improve factual grounding but lack an internal policy for when and how to retrieve. We propose PixSearch, the first end-to-end Segmenting Large Multimodal Model (LMM) that unifies region-level perception and retrieval-augmented reasoning. During encoding, PixSearch emits <search> tokens to trigger retrieval, selects query modalities (text, image, or region), and generates pixel-level masks that directly serve as visual queries, eliminating the reliance on modular pipelines (detectors, segmenters, captioners, etc.). A two-stage supervised fine-tuning regimen with search-interleaved supervision teaches retrieval timing and query selection while preserving segmentation ability. On egocentric and entity-centric VQA benchmarks, PixSearch substantially improves factual consistency and generalization, yielding a 19.7% relative gain in accuracy on CRAG-MM compared to whole image retrieval, while retaining competitive reasoning performance on various VQA and text-only QA tasks.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Visual Question Answering (VQA) often requires coupling fine-grained perception with factual knowledge beyond the input image. Prior multimodal Retrieval-Augmented Generation (MM-RAG) systems improve factual grounding but lack an internal policy for when and how to retrieve. We propose PixSearch, the first end-to-end Segmenting Large Multimodal Model (LMM) that unifies region-level perception and retrieval-augmented reasoning. During encoding, PixSearch emits <search> tokens to trigger retrieval, selects query modalities (text, image, or region), and generates pixel-level masks that directly serve as visual queries, eliminating the reliance on modular pipelines (detectors, segmenters, captioners, etc.). A two-stage supervised fine-tuning regimen with search-interleaved supervision teaches retrieval timing and query selection while preserving segmentation ability. On egocentric and entity-centric VQA benchmarks, PixSearch substantially improves factual consistency and generalization, yielding a 19.7% relative gain in accuracy on CRAG-MM compared to whole image retrieval, while retaining competitive reasoning performance on various VQA and text-only QA tasks."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T00:46:08Z",
            "published_parsed": [
                2026,
                1,
                27,
                0,
                46,
                8,
                1,
                27,
                0
            ],
            "arxiv_comment": "Preprint",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Jeonghwan Kim"
                },
                {
                    "name": "Renjie Tao"
                },
                {
                    "name": "Sanat Sharma"
                },
                {
                    "name": "Jiaqi Wang"
                },
                {
                    "name": "Kai Sun"
                },
                {
                    "name": "Zhaojiang Lin"
                },
                {
                    "name": "Seungwhan Moon"
                },
                {
                    "name": "Lambert Mathias"
                },
                {
                    "name": "Anuj Kumar"
                },
                {
                    "name": "Heng Ji"
                },
                {
                    "name": "Xin Luna Dong"
                }
            ],
            "author_detail": {
                "name": "Xin Luna Dong"
            },
            "author": "Xin Luna Dong",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "知识丰富的大型多模态模型的基于像素的检索",
            "abstract_cn": "视觉问答（VQA）通常需要将细粒度感知与输入图像之外的事实知识结合起来。先前的多模式检索增强生成（MM-RAG）系统改善了事实基础，但缺乏何时以及如何检索的内部策略。我们提出了 PixSearch，这是第一个端到端分段大型多模态模型（LMM），它统一了区域级感知和检索增强推理。在编码过程中，PixSearch 发出 <search> 标记来触发检索，选择查询模式（文本、图像或区域），并生成直接用作视觉查询的像素级掩码，从而消除对模块化管道（检测器、分段器、字幕器等）的依赖。具有搜索交错监督的两阶段监督微调方案可以教授检索时间和查询选择，同时保留分段能力。在以自我为中心和以实体为中心的 VQA 基准上，PixSearch 显着提高了事实一致性和泛化性，与整个图像检索相比，CRAG-MM 的准确率相对提高了 19.7%，同时在各种 VQA 和纯文本 QA 任务上保持有竞争力的推理性能。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19099v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19099v1",
            "title": "m2sv: A Scalable Benchmark for Map-to-Street-View Spatial Reasoning",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "m2sv: A Scalable Benchmark for Map-to-Street-View Spatial Reasoning"
            },
            "updated": "2026-01-27T02:01:56Z",
            "updated_parsed": [
                2026,
                1,
                27,
                2,
                1,
                56,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19099v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19099v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Vision--language models (VLMs) achieve strong performance on many multimodal benchmarks but remain brittle on spatial reasoning tasks that require aligning abstract overhead representations with egocentric views. We introduce m2sv, a scalable benchmark for map-to-street-view spatial reasoning that asks models to infer camera viewing direction by aligning a north-up overhead map with a Street View image captured at the same real-world intersection. We release m2sv-20k, a geographically diverse benchmark with controlled ambiguity, along with m2sv-sft-11k, a curated set of structured reasoning traces for supervised fine-tuning.\n  Despite strong performance on existing multimodal benchmarks, the best evaluated VLM achieves only 65.2% accuracy on m2sv, far below the human baseline of 95%. While supervised fine-tuning and reinforcement learning yield consistent gains, cross-benchmark evaluations reveal limited transfer. Beyond aggregate accuracy, we systematically analyze difficulty in map-to-street-view reasoning using both structural signals and human effort, and conduct an extensive failure analysis of adapted open models. Our findings highlight persistent gaps in geometric alignment, evidence aggregation, and reasoning consistency, motivating future work on grounded spatial reasoning across viewpoints.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Vision--language models (VLMs) achieve strong performance on many multimodal benchmarks but remain brittle on spatial reasoning tasks that require aligning abstract overhead representations with egocentric views. We introduce m2sv, a scalable benchmark for map-to-street-view spatial reasoning that asks models to infer camera viewing direction by aligning a north-up overhead map with a Street View image captured at the same real-world intersection. We release m2sv-20k, a geographically diverse benchmark with controlled ambiguity, along with m2sv-sft-11k, a curated set of structured reasoning traces for supervised fine-tuning.\n  Despite strong performance on existing multimodal benchmarks, the best evaluated VLM achieves only 65.2% accuracy on m2sv, far below the human baseline of 95%. While supervised fine-tuning and reinforcement learning yield consistent gains, cross-benchmark evaluations reveal limited transfer. Beyond aggregate accuracy, we systematically analyze difficulty in map-to-street-view reasoning using both structural signals and human effort, and conduct an extensive failure analysis of adapted open models. Our findings highlight persistent gaps in geometric alignment, evidence aggregation, and reasoning consistency, motivating future work on grounded spatial reasoning across viewpoints."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T02:01:56Z",
            "published_parsed": [
                2026,
                1,
                27,
                2,
                1,
                56,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Yosub Shin"
                },
                {
                    "name": "Michael Buriek"
                },
                {
                    "name": "Igor Molybog"
                }
            ],
            "author_detail": {
                "name": "Igor Molybog"
            },
            "author": "Igor Molybog",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "m2sv：地图到街景空间推理的可扩展基准",
            "abstract_cn": "视觉语言模型 (VLM) 在许多多模式基准上实现了强大的性能，但在需要将抽象开销表示与以自我为中心的视图对齐的空间推理任务上仍然很脆弱。我们引入了 m2sv，这是一种用于地图到街景空间推理的可扩展基准，要求模型通过将北上的俯视图与在同一现实世界交叉口捕获的街景图像对齐来推断相机的观看方向。我们发布了 m2sv-20k（一个具有受控模糊性的地理多样化基准），以及 m2sv-sft-11k（一组用于监督微调的结构化推理跟踪）。\n  尽管在现有多模态基准上表现强劲，但评估最好的 VLM 在 m2sv 上仅达到 65.2% 的准确率，远低于人类 95% 的基线。虽然监督微调和强化学习产生了一致的收益，但跨基准评估显示迁移有限。除了总体准确性之外，我们还使用结构信号和人力系统地分析地图到街景推理的难度，并对适应的开放模型进行广泛的失败分析。我们的研究结果强调了几何对齐、证据聚合和推理一致性方面持续存在的差距，激励了未来跨观点的扎根空间推理工作。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19114v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19114v1",
            "title": "Reg-TTR, Test-Time Refinement for Fast, Robust and Accurate Image Registration",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Reg-TTR, Test-Time Refinement for Fast, Robust and Accurate Image Registration"
            },
            "updated": "2026-01-27T02:36:27Z",
            "updated_parsed": [
                2026,
                1,
                27,
                2,
                36,
                27,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19114v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19114v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Traditional image registration methods are robust but slow due to their iterative nature. While deep learning has accelerated inference, it often struggles with domain shifts. Emerging registration foundation models offer a balance of speed and robustness, yet typically cannot match the peak accuracy of specialized models trained on specific datasets. To mitigate this limitation, we propose Reg-TTR, a test-time refinement framework that synergizes the complementary strengths of both deep learning and conventional registration techniques. By refining the predictions of pre-trained models at inference, our method delivers significantly improved registration accuracy at a modest computational cost, requiring only 21% additional inference time (0.56s). We evaluate Reg-TTR on two distinct tasks and show that it achieves state-of-the-art (SOTA) performance while maintaining inference speeds close to previous deep learning methods. As foundation models continue to emerge, our framework offers an efficient strategy to narrow the performance gap between registration foundation models and SOTA methods trained on specialized datasets. The source code will be publicly available following the acceptance of this work.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Traditional image registration methods are robust but slow due to their iterative nature. While deep learning has accelerated inference, it often struggles with domain shifts. Emerging registration foundation models offer a balance of speed and robustness, yet typically cannot match the peak accuracy of specialized models trained on specific datasets. To mitigate this limitation, we propose Reg-TTR, a test-time refinement framework that synergizes the complementary strengths of both deep learning and conventional registration techniques. By refining the predictions of pre-trained models at inference, our method delivers significantly improved registration accuracy at a modest computational cost, requiring only 21% additional inference time (0.56s). We evaluate Reg-TTR on two distinct tasks and show that it achieves state-of-the-art (SOTA) performance while maintaining inference speeds close to previous deep learning methods. As foundation models continue to emerge, our framework offers an efficient strategy to narrow the performance gap between registration foundation models and SOTA methods trained on specialized datasets. The source code will be publicly available following the acceptance of this work."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T02:36:27Z",
            "published_parsed": [
                2026,
                1,
                27,
                2,
                36,
                27,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Lin Chen"
                },
                {
                    "name": "Yue He"
                },
                {
                    "name": "Fengting Zhang"
                },
                {
                    "name": "Yaonan Wang"
                },
                {
                    "name": "Fengming Lin"
                },
                {
                    "name": "Xiang Chen"
                },
                {
                    "name": "Min Liu"
                }
            ],
            "author_detail": {
                "name": "Min Liu"
            },
            "author": "Min Liu",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "Reg-TTR，测试时间细化，实现快速、稳健和准确的图像配准",
            "abstract_cn": "传统的图像配准方法虽然稳健，但由于其迭代性质而速度缓慢。虽然深度学习加速了推理，但它常常难以应对领域转移。新兴的配准基础模型提供了速度和稳健性的平衡，但通常无法与在特定数据集上训练的专用模型的峰值准确性相匹配。为了缓解这一限制，我们提出了 Reg-TTR，这是一种测试时细化框架，可以协同深度学习和传统注册技术的互补优势。通过在推理时完善预训练模型的预测，我们的方法以适度的计算成本显着提高了配准精度，仅需要 21% 的额外推理时间（0.56 秒）。我们在两个不同的任务上评估 Reg-TTR，并表明它实现了最先进的 (SOTA) 性能，同时保持接近以前的深度学习方法的推理速度。随着基础模型的不断出现，我们的框架提供了一种有效的策略来缩小注册基础模型和在专门数据集上训练的 SOTA 方法之间的性能差距。这项工作被接受后，源代码将公开可用。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19115v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19115v1",
            "title": "FBSDiff++: Improved Frequency Band Substitution of Diffusion Features for Efficient and Highly Controllable Text-Driven Image-to-Image Translation",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "FBSDiff++: Improved Frequency Band Substitution of Diffusion Features for Efficient and Highly Controllable Text-Driven Image-to-Image Translation"
            },
            "updated": "2026-01-27T02:39:20Z",
            "updated_parsed": [
                2026,
                1,
                27,
                2,
                39,
                20,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19115v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19115v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "With large-scale text-to-image (T2I) diffusion models achieving significant advancements in open-domain image creation, increasing attention has been focused on their natural extension to the realm of text-driven image-to-image (I2I) translation, where a source image acts as visual guidance to the generated image in addition to the textual guidance provided by the text prompt. We propose FBSDiff, a novel framework adapting off-the-shelf T2I diffusion model into the I2I paradigm from a fresh frequency-domain perspective. Through dynamic frequency band substitution of diffusion features, FBSDiff realizes versatile and highly controllable text-driven I2I in a plug-and-play manner (without need for model training, fine-tuning, or online optimization), allowing appearance-guided, layout-guided, and contour-guided I2I translation by progressively substituting low-frequency band, mid-frequency band, and high-frequency band of latent diffusion features, respectively. In addition, FBSDiff flexibly enables continuous control over I2I correlation intensity simply by tuning the bandwidth of the substituted frequency band. To further promote image translation efficiency, flexibility, and functionality, we propose FBSDiff++ which improves upon FBSDiff mainly in three aspects: (1) accelerate inference speed by a large margin (8.9$\\times$ speedup in inference) with refined model architecture; (2) improve the Frequency Band Substitution module to allow for input source images of arbitrary resolution and aspect ratio; (3) extend model functionality to enable localized image manipulation and style-specific content creation with only subtle adjustments to the core method. Extensive qualitative and quantitative experiments verify superiority of FBSDiff++ in I2I translation visual quality, efficiency, versatility, and controllability compared to related advanced approaches.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "With large-scale text-to-image (T2I) diffusion models achieving significant advancements in open-domain image creation, increasing attention has been focused on their natural extension to the realm of text-driven image-to-image (I2I) translation, where a source image acts as visual guidance to the generated image in addition to the textual guidance provided by the text prompt. We propose FBSDiff, a novel framework adapting off-the-shelf T2I diffusion model into the I2I paradigm from a fresh frequency-domain perspective. Through dynamic frequency band substitution of diffusion features, FBSDiff realizes versatile and highly controllable text-driven I2I in a plug-and-play manner (without need for model training, fine-tuning, or online optimization), allowing appearance-guided, layout-guided, and contour-guided I2I translation by progressively substituting low-frequency band, mid-frequency band, and high-frequency band of latent diffusion features, respectively. In addition, FBSDiff flexibly enables continuous control over I2I correlation intensity simply by tuning the bandwidth of the substituted frequency band. To further promote image translation efficiency, flexibility, and functionality, we propose FBSDiff++ which improves upon FBSDiff mainly in three aspects: (1) accelerate inference speed by a large margin (8.9$\\times$ speedup in inference) with refined model architecture; (2) improve the Frequency Band Substitution module to allow for input source images of arbitrary resolution and aspect ratio; (3) extend model functionality to enable localized image manipulation and style-specific content creation with only subtle adjustments to the core method. Extensive qualitative and quantitative experiments verify superiority of FBSDiff++ in I2I translation visual quality, efficiency, versatility, and controllability compared to related advanced approaches."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T02:39:20Z",
            "published_parsed": [
                2026,
                1,
                27,
                2,
                39,
                20,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Xiang Gao"
                },
                {
                    "name": "Yunpeng Jia"
                }
            ],
            "author_detail": {
                "name": "Yunpeng Jia"
            },
            "author": "Yunpeng Jia",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "FBSDiff++：改进扩散特征的频带替代，实现高效且高度可控的文本驱动的图像到图像转换",
            "abstract_cn": "随着大规模文本到图像（T2I）扩散模型在开放域图像创建方面取得显着进步，越来越多的注意力集中在它们对文本驱动的图像到图像（I2I）翻译领域的自然扩展上，其中除了文本提示提供的文本指导之外，源图像还充当生成图像的视觉指导。我们提出了 FBSDiff，这是一种新颖的框架，从全新的频域角度将现成的 T2I 扩散模型融入 I2I 范式。通过扩散特征的动态频段替换，FBSDiff以即插即用的方式实现了通用且高度可控的文本驱动I2I（无需模型训练、微调或在线优化），通过逐步替换潜在扩散特征的低频段、中频段和高频段，允许外观引导、布局引导和轮廓引导的I2I翻译。此外，FBSDiff 只需调整替代频段的带宽即可灵活地连续控制 I2I 相关强度。为了进一步提高图像翻译效率、灵活性和功能性，我们提出了 FBSDiff++，它主要在三个方面对 FBSDiff 进行了改进：（1）通过精细的模型架构大幅提高推理速度（推理速度提升 8.9$\\times$）； (2) 改进频段替换模块，允许输入任意分辨率和宽高比的源图像； (3) 扩展模型功能，只需对核心方法进行细微调整即可实现本地化图像操作和特定于风格的内容创建。广泛的定性和定量实验验证了 FBSDiff++ 与相关先进方法相比在 I2I 翻译视觉质量、效率、多功能性和可控性方面的优越性。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19129v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19129v1",
            "title": "CLIP-Guided Unsupervised Semantic-Aware Exposure Correction",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "CLIP-Guided Unsupervised Semantic-Aware Exposure Correction"
            },
            "updated": "2026-01-27T02:53:18Z",
            "updated_parsed": [
                2026,
                1,
                27,
                2,
                53,
                18,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19129v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19129v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Improper exposure often leads to severe loss of details, color distortion, and reduced contrast. Exposure correction still faces two critical challenges: (1) the ignorance of object-wise regional semantic information causes the color shift artifacts; (2) real-world exposure images generally have no ground-truth labels, and its labeling entails massive manual editing. To tackle the challenges, we propose a new unsupervised semantic-aware exposure correction network. It contains an adaptive semantic-aware fusion module, which effectively fuses the semantic information extracted from a pre-trained Fast Segment Anything Model into a shared image feature space. Then the fused features are used by our multi-scale residual spatial mamba group to restore the details and adjust the exposure. To avoid manual editing, we propose a pseudo-ground truth generator guided by CLIP, which is fine-tuned to automatically identify exposure situations and instruct the tailored corrections. Also, we leverage the rich priors from the FastSAM and CLIP to develop a semantic-prompt consistency loss to enforce semantic consistency and image-prompt alignment for unsupervised training. Comprehensive experimental results illustrate the effectiveness of our method in correcting real-world exposure images and outperforms state-of-the-art unsupervised methods both numerically and visually.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Improper exposure often leads to severe loss of details, color distortion, and reduced contrast. Exposure correction still faces two critical challenges: (1) the ignorance of object-wise regional semantic information causes the color shift artifacts; (2) real-world exposure images generally have no ground-truth labels, and its labeling entails massive manual editing. To tackle the challenges, we propose a new unsupervised semantic-aware exposure correction network. It contains an adaptive semantic-aware fusion module, which effectively fuses the semantic information extracted from a pre-trained Fast Segment Anything Model into a shared image feature space. Then the fused features are used by our multi-scale residual spatial mamba group to restore the details and adjust the exposure. To avoid manual editing, we propose a pseudo-ground truth generator guided by CLIP, which is fine-tuned to automatically identify exposure situations and instruct the tailored corrections. Also, we leverage the rich priors from the FastSAM and CLIP to develop a semantic-prompt consistency loss to enforce semantic consistency and image-prompt alignment for unsupervised training. Comprehensive experimental results illustrate the effectiveness of our method in correcting real-world exposure images and outperforms state-of-the-art unsupervised methods both numerically and visually."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T02:53:18Z",
            "published_parsed": [
                2026,
                1,
                27,
                2,
                53,
                18,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Puzhen Wu"
                },
                {
                    "name": "Han Weng"
                },
                {
                    "name": "Quan Zheng"
                },
                {
                    "name": "Yi Zhan"
                },
                {
                    "name": "Hewei Wang"
                },
                {
                    "name": "Yiming Li"
                },
                {
                    "name": "Jiahui Han"
                },
                {
                    "name": "Rui Xu"
                }
            ],
            "author_detail": {
                "name": "Rui Xu"
            },
            "author": "Rui Xu",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "CLIP 引导的无监督语义感知曝光校正",
            "abstract_cn": "曝光不当通常会导致细节严重丢失、色彩失真和对比度降低。曝光校正仍然面临两个关键挑战：（1）对对象区域语义信息的无知导致颜色偏移伪影； （2）真实世界的曝光图像通常没有真实标签，其标签需要大量的手动编辑。为了应对这些挑战，我们提出了一种新的无监督语义感知曝光校正网络。它包含一个自适应语义感知融合模块，可有效将从预训练的快速分段任意模型中提取的语义信息融合到共享图像特征空间中。然后，我们的多尺度残差空间曼巴组使用融合特征来恢复细节并调整曝光。为了避免手动编辑，我们提出了一个由 CLIP 引导的伪地面实况生成器，它经过微调可以自动识别曝光情况并指示量身定制的校正。此外，我们利用 FastSAM 和 CLIP 的丰富先验来开发语义提示一致性损失，以强制无监督训练的语义一致性和图像提示对齐。综合实验结果说明了我们的方法在校正现实世界曝光图像方面的有效性，并且在数值和视觉上都优于最先进的无监督方法。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19155v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19155v1",
            "title": "LocationAgent: A Hierarchical Agent for Image Geolocation via Decoupling Strategy and Evidence from Parametric Knowledge",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "LocationAgent: A Hierarchical Agent for Image Geolocation via Decoupling Strategy and Evidence from Parametric Knowledge"
            },
            "updated": "2026-01-27T03:40:03Z",
            "updated_parsed": [
                2026,
                1,
                27,
                3,
                40,
                3,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19155v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19155v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Image geolocation aims to infer capture locations based on visual content. Fundamentally, this constitutes a reasoning process composed of \\textit{hypothesis-verification cycles}, requiring models to possess both geospatial reasoning capabilities and the ability to verify evidence against geographic facts. Existing methods typically internalize location knowledge and reasoning patterns into static memory via supervised training or trajectory-based reinforcement fine-tuning. Consequently, these methods are prone to factual hallucinations and generalization bottlenecks in open-world settings or scenarios requiring dynamic knowledge. To address these challenges, we propose a Hierarchical Localization Agent, called LocationAgent. Our core philosophy is to retain hierarchical reasoning logic within the model while offloading the verification of geographic evidence to external tools. To implement hierarchical reasoning, we design the RER architecture (Reasoner-Executor-Recorder), which employs role separation and context compression to prevent the drifting problem in multi-step reasoning. For evidence verification, we construct a suite of clue exploration tools that provide diverse evidence to support location reasoning. Furthermore, to address data leakage and the scarcity of Chinese data in existing datasets, we introduce CCL-Bench (China City Location Bench), an image geolocation benchmark encompassing various scene granularities and difficulty levels. Extensive experiments demonstrate that LocationAgent significantly outperforms existing methods by at least 30\\% in zero-shot settings.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Image geolocation aims to infer capture locations based on visual content. Fundamentally, this constitutes a reasoning process composed of \\textit{hypothesis-verification cycles}, requiring models to possess both geospatial reasoning capabilities and the ability to verify evidence against geographic facts. Existing methods typically internalize location knowledge and reasoning patterns into static memory via supervised training or trajectory-based reinforcement fine-tuning. Consequently, these methods are prone to factual hallucinations and generalization bottlenecks in open-world settings or scenarios requiring dynamic knowledge. To address these challenges, we propose a Hierarchical Localization Agent, called LocationAgent. Our core philosophy is to retain hierarchical reasoning logic within the model while offloading the verification of geographic evidence to external tools. To implement hierarchical reasoning, we design the RER architecture (Reasoner-Executor-Recorder), which employs role separation and context compression to prevent the drifting problem in multi-step reasoning. For evidence verification, we construct a suite of clue exploration tools that provide diverse evidence to support location reasoning. Furthermore, to address data leakage and the scarcity of Chinese data in existing datasets, we introduce CCL-Bench (China City Location Bench), an image geolocation benchmark encompassing various scene granularities and difficulty levels. Extensive experiments demonstrate that LocationAgent significantly outperforms existing methods by at least 30\\% in zero-shot settings."
            },
            "tags": [
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T03:40:03Z",
            "published_parsed": [
                2026,
                1,
                27,
                3,
                40,
                3,
                1,
                27,
                0
            ],
            "arxiv_comment": "9 pages, 5 figures, 3 tables",
            "arxiv_primary_category": {
                "term": "cs.AI"
            },
            "authors": [
                {
                    "name": "Qiujun Li"
                },
                {
                    "name": "Zijin Xiao"
                },
                {
                    "name": "Xulin Wang"
                },
                {
                    "name": "Zhidan Ma"
                },
                {
                    "name": "Cheng Yang"
                },
                {
                    "name": "Haifeng Li"
                }
            ],
            "author_detail": {
                "name": "Haifeng Li"
            },
            "author": "Haifeng Li",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "LocationAgent：通过解耦策略和参数知识证据进行图像地理定位的分层代理",
            "abstract_cn": "图像地理定位旨在根据视觉内容推断捕获位置。从根本上来说，这构成了一个由\\textit{假设验证循环}组成的推理过程，要求模型既具有地理空间推理能力，又具有验证地理事实证据的能力。现有方法通常通过监督训练或基于轨迹的强化微调将位置知识和推理模式内化到静态记忆中。因此，这些方法在开放世界环境或需要动态知识的场景中容易出现事实幻觉和泛化瓶颈。为了应对这些挑战，我们提出了一种分层定位代理，称为 LocationAgent。我们的核心理念是在模型中保留层次推理逻辑，同时将地理证据的验证转移到外部工具。为了实现分层推理，我们设计了RER架构（Reasoner-Executor-Recorder），它采用角色分离和上下文压缩来防止多步推理中的漂移问题。为了进行证据验证，我们构建了一套线索探索工具，可以提供多种证据来支持位置推理。此外，为了解决现有数据集中的数据泄露和中国数据稀缺的问题，我们引入了 CCL-Bench（中国城市定位基准），这是一种涵盖各种场景粒度和难度级别的图像地理定位基准。大量实验表明，在零样本设置中，LocationAgent 的性能明显优于现有方法至少 30%。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19157v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19157v1",
            "title": "GTFMN: Guided Texture and Feature Modulation Network for Low-Light Image Enhancement and Super-Resolution",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "GTFMN: Guided Texture and Feature Modulation Network for Low-Light Image Enhancement and Super-Resolution"
            },
            "updated": "2026-01-27T03:43:39Z",
            "updated_parsed": [
                2026,
                1,
                27,
                3,
                43,
                39,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19157v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19157v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Low-light image super-resolution (LLSR) is a challenging task due to the coupled degradation of low resolution and poor illumination. To address this, we propose the Guided Texture and Feature Modulation Network (GTFMN), a novel framework that decouples the LLSR task into two sub-problems: illumination estimation and texture restoration. First, our network employs a dedicated Illumination Stream whose purpose is to predict a spatially varying illumination map that accurately captures lighting distribution. Further, this map is utilized as an explicit guide within our novel Illumination Guided Modulation Block (IGM Block) to dynamically modulate features in the Texture Stream. This mechanism achieves spatially adaptive restoration, enabling the network to intensify enhancement in poorly lit regions while preserving details in well-exposed areas. Extensive experiments demonstrate that GTFMN achieves the best performance among competing methods on the OmniNormal5 and OmniNormal15 datasets, outperforming them in both quantitative metrics and visual quality.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Low-light image super-resolution (LLSR) is a challenging task due to the coupled degradation of low resolution and poor illumination. To address this, we propose the Guided Texture and Feature Modulation Network (GTFMN), a novel framework that decouples the LLSR task into two sub-problems: illumination estimation and texture restoration. First, our network employs a dedicated Illumination Stream whose purpose is to predict a spatially varying illumination map that accurately captures lighting distribution. Further, this map is utilized as an explicit guide within our novel Illumination Guided Modulation Block (IGM Block) to dynamically modulate features in the Texture Stream. This mechanism achieves spatially adaptive restoration, enabling the network to intensify enhancement in poorly lit regions while preserving details in well-exposed areas. Extensive experiments demonstrate that GTFMN achieves the best performance among competing methods on the OmniNormal5 and OmniNormal15 datasets, outperforming them in both quantitative metrics and visual quality."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T03:43:39Z",
            "published_parsed": [
                2026,
                1,
                27,
                3,
                43,
                39,
                1,
                27,
                0
            ],
            "arxiv_comment": "\\c{opyright} 2026 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Yongsong Huang"
                },
                {
                    "name": "Tzu-Hsuan Peng"
                },
                {
                    "name": "Tomo Miyazaki"
                },
                {
                    "name": "Xiaofeng Liu"
                },
                {
                    "name": "Chun-Ting Chou"
                },
                {
                    "name": "Ai-Chun Pang"
                },
                {
                    "name": "Shinichiro Omachi"
                }
            ],
            "author_detail": {
                "name": "Shinichiro Omachi"
            },
            "author": "Shinichiro Omachi",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "GTFMN：用于低光图像增强和超分辨率的引导纹理和特征调制网络",
            "abstract_cn": "由于低分辨率和不良照明的耦合退化，低光图像超分辨率（LLSR）是一项具有挑战性的任务。为了解决这个问题，我们提出了引导纹理和特征调制网络（GTFMN），这是一种新颖的框架，它将 LLSR 任务解耦为两个子问题：光照估计和纹理恢复。首先，我们的网络采用专用的照明流，其目的是预测空间变化的照明图，以准确捕获照明分布。此外，该图被用作我们新颖的照明引导调制块（IGM 块）中的明确指南，以动态调制纹理流中的特征。这种机制实现了空间自适应恢复，使网络能够在光线不足的区域加强增强，同时保留曝光良好区域的细节。大量实验表明，GTFMN 在 OmniNormal5 和 OmniNormal15 数据集上的竞争方法中实现了最佳性能，在定量指标和视觉质量方面均优于它们。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19180v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19180v1",
            "title": "SNR-Edit: Structure-Aware Noise Rectification for Inversion-Free Flow-Based Editing",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "SNR-Edit: Structure-Aware Noise Rectification for Inversion-Free Flow-Based Editing"
            },
            "updated": "2026-01-27T04:24:21Z",
            "updated_parsed": [
                2026,
                1,
                27,
                4,
                24,
                21,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19180v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19180v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Inversion-free image editing using flow-based generative models challenges the prevailing inversion-based pipelines. However, existing approaches rely on fixed Gaussian noise to construct the source trajectory, leading to biased trajectory dynamics and causing structural degradation or quality loss. To address this, we introduce SNR-Edit, a training-free framework achieving faithful Latent Trajectory Correction via adaptive noise control. Mechanistically, SNR-Edit uses structure-aware noise rectification to inject segmentation constraints into the initial noise, anchoring the stochastic component of the source trajectory to the real image's implicit inversion position and reducing trajectory drift during source--target transport. This lightweight modification yields smoother latent trajectories and ensures high-fidelity structural preservation without requiring model tuning or inversion. Across SD3 and FLUX, evaluations on PIE-Bench and SNR-Bench show that SNR-Edit delivers performance on pixel-level metrics and VLM-based scoring, while adding only about 1s overhead per image.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Inversion-free image editing using flow-based generative models challenges the prevailing inversion-based pipelines. However, existing approaches rely on fixed Gaussian noise to construct the source trajectory, leading to biased trajectory dynamics and causing structural degradation or quality loss. To address this, we introduce SNR-Edit, a training-free framework achieving faithful Latent Trajectory Correction via adaptive noise control. Mechanistically, SNR-Edit uses structure-aware noise rectification to inject segmentation constraints into the initial noise, anchoring the stochastic component of the source trajectory to the real image's implicit inversion position and reducing trajectory drift during source--target transport. This lightweight modification yields smoother latent trajectories and ensures high-fidelity structural preservation without requiring model tuning or inversion. Across SD3 and FLUX, evaluations on PIE-Bench and SNR-Bench show that SNR-Edit delivers performance on pixel-level metrics and VLM-based scoring, while adding only about 1s overhead per image."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T04:24:21Z",
            "published_parsed": [
                2026,
                1,
                27,
                4,
                24,
                21,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Lifan Jiang"
                },
                {
                    "name": "Boxi Wu"
                },
                {
                    "name": "Yuhang Pei"
                },
                {
                    "name": "Tianrun Wu"
                },
                {
                    "name": "Yongyuan Chen"
                },
                {
                    "name": "Yan Zhao"
                },
                {
                    "name": "Shiyu Yu"
                },
                {
                    "name": "Deng Cai"
                }
            ],
            "author_detail": {
                "name": "Deng Cai"
            },
            "author": "Deng Cai",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "SNR-Edit：结构感知噪声校正，用于基于无反转流的编辑",
            "abstract_cn": "使用基于流的生成模型的无反演图像编辑挑战了流行的基于反演的管道。然而，现有方法依赖固定高斯噪声来构建源轨迹，导致轨迹动态偏差并导致结构退化或质量损失。为了解决这个问题，我们引入了 SNR-Edit，这是一种无需训练的框架，通过自适应噪声控制实现忠实的潜在轨迹校正。从机制上讲，SNR-Edit 使用结构感知噪声校正将分割约束注入初始噪声，将源轨迹的随机分量锚定到真实图像的隐式反转位置，并减少源-目标传输期间的轨迹漂移。这种轻量级的修改产生更平滑的潜在轨迹，并确保高保真结构保存，而不需要模型调整或反演。在 SD3 和 FLUX 中，PIE-Bench 和 SNR-Bench 的评估表明，SNR-Edit 在像素级指标和基于 VLM 的评分方面提供了性能，同时每个图像仅增加了约 1 秒的开销。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19216v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19216v1",
            "title": "Bridging Visual and Wireless Sensing: A Unified Radiation Field for 3D Radio Map Construction",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Bridging Visual and Wireless Sensing: A Unified Radiation Field for 3D Radio Map Construction"
            },
            "updated": "2026-01-27T05:35:50Z",
            "updated_parsed": [
                2026,
                1,
                27,
                5,
                35,
                50,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19216v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19216v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "The emerging applications of next-generation wireless networks (e.g., immersive 3D communication, low-altitude networks, and integrated sensing and communication) necessitate high-fidelity environmental intelligence. 3D radio maps have emerged as a critical tool for this purpose, enabling spectrum-aware planning and environment-aware sensing by bridging the gap between physical environments and electromagnetic signal propagation. However, constructing accurate 3D radio maps requires fine-grained 3D geometric information and a profound understanding of electromagnetic wave propagation. Existing approaches typically treat optical and wireless knowledge as distinct modalities, failing to exploit the fundamental physical principles governing both light and electromagnetic propagation. To bridge this gap, we propose URF-GS, a unified radio-optical radiation field representation framework for accurate and generalizable 3D radio map construction based on 3D Gaussian splatting (3D-GS) and inverse rendering. By fusing visual and wireless sensing observations, URF-GS recovers scene geometry and material properties while accurately predicting radio signal behavior at arbitrary transmitter-receiver (Tx-Rx) configurations. Experimental results demonstrate that URF-GS achieves up to a 24.7% improvement in spatial spectrum prediction accuracy and a 10x increase in sample efficiency for 3D radio map construction compared with neural radiance field (NeRF)-based methods. This work establishes a foundation for next-generation wireless networks by integrating perception, interaction, and communication through holistic radiation field reconstruction.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "The emerging applications of next-generation wireless networks (e.g., immersive 3D communication, low-altitude networks, and integrated sensing and communication) necessitate high-fidelity environmental intelligence. 3D radio maps have emerged as a critical tool for this purpose, enabling spectrum-aware planning and environment-aware sensing by bridging the gap between physical environments and electromagnetic signal propagation. However, constructing accurate 3D radio maps requires fine-grained 3D geometric information and a profound understanding of electromagnetic wave propagation. Existing approaches typically treat optical and wireless knowledge as distinct modalities, failing to exploit the fundamental physical principles governing both light and electromagnetic propagation. To bridge this gap, we propose URF-GS, a unified radio-optical radiation field representation framework for accurate and generalizable 3D radio map construction based on 3D Gaussian splatting (3D-GS) and inverse rendering. By fusing visual and wireless sensing observations, URF-GS recovers scene geometry and material properties while accurately predicting radio signal behavior at arbitrary transmitter-receiver (Tx-Rx) configurations. Experimental results demonstrate that URF-GS achieves up to a 24.7% improvement in spatial spectrum prediction accuracy and a 10x increase in sample efficiency for 3D radio map construction compared with neural radiance field (NeRF)-based methods. This work establishes a foundation for next-generation wireless networks by integrating perception, interaction, and communication through holistic radiation field reconstruction."
            },
            "tags": [
                {
                    "term": "cs.NI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.LG",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T05:35:50Z",
            "published_parsed": [
                2026,
                1,
                27,
                5,
                35,
                50,
                1,
                27,
                0
            ],
            "arxiv_comment": "The code for this work will be publicly available at: https://github.com/wenchaozheng/URF-GS",
            "arxiv_primary_category": {
                "term": "cs.NI"
            },
            "authors": [
                {
                    "name": "Chaozheng Wen"
                },
                {
                    "name": "Jingwen Tong"
                },
                {
                    "name": "Zehong Lin"
                },
                {
                    "name": "Chenghong Bian"
                },
                {
                    "name": "Jun Zhang"
                }
            ],
            "author_detail": {
                "name": "Jun Zhang"
            },
            "author": "Jun Zhang",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "连接视觉和无线传感：用于 3D 无线电地图构建的统一辐射场",
            "abstract_cn": "下一代无线网络的新兴应用（例如沉浸式 3D 通信、低空网络、集成传感与通信）需要高保真环境智能。 3D 无线电地图已成为实现此目的的关键工具，通过弥合物理环境和电磁信号传播之间的差距，实现频谱感知规划和环境感知传感。然而，构建精确的 3D 无线电地图需要细粒度的 3D 几何信息和对电磁波传播的深刻理解。现有方法通常将光学和无线知识视为不同的模式，未能利用控制光和电磁传播的基本物理原理。为了弥补这一差距，我们提出了 URF-GS，这是一种统一的无线电光辐射场表示框架，用于基于 3D 高斯分布 (3D-GS) 和逆渲染的精确且可概括的 3D 无线电地图构建。通过融合视觉和无线传感观测，URF-GS 可以恢复场景几何形状和材料属性，同时准确预测任意发射器-接收器 (Tx-Rx) 配置下的无线电信号行为。实验结果表明，与基于神经辐射场 (NeRF) 的方法相比，URF-GS 的空间谱预测精度提高了 24.7%，3D 射电图构建的样本效率提高了 10 倍。这项工作通过整体辐射场重建整合感知、交互和通信，为下一代无线网络奠定了基础。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19236v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19236v1",
            "title": "VC-Bench: Pioneering the Video Connecting Benchmark with a Dataset and Evaluation Metrics",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "VC-Bench: Pioneering the Video Connecting Benchmark with a Dataset and Evaluation Metrics"
            },
            "updated": "2026-01-27T06:15:12Z",
            "updated_parsed": [
                2026,
                1,
                27,
                6,
                15,
                12,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19236v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19236v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "While current video generation focuses on text or image conditions, practical applications like video editing and vlogging often need to seamlessly connect separate clips. In our work, we introduce Video Connecting, an innovative task that aims to generate smooth intermediate video content between given start and end clips. However, the absence of standardized evaluation benchmarks has hindered the development of this task. To bridge this gap, we proposed VC-Bench, a novel benchmark specifically designed for video connecting. It includes 1,579 high-quality videos collected from public platforms, covering 15 main categories and 72 subcategories to ensure diversity and structure. VC-Bench focuses on three core aspects: Video Quality Score VQS, Start-End Consistency Score SECS, and Transition Smoothness Score TSS. Together, they form a comprehensive framework that moves beyond conventional quality-only metrics. We evaluated multiple state-of-the-art video generation models on VC-Bench. Experimental results reveal significant limitations in maintaining start-end consistency and transition smoothness, leading to lower overall coherence and fluidity. We expect that VC-Bench will serve as a pioneering benchmark to inspire and guide future research in video connecting. The evaluation metrics and dataset are publicly available at: https://anonymous.4open.science/r/VC-Bench-1B67/.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "While current video generation focuses on text or image conditions, practical applications like video editing and vlogging often need to seamlessly connect separate clips. In our work, we introduce Video Connecting, an innovative task that aims to generate smooth intermediate video content between given start and end clips. However, the absence of standardized evaluation benchmarks has hindered the development of this task. To bridge this gap, we proposed VC-Bench, a novel benchmark specifically designed for video connecting. It includes 1,579 high-quality videos collected from public platforms, covering 15 main categories and 72 subcategories to ensure diversity and structure. VC-Bench focuses on three core aspects: Video Quality Score VQS, Start-End Consistency Score SECS, and Transition Smoothness Score TSS. Together, they form a comprehensive framework that moves beyond conventional quality-only metrics. We evaluated multiple state-of-the-art video generation models on VC-Bench. Experimental results reveal significant limitations in maintaining start-end consistency and transition smoothness, leading to lower overall coherence and fluidity. We expect that VC-Bench will serve as a pioneering benchmark to inspire and guide future research in video connecting. The evaluation metrics and dataset are publicly available at: https://anonymous.4open.science/r/VC-Bench-1B67/."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.MM",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T06:15:12Z",
            "published_parsed": [
                2026,
                1,
                27,
                6,
                15,
                12,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Zhiyu Yin"
                },
                {
                    "name": "Zhipeng Liu"
                },
                {
                    "name": "Kehai Chen"
                },
                {
                    "name": "Lemao Liu"
                },
                {
                    "name": "Jin Liu"
                },
                {
                    "name": "Hong-Dong Li"
                },
                {
                    "name": "Yang Xiang"
                },
                {
                    "name": "Min Zhang"
                }
            ],
            "author_detail": {
                "name": "Min Zhang"
            },
            "author": "Min Zhang",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "VC-Bench：利用数据集和评估指标开创视频连接基准",
            "abstract_cn": "虽然当前的视频生成侧重于文本或图像条件，但视频编辑和视频博客等实际应用通常需要无缝连接单独的剪辑。在我们的工作中，我们引入了视频连接，这是一项创新任务，旨在在给定的开始和结束剪辑之间生成流畅的中间视频内容。然而，标准化评价基准的缺乏阻碍了这项任务的开展。为了弥补这一差距，我们提出了 VC-Bench，这是一种专为视频连接设计的新颖基准。它包含从公共平台收集的1,579个高质量视频，涵盖15个大类和72个小类，以确保多样性和结构。 VC-Bench关注三个核心方面：视频质量得分VQS、开始-结束一致性得分SECS和过渡平滑度得分TSS。它们共同构成了一个全面的框架，超越了传统的仅质量指标。我们在 VC-Bench 上评估了多种最先进的视频生成模型。实验结果表明，在维持起始端一致性和过渡平滑度方面存在显着局限性，导致整体连贯性和流动性较低。我们期望 VC-Bench 将成为启发和指导未来视频连接研究的开创性基准。评估指标和数据集可公开获取：https://anonymous.4open.science/r/VC-Bench-1B67/。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19247v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19247v1",
            "title": "TIGaussian: Disentangle Gaussians for Spatial-Awared Text-Image-3D Alignment",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "TIGaussian: Disentangle Gaussians for Spatial-Awared Text-Image-3D Alignment"
            },
            "updated": "2026-01-27T06:30:32Z",
            "updated_parsed": [
                2026,
                1,
                27,
                6,
                30,
                32,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19247v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19247v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "While visual-language models have profoundly linked features between texts and images, the incorporation of 3D modality data, such as point clouds and 3D Gaussians, further enables pretraining for 3D-related tasks, e.g., cross-modal retrieval, zero-shot classification, and scene recognition. As challenges remain in extracting 3D modal features and bridging the gap between different modalities, we propose TIGaussian, a framework that harnesses 3D Gaussian Splatting (3DGS) characteristics to strengthen cross-modality alignment through multi-branch 3DGS tokenizer and modality-specific 3D feature alignment strategies. Specifically, our multi-branch 3DGS tokenizer decouples the intrinsic properties of 3DGS structures into compact latent representations, enabling more generalizable feature extraction. To further bridge the modality gap, we develop a bidirectional cross-modal alignment strategies: a multi-view feature fusion mechanism that leverages diffusion priors to resolve perspective ambiguity in image-3D alignment, while a text-3D projection module adaptively maps 3D features to text embedding space for better text-3D alignment. Extensive experiments on various datasets demonstrate the state-of-the-art performance of TIGaussian in multiple tasks.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "While visual-language models have profoundly linked features between texts and images, the incorporation of 3D modality data, such as point clouds and 3D Gaussians, further enables pretraining for 3D-related tasks, e.g., cross-modal retrieval, zero-shot classification, and scene recognition. As challenges remain in extracting 3D modal features and bridging the gap between different modalities, we propose TIGaussian, a framework that harnesses 3D Gaussian Splatting (3DGS) characteristics to strengthen cross-modality alignment through multi-branch 3DGS tokenizer and modality-specific 3D feature alignment strategies. Specifically, our multi-branch 3DGS tokenizer decouples the intrinsic properties of 3DGS structures into compact latent representations, enabling more generalizable feature extraction. To further bridge the modality gap, we develop a bidirectional cross-modal alignment strategies: a multi-view feature fusion mechanism that leverages diffusion priors to resolve perspective ambiguity in image-3D alignment, while a text-3D projection module adaptively maps 3D features to text embedding space for better text-3D alignment. Extensive experiments on various datasets demonstrate the state-of-the-art performance of TIGaussian in multiple tasks."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T06:30:32Z",
            "published_parsed": [
                2026,
                1,
                27,
                6,
                30,
                32,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Jiarun Liu"
                },
                {
                    "name": "Qifeng Chen"
                },
                {
                    "name": "Yiru Zhao"
                },
                {
                    "name": "Minghua Liu"
                },
                {
                    "name": "Baorui Ma"
                },
                {
                    "name": "Sheng Yang"
                }
            ],
            "author_detail": {
                "name": "Sheng Yang"
            },
            "author": "Sheng Yang",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "TIGaussian：解开高斯以实现空间感知的文本-图像-3D 对齐",
            "abstract_cn": "虽然视觉语言模型在文本和图像之间具有深刻的联系特征，但点云和 3D 高斯等 3D 模态数据的结合进一步支持 3D 相关任务的预训练，例如跨模态检索、零样本分类和场景识别。由于提取 3D 模态特征和弥合不同模态之间的差距仍然存在挑战，我们提出了 TIGaussian，这是一个利用 3D 高斯分布 (3DGS) 特征通过多分支 3DGS 标记器和特定模态 3D 特征对齐策略来加强跨模态对齐的框架。具体来说，我们的多分支 3DGS 分词器将 3DGS 结构的内在属性解耦为紧凑的潜在表示，从而实现更通用的特征提取。为了进一步弥合模态差距，我们开发了一种双向跨模态对齐策略：一种多视图特征融合机制，利用扩散先验来解决图像 3D 对齐中的透视模糊性，而文本 3D 投影模块自适应地将 3D 特征映射到文本嵌入空间，以实现更好的文本 3D 对齐。对各种数据集的大量实验证明了 TIGaussian 在多个任务中的最先进的性能。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19262v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19262v1",
            "title": "Handcrafted Feature Fusion for Reliable Detection of AI-Generated Images",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Handcrafted Feature Fusion for Reliable Detection of AI-Generated Images"
            },
            "updated": "2026-01-27T06:43:01Z",
            "updated_parsed": [
                2026,
                1,
                27,
                6,
                43,
                1,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19262v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19262v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "The rapid progress of generative models has enabled the creation of highly realistic synthetic images, raising concerns about authenticity and trust in digital media. Detecting such fake content reliably is an urgent challenge. While deep learning approaches dominate current literature, handcrafted features remain attractive for their interpretability, efficiency, and generalizability. In this paper, we conduct a systematic evaluation of handcrafted descriptors, including raw pixels, color histograms, Discrete Cosine Transform (DCT), Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP), Gray-Level Co-occurrence Matrix (GLCM), and wavelet features, on the CIFAKE dataset of real versus synthetic images. Using 50,000 training and 10,000 test samples, we benchmark seven classifiers ranging from Logistic Regression to advanced gradient-boosted ensembles (LightGBM, XGBoost, CatBoost). Results demonstrate that LightGBM consistently outperforms alternatives, achieving PR-AUC 0.9879, ROC-AUC 0.9878, F1 0.9447, and a Brier score of 0.0414 with mixed features, representing strong gains in calibration and discrimination over simpler descriptors. Across three configurations (baseline, advanced, mixed), performance improves monotonically, confirming that combining diverse handcrafted features yields substantial benefit. These findings highlight the continued relevance of carefully engineered features and ensemble learning for detecting synthetic images, particularly in contexts where interpretability and computational efficiency are critical.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "The rapid progress of generative models has enabled the creation of highly realistic synthetic images, raising concerns about authenticity and trust in digital media. Detecting such fake content reliably is an urgent challenge. While deep learning approaches dominate current literature, handcrafted features remain attractive for their interpretability, efficiency, and generalizability. In this paper, we conduct a systematic evaluation of handcrafted descriptors, including raw pixels, color histograms, Discrete Cosine Transform (DCT), Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP), Gray-Level Co-occurrence Matrix (GLCM), and wavelet features, on the CIFAKE dataset of real versus synthetic images. Using 50,000 training and 10,000 test samples, we benchmark seven classifiers ranging from Logistic Regression to advanced gradient-boosted ensembles (LightGBM, XGBoost, CatBoost). Results demonstrate that LightGBM consistently outperforms alternatives, achieving PR-AUC 0.9879, ROC-AUC 0.9878, F1 0.9447, and a Brier score of 0.0414 with mixed features, representing strong gains in calibration and discrimination over simpler descriptors. Across three configurations (baseline, advanced, mixed), performance improves monotonically, confirming that combining diverse handcrafted features yields substantial benefit. These findings highlight the continued relevance of carefully engineered features and ensemble learning for detecting synthetic images, particularly in contexts where interpretability and computational efficiency are critical."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T06:43:01Z",
            "published_parsed": [
                2026,
                1,
                27,
                6,
                43,
                1,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Syed Mehedi Hasan Nirob"
                },
                {
                    "name": "Moqsadur Rahman"
                },
                {
                    "name": "Shamim Ehsan"
                },
                {
                    "name": "Summit Haque"
                }
            ],
            "author_detail": {
                "name": "Summit Haque"
            },
            "author": "Summit Haque",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "手工特征融合，用于可靠检测人工智能生成的图像",
            "abstract_cn": "生成模型的快速进步使得能够创建高度逼真的合成图像，引发了人们对数字媒体的真实性和信任度的担忧。可靠地检测此类虚假内容是一项紧迫的挑战。虽然深度学习方法在当前文献中占主导地位，但手工制作的特征因其可解释性、效率和普遍性而仍然具有吸引力。在本文中，我们在真实与合成图像的 CIFAKE 数据集上对手工制作的描述符进行了系统评估，包括原始像素、颜色直方图、离散余弦变换 (DCT)、定向梯度直方图 (HOG)、局部二值模式 (LBP)、灰度共生矩阵 (GLCM) 和小波特征。使用 50,000 个训练样本和 10,000 个测试样本，我们对从逻辑回归到高级梯度增强集成（LightGBM、XGBoost、CatBoost）等七种分类器进行了基准测试。结果表明，LightGBM 始终优于替代方案，实现了 PR-AUC 0.9879、ROC-AUC 0.9878、F1 0.9447，混合特征的 Brier 分数为 0.0414，这表明在校准和区分较简单描述符方面取得了巨大进步。在三种配置（基线、高级、混合）中，性能单调提高，证实结合不同的手工功能会产生巨大的好处。这些发现强调了精心设计的特征和集成学习对于检测合成图像的持续相关性，特别是在可解释性和计算效率至关重要的情况下。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19295v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19295v1",
            "title": "ProMist-5K: A Comprehensive Dataset for Digital Emulation of Cinematic Pro-Mist Filter Effects",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "ProMist-5K: A Comprehensive Dataset for Digital Emulation of Cinematic Pro-Mist Filter Effects"
            },
            "updated": "2026-01-27T07:37:00Z",
            "updated_parsed": [
                2026,
                1,
                27,
                7,
                37,
                0,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19295v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19295v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Pro-Mist filters are widely used in cinematography for their ability to create soft halation, lower contrast, and produce a distinctive, atmospheric style. These effects are difficult to reproduce digitally due to the complex behavior of light diffusion. We present ProMist-5K, a dataset designed to support cinematic style emulation. It is built using a physically inspired pipeline in a scene-referred linear space and includes 20,000 high-resolution image pairs across four configurations, covering two filter densities (1/2 and 1/8) and two focal lengths (20mm and 50mm). Unlike general style datasets, ProMist-5K focuses on realistic glow and highlight diffusion effects. Multiple blur layers and carefully tuned weighting are used to model the varying intensity and spread of optical diffusion. The dataset provides a consistent and controllable target domain that supports various image translation models and learning paradigms. Experiments show that the dataset works well across different training settings and helps capture both subtle and strong cinematic appearances. ProMist-5K offers a practical and physically grounded resource for film-inspired image transformation, bridging the gap between digital flexibility and traditional lens aesthetics. The dataset is available at https://www.kaggle.com/datasets/yingtielei/promist5k.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Pro-Mist filters are widely used in cinematography for their ability to create soft halation, lower contrast, and produce a distinctive, atmospheric style. These effects are difficult to reproduce digitally due to the complex behavior of light diffusion. We present ProMist-5K, a dataset designed to support cinematic style emulation. It is built using a physically inspired pipeline in a scene-referred linear space and includes 20,000 high-resolution image pairs across four configurations, covering two filter densities (1/2 and 1/8) and two focal lengths (20mm and 50mm). Unlike general style datasets, ProMist-5K focuses on realistic glow and highlight diffusion effects. Multiple blur layers and carefully tuned weighting are used to model the varying intensity and spread of optical diffusion. The dataset provides a consistent and controllable target domain that supports various image translation models and learning paradigms. Experiments show that the dataset works well across different training settings and helps capture both subtle and strong cinematic appearances. ProMist-5K offers a practical and physically grounded resource for film-inspired image transformation, bridging the gap between digital flexibility and traditional lens aesthetics. The dataset is available at https://www.kaggle.com/datasets/yingtielei/promist5k."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T07:37:00Z",
            "published_parsed": [
                2026,
                1,
                27,
                7,
                37,
                0,
                1,
                27,
                0
            ],
            "arxiv_comment": "Accepted by ICASSP2026",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Yingtie Lei"
                },
                {
                    "name": "Zimeng Li"
                },
                {
                    "name": "Chi-Man Pun"
                },
                {
                    "name": "Wangyu Wu"
                },
                {
                    "name": "Junke Yang"
                },
                {
                    "name": "Xuhang Chen"
                }
            ],
            "author_detail": {
                "name": "Xuhang Chen"
            },
            "author": "Xuhang Chen",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "ProMist-5K：用于电影 Pro-Mist 滤镜效果数字仿真的综合数据集",
            "abstract_cn": "Pro-Mist 滤镜因其能够产生柔和的光晕、降低对比度并产生独特的大气风格而广泛应用于电影摄影中。由于光漫射的复杂行为，这些效果很难以数字方式再现。我们推出了 ProMist-5K，这是一个旨在支持电影风格模拟的数据集。它是在场景参考线性空间中使用受物理启发的管道构建的，包括跨四种配置的 20,000 个高分辨率图像对，涵盖两种滤镜密度（1/2 和 1/8）和两种焦距（20mm 和 50mm）。与一般风格数据集不同，ProMist-5K 专注于逼真的发光和高光扩散效果。使用多个模糊层和精心调整的权重来模拟光学扩散的变化强度和扩散。该数据集提供了一致且可控的目标域，支持各种图像翻译模型和学习范式。实验表明，该数据集在不同的训练设置中都能很好地工作，并有助于捕捉微妙和强烈的电影外观。 ProMist-5K 为电影启发的图像转换提供了实用且基于物理的资源，弥合了数字灵活性和传统镜头美学之间的差距。该数据集可在 https://www.kaggle.com/datasets/yingtielei/promist5k 获取。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19309v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19309v1",
            "title": "Beyond Shadows: A Large-Scale Benchmark and Multi-Stage Framework for High-Fidelity Facial Shadow Removal",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Beyond Shadows: A Large-Scale Benchmark and Multi-Stage Framework for High-Fidelity Facial Shadow Removal"
            },
            "updated": "2026-01-27T07:48:31Z",
            "updated_parsed": [
                2026,
                1,
                27,
                7,
                48,
                31,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19309v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19309v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Facial shadows often degrade image quality and the performance of vision algorithms. Existing methods struggle to remove shadows while preserving texture, especially under complex lighting conditions, and they lack real-world paired datasets for training. We present the Augmented Shadow Face in the Wild (ASFW) dataset, the first large-scale real-world dataset for facial shadow removal, containing 1,081 paired shadow and shadow-free images created via a professional Photoshop workflow. ASFW offers photorealistic shadow variations and accurate ground truths, bridging the gap between synthetic and real domains. Deep models trained on ASFW demonstrate improved shadow removal in real-world conditions. We also introduce the Face Shadow Eraser (FSE) method to showcase the effectiveness of the dataset. Experiments demonstrate that ASFW enhances the performance of facial shadow removal models, setting new standards for this task.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Facial shadows often degrade image quality and the performance of vision algorithms. Existing methods struggle to remove shadows while preserving texture, especially under complex lighting conditions, and they lack real-world paired datasets for training. We present the Augmented Shadow Face in the Wild (ASFW) dataset, the first large-scale real-world dataset for facial shadow removal, containing 1,081 paired shadow and shadow-free images created via a professional Photoshop workflow. ASFW offers photorealistic shadow variations and accurate ground truths, bridging the gap between synthetic and real domains. Deep models trained on ASFW demonstrate improved shadow removal in real-world conditions. We also introduce the Face Shadow Eraser (FSE) method to showcase the effectiveness of the dataset. Experiments demonstrate that ASFW enhances the performance of facial shadow removal models, setting new standards for this task."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T07:48:31Z",
            "published_parsed": [
                2026,
                1,
                27,
                7,
                48,
                31,
                1,
                27,
                0
            ],
            "arxiv_comment": "Accepted by ICASSP2026",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Tailong Luo"
                },
                {
                    "name": "Jiesong Bai"
                },
                {
                    "name": "Jinyang Huang"
                },
                {
                    "name": "Junyu Xia"
                },
                {
                    "name": "Wangyu Wu"
                },
                {
                    "name": "Xuhang Chen"
                }
            ],
            "author_detail": {
                "name": "Xuhang Chen"
            },
            "author": "Xuhang Chen",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "超越阴影：高保真面部阴影去除的大规模基准和多阶段框架",
            "abstract_cn": "面部阴影通常会降低图像质量和视觉算法的性能。现有的方法很难在保留纹理的同时去除阴影，尤其是在复杂的光照条件下，而且它们缺乏用于训练的真实配对数据集。我们推出了野外增强阴影面部 (ASFW) 数据集，这是第一个用于面部阴影去除的大型现实世界数据集，包含通过专业 Photoshop 工作流程创建的 1,081 配对阴影和无阴影图像。 ASFW 提供逼真的阴影变化和准确的地面实况，弥合了合成域和真实域之间的差距。在 ASFW 上训练的深度模型展示了现实条件下阴影去除效果的改进。我们还引入了 Face Shadow Eraser (FSE) 方法来展示数据集的有效性。实验表明，ASFW 增强了面部阴影去除模型的性能，为该任务设定了新标准。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19314v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19314v1",
            "title": "Instance-Guided Radar Depth Estimation for 3D Object Detection",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Instance-Guided Radar Depth Estimation for 3D Object Detection"
            },
            "updated": "2026-01-27T07:53:24Z",
            "updated_parsed": [
                2026,
                1,
                27,
                7,
                53,
                24,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19314v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19314v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Accurate depth estimation is fundamental to 3D perception in autonomous driving, supporting tasks such as detection, tracking, and motion planning. However, monocular camera-based 3D detection suffers from depth ambiguity and reduced robustness under challenging conditions. Radar provides complementary advantages such as resilience to poor lighting and adverse weather, but its sparsity and low resolution limit its direct use in detection frameworks. This motivates the need for effective Radar-camera fusion with improved preprocessing and depth estimation strategies. We propose an end-to-end framework that enhances monocular 3D object detection through two key components. First, we introduce InstaRadar, an instance segmentation-guided expansion method that leverages pre-trained segmentation masks to enhance Radar density and semantic alignment, producing a more structured representation. InstaRadar achieves state-of-the-art results in Radar-guided depth estimation, showing its effectiveness in generating high-quality depth features. Second, we integrate the pre-trained RCDPT into the BEVDepth framework as a replacement for its depth module. With InstaRadar-enhanced inputs, the RCDPT integration consistently improves 3D detection performance. Overall, these components yield steady gains over the baseline BEVDepth model, demonstrating the effectiveness of InstaRadar and the advantage of explicit depth supervision in 3D object detection. Although the framework lags behind Radar-camera fusion models that directly extract BEV features, since Radar serves only as guidance rather than an independent feature stream, this limitation highlights potential for improvement. Future work will extend InstaRadar to point cloud-like representations and integrate a dedicated Radar branch with temporal cues for enhanced BEV fusion.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Accurate depth estimation is fundamental to 3D perception in autonomous driving, supporting tasks such as detection, tracking, and motion planning. However, monocular camera-based 3D detection suffers from depth ambiguity and reduced robustness under challenging conditions. Radar provides complementary advantages such as resilience to poor lighting and adverse weather, but its sparsity and low resolution limit its direct use in detection frameworks. This motivates the need for effective Radar-camera fusion with improved preprocessing and depth estimation strategies. We propose an end-to-end framework that enhances monocular 3D object detection through two key components. First, we introduce InstaRadar, an instance segmentation-guided expansion method that leverages pre-trained segmentation masks to enhance Radar density and semantic alignment, producing a more structured representation. InstaRadar achieves state-of-the-art results in Radar-guided depth estimation, showing its effectiveness in generating high-quality depth features. Second, we integrate the pre-trained RCDPT into the BEVDepth framework as a replacement for its depth module. With InstaRadar-enhanced inputs, the RCDPT integration consistently improves 3D detection performance. Overall, these components yield steady gains over the baseline BEVDepth model, demonstrating the effectiveness of InstaRadar and the advantage of explicit depth supervision in 3D object detection. Although the framework lags behind Radar-camera fusion models that directly extract BEV features, since Radar serves only as guidance rather than an independent feature stream, this limitation highlights potential for improvement. Future work will extend InstaRadar to point cloud-like representations and integrate a dedicated Radar branch with temporal cues for enhanced BEV fusion."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T07:53:24Z",
            "published_parsed": [
                2026,
                1,
                27,
                7,
                53,
                24,
                1,
                27,
                0
            ],
            "arxiv_comment": "Accepted to IPMV2026",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Chen-Chou Lo"
                },
                {
                    "name": "Patrick Vandewalle"
                }
            ],
            "author_detail": {
                "name": "Patrick Vandewalle"
            },
            "author": "Patrick Vandewalle",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "用于 3D 物体检测的实例引导雷达深度估计",
            "abstract_cn": "准确的深度估计是自动驾驶 3D 感知的基础，支持检测、跟踪和运动规划等任务。然而，基于单目相机的 3D 检测在挑战性条件下会遇到深度模糊和鲁棒性降低的问题。雷达提供了互补的优势，例如对不良照明和恶劣天气的适应能力，但其稀疏性和低分辨率限制了其在检测框架中的直接使用。这激发了对有效的雷达相机融合以及改进的预处理和深度估计策略的需求。我们提出了一个端到端框架，通过两个关键组件增强单目 3D 对象检测。首先，我们介绍 InstaRadar，这是一种实例分割引导的扩展方法，它利用预先训练的分割掩模来增强 Radar 密度和语义对齐，从而产生更结构化的表示。 InstaRadar 在雷达引导深度估计方面取得了最先进的结果，显示了其在生成高质量深度特征方面的有效性。其次，我们将预训练的 RCDPT 集成到 BEVDepth 框架中，作为其深度模块的替代品。借助 InstaRadar 增强型输入，RCDPT 集成不断提高 3D 检测性能。总体而言，这些组件比基线 BEVDepth 模型产生稳定的增益，证明了 InstaRadar 的有效性以及 3D 对象检测中显式深度监督的优势。尽管该框架落后于直接提取 BEV 特征的雷达相机融合模型，但由于雷达仅充当指导而不是独立的特征流，因此这一限制凸显了改进的潜力。未来的工作将把 InstaRadar 扩展到类似点云的表示，并将专用的 Radar 分支与时间线索集成，以增强 BEV 融合。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19365v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19365v1",
            "title": "Pareto-Guided Optimization for Uncertainty-Aware Medical Image Segmentation",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Pareto-Guided Optimization for Uncertainty-Aware Medical Image Segmentation"
            },
            "updated": "2026-01-27T08:47:01Z",
            "updated_parsed": [
                2026,
                1,
                27,
                8,
                47,
                1,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19365v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19365v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Uncertainty in medical image segmentation is inherently non-uniform, with boundary regions exhibiting substantially higher ambiguity than interior areas. Conventional training treats all pixels equally, leading to unstable optimization during early epochs when predictions are unreliable. We argue that this instability hinders convergence toward Pareto-optimal solutions and propose a region-wise curriculum strategy that prioritizes learning from certain regions and gradually incorporates uncertain ones, reducing gradient variance. Methodologically, we introduce a Pareto-consistent loss that balances trade-offs between regional uncertainties by adaptively reshaping the loss landscape and constraining convergence dynamics between interior and boundary regions; this guides the model toward Pareto-approximate solutions. To address boundary ambiguity, we further develop a fuzzy labeling mechanism that maintains binary confidence in non-boundary areas while enabling smooth transitions near boundaries, stabilizing gradients, and expanding flat regions in the loss surface. Experiments on brain metastasis and non-metastatic tumor segmentation show consistent improvements across multiple configurations, with our method outperforming traditional crisp-set approaches in all tumor subregions.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Uncertainty in medical image segmentation is inherently non-uniform, with boundary regions exhibiting substantially higher ambiguity than interior areas. Conventional training treats all pixels equally, leading to unstable optimization during early epochs when predictions are unreliable. We argue that this instability hinders convergence toward Pareto-optimal solutions and propose a region-wise curriculum strategy that prioritizes learning from certain regions and gradually incorporates uncertain ones, reducing gradient variance. Methodologically, we introduce a Pareto-consistent loss that balances trade-offs between regional uncertainties by adaptively reshaping the loss landscape and constraining convergence dynamics between interior and boundary regions; this guides the model toward Pareto-approximate solutions. To address boundary ambiguity, we further develop a fuzzy labeling mechanism that maintains binary confidence in non-boundary areas while enabling smooth transitions near boundaries, stabilizing gradients, and expanding flat regions in the loss surface. Experiments on brain metastasis and non-metastatic tumor segmentation show consistent improvements across multiple configurations, with our method outperforming traditional crisp-set approaches in all tumor subregions."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T08:47:01Z",
            "published_parsed": [
                2026,
                1,
                27,
                8,
                47,
                1,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Jinming Zhang"
                },
                {
                    "name": "Xi Yang"
                },
                {
                    "name": "Youpeng Yang"
                },
                {
                    "name": "Haosen Shi"
                },
                {
                    "name": "Yuyao Yan"
                },
                {
                    "name": "Qiufeng Wang"
                },
                {
                    "name": "Guangliang Cheng"
                },
                {
                    "name": "Kaizhu Huang"
                }
            ],
            "author_detail": {
                "name": "Kaizhu Huang"
            },
            "author": "Kaizhu Huang",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "帕累托引导的不确定性医学图像分割优化",
            "abstract_cn": "医学图像分割的不确定性本质上是不均匀的，边界区域比内部区域表现出更高的模糊性。传统训练平等对待所有像素，导致预测不可靠的早期阶段优化不稳定。我们认为这种不稳定性阻碍了向帕累托最优解决方案的收敛，并提出了一种按区域的课程策略，优先考虑从某些区域学习并逐渐纳入不确定的区域，从而减少梯度方差。在方法上，我们引入了帕累托一致损失，通过自适应地重塑损失景观并限制内部和边界区域之间的收敛动态来平衡区域不确定性之间的权衡；这引导模型走向帕累托近似解决方案。为了解决边界模糊性，我们进一步开发了一种模糊标记机制，该机制保持非边界区域的二元置信度，同时实现边界附近的平滑过渡，稳定梯度并扩大损失表面中的平坦区域。脑转移和非转移性肿瘤分割的实验表明，多种配置都有一致的改进，我们的方法在所有肿瘤分区中都优于传统的脆集方法。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19378v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19378v1",
            "title": "Establishing dermatopathology encyclopedia DermpathNet with Artificial Intelligence-Based Workflow",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Establishing dermatopathology encyclopedia DermpathNet with Artificial Intelligence-Based Workflow"
            },
            "updated": "2026-01-27T09:02:29Z",
            "updated_parsed": [
                2026,
                1,
                27,
                9,
                2,
                29,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19378v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19378v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Accessing high-quality, open-access dermatopathology image datasets for learning and cross-referencing is a common challenge for clinicians and dermatopathology trainees. To establish a comprehensive open-access dermatopathology dataset for educational, cross-referencing, and machine-learning purposes, we employed a hybrid workflow to curate and categorize images from the PubMed Central (PMC) repository. We used specific keywords to extract relevant images, and classified them using a novel hybrid method that combined deep learning-based image modality classification with figure caption analyses. Validation on 651 manually annotated images demonstrated the robustness of our workflow, with an F-score of 89.6\\% for the deep learning approach, 61.0\\% for the keyword-based retrieval method, and 90.4\\% for the hybrid approach. We retrieved over 7,772 images across 166 diagnoses and released this fully annotated dataset, reviewed by board-certified dermatopathologists. Using our dataset as a challenging task, we found the current image analysis algorithm from OpenAI inadequate for analyzing dermatopathology images. In conclusion, we have developed a large, peer-reviewed, open-access dermatopathology image dataset, DermpathNet, which features a semi-automated curation workflow.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Accessing high-quality, open-access dermatopathology image datasets for learning and cross-referencing is a common challenge for clinicians and dermatopathology trainees. To establish a comprehensive open-access dermatopathology dataset for educational, cross-referencing, and machine-learning purposes, we employed a hybrid workflow to curate and categorize images from the PubMed Central (PMC) repository. We used specific keywords to extract relevant images, and classified them using a novel hybrid method that combined deep learning-based image modality classification with figure caption analyses. Validation on 651 manually annotated images demonstrated the robustness of our workflow, with an F-score of 89.6\\% for the deep learning approach, 61.0\\% for the keyword-based retrieval method, and 90.4\\% for the hybrid approach. We retrieved over 7,772 images across 166 diagnoses and released this fully annotated dataset, reviewed by board-certified dermatopathologists. Using our dataset as a challenging task, we found the current image analysis algorithm from OpenAI inadequate for analyzing dermatopathology images. In conclusion, we have developed a large, peer-reviewed, open-access dermatopathology image dataset, DermpathNet, which features a semi-automated curation workflow."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T09:02:29Z",
            "published_parsed": [
                2026,
                1,
                27,
                9,
                2,
                29,
                1,
                27,
                0
            ],
            "arxiv_comment": "Accepted by Scientific Data",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Ziyang Xu"
                },
                {
                    "name": "Mingquan Lin"
                },
                {
                    "name": "Yiliang Zhou"
                },
                {
                    "name": "Zihan Xu"
                },
                {
                    "name": "Seth J. Orlow"
                },
                {
                    "name": "Zihan Xu"
                },
                {
                    "name": "Shane A. Meehan"
                },
                {
                    "name": "Alexandra Flamm"
                },
                {
                    "name": "Ata S. Moshiri"
                },
                {
                    "name": "Yifan Peng"
                }
            ],
            "author_detail": {
                "name": "Yifan Peng"
            },
            "author": "Yifan Peng",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "利用基于人工智能的工作流程建立皮肤病理学百科全书 DermpathNet",
            "abstract_cn": "访问高质量、开放的皮肤病理学图像数据集进行学习和交叉引用是临床医生和皮肤病理学学员面临的共同挑战。为了建立一个用于教育、交叉引用和机器学习目的的全面的开放获取皮肤病理学数据集，我们采用了混合工作流程来对 PubMed Central (PMC) 存储库中的图像进行整理和分类。我们使用特定的关键字来提取相关图像，并使用一种新颖的混合方法对它们进行分类，该方法将基于深度学习的图像模态分类与图形标题分析相结合。对 651 个手动注释图像的验证证明了我们工作流程的稳健性，深度学习方法的 F 分数为 89.6%，基于关键字的检索方法的 F 分数为 61.0%，混合方法的 F 分数为 90.4%。我们检索了 166 项诊断中的超过 7,772 张图像，并发布了这个完整注释的数据集，并由委员会认证的皮肤病理学家进行了审查。使用我们的数据集作为一项具有挑战性的任务，我们发现 OpenAI 当前的图像分析算法不足以分析皮肤病理学图像。总之，我们开发了一个大型的、经过同行评审的、开放获取的皮肤病理学图像数据集 DermpathNet，它具有半自动管理工作流程。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19430v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19430v1",
            "title": "Unveiling Perceptual Artifacts: A Fine-Grained Benchmark for Interpretable AI-Generated Image Detection",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Unveiling Perceptual Artifacts: A Fine-Grained Benchmark for Interpretable AI-Generated Image Detection"
            },
            "updated": "2026-01-27T10:09:17Z",
            "updated_parsed": [
                2026,
                1,
                27,
                10,
                9,
                17,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19430v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19430v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Current AI-Generated Image (AIGI) detection approaches predominantly rely on binary classification to distinguish real from synthetic images, often lacking interpretable or convincing evidence to substantiate their decisions. This limitation stems from existing AIGI detection benchmarks, which, despite featuring a broad collection of synthetic images, remain restricted in their coverage of artifact diversity and lack detailed, localized annotations. To bridge this gap, we introduce a fine-grained benchmark towards eXplainable AI-Generated image Detection, named X-AIGD, which provides pixel-level, categorized annotations of perceptual artifacts, spanning low-level distortions, high-level semantics, and cognitive-level counterfactuals. These comprehensive annotations facilitate fine-grained interpretability evaluation and deeper insight into model decision-making processes. Our extensive investigation using X-AIGD provides several key insights: (1) Existing AIGI detectors demonstrate negligible reliance on perceptual artifacts, even at the most basic distortion level. (2) While AIGI detectors can be trained to identify specific artifacts, they still substantially base their judgment on uninterpretable features. (3) Explicitly aligning model attention with artifact regions can increase the interpretability and generalization of detectors. The data and code are available at: https://github.com/Coxy7/X-AIGD.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Current AI-Generated Image (AIGI) detection approaches predominantly rely on binary classification to distinguish real from synthetic images, often lacking interpretable or convincing evidence to substantiate their decisions. This limitation stems from existing AIGI detection benchmarks, which, despite featuring a broad collection of synthetic images, remain restricted in their coverage of artifact diversity and lack detailed, localized annotations. To bridge this gap, we introduce a fine-grained benchmark towards eXplainable AI-Generated image Detection, named X-AIGD, which provides pixel-level, categorized annotations of perceptual artifacts, spanning low-level distortions, high-level semantics, and cognitive-level counterfactuals. These comprehensive annotations facilitate fine-grained interpretability evaluation and deeper insight into model decision-making processes. Our extensive investigation using X-AIGD provides several key insights: (1) Existing AIGI detectors demonstrate negligible reliance on perceptual artifacts, even at the most basic distortion level. (2) While AIGI detectors can be trained to identify specific artifacts, they still substantially base their judgment on uninterpretable features. (3) Explicitly aligning model attention with artifact regions can increase the interpretability and generalization of detectors. The data and code are available at: https://github.com/Coxy7/X-AIGD."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T10:09:17Z",
            "published_parsed": [
                2026,
                1,
                27,
                10,
                9,
                17,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Yao Xiao"
                },
                {
                    "name": "Weiyan Chen"
                },
                {
                    "name": "Jiahao Chen"
                },
                {
                    "name": "Zijie Cao"
                },
                {
                    "name": "Weijian Deng"
                },
                {
                    "name": "Binbin Yang"
                },
                {
                    "name": "Ziyi Dong"
                },
                {
                    "name": "Xiangyang Ji"
                },
                {
                    "name": "Wei Ke"
                },
                {
                    "name": "Pengxu Wei"
                },
                {
                    "name": "Liang Lin"
                }
            ],
            "author_detail": {
                "name": "Liang Lin"
            },
            "author": "Liang Lin",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "揭开感知伪影：可解释的人工智能生成图像检测的细粒度基准",
            "abstract_cn": "当前的人工智能生成图像（AIGI）检测方法主要依靠二元分类来区分真实图像和合成图像，通常缺乏可解释或令人信服的证据来证实其决策。这一限制源于现有的 AIGI 检测基准，尽管其具有广泛的合成图像集合，但其对工件多样性的覆盖范围仍然受到限制，并且缺乏详细的本地化注释。为了弥补这一差距，我们引入了一个针对可解释人工智能生成图像检测的细粒度基准，名为 X-AIGD，它提供了像素级的感知伪影的分类注释，涵盖低级失真、高级语义和认知级反事实。这些全面的注释有助于细粒度的可解释性评估和对模型决策过程的更深入了解。我们使用 X-AIGD 进行的广泛调查提供了几个关键见解：（1）现有的 AIGI 探测器表现出对感知伪影的依赖可以忽略不计，即使在最基本的失真水平上也是如此。 (2) 虽然 AIGI 检测器可以被训练来识别特定的伪影，但它们的判断仍然基本上基于无法解释的特征。 (3) 明确地将模型注意力与伪影区域对齐可以提高检测器的可解释性和泛化性。数据和代码可在以下网址获取：https://github.com/Coxy7/X-AIGD。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19433v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19433v1",
            "title": "RoamScene3D: Immersive Text-to-3D Scene Generation via Adaptive Object-aware Roaming",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "RoamScene3D: Immersive Text-to-3D Scene Generation via Adaptive Object-aware Roaming"
            },
            "updated": "2026-01-27T10:10:55Z",
            "updated_parsed": [
                2026,
                1,
                27,
                10,
                10,
                55,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19433v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19433v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Generating immersive 3D scenes from texts is a core task in computer vision, crucial for applications in virtual reality and game development. Despite the promise of leveraging 2D diffusion priors, existing methods suffer from spatial blindness and rely on predefined trajectories that fail to exploit the inner relationships among salient objects. Consequently, these approaches are unable to comprehend the semantic layout, preventing them from exploring the scene adaptively to infer occluded content. Moreover, current inpainting models operate in 2D image space, struggling to plausibly fill holes caused by camera motion. To address these limitations, we propose RoamScene3D, a novel framework that bridges the gap between semantic guidance and spatial generation. Our method reasons about the semantic relations among objects and produces consistent and photorealistic scenes. Specifically, we employ a vision-language model (VLM) to construct a scene graph that encodes object relations, guiding the camera to perceive salient object boundaries and plan an adaptive roaming trajectory. Furthermore, to mitigate the limitations of static 2D priors, we introduce a Motion-Injected Inpainting model that is fine-tuned on a synthetic panoramic dataset integrating authentic camera trajectories, making it adaptive to camera motion. Extensive experiments demonstrate that with semantic reasoning and geometric constraints, our method significantly outperforms state-of-the-art approaches in producing consistent and photorealistic scenes. Our code is available at https://github.com/JS-CHU/RoamScene3D.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Generating immersive 3D scenes from texts is a core task in computer vision, crucial for applications in virtual reality and game development. Despite the promise of leveraging 2D diffusion priors, existing methods suffer from spatial blindness and rely on predefined trajectories that fail to exploit the inner relationships among salient objects. Consequently, these approaches are unable to comprehend the semantic layout, preventing them from exploring the scene adaptively to infer occluded content. Moreover, current inpainting models operate in 2D image space, struggling to plausibly fill holes caused by camera motion. To address these limitations, we propose RoamScene3D, a novel framework that bridges the gap between semantic guidance and spatial generation. Our method reasons about the semantic relations among objects and produces consistent and photorealistic scenes. Specifically, we employ a vision-language model (VLM) to construct a scene graph that encodes object relations, guiding the camera to perceive salient object boundaries and plan an adaptive roaming trajectory. Furthermore, to mitigate the limitations of static 2D priors, we introduce a Motion-Injected Inpainting model that is fine-tuned on a synthetic panoramic dataset integrating authentic camera trajectories, making it adaptive to camera motion. Extensive experiments demonstrate that with semantic reasoning and geometric constraints, our method significantly outperforms state-of-the-art approaches in producing consistent and photorealistic scenes. Our code is available at https://github.com/JS-CHU/RoamScene3D."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T10:10:55Z",
            "published_parsed": [
                2026,
                1,
                27,
                10,
                10,
                55,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Jisheng Chu"
                },
                {
                    "name": "Wenrui Li"
                },
                {
                    "name": "Rui Zhao"
                },
                {
                    "name": "Wangmeng Zuo"
                },
                {
                    "name": "Shifeng Chen"
                },
                {
                    "name": "Xiaopeng Fan"
                }
            ],
            "author_detail": {
                "name": "Xiaopeng Fan"
            },
            "author": "Xiaopeng Fan",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "RoamScene3D：通过自适应对象感知漫游生成沉浸式文本到 3D 场景",
            "abstract_cn": "从文本生成沉浸式 3D 场景是计算机视觉的核心任务，对于虚拟现实和游戏开发中的应用至关重要。尽管有望利用二维扩散先验，但现有方法存在空间盲性，并且依赖于无法利用显着对象之间的内部关系的预定义轨迹。因此，这些方法无法理解语义布局，从而阻止它们自适应地探索场景以推断被遮挡的内容。此外，当前的修复模型在 2D 图像空间中运行，难以合理地填补相机运动造成的漏洞。为了解决这些限制，我们提出了 RoamScene3D，这是一种弥合语义引导和空间生成之间差距的新颖框架。我们的方法推理对象之间的语义关系并产生一致且逼真的场景。具体来说，我们采用视觉语言模型（VLM）来构建对对象关系进行编码的场景图，引导相机感知显着的对象边界并规划自适应漫游轨迹。此外，为了减轻静态 2D 先验的局限性，我们引入了运动注入修复模型，该模型在集成真实相机轨迹的合成全景数据集上进行微调，使其适应相机运动。大量的实验表明，通过语义推理和几何约束，我们的方法在生成一致且逼真的场景方面显着优于最先进的方法。我们的代码可在 https://github.com/JS-CHU/RoamScene3D 获取。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19446v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19446v1",
            "title": "DSTCS: Dual-Student Teacher Framework with Segment Anything Model for Semi-Supervised Pubic Symphysis Fetal Head Segmentation",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "DSTCS: Dual-Student Teacher Framework with Segment Anything Model for Semi-Supervised Pubic Symphysis Fetal Head Segmentation"
            },
            "updated": "2026-01-27T10:32:28Z",
            "updated_parsed": [
                2026,
                1,
                27,
                10,
                32,
                28,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19446v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19446v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Segmentation of the pubic symphysis and fetal head (PSFH) is a critical procedure in intrapartum monitoring and is essential for evaluating labor progression and identifying potential delivery complications. However, achieving accurate segmentation remains a significant challenge due to class imbalance, ambiguous boundaries, and noise interference in ultrasound images, compounded by the scarcity of high-quality annotated data. Current research on PSFH segmentation predominantly relies on CNN and Transformer architectures, leaving the potential of more powerful models underexplored. In this work, we propose a Dual-Student and Teacher framework combining CNN and SAM (DSTCS), which integrates the Segment Anything Model (SAM) into a dual student-teacher architecture. A cooperative learning mechanism between the CNN and SAM branches significantly improves segmentation accuracy. The proposed scheme also incorporates a specialized data augmentation strategy optimized for boundary processing and a novel loss function. Extensive experiments on the MICCAI 2023 and 2024 PSFH segmentation benchmarks demonstrate that our method exhibits superior robustness and significantly outperforms existing techniques, providing a reliable segmentation tool for clinical practice.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Segmentation of the pubic symphysis and fetal head (PSFH) is a critical procedure in intrapartum monitoring and is essential for evaluating labor progression and identifying potential delivery complications. However, achieving accurate segmentation remains a significant challenge due to class imbalance, ambiguous boundaries, and noise interference in ultrasound images, compounded by the scarcity of high-quality annotated data. Current research on PSFH segmentation predominantly relies on CNN and Transformer architectures, leaving the potential of more powerful models underexplored. In this work, we propose a Dual-Student and Teacher framework combining CNN and SAM (DSTCS), which integrates the Segment Anything Model (SAM) into a dual student-teacher architecture. A cooperative learning mechanism between the CNN and SAM branches significantly improves segmentation accuracy. The proposed scheme also incorporates a specialized data augmentation strategy optimized for boundary processing and a novel loss function. Extensive experiments on the MICCAI 2023 and 2024 PSFH segmentation benchmarks demonstrate that our method exhibits superior robustness and significantly outperforms existing techniques, providing a reliable segmentation tool for clinical practice."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T10:32:28Z",
            "published_parsed": [
                2026,
                1,
                27,
                10,
                32,
                28,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Yalin Luo"
                },
                {
                    "name": "Shun Long"
                },
                {
                    "name": "Huijin Wang"
                },
                {
                    "name": "Jieyun Bai"
                }
            ],
            "author_detail": {
                "name": "Jieyun Bai"
            },
            "author": "Jieyun Bai",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "DSTCS：具有分段任意模型的双学生教师框架，用于半监督耻骨联合胎头分割",
            "abstract_cn": "耻骨联合和胎头 (PSFH) 的分割是产时监测的关键程序，对于评估产程进展和识别潜在的分娩并发症至关重要。然而，由于超声图像中的类别不平衡、边界模糊和噪声干扰，再加上高质量注释数据的稀缺，实现准确的分割仍然是一个重大挑战。目前 PSFH 分割的研究主要依赖于 CNN 和 Transformer 架构，而更强大的模型的潜力尚未得到充分开发。在这项工作中，我们提出了一种结合 CNN 和 SAM (DSTCS) 的双学生和教师框架，它将分段任意模型 (SAM) 集成到双学生-教师架构中。 CNN 和 SAM 分支之间的协作学习机制显着提高了分割精度。所提出的方案还结合了针对边界处理优化的专门数据增强策略和新颖的损失函数。对 MICCAI 2023 和 2024 PSFH 分割基准的大量实验表明，我们的方法表现出卓越的稳健性，并且显着优于现有技术，为临床实践提供了可靠的分割工具。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19489v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19489v1",
            "title": "Fast Converging 3D Gaussian Splatting for 1-Minute Reconstruction",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Fast Converging 3D Gaussian Splatting for 1-Minute Reconstruction"
            },
            "updated": "2026-01-27T11:20:37Z",
            "updated_parsed": [
                2026,
                1,
                27,
                11,
                20,
                37,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19489v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19489v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We present a fast 3DGS reconstruction pipeline designed to converge within one minute, developed for the SIGGRAPH Asia 3DGS Fast Reconstruction Challenge. The challenge consists of an initial round using SLAM-generated camera poses (with noisy trajectories) and a final round using COLMAP poses (highly accurate). To robustly handle these heterogeneous settings, we develop a two-stage solution. In the first round, we use reverse per-Gaussian parallel optimization and compact forward splatting based on Taming-GS and Speedy-splat, load-balanced tiling, an anchor-based Neural-Gaussian representation enabling rapid convergence with fewer learnable parameters, initialization from monocular depth and partially from feed-forward 3DGS models, and a global pose refinement module for noisy SLAM trajectories. In the final round, the accurate COLMAP poses change the optimization landscape; we disable pose refinement, revert from Neural-Gaussians back to standard 3DGS to eliminate MLP inference overhead, introduce multi-view consistency-guided Gaussian splitting inspired by Fast-GS, and introduce a depth estimator to supervise the rendered depth. Together, these techniques enable high-fidelity reconstruction under a strict one-minute budget. Our method achieved the top performance with a PSNR of 28.43 and ranked first in the competition.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We present a fast 3DGS reconstruction pipeline designed to converge within one minute, developed for the SIGGRAPH Asia 3DGS Fast Reconstruction Challenge. The challenge consists of an initial round using SLAM-generated camera poses (with noisy trajectories) and a final round using COLMAP poses (highly accurate). To robustly handle these heterogeneous settings, we develop a two-stage solution. In the first round, we use reverse per-Gaussian parallel optimization and compact forward splatting based on Taming-GS and Speedy-splat, load-balanced tiling, an anchor-based Neural-Gaussian representation enabling rapid convergence with fewer learnable parameters, initialization from monocular depth and partially from feed-forward 3DGS models, and a global pose refinement module for noisy SLAM trajectories. In the final round, the accurate COLMAP poses change the optimization landscape; we disable pose refinement, revert from Neural-Gaussians back to standard 3DGS to eliminate MLP inference overhead, introduce multi-view consistency-guided Gaussian splitting inspired by Fast-GS, and introduce a depth estimator to supervise the rendered depth. Together, these techniques enable high-fidelity reconstruction under a strict one-minute budget. Our method achieved the top performance with a PSNR of 28.43 and ranked first in the competition."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T11:20:37Z",
            "published_parsed": [
                2026,
                1,
                27,
                11,
                20,
                37,
                1,
                27,
                0
            ],
            "arxiv_comment": "First Rank of SIGGRAPH Asia 2025 3DGS Challenge. Code available at",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Ziyu Zhang"
                },
                {
                    "name": "Tianle Liu"
                },
                {
                    "name": "Diantao Tu"
                },
                {
                    "name": "Shuhan Shen"
                }
            ],
            "author_detail": {
                "name": "Shuhan Shen"
            },
            "author": "Shuhan Shen",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "用于 1 分钟重建的快速收敛 3D 高斯分布",
            "abstract_cn": "我们提出了一种快速 3DGS 重建管道，旨在在一分钟内收敛，是为 SIGGRAPH 亚洲 3DGS 快速重建挑战赛开发的。该挑战包括使用 SLAM 生成的相机姿势（具有噪声轨迹）的初始回合和使用 COLMAP 姿势（高度准确）的最后一轮。为了稳健地处理这些异构设置，我们开发了一个两阶段解决方案。在第一轮中，我们使用反向每高斯并行优化和基于 Taming-GS 和 Speedy-splat 的紧凑前向泼溅、负载平衡平铺、基于锚点的神经高斯表示，可以使用更少的可学习参数快速收敛、从单目深度初始化并部分从前馈 3DGS 模型进行初始化，以及用于噪声 SLAM 轨迹的全局姿态细化模块。在最后一轮中，准确的 COLMAP 姿势改变了优化格局；我们禁用姿势细化，从神经高斯恢复到标准 3DGS 以消除 MLP 推理开销，引入受 Fast-GS 启发的多视图一致性引导高斯分割，并引入深度估计器来监督渲染深度。这些技术共同实现了在严格的一分钟预算下的高保真重建。我们的方法以 28.43 的 PSNR 达到了最佳性能，在比赛中排名第一。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19498v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19498v1",
            "title": "Cortex-Grounded Diffusion Models for Brain Image Generation",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Cortex-Grounded Diffusion Models for Brain Image Generation"
            },
            "updated": "2026-01-27T11:34:43Z",
            "updated_parsed": [
                2026,
                1,
                27,
                11,
                34,
                43,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19498v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19498v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Synthetic neuroimaging data can mitigate critical limitations of real-world datasets, including the scarcity of rare phenotypes, domain shifts across scanners, and insufficient longitudinal coverage. However, existing generative models largely rely on weak conditioning signals, such as labels or text, which lack anatomical grounding and often produce biologically implausible outputs. To this end, we introduce Cor2Vox, a cortex-grounded generative framework for brain magnetic resonance image (MRI) synthesis that ties image generation to continuous structural priors of the cerebral cortex. It leverages high-resolution cortical surfaces to guide a 3D shape-to-image Brownian bridge diffusion process, enabling topologically faithful synthesis and precise control over underlying anatomies. To support the generation of new, realistic brain shapes, we developed a large-scale statistical shape model of cortical morphology derived from over 33,000 UK Biobank scans. We validated the fidelity of Cor2Vox based on traditional image quality metrics, advanced cortical surface reconstruction, and whole-brain segmentation quality, outperforming many baseline methods. Across three applications, namely (i) anatomically consistent synthesis, (ii) simulation of progressive gray matter atrophy, and (iii) harmonization of in-house frontotemporal dementia scans with public datasets, Cor2Vox preserved fine-grained cortical morphology at the sub-voxel level, exhibiting remarkable robustness to variations in cortical geometry and disease phenotype without retraining.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Synthetic neuroimaging data can mitigate critical limitations of real-world datasets, including the scarcity of rare phenotypes, domain shifts across scanners, and insufficient longitudinal coverage. However, existing generative models largely rely on weak conditioning signals, such as labels or text, which lack anatomical grounding and often produce biologically implausible outputs. To this end, we introduce Cor2Vox, a cortex-grounded generative framework for brain magnetic resonance image (MRI) synthesis that ties image generation to continuous structural priors of the cerebral cortex. It leverages high-resolution cortical surfaces to guide a 3D shape-to-image Brownian bridge diffusion process, enabling topologically faithful synthesis and precise control over underlying anatomies. To support the generation of new, realistic brain shapes, we developed a large-scale statistical shape model of cortical morphology derived from over 33,000 UK Biobank scans. We validated the fidelity of Cor2Vox based on traditional image quality metrics, advanced cortical surface reconstruction, and whole-brain segmentation quality, outperforming many baseline methods. Across three applications, namely (i) anatomically consistent synthesis, (ii) simulation of progressive gray matter atrophy, and (iii) harmonization of in-house frontotemporal dementia scans with public datasets, Cor2Vox preserved fine-grained cortical morphology at the sub-voxel level, exhibiting remarkable robustness to variations in cortical geometry and disease phenotype without retraining."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.LG",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T11:34:43Z",
            "published_parsed": [
                2026,
                1,
                27,
                11,
                34,
                43,
                1,
                27,
                0
            ],
            "arxiv_comment": "preprint",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Fabian Bongratz"
                },
                {
                    "name": "Yitong Li"
                },
                {
                    "name": "Sama Elbaroudy"
                },
                {
                    "name": "Christian Wachinger"
                }
            ],
            "author_detail": {
                "name": "Christian Wachinger"
            },
            "author": "Christian Wachinger",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "用于生成大脑图像的皮层接地扩散模型",
            "abstract_cn": "合成神经影像数据可以减轻现实世界数据集的关键局限性，包括稀有表型的稀缺、扫描仪之间的域转移以及纵向覆盖范围不足。然而，现有的生成模型很大程度上依赖于弱条件信号，例如标签或文本，这些信号缺乏解剖学基础，并且经常产生生物学上不可信的输出。为此，我们引入了 Cor2Vox，这是一种基于皮层的脑磁共振图像 (MRI) 合成生成框架，它将图像生成与大脑皮层的连续结构先验联系起来。它利用高分辨率皮质表面来引导 3D 形状到图像布朗桥扩散过程，从而实现拓扑忠实的合成和对底层解剖结构的精确控制。为了支持新的、真实的大脑形状的生成，我们开发了一个大规模的皮质形态统计形状模型，该模型源自超过 33,000 个英国生物银行扫描。我们基于传统图像质量指标、先进的皮层表面重建和全脑分割质量验证了 Cor2Vox 的保真度，其性能优于许多基线方法。在三个应用中，即（i）解剖学上一致的合成，（ii）进行性灰质萎缩的模拟，以及（iii）内部额颞叶痴呆扫描与公共数据集的协调，Cor2Vox 在亚体素水平上保留了细粒度的皮质形态，在无需重新训练的情况下对皮质几何和疾病表型的变化表现出显着的鲁棒性。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19519v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19519v1",
            "title": "Mocap Anywhere: Towards Pairwise-Distance based Motion Capture in the Wild (for the Wild)",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Mocap Anywhere: Towards Pairwise-Distance based Motion Capture in the Wild (for the Wild)"
            },
            "updated": "2026-01-27T11:58:34Z",
            "updated_parsed": [
                2026,
                1,
                27,
                11,
                58,
                34,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19519v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19519v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We introduce a novel motion capture system that reconstructs full-body 3D motion using only sparse pairwise distance (PWD) measurements from body-mounted(UWB) sensors. Using time-of-flight ranging between wireless nodes, our method eliminates the need for external cameras, enabling robust operation in uncontrolled and outdoor environments. Unlike traditional optical or inertial systems, our approach is shape-invariant and resilient to environmental constraints such as lighting and magnetic interference. At the core of our system is Wild-Poser (WiP for short), a compact, real-time Transformer-based architecture that directly predicts 3D joint positions from noisy or corrupted PWD measurements, which can later be used for joint rotation reconstruction via learned methods. WiP generalizes across subjects of varying morphologies, including non-human species, without requiring individual body measurements or shape fitting. Operating in real time, WiP achieves low joint position error and demonstrates accurate 3D motion reconstruction for both human and animal subjects in-the-wild. Our empirical analysis highlights its potential for scalable, low-cost, and general purpose motion capture in real-world settings.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We introduce a novel motion capture system that reconstructs full-body 3D motion using only sparse pairwise distance (PWD) measurements from body-mounted(UWB) sensors. Using time-of-flight ranging between wireless nodes, our method eliminates the need for external cameras, enabling robust operation in uncontrolled and outdoor environments. Unlike traditional optical or inertial systems, our approach is shape-invariant and resilient to environmental constraints such as lighting and magnetic interference. At the core of our system is Wild-Poser (WiP for short), a compact, real-time Transformer-based architecture that directly predicts 3D joint positions from noisy or corrupted PWD measurements, which can later be used for joint rotation reconstruction via learned methods. WiP generalizes across subjects of varying morphologies, including non-human species, without requiring individual body measurements or shape fitting. Operating in real time, WiP achieves low joint position error and demonstrates accurate 3D motion reconstruction for both human and animal subjects in-the-wild. Our empirical analysis highlights its potential for scalable, low-cost, and general purpose motion capture in real-world settings."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.GR",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.LG",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T11:58:34Z",
            "published_parsed": [
                2026,
                1,
                27,
                11,
                58,
                34,
                1,
                27,
                0
            ],
            "arxiv_comment": "14 pages, 15 figures",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Ofir Abramovich"
                },
                {
                    "name": "Ariel Shamir"
                },
                {
                    "name": "Andreas Aristidou"
                }
            ],
            "author_detail": {
                "name": "Andreas Aristidou"
            },
            "author": "Andreas Aristidou",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "Mocap Anywhere：在野外进行基于成对距离的动作捕捉（for the Wild）",
            "abstract_cn": "我们引入了一种新颖的运动捕捉系统，该系统仅使用来自人体安装 (UWB) 传感器的稀疏成对距离 (PWD) 测量来重建全身 3D 运动。我们的方法利用无线节点之间的飞行时间测距，无需外部摄像头，从而能够在不受控制的室外环境中实现稳健运行。与传统的光学或惯性系统不同，我们的方法具有形状不变性，并且能够适应照明和磁干扰等环境限制。我们系统的核心是 Wild-Poser（简称 WiP），这是一种紧凑的、基于 Transformer 的实时架构，可以直接从噪声或损坏的 PWD 测量中预测 3D 关节位置，稍后可以通过学习方法用于关节旋转重建。 WiP 适用于不同形态的受试者，包括非人类物种，无需进行个人身体测量或形状拟合。 WiP 实时运行，可实现较低的关节位置误差，并为野外的人类和动物对象演示准确的 3D 运动重建。我们的实证分析强调了其在现实世界环境中可扩展、低成本和通用运动捕捉的潜力。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19526v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19526v1",
            "title": "A Non-Invasive 3D Gait Analysis Framework for Quantifying Psychomotor Retardation in Major Depressive Disorder",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "A Non-Invasive 3D Gait Analysis Framework for Quantifying Psychomotor Retardation in Major Depressive Disorder"
            },
            "updated": "2026-01-27T12:07:21Z",
            "updated_parsed": [
                2026,
                1,
                27,
                12,
                7,
                21,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19526v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19526v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Predicting the status of Major Depressive Disorder (MDD) from objective, non-invasive methods is an active research field. Yet, extracting automatically objective, interpretable features for a detailed analysis of the patient state remains largely unexplored.\n  Among MDD's symptoms, Psychomotor retardation (PMR) is a core item, yet its clinical assessment remains largely subjective. While 3D motion capture offers an objective alternative, its reliance on specialized hardware often precludes routine clinical use. In this paper, we propose a non-invasive computational framework that transforms monocular RGB video into clinically relevant 3D gait kinematics. Our pipeline uses Gravity-View Coordinates along with a novel trajectory-correction algorithm that leverages the closed-loop topology of our adapted Timed Up and Go (TUG) protocol to mitigate monocular depth errors. This novel pipeline enables the extraction of 297 explicit gait biomechanical biomarkers from a single camera capture.\n  To address the challenges of small clinical datasets, we introduce a stability-based machine learning framework that identifies robust motor signatures while preventing overfitting. Validated on the CALYPSO dataset, our method achieves an 83.3% accuracy in detecting PMR and explains 64% of the variance in overall depression severity (R^2=0.64). Notably, our study reveals a strong link between reduced ankle propulsion and restricted pelvic mobility to the depressive motor phenotype. These results demonstrate that physical movement serves as a robust proxy for the cognitive state, offering a transparent and scalable tool for the objective monitoring of depression in standard clinical environments.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Predicting the status of Major Depressive Disorder (MDD) from objective, non-invasive methods is an active research field. Yet, extracting automatically objective, interpretable features for a detailed analysis of the patient state remains largely unexplored.\n  Among MDD's symptoms, Psychomotor retardation (PMR) is a core item, yet its clinical assessment remains largely subjective. While 3D motion capture offers an objective alternative, its reliance on specialized hardware often precludes routine clinical use. In this paper, we propose a non-invasive computational framework that transforms monocular RGB video into clinically relevant 3D gait kinematics. Our pipeline uses Gravity-View Coordinates along with a novel trajectory-correction algorithm that leverages the closed-loop topology of our adapted Timed Up and Go (TUG) protocol to mitigate monocular depth errors. This novel pipeline enables the extraction of 297 explicit gait biomechanical biomarkers from a single camera capture.\n  To address the challenges of small clinical datasets, we introduce a stability-based machine learning framework that identifies robust motor signatures while preventing overfitting. Validated on the CALYPSO dataset, our method achieves an 83.3% accuracy in detecting PMR and explains 64% of the variance in overall depression severity (R^2=0.64). Notably, our study reveals a strong link between reduced ankle propulsion and restricted pelvic mobility to the depressive motor phenotype. These results demonstrate that physical movement serves as a robust proxy for the cognitive state, offering a transparent and scalable tool for the objective monitoring of depression in standard clinical environments."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T12:07:21Z",
            "published_parsed": [
                2026,
                1,
                27,
                12,
                7,
                21,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Fouad Boutaleb"
                },
                {
                    "name": "Emery Pierson"
                },
                {
                    "name": "Mohamed Daoudi"
                },
                {
                    "name": "Clémence Nineuil"
                },
                {
                    "name": "Ali Amad"
                },
                {
                    "name": "Fabien D'Hondt"
                }
            ],
            "author_detail": {
                "name": "Fabien D'Hondt"
            },
            "author": "Fabien D'Hondt",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "用于量化重度抑郁症精神运动迟缓的非侵入性 3D 步态分析框架",
            "abstract_cn": "通过客观、非侵入性的方法预测重度抑郁症 (MDD) 的状况是一个活跃的研究领域。然而，自动提取客观的、可解释的特征以对患者状态进行详细分析仍然很大程度上未被探索。\n  在 MDD 的症状中，精神运动迟缓（PMR）是一个核心项目，但其临床评估仍然很大程度上是主观的。虽然 3D 动作捕捉提供了一种客观的替代方案，但其对专用硬件的依赖通常妨碍了常规临床使用。在本文中，我们提出了一种非侵入性计算框架，可将单眼 RGB 视频转换为临床相关的 3D 步态运动学。我们的流程使用重力视图坐标以及新颖的轨迹校正算法，该算法利用我们改编的 Timed Up and Go (TUG) 协议的闭环拓扑来减轻单眼深度误差。这种新颖的流程能够从单个相机捕​​获中提取 297 个显式步态生物力学生物标记。\n  为了解决小型临床数据集的挑战，我们引入了基于稳定性的机器学习框架，该框架可以识别强大的运动特征，同时防止过度拟合。在 CALYPSO 数据集上进行验证，我们的方法在检测 PMR 方面达到了 83.3% 的准确率，并解释了总体抑郁严重程度的 64% 的方差 (R^2=0.64)。值得注意的是，我们的研究揭示了踝关节推进力减少和骨盆活动受限与抑郁运动表型之间的密切联系。这些结果表明，身体运动可以作为认知状态的有力代理，为标准临床环境中抑郁症的客观监测提供透明且可扩展的工具。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19557v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19557v1",
            "title": "The S3LI Vulcano Dataset: A Dataset for Multi-Modal SLAM in Unstructured Planetary Environments",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "The S3LI Vulcano Dataset: A Dataset for Multi-Modal SLAM in Unstructured Planetary Environments"
            },
            "updated": "2026-01-27T12:49:40Z",
            "updated_parsed": [
                2026,
                1,
                27,
                12,
                49,
                40,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19557v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19557v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "We release the S3LI Vulcano dataset, a multi-modal dataset towards development and benchmarking of Simultaneous Localization and Mapping (SLAM) and place recognition algorithms that rely on visual and LiDAR modalities. Several sequences are recorded on the volcanic island of Vulcano, from the Aeolian Islands in Sicily, Italy. The sequences provide users with data from a variety of environments, textures and terrains, including basaltic or iron-rich rocks, geological formations from old lava channels, as well as dry vegetation and water. The data (rmc.dlr.de/s3li_dataset) is accompanied by an open source toolkit (github.com/DLR-RM/s3li-toolkit) providing tools for generating ground truth poses as well as preparation of labelled samples for place recognition tasks.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We release the S3LI Vulcano dataset, a multi-modal dataset towards development and benchmarking of Simultaneous Localization and Mapping (SLAM) and place recognition algorithms that rely on visual and LiDAR modalities. Several sequences are recorded on the volcanic island of Vulcano, from the Aeolian Islands in Sicily, Italy. The sequences provide users with data from a variety of environments, textures and terrains, including basaltic or iron-rich rocks, geological formations from old lava channels, as well as dry vegetation and water. The data (rmc.dlr.de/s3li_dataset) is accompanied by an open source toolkit (github.com/DLR-RM/s3li-toolkit) providing tools for generating ground truth poses as well as preparation of labelled samples for place recognition tasks."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.RO",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T12:49:40Z",
            "published_parsed": [
                2026,
                1,
                27,
                12,
                49,
                40,
                1,
                27,
                0
            ],
            "arxiv_comment": "Accepted submission to the 2026 IEEE Aerospace Conference",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Riccardo Giubilato"
                },
                {
                    "name": "Marcus Gerhard Müller"
                },
                {
                    "name": "Marco Sewtz"
                },
                {
                    "name": "Laura Alejandra Encinar Gonzalez"
                },
                {
                    "name": "John Folkesson"
                },
                {
                    "name": "Rudolph Triebel"
                }
            ],
            "author_detail": {
                "name": "Rudolph Triebel"
            },
            "author": "Rudolph Triebel",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "S3LI Vulcano 数据集：非结构化行星环境中的多模态 SLAM 数据集",
            "abstract_cn": "我们发布了 S3LI Vulcano 数据集，这是一个多模态数据集，用于开发和基准测试同时定位和建图 (SLAM) 以及依赖视觉和 LiDAR 模态的地点识别算法。在意大利西西里岛伊奥利亚群岛的武尔卡诺火山岛上记录了几个序列。这些序列为用户提供了来自各种环境、纹理和地形的数据，包括玄武岩或富含铁的岩石、古老熔岩通道的地质构造以及干燥的植被和水。该数据 (rmc.dlr.de/s3li_dataset) 附带一个开源工具包 (github.com/DLR-RM/s3li-toolkit)，提供用于生成地面真实姿势以及为地点识别任务准备标记样本的工具。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19582v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19582v1",
            "title": "ScenePilot-Bench: A Large-Scale Dataset and Benchmark for Evaluation of Vision-Language Models in Autonomous Driving",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "ScenePilot-Bench: A Large-Scale Dataset and Benchmark for Evaluation of Vision-Language Models in Autonomous Driving"
            },
            "updated": "2026-01-27T13:17:50Z",
            "updated_parsed": [
                2026,
                1,
                27,
                13,
                17,
                50,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19582v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19582v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "In this paper, we introduce ScenePilot-Bench, a large-scale first-person driving benchmark designed to evaluate vision-language models (VLMs) in autonomous driving scenarios. ScenePilot-Bench is built upon ScenePilot-4K, a diverse dataset comprising 3,847 hours of driving videos, annotated with multi-granularity information including scene descriptions, risk assessments, key participant identification, ego trajectories, and camera parameters. The benchmark features a four-axis evaluation suite that assesses VLM capabilities in scene understanding, spatial perception, motion planning, and GPT-Score, with safety-aware metrics and cross-region generalization settings. We benchmark representative VLMs on ScenePilot-Bench, providing empirical analyses that clarify current performance boundaries and identify gaps for driving-oriented reasoning. ScenePilot-Bench offers a comprehensive framework for evaluating and advancing VLMs in safety-critical autonomous driving contexts.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "In this paper, we introduce ScenePilot-Bench, a large-scale first-person driving benchmark designed to evaluate vision-language models (VLMs) in autonomous driving scenarios. ScenePilot-Bench is built upon ScenePilot-4K, a diverse dataset comprising 3,847 hours of driving videos, annotated with multi-granularity information including scene descriptions, risk assessments, key participant identification, ego trajectories, and camera parameters. The benchmark features a four-axis evaluation suite that assesses VLM capabilities in scene understanding, spatial perception, motion planning, and GPT-Score, with safety-aware metrics and cross-region generalization settings. We benchmark representative VLMs on ScenePilot-Bench, providing empirical analyses that clarify current performance boundaries and identify gaps for driving-oriented reasoning. ScenePilot-Bench offers a comprehensive framework for evaluating and advancing VLMs in safety-critical autonomous driving contexts."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T13:17:50Z",
            "published_parsed": [
                2026,
                1,
                27,
                13,
                17,
                50,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Yujin Wang"
                },
                {
                    "name": "Yutong Zheng"
                },
                {
                    "name": "Wenxian Fan"
                },
                {
                    "name": "Tianyi Wang"
                },
                {
                    "name": "Hongqing Chu"
                },
                {
                    "name": "Daxin Tian"
                },
                {
                    "name": "Bingzhao Gao"
                },
                {
                    "name": "Jianqiang Wang"
                },
                {
                    "name": "Hong Chen"
                }
            ],
            "author_detail": {
                "name": "Hong Chen"
            },
            "author": "Hong Chen",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "ScenePilot-Bench：自动驾驶视觉语言模型评估的大规模数据集和基准",
            "abstract_cn": "在本文中，我们介绍了 ScenePilot-Bench，这是一个大型第一人称驾驶基准测试，旨在评估自动驾驶场景中的视觉语言模型 (VLM)。 ScenePilot-Bench 基于 ScenePilot-4K 构建，ScenePilot-4K 是一个多样化的数据集，包含 3,847 小时的驾驶视频，并带有多粒度信息注释，包括场景描述、风险评估、关键参与者识别、自我轨迹和摄像头参数。该基准测试具有四轴评估套件，可评估 VLM 在场景理解、空间感知、运动规划和 GPT 评分方面的功能，并具有安全意识指标和跨区域泛化设置。我们在 ScenePilot-Bench 上对代表性 VLM 进行基准测试，提供实证分析，阐明当前的性能边界并确定驾驶导向推理的差距。 ScenePilot-Bench 提供了一个全面的框架，用于在安全关键的自动驾驶环境中评估和推进 VLM。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19593v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19593v1",
            "title": "Localized Latent Editing for Dose-Response Modeling in Botulinum Toxin Injection Planning",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Localized Latent Editing for Dose-Response Modeling in Botulinum Toxin Injection Planning"
            },
            "updated": "2026-01-27T13:26:29Z",
            "updated_parsed": [
                2026,
                1,
                27,
                13,
                26,
                29,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19593v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19593v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Botulinum toxin (Botox) injections are the gold standard for managing facial asymmetry and aesthetic rejuvenation, yet determining the optimal dosage remains largely intuitive, often leading to suboptimal outcomes. We propose a localized latent editing framework that simulates Botulinum Toxin injection effects for injection planning through dose-response modeling. Our key contribution is a Region-Specific Latent Axis Discovery method that learns localized muscle relaxation trajectories in StyleGAN2's latent space, enabling precise control over specific facial regions without global side effects. By correlating these localized latent trajectories with injected toxin units, we learn a predictive dose-response model. We rigorously compare two approaches: direct metric regression versus image-based generative simulation on a clinical dataset of N=360 images from 46 patients. On a hold-out test set, our framework demonstrates moderate-to-strong structural correlations for geometric asymmetry metrics, confirming that the generative model correctly captures the direction of morphological changes. While biological variability limits absolute precision, we introduce a hybrid \"Human-in-the-Loop\" workflow where clinicians interactively refine simulations, bridging the gap between pathological reconstruction and cosmetic planning.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Botulinum toxin (Botox) injections are the gold standard for managing facial asymmetry and aesthetic rejuvenation, yet determining the optimal dosage remains largely intuitive, often leading to suboptimal outcomes. We propose a localized latent editing framework that simulates Botulinum Toxin injection effects for injection planning through dose-response modeling. Our key contribution is a Region-Specific Latent Axis Discovery method that learns localized muscle relaxation trajectories in StyleGAN2's latent space, enabling precise control over specific facial regions without global side effects. By correlating these localized latent trajectories with injected toxin units, we learn a predictive dose-response model. We rigorously compare two approaches: direct metric regression versus image-based generative simulation on a clinical dataset of N=360 images from 46 patients. On a hold-out test set, our framework demonstrates moderate-to-strong structural correlations for geometric asymmetry metrics, confirming that the generative model correctly captures the direction of morphological changes. While biological variability limits absolute precision, we introduce a hybrid \"Human-in-the-Loop\" workflow where clinicians interactively refine simulations, bridging the gap between pathological reconstruction and cosmetic planning."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T13:26:29Z",
            "published_parsed": [
                2026,
                1,
                27,
                13,
                26,
                29,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Estèphe Arnaud"
                },
                {
                    "name": "Mohamed Daoudi"
                },
                {
                    "name": "Pierre Guerreschi"
                }
            ],
            "author_detail": {
                "name": "Pierre Guerreschi"
            },
            "author": "Pierre Guerreschi",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "肉毒杆菌毒素注射计划中剂量反应模型的局部潜在编辑",
            "abstract_cn": "肉毒杆菌毒素 (Botox) 注射是治疗面部不对称和美容年轻化的黄金标准，但确定最佳剂量在很大程度上仍然是直观的，通常会导致次优的结果。我们提出了一种局部潜在编辑框架，可通过剂量反应模型模拟肉毒杆菌毒素注射效果，以制定注射计划。我们的主要贡献是一种区域特定的潜在轴发现方法，该方法可以学习 StyleGAN2 潜在空间中的局部肌肉松弛轨迹，从而能够精确控制特定的面部区域，而不会产生全局副作用。通过将这些局部潜在轨迹与注射毒素单位相关联，我们学习了预测剂量反应模型。我们严格比较两种方法：直接度量回归与基于图像的生成模拟，在来自 46 名患者的 N=360 图像的临床数据集上进行。在保留测试集上，我们的框架展示了几何不对称度量的中等到强的结构相关性，证实生成模型正确地捕获了形态变化的方向。虽然生物变异性限制了绝对精度，但我们引入了混合“人机循环”工作流程，临床医生可以交互式地完善模拟，从而弥合病理重建和美容规划之间的差距。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19618v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19618v1",
            "title": "The role of self-supervised pretraining in differentially private medical image analysis",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "The role of self-supervised pretraining in differentially private medical image analysis"
            },
            "updated": "2026-01-27T13:50:43Z",
            "updated_parsed": [
                2026,
                1,
                27,
                13,
                50,
                43,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19618v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19618v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Differential privacy (DP) provides formal protection for sensitive data but typically incurs substantial losses in diagnostic performance. Model initialization has emerged as a critical factor in mitigating this degradation, yet the role of modern self-supervised learning under full-model DP remains poorly understood. Here, we present a large-scale evaluation of initialization strategies for differentially private medical image analysis, using chest radiograph classification as a representative benchmark with more than 800,000 images. Using state-of-the-art ConvNeXt models trained with DP-SGD across realistic privacy regimes, we compare non-domain-specific supervised ImageNet initialization, non-domain-specific self-supervised DINOv3 initialization, and domain-specific supervised pretraining on MIMIC-CXR, the largest publicly available chest radiograph dataset. Evaluations are conducted across five external datasets spanning diverse institutions and acquisition settings. We show that DINOv3 initialization consistently improves diagnostic utility relative to ImageNet initialization under DP, but remains inferior to domain-specific supervised pretraining, which achieves performance closest to non-private baselines. We further demonstrate that initialization choice strongly influences demographic fairness, cross-dataset generalization, and robustness to data scale and model capacity under privacy constraints. The results establish initialization strategy as a central determinant of utility, fairness, and generalization in differentially private medical imaging.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Differential privacy (DP) provides formal protection for sensitive data but typically incurs substantial losses in diagnostic performance. Model initialization has emerged as a critical factor in mitigating this degradation, yet the role of modern self-supervised learning under full-model DP remains poorly understood. Here, we present a large-scale evaluation of initialization strategies for differentially private medical image analysis, using chest radiograph classification as a representative benchmark with more than 800,000 images. Using state-of-the-art ConvNeXt models trained with DP-SGD across realistic privacy regimes, we compare non-domain-specific supervised ImageNet initialization, non-domain-specific self-supervised DINOv3 initialization, and domain-specific supervised pretraining on MIMIC-CXR, the largest publicly available chest radiograph dataset. Evaluations are conducted across five external datasets spanning diverse institutions and acquisition settings. We show that DINOv3 initialization consistently improves diagnostic utility relative to ImageNet initialization under DP, but remains inferior to domain-specific supervised pretraining, which achieves performance closest to non-private baselines. We further demonstrate that initialization choice strongly influences demographic fairness, cross-dataset generalization, and robustness to data scale and model capacity under privacy constraints. The results establish initialization strategy as a central determinant of utility, fairness, and generalization in differentially private medical imaging."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.AI",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.LG",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T13:50:43Z",
            "published_parsed": [
                2026,
                1,
                27,
                13,
                50,
                43,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Soroosh Tayebi Arasteh"
                },
                {
                    "name": "Mina Farajiamiri"
                },
                {
                    "name": "Mahshad Lotfinia"
                },
                {
                    "name": "Behrus Hinrichs-Puladi"
                },
                {
                    "name": "Jonas Bienzeisler"
                },
                {
                    "name": "Mohamed Alhaskir"
                },
                {
                    "name": "Mirabela Rusu"
                },
                {
                    "name": "Christiane Kuhl"
                },
                {
                    "name": "Sven Nebelung"
                },
                {
                    "name": "Daniel Truhn"
                }
            ],
            "author_detail": {
                "name": "Daniel Truhn"
            },
            "author": "Daniel Truhn",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "自监督预训练在差分隐私医学图像分析中的作用",
            "abstract_cn": "差分隐私 (DP) 为敏感数据提供正式保护，但通常会导致诊断性能大幅下降。模型初始化已成为缓解这种退化的关键因素，但现代自监督学习在全模型 DP 下的作用仍然知之甚少。在这里，我们使用胸片分类作为具有超过 800,000 张图像的代表性基准，对差分隐私医学图像分析的初始化策略进行了大规模评估。使用在现实隐私制度中使用 DP-SGD 训练的最先进的 ConvNeXt 模型，我们比较了非特定领域的监督 ImageNet 初始化、非特定领域的自监督 DINOv3 初始化以及 MIMIC-CXR（最大的公开可用胸部 X 光数据集）上的特定领域的监督预训练。评估是在跨越不同机构和采集环境的五个外部数据集上进行的。我们表明，相对于 DP 下的 ImageNet 初始化，DINOv3 初始化始终提高了诊断效用，但仍然不如特定领域的监督预训练，后者实现的性能最接近非私有基线。我们进一步证明，初始化选择强烈影响人口统计公平性、跨数据集泛化以及隐私约束下数据规模和模型容量的鲁棒性。结果将初始化策略确立为差异隐私医学成像中效用、公平性和泛化的核心决定因素。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19680v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19680v1",
            "title": "A new Image Similarity Metric for a Perceptual and Transparent Geometric and Chromatic Assessment",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "A new Image Similarity Metric for a Perceptual and Transparent Geometric and Chromatic Assessment"
            },
            "updated": "2026-01-27T14:59:01Z",
            "updated_parsed": [
                2026,
                1,
                27,
                14,
                59,
                1,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19680v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19680v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "In the literature, several studies have shown that state-of-the-art image similarity metrics are not perceptual metrics; moreover, they have difficulty evaluating images, especially when texture distortion is also present. In this work, we propose a new perceptual metric composed of two terms. The first term evaluates the dissimilarity between the textures of two images using Earth Mover's Distance. The second term evaluates the chromatic dissimilarity between two images in the Oklab perceptual color space. We evaluated the performance of our metric on a non-traditional dataset, called Berkeley-Adobe Perceptual Patch Similarity, which contains a wide range of complex distortions in shapes and colors. We have shown that our metric outperforms the state of the art, especially when images contain shape distortions, confirming also its greater perceptiveness. Furthermore, although deep black-box metrics could be very accurate, they only provide similarity scores between two images, without explaining their main differences and similarities. Our metric, on the other hand, provides visual explanations to support the calculated score, making the similarity assessment transparent and justified.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "In the literature, several studies have shown that state-of-the-art image similarity metrics are not perceptual metrics; moreover, they have difficulty evaluating images, especially when texture distortion is also present. In this work, we propose a new perceptual metric composed of two terms. The first term evaluates the dissimilarity between the textures of two images using Earth Mover's Distance. The second term evaluates the chromatic dissimilarity between two images in the Oklab perceptual color space. We evaluated the performance of our metric on a non-traditional dataset, called Berkeley-Adobe Perceptual Patch Similarity, which contains a wide range of complex distortions in shapes and colors. We have shown that our metric outperforms the state of the art, especially when images contain shape distortions, confirming also its greater perceptiveness. Furthermore, although deep black-box metrics could be very accurate, they only provide similarity scores between two images, without explaining their main differences and similarities. Our metric, on the other hand, provides visual explanations to support the calculated score, making the similarity assessment transparent and justified."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T14:59:01Z",
            "published_parsed": [
                2026,
                1,
                27,
                14,
                59,
                1,
                1,
                27,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Antonio Di Marino"
                },
                {
                    "name": "Vincenzo Bevilacqua"
                },
                {
                    "name": "Emanuel Di Nardo"
                },
                {
                    "name": "Angelo Ciaramella"
                },
                {
                    "name": "Ivanoe De Falco"
                },
                {
                    "name": "Giovanna Sannino"
                }
            ],
            "author_detail": {
                "name": "Giovanna Sannino"
            },
            "author": "Giovanna Sannino",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "用于感知和透明几何和色彩评估的新图像相似性度量",
            "abstract_cn": "在文献中，一些研究表明，最先进的图像相似性度量不是感知度量；而是感知度量。此外，他们很难评估图像，特别是当纹理失真也存在时。在这项工作中，我们提出了一种由两个术语组成的新感知度量。第一项使用地球移动者距离评估两个图像纹理之间的差异。第二项评估 Oklab 感知色彩空间中两个图像之间的色彩差异。我们在一个名为 Berkeley-Adobe 感知补丁相似度的非传统数据集上评估了我们的指标的性能，该数据集包含各种形状和颜色的复杂扭曲。我们已经证明，我们的指标优于现有技术，特别是当图像包含形状扭曲时，也证实了其更大的感知能力。此外，虽然深度黑盒指标可能非常准确，但它们仅提供两个图像之间的相似度分数，而没有解释它们的主要差异和相似之处。另一方面，我们的指标提供了可视化解释来支持计算的分数，使相似性评估透明且合理。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19690v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19690v1",
            "title": "DSVM-UNet : Enhancing VM-UNet with Dual Self-distillation for Medical Image Segmentation",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "DSVM-UNet : Enhancing VM-UNet with Dual Self-distillation for Medical Image Segmentation"
            },
            "updated": "2026-01-27T15:06:38Z",
            "updated_parsed": [
                2026,
                1,
                27,
                15,
                6,
                38,
                1,
                27,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19690v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19690v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Vision Mamba models have been extensively researched in various fields, which address the limitations of previous models by effectively managing long-range dependencies with a linear-time overhead. Several prospective studies have further designed Vision Mamba based on UNet(VM-UNet) for medical image segmentation. These approaches primarily focus on optimizing architectural designs by creating more complex structures to enhance the model's ability to perceive semantic features. In this paper, we propose a simple yet effective approach to improve the model by Dual Self-distillation for VM-UNet (DSVM-UNet) without any complex architectural designs. To achieve this goal, we develop double self-distillation methods to align the features at both the global and local levels. Extensive experiments conducted on the ISIC2017, ISIC2018, and Synapse benchmarks demonstrate that our approach achieves state-of-the-art performance while maintaining computational efficiency. Code is available at https://github.com/RoryShao/DSVM-UNet.git.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Vision Mamba models have been extensively researched in various fields, which address the limitations of previous models by effectively managing long-range dependencies with a linear-time overhead. Several prospective studies have further designed Vision Mamba based on UNet(VM-UNet) for medical image segmentation. These approaches primarily focus on optimizing architectural designs by creating more complex structures to enhance the model's ability to perceive semantic features. In this paper, we propose a simple yet effective approach to improve the model by Dual Self-distillation for VM-UNet (DSVM-UNet) without any complex architectural designs. To achieve this goal, we develop double self-distillation methods to align the features at both the global and local levels. Extensive experiments conducted on the ISIC2017, ISIC2018, and Synapse benchmarks demonstrate that our approach achieves state-of-the-art performance while maintaining computational efficiency. Code is available at https://github.com/RoryShao/DSVM-UNet.git."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-27T15:06:38Z",
            "published_parsed": [
                2026,
                1,
                27,
                15,
                6,
                38,
                1,
                27,
                0
            ],
            "arxiv_comment": "5 pages, 1 figures",
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "arxiv_journal_ref": "IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2026)",
            "authors": [
                {
                    "name": "Renrong Shao"
                },
                {
                    "name": "Dongyang Li"
                },
                {
                    "name": "Dong Xia"
                },
                {
                    "name": "Lin Shao"
                },
                {
                    "name": "Jiangdong Lu"
                },
                {
                    "name": "Fen Zheng"
                },
                {
                    "name": "Lulu Zhang"
                }
            ],
            "author_detail": {
                "name": "Lulu Zhang"
            },
            "author": "Lulu Zhang",
            "journal": "arXiv: AI & Vision (Optics)",
            "title_cn": "DSVM-UNet：通过双自蒸馏增强 VM-UNet 用于医学图像分割",
            "abstract_cn": "Vision Mamba 模型已在各个领域得到广泛研究，它通过以线性时间开销有效管理远程依赖关系来解决先前模型的局限性。一些前瞻性研究进一步设计了基于UNet（VM-UNet）的Vision Mamba用于医学图像分割。这些方法主要侧重于通过创建更复杂的结构来优化架构设计，以增强模型感知语义特征的能力。在本文中，我们提出了一种简单而有效的方法，通过VM-UNet（DSVM-UNet）的双自蒸馏来改进模型，而无需任何复杂的架构设计。为了实现这一目标，我们开发了双重自蒸馏方法，以协调全球和局部层面的特征。在 ISIC2017、ISIC2018 和 Synapse 基准测试上进行的大量实验表明，我们的方法在保持计算效率的同时实现了最先进的性能。代码可在 https://github.com/RoryShao/DSVM-UNet.git 获取。"
        },
        {
            "id": "http://arxiv.org/abs/2601.18849v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.18849v1",
            "title": "Audio-Driven Talking Face Generation with Blink Embedding and Hash Grid Landmarks Encoding",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Audio-Driven Talking Face Generation with Blink Embedding and Hash Grid Landmarks Encoding"
            },
            "updated": "2026-01-26T14:03:30Z",
            "updated_parsed": [
                2026,
                1,
                26,
                14,
                3,
                30,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.18849v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.18849v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Dynamic Neural Radiance Fields (NeRF) have demonstrated considerable success in generating high-fidelity 3D models of talking portraits. Despite significant advancements in the rendering speed and generation quality, challenges persist in accurately and efficiently capturing mouth movements in talking portraits. To tackle this challenge, we propose an automatic method based on blink embedding and hash grid landmarks encoding in this study, which can substantially enhance the fidelity of talking faces. Specifically, we leverage facial features encoded as conditional features and integrate audio features as residual terms into our model through a Dynamic Landmark Transformer. Furthermore, we employ neural radiance fields to model the entire face, resulting in a lifelike face representation. Experimental evaluations have validated the superiority of our approach to existing methods.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Dynamic Neural Radiance Fields (NeRF) have demonstrated considerable success in generating high-fidelity 3D models of talking portraits. Despite significant advancements in the rendering speed and generation quality, challenges persist in accurately and efficiently capturing mouth movements in talking portraits. To tackle this challenge, we propose an automatic method based on blink embedding and hash grid landmarks encoding in this study, which can substantially enhance the fidelity of talking faces. Specifically, we leverage facial features encoded as conditional features and integrate audio features as residual terms into our model through a Dynamic Landmark Transformer. Furthermore, we employ neural radiance fields to model the entire face, resulting in a lifelike face representation. Experimental evaluations have validated the superiority of our approach to existing methods."
            },
            "tags": [
                {
                    "term": "cs.CV",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T14:03:30Z",
            "published_parsed": [
                2026,
                1,
                26,
                14,
                3,
                30,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.CV"
            },
            "authors": [
                {
                    "name": "Yuhui Zhang"
                },
                {
                    "name": "Hui Yu"
                },
                {
                    "name": "Wei Liang"
                },
                {
                    "name": "Sunjie Zhang"
                }
            ],
            "author_detail": {
                "name": "Sunjie Zhang"
            },
            "author": "Sunjie Zhang",
            "journal": "arXiv: Nerf & Neural Fields",
            "title_cn": "使用 Blink 嵌入和哈希网格地标编码的音频驱动的说话人脸生成",
            "abstract_cn": "动态神经辐射场 (NeRF) 在生成说话肖像的高保真 3D 模型方面取得了相当大的成功。尽管渲染速度和生成质量取得了显着进步，但准确有效地捕捉说话肖像中的嘴部运动仍然存在挑战。为了应对这一挑战，我们在本研究中提出了一种基于眨眼嵌入和哈希网格地标编码的自动方法，该方法可以大大提高说话面孔的保真度。具体来说，我们利用编码为条件特征的面部特征，并通过动态地标变压器将音频特征作为残差项集成到我们的模型中。此外，我们采用神经辐射场对整个面部进行建模，从而产生逼真的面部表征。实验评估验证了我们的方法相对于现有方法的优越性。"
        },
        {
            "id": "http://arxiv.org/abs/2601.19041v1",
            "guidislink": true,
            "link": "https://arxiv.org/abs/2601.19041v1",
            "title": "HEATACO: Heatmap-Guided Ant Colony Decoding for Large-Scale Travelling Salesman Problems",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "HEATACO: Heatmap-Guided Ant Colony Decoding for Large-Scale Travelling Salesman Problems"
            },
            "updated": "2026-01-26T23:51:19Z",
            "updated_parsed": [
                2026,
                1,
                26,
                23,
                51,
                19,
                0,
                26,
                0
            ],
            "links": [
                {
                    "href": "https://arxiv.org/abs/2601.19041v1",
                    "rel": "alternate",
                    "type": "text/html"
                },
                {
                    "href": "https://arxiv.org/pdf/2601.19041v1",
                    "rel": "related",
                    "type": "application/pdf",
                    "title": "pdf"
                }
            ],
            "summary": "Heatmap-based non-autoregressive solvers for large-scale Travelling Salesman Problems output dense edge-probability scores, yet final performance largely hinges on the decoder that must satisfy degree-2 constraints and form a single Hamiltonian tour. Greedy commitment can cascade into irreparable mistakes at large $N$, whereas MCTS-guided local search is accurate but compute-heavy and highly engineered. We instead treat the heatmap as a soft edge prior and cast decoding as probabilistic tour construction under feasibility constraints, where the key is to correct local mis-rankings via inexpensive global coordination. Based on this view, we introduce HeatACO, a plug-and-play Max-Min Ant System decoder whose transition policy is softly biased by the heatmap while pheromone updates provide lightweight, instance-specific feedback to resolve global conflicts; optional 2-opt/3-opt post-processing further improves tour quality. On TSP500/1K/10K, using heatmaps produced by four pretrained predictors, HeatACO+2opt achieves gaps down to 0.11%/0.23%/1.15% with seconds-to-minutes CPU decoding for fixed heatmaps, offering a better quality--time trade-off than greedy decoding and published MCTS-based decoders. Finally, we find the gains track heatmap reliability: under distribution shift, miscalibration and confidence collapse bound decoding improvements, suggesting heatmap generalisation is a primary lever for further progress.",
            "summary_detail": {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Heatmap-based non-autoregressive solvers for large-scale Travelling Salesman Problems output dense edge-probability scores, yet final performance largely hinges on the decoder that must satisfy degree-2 constraints and form a single Hamiltonian tour. Greedy commitment can cascade into irreparable mistakes at large $N$, whereas MCTS-guided local search is accurate but compute-heavy and highly engineered. We instead treat the heatmap as a soft edge prior and cast decoding as probabilistic tour construction under feasibility constraints, where the key is to correct local mis-rankings via inexpensive global coordination. Based on this view, we introduce HeatACO, a plug-and-play Max-Min Ant System decoder whose transition policy is softly biased by the heatmap while pheromone updates provide lightweight, instance-specific feedback to resolve global conflicts; optional 2-opt/3-opt post-processing further improves tour quality. On TSP500/1K/10K, using heatmaps produced by four pretrained predictors, HeatACO+2opt achieves gaps down to 0.11%/0.23%/1.15% with seconds-to-minutes CPU decoding for fixed heatmaps, offering a better quality--time trade-off than greedy decoding and published MCTS-based decoders. Finally, we find the gains track heatmap reliability: under distribution shift, miscalibration and confidence collapse bound decoding improvements, suggesting heatmap generalisation is a primary lever for further progress."
            },
            "tags": [
                {
                    "term": "cs.NE",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                },
                {
                    "term": "cs.LG",
                    "scheme": "http://arxiv.org/schemas/atom",
                    "label": null
                }
            ],
            "published": "2026-01-26T23:51:19Z",
            "published_parsed": [
                2026,
                1,
                26,
                23,
                51,
                19,
                0,
                26,
                0
            ],
            "arxiv_primary_category": {
                "term": "cs.NE"
            },
            "authors": [
                {
                    "name": "Bo-Cheng Lin"
                },
                {
                    "name": "Yi Mei"
                },
                {
                    "name": "Mengjie Zhang"
                }
            ],
            "author_detail": {
                "name": "Mengjie Zhang"
            },
            "author": "Mengjie Zhang",
            "journal": "arXiv: Nerf & Neural Fields",
            "title_cn": "HATACO：针对大规模旅行商问题的热图引导蚁群解码",
            "abstract_cn": "用于大规模旅行商问题的基于热图的非自回归求解器输出密集的边缘概率分数，但最终性能很大程度上取决于必须满足 2 度约束并形成单个哈密顿游览的解码器。贪婪的承诺可能会导致无法挽回的错误，而 MCTS 引导的本地搜索虽然准确，但计算量大且工程化程度高。相反，我们将热图视为软边缘先验，并将解码视为可行性约束下的概率巡回构建，其中关键是通过廉价的全局协调来纠正局部错误排名。基于这种观点，我们引入了 HeatACO，一种即插即用的最大-最小蚂蚁系统解码器，其转换策略受到热图的轻微偏差，而信息素更新提供轻量级的、特定于实例的反馈来解决全局冲突；可选的 2-opt/3-opt 后处理进一步提高了游览质量。在 TSP500/1K/10K 上，使用四个预训练预测器生成的热图，HeatACO+2opt 通过对固定热图进行秒到分钟的 CPU 解码，将差距降至 0.11%/0.23%/1.15%，提供了比贪婪解码和已发布的基于 MCTS 的解码器更好的质量-时间权衡。最后，我们发现收益跟踪热图可靠性：在分布偏移、错误校准和置信度崩溃的情况下，解码改进受到限制，这表明热图泛化是进一步进步的主要杠杆。"
        },
        {
            "id": "https://doi.org/10.1364/oe.581048",
            "title": "Critically coupled high-Q plasmonic guided mode resonances in the visible",
            "link": "https://doi.org/10.1364/oe.581048",
            "published": "2026-01-09",
            "author": "Shunyu Yao, Zhenshi Chen, Chengkun Yang, Yirui Xu, Yiqin Xu",
            "summary": "<jats:p>\n                    High-quality factor (Q factor) plasmonic resonances in the visible spectrum are typically limited by the intrinsic absorptive loss of metals, necessitating a trade-off between resonance linewidth and coupling efficiency. This work demonstrates that an ultrathin silver film supporting long-range surface-plasmon polaritons (LRSPPs) provides a low-loss interaction access for a square lattice of Ag nanoparticles, enabling critical coupling to a guided-mode resonance (GMR) at\n                    <jats:italic toggle=\"yes\">λ</jats:italic>\n                     = 633 nm. The collective LRSPP-GMR yields a Q factor of 361 with a coupling efficiency of 99.8 %. By slightly under-coupling, the Q factor rises to ∼ 600 while the efficiency remains above 80 %. The resonance persists down to 558 nm, with a Q factor greater than 100, covering most of the visible spectrum. Coupled-mode theory and coupled-dipole simulations demonstrate that the silver film simultaneously suppresses both radiative leakage and resistive dissipation, thereby reconciling the two canonical loss channels that typically preclude critical coupling in plasmonic metasurfaces. Owing to the simultaneous boost in Q factor and moderate mode volume, the optimized Purcell factor of LRSPP-GMR resonators reaches ∼5 × 10\n                    <jats:sup>21</jats:sup>\n                    m\n                    <jats:sup>−3</jats:sup>\n                    at\n                    <jats:italic toggle=\"yes\">λ</jats:italic>\n                     = 633 nm, twice that of uncoupled SPP GMRs, demonstrating its superior enhancement of light-matter interaction. This work provides a straightforward route to understand and realize ultranarrow, efficiently excited plasmonic resonances for SERS, nonlinear optics, Purcell-enhanced emission, and sensing.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "可见光中的临界耦合高 Q 等离子体导模共振",
            "abstract_cn": "<贾茨：p>\n                    可见光谱中的高质量因子（Q 因子）等离子体共振通常受到金属固有吸收损耗的限制，因此需要在共振线宽和耦合效率之间进行权衡。这项工作表明，支持长程表面等离子体激元 (LRSPP) 的超薄银膜为银纳米颗粒的方格提供了低损耗的相互作用通道，从而能够在\n                    <jats：斜体切换=“是”>λ</ jats：斜体>\n                     = 633 nm。集体 LRSPP-GMR 产生的 Q 因子为 361，耦合效率为 99.8%。通过轻微的欠耦合，Q 因子升至~ 600，同时效率保持在 80 % 以上。共振持续低至 558 nm，Q 因子大于 100，覆盖大部分可见光谱。耦合模式理论和耦合偶极子模拟表明，银膜同时抑制辐射泄漏和电阻耗散，从而协调通常排除等离子体超表面中关键耦合的两个规范损耗通道。由于Q因子和适度模式体积的同时提升，LRSPP-GMR谐振器的优化Purcell因子达到∼5 × 10\n                    <贾茨：sup>21</贾茨：sup>\n                    米\n                    <jats:sup>−3</jats:sup>\n                    在\n                    <jats：斜体切换=“是”>λ</ jats：斜体>\n                     = 633 nm，是非耦合 SPP GMR 的两倍，证明了其对光与物质相互作用的卓越增强。这项工作为理解和实现用于 SERS、非线性光学、珀塞尔增强发射和传感的超窄、有效激发的等离子体共振提供了一条简单的途径。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.579625",
            "title": "Inverse design of microcavities for fluorescent excitation and collection using Lorentz reciprocity and topology optimisation",
            "link": "https://doi.org/10.1364/oe.579625",
            "published": "2026-01-22",
            "author": "Wen Qi Zhang, A. D. Greentree, D. A. Simpson, J. Dalgleish, H. Ebendorff-Heideprime, B. C. Gibson, Shahraam Afshar V.",
            "summary": "<jats:p>We present a theoretical and computational framework for the inverse design of photonic structures aimed at enhancing fluorescence excitation and collection from incoherent emitters, particularly nitrogen-vacancy centres in diamond. By integrating Lorentz reciprocity with topology optimisation, we formulate an objective function based on electromagnetic field intensities at both excitation and emission wavelengths. This approach enables the simultaneous optimisation of structure for both input excitation and output collection. We demonstrate the method through three two-dimensional design cases. Our results reveal fluorescence signal enhancements of up to six orders of magnitude compared to bulk diamond, attributed to the formation of resonant cavities for both excitation and emission frequencies. This framework shall be broadly applicable to fluorescent-based sensing, quantum photonics, and microcavity laser design.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "使用洛伦兹互易性和拓扑优化进行荧光激发和收集的微腔逆向设计",
            "abstract_cn": "<jats:p>我们提出了光子结构逆向设计的理论和计算框架，旨在增强非相干发射体（特别是金刚石中的氮空位中心）的荧光激发和收集。通过将洛伦兹互易性与拓扑优化相结合，我们制定了基于激发和发射波长处的电磁场强度的目标函数。这种方法能够同时优化输入激励和输出收集的结构。我们通过三个二维设计案例演示了该方法。我们的结果表明，与块状金刚石相比，荧光信号增强高达六个数量级，这归因于激发和发射频率共振腔的形成。该框架应广泛适用于基于荧光的传感、量子光子学和微腔激光器设计。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.573827",
            "title": "Interferogram-free adaptive wavefront interferometry: fourier spot analysis enhancing adaptive compensation performance",
            "link": "https://doi.org/10.1364/oe.573827",
            "published": "2026-01-07",
            "author": "Peng Gao, Qi Lu, Yifan Ding, Weichao Gong, Shijie Liu, Jianda Shao",
            "summary": "<jats:p>\n                    Over the past decades, adaptive wavefront interferometry (AWI) has been widely employed as a high-resolution and intelligent metrological technique for measuring freeform surfaces with substantial surface error deviations. However, conventional AWI approaches predominantly rely on the detection, reconstruction, and sparsification of incomplete interferograms—a process that inherently constrains the efficacy and directionality of the initial optimization phase due to the limited information provided by such interferograms. This study presents an improved AWI methodology that enhances directional optimization and efficient measurement for freeform surfaces with significant deviations by optimizing the Fourier spot (FS). Significantly, this approach eliminates the requirement for wavefront sensors or phase-shifting procedures throughout the optimization process, substantially simplifying the measurement process. Numerical simulations demonstrated that a freeform wavefront with a peak-to-valley (PV) value of 109.1\n                    <jats:italic>λ</jats:italic>\n                    (\n                    <jats:italic>λ</jats:italic>\n                    = 632.8 nm) and root-mean-square (RMS) of 13.49\n                    <jats:italic>λ</jats:italic>\n                    could be effectively compensated within tens of iterations. In experiments, a test of a freeform surface with a PV of 104.1\n                    <jats:italic>λ</jats:italic>\n                    and RMS of 24.89\n                    <jats:italic>λ</jats:italic>\n                    , which initially produced indistinguishable interference fringes, was successfully accomplished in 60 iterations, achieving a measurement error with PV of 0.89\n                    <jats:italic>λ</jats:italic>\n                    and RMS of 0.17\n                    <jats:italic>λ</jats:italic>\n                    . These findings confirm that the proposed IF-AWI method is capable of efficiently and accurately measuring freeform surfaces with substantial deviations.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "无干涉图自适应波前干涉测量：增强自适应补偿性能的傅里叶光斑分析",
            "abstract_cn": "<贾茨：p>\n                    在过去的几十年里，自适应波前干涉测量（AWI）作为一种高分辨率和智能计量技术已被广泛采用，用于测量具有较大表面误差偏差的自由曲面。然而，传统的 AWI 方法主要依赖于不完整干涉图的检测、重建和稀疏化，由于此类干涉图提供的信息有限，这一过程本质上限制了初始优化阶段的功效和方向性。本研究提出了一种改进的 AWI 方法，通过优化傅立叶光斑 (FS)，增强了具有显着偏差的自由曲面的方向优化和高效测量。值得注意的是，这种方法消除了整个优化过程中对波前传感器或相移程序的需求，从而大大简化了测量过程。数值模拟表明，自由形状波前的峰谷 (PV) 值为 109.1\n                    <jats:斜体>λ</jats:斜体>\n                    （\n                    <jats:斜体>λ</jats:斜体>\n                    = 632.8 nm），均方根 (RMS) 为 13.49\n                    <jats:斜体>λ</jats:斜体>\n                    可以在数十次迭代内得到有效补偿。在实验中，测试了 PV 为 104.1 的自由曲面\n                    <jats:斜体>λ</jats:斜体>\n                    RMS 为 24.89\n                    <jats:斜体>λ</jats:斜体>\n                    最初产生了无法区分的干涉条纹，经过 60 次迭代成功完成，测量误差 PV 为 0.89\n                    <jats:斜体>λ</jats:斜体>\n                    均方根值为 0.17\n                    <jats:斜体>λ</jats:斜体>\n                    。这些发现证实，所提出的 IF-AWI 方法能够有效、准确地测量存在较大偏差的自由曲面。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.582555",
            "title": "Plasmon-induced multipartite interactions and entanglement in quantum emitter hybrid systems",
            "link": "https://doi.org/10.1364/oe.582555",
            "published": "2026-01-13",
            "author": "Peng-tao Du, Guang-ming Huang, Gao-xiang Li, Yaping Yang, Wei Fang",
            "summary": "<jats:p>This study investigates multipartite entanglement in quantum emitter (QE) systems coupled to a two-dimensional hyperbolic surface (TDHS). Within the master equation framework, which distinguishes the contributions of surface plasmon field (SPF) with different spatial modes, we demonstrate that both the collective decay coefficients and the in-plane emission pattern of the emitters are strongly governed by the polarization of the transition dipole. Numerical analysis further reveals that the TDHS functions as a planar plasmonic waveguide supporting both reciprocal and nonreciprocal inter-emitter interactions. Building on these intriguing properties, we analyze the dynamics of spontaneously generated entanglement (SGE) in tripartite and quadripartite systems under various interaction configurations. Our results show that in certain two-dimensional geometries, strong nonreciprocal interactions enhance global entanglement compared with one-dimensional arrangements. Notably, the rhombic configuration supports destructive interference that suppresses on-site decay and drives the system into dark states with steady entanglement. Moreover, for systems initialized in mixed states, entanglement generation relies mainly on reciprocal interactions and shows only weak dependence on the interaction geometry. These findings provide a versatile route for engineering multipartite entanglement in TDHS-based plasmonic architectures, with promising applications in quantum information processing and integrated photonic devices.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "量子发射器混合系统中等离激元诱导的多部分相互作用和纠缠",
            "abstract_cn": "<jats:p>这项研究研究了耦合到二维双曲表面 (TDHS) 的量子发射器 (QE) 系统中的多部分纠缠。在区分表面等离子体场（SPF）与不同空间模式的贡献的主方程框架内，我们证明了发射器的集体衰减系数和面内发射模式都受到过渡偶极子极化的强烈控制。数值分析进一步表明，TDHS 充当平面等离子体波导，支持互易和非互易发射器间相互作用。基于这些有趣的特性，我们分析了在各种相互作用配置下三方和四方系统中自发产生的纠缠（SGE）的动力学。我们的结果表明，在某些二维几何结构中，与一维排列相比，强的非互易相互作用增强了全局纠缠。值得注意的是，菱形结构支持相消干涉，抑制现场衰变并驱动系统进入稳定纠缠的暗态。此外，对于在混合状态下初始化的系统，纠缠的产生主要依赖于相互的相互作用，并且对相互作用几何形状的依赖性很弱。这些发现为基于 TDHS 的等离子体结构中的多部分纠缠工程提供了一条通用途径，在量子信息处理和集成光子器件中具有广阔的应用前景。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.583470",
            "title": "Adaptive hybrid ranging and trajectory extraction for single-photon lidar space-debris detection",
            "link": "https://doi.org/10.1364/oe.583470",
            "published": "2026-01-20",
            "author": "Qi’an Wang, Fan Yang, Lan Li, Shihan Rong, Yinan Hu, Nanhui Xu, Weiming Xu, Buhua Tu",
            "summary": "<jats:p>With the exponential growth of on-orbit space debris, timely detection and monitoring are essential for space situational awareness. Space-borne single-photon Lidar (SSPL) offers day-and-night operability and high pointing agility. Debris observations are often characterized by extremely low signal-to-noise ratios (SNR) and signal loss, which hinder reliable target discrimination and the extraction of distance trajectories. We present a variational Bayesian adaptive Kalman filtering with the Spatio-Temporal Association (VBAKF-STA) algorithm for space-borne, thousand-kilometer-range observation, integrating a variational Bayesian adaptive Kalman filter (VBAKF) with a local-measurement module to identify signal photons and reconstruct distance trajectories. Simulation results demonstrate that the VBAKF-STA recovers complete and accurate distance trajectories when SNR &lt; −18 dB with intermittent signal loss and outperforms conventional baselines in terms of accuracy and robustness. The results support an efficient and resilient space-borne data-processing scheme for long-range, active detection of non-cooperative space targets at the thousand-kilometer scale.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "用于单光子激光雷达空间碎片检测的自适应混合测距和轨迹提取",
            "abstract_cn": "<jats:p>随着在轨空间碎片的指数级增长，及时检测和监测对于空间态势感知至关重要。星载单光子激光雷达 (SSPL) 提供昼夜可操作性和高指向灵活性。碎片观测通常具有极低的信噪比 (SNR) 和信号丢失的特点，这阻碍了可靠的目标辨别和距离轨迹的提取。我们提出了一种采用时空关联 (VBAKF-STA) 算法的变分贝叶斯自适应卡尔曼滤波，用于星载数千公里范围的观测，将变分贝叶斯自适应卡尔曼滤波器 (VBAKF) 与局部测量模块集成，以识别信号光子并重建距离轨迹。仿真结果表明，当SNR < 1时，VBAKF-STA能够恢复完整且准确的距离轨迹。 −18 dB，具有间歇性信号丢失，在准确性和鲁棒性方面优于传统基线。研究结果支持一种高效、有弹性的星载数据处理方案，可用于远程、主动检测数千公里尺度的非合作空间目标。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.585778",
            "title": "Doubly resonant mid-infrared PPMgLN optical parametric oscillator pumped by a 1908 nm Tm:YLF laser",
            "link": "https://doi.org/10.1364/oe.585778",
            "published": "2026-01-12",
            "author": "Yizhe Zheng, Kai Zhong, Jing Chi, Yuxin Liu, Kai Chen, Jining Li, Degang Xu, Jianquan Yao",
            "summary": "<jats:p>\n                    A high-power mid-infrared (MIR) optical parametric oscillator (OPO) is reported, which was pumped by a diode-end-pumped, acousto-optically Q-switched Tm:YLF laser at 1908nm. Based on thermal simulations of the Tm:YLF crystal, the pump power range was rationally selected, yielding 12.88 W of 1908 nm laser output at the laser diode power of 70 W and repetition rate of 4.2 kHz, with a pulse width of 110.40 ns. Using a dual-pass doubly resonant cavity and a 50 mm-long PPMgLN crystal, the maximum MIR output power of 2.35 W was achieved at 130 °C, corresponding to the conversion efficiency of 18.25%. It is believed to be the highest average power, peak power, and single pulse energy reported to date for PPMgLN-based OPOs pumped at around 2 µm. The MIR OPO was tunable across the range of 3.58-4.10 µm. The output characteristics were systematically investigated under different output couplers, cavity geometries, and crystal lengths. The OPO exhibited good pulse stability with the MIR pulse width of 46.20 ns and a good beam profile (\n                    <jats:italic>M</jats:italic>\n                    <jats:sub>\n                      <jats:italic>x</jats:italic>\n                    </jats:sub>\n                    <jats:sup>2</jats:sup>\n                     = 4.87,\n                    <jats:italic>M</jats:italic>\n                    <jats:sub>\n                      <jats:italic>y</jats:italic>\n                    </jats:sub>\n                    <jats:sup>2</jats:sup>\n                     = 6.44). Additionally, analysis of parasitic nonlinear processes confirmed the presence of first-order quasi-phase-matching sum-frequency mixing, which provided a convenient approach for monitoring the MIR wavelength.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "由 1908 nm Tm:YLF 激光器泵浦的双谐振中红外 PPMgLN 光学参量振荡器",
            "abstract_cn": "<贾茨：p>\n                    报道了一种高功率中红外（MIR）光参量振荡器（OPO），它由二极管端泵浦、声光调Q Tm:YLF 激光器在1908nm 处泵浦。基于Tm:YLF晶体的热模拟，合理选择泵浦功率范围，在激光二极管功率70 W、重复频率4.2kHz、脉冲宽度110.40 ns的情况下，产生12.88 W的1908 nm激光输出。采用双通双谐振腔和50mm长的PPMgLN晶体，在130℃时实现了2.35W的最大MIR输出功率，对应的转换效率为18.25%。据信，这是迄今为止报道的以 2 μm 左右泵浦的基于 PPMgLN 的 OPO 的最高平均功率、峰值功率和单脉冲能量。 MIR OPO 的可调范围为 3.58-4.10 μm。在不同的输出耦合器、腔体几何形状和晶体长度下系统地研究了输出特性。 OPO 表现出良好的脉冲稳定性，中红外脉冲宽度为 46.20 ns，并且具有良好的光束轮廓（\n                    <jats:斜体>M</jats:斜体>\n                    <贾茨：子>\n                      <jats:斜体>x</jats:斜体>\n                    </贾茨：子>\n                    <贾茨：sup>2</贾茨：sup>\n                     = 4.87,\n                    <jats:斜体>M</jats:斜体>\n                    <贾茨：子>\n                      <jats:斜体>y</jats:斜体>\n                    </贾茨：子>\n                    <贾茨：sup>2</贾茨：sup>\n                     = 6.44）。此外，寄生非线性过程的分析证实了一阶准相位匹配和频混频的存在，这为监测中红外波长提供了一种便捷的方法。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.578907",
            "title": "Long-path free-space photothermal spectroscopy based on coherent light Fabry-Perot demodulator",
            "link": "https://doi.org/10.1364/oe.578907",
            "published": "2026-01-09",
            "author": "Daowang Peng, Jiaquan Lin, Chenyang Yue, Zhong Zuo, Guojie Wu, Tianli Gao, Zhenfeng Gong, Liang Mei",
            "summary": "<jats:p>\n                    We present a long-range free-space photothermal spectroscopy (PTS) system based on a coherent light Fabry-Pérot (FP) demodulator employing a broadband mode-locked pulse laser with high coherence. By combining fast Fourier transform and Buneman frequency estimation, the PTS system achieves a sub-nanometer optical path difference of the FP interferometer with a refresh rate of 17 kHz, which can enable real-time sensing of photothermal-induced refractive index variations over an extended optical path of 1.8 m. The high-resolution demodulation of the FP interferometer makes it possible to detect trace acetylene with a minimum detection limit (MDL) of 3.6 ppm, corresponding to a normalized noise-equivalent absorption (NNEA) coefficient of 4.1 × 10\n                    <jats:sup>−7 </jats:sup>\n                    cm\n                    <jats:sup>-1</jats:sup>\n                    ·W·Hz\n                    <jats:sup>-1/2</jats:sup>\n                    . The proposed approach offers significant sensitivity improvement compared with conventional white-light demodulators and provides a promising platform for high-precision, long-path PTS in trace sensing.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "基于相干光法布里-珀罗解调器的长光程自由空间光热光谱",
            "abstract_cn": "<贾茨：p>\n                    我们提出了一种基于相干光法布里-珀罗（FP）解调器的远程自由空间光热光谱（PTS）系统，该解调器采用具有高相干性的宽带锁模脉冲激光器。通过结合快速傅立叶变换和布内曼频率估计，PTS系统实现了刷新率为17 kHz的FP干涉仪的亚纳米光程差，可以在1.8米的扩展光程上实时感测光热引起的折射率变化。 FP干涉仪的高分辨率解调使得能够以3.6 ppm的最小检测限（MDL）检测痕量乙炔，对应于4.1 × 10的归一化噪声等效吸收（NNEA）系数\n                    <贾茨：sup>−7 </贾茨：sup>\n                    厘米\n                    <贾茨：sup>-1</贾茨：sup>\n                    ·宽·赫兹\n                    <贾茨：sup>-1/2</贾茨：sup>\n                    。与传统的白光解调器相比，所提出的方法显着提高了灵敏度，并为痕量传感中的高精度、长路径 PTS 提供了一个有前途的平台。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.586503",
            "title": "Nanosecond pulsed deep-red Raman laser operating at 735 and 750 nm",
            "link": "https://doi.org/10.1364/oe.586503",
            "published": "2026-01-07",
            "author": "Kai Ouyang, Xiaoman Xu, Zefeng Xiao, Hui Zhao, Siqi Zhu, Hao Yin, Zhen Li, Zhenqiang Chen, Shibo Dai, Shangzhi Hu",
            "summary": "<jats:p>A wavelength-selectable nanosecond pulsed deep-red Raman laser operating at 735 and 750 nm was demonstrated based on an acousto-optically Q-switched intracavity frequency-doubled KGW Raman laser system pumped by the π-polarized Nd:YLF laser at 1321 nm. To compensate for the strong negative thermal lensing induced by the π-polarized fundamental beam, a positive spherical lens was incorporated, significantly extending the resonator’s stability region and enhancing the output power. Under the optimal pulse repetition frequency of 4 kHz, the maximum average output powers of 2.1 and 2.8 W were obtained at 735 and 750 nm, with the pulse widths of 5.6 and 6.6 ns, respectively. Moreover, the pulse energies were elevated to 1.2 and 1.6 mJ at a 1 kHz repetition rate, corresponding to the pulse widths of 3.3 and 5.3 ns and the peak powers of up to 377 and 308 kW, respectively. Notably, the wavelengths of 735 and 750 nm align well with the absorption peaks of the fluorescent dyes BTPETTQ nanoparticles and Sulfo-Cyanine7, respectively, suggesting strong potential for biomedical photoacoustic imaging applications.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "工作波长为 735 和 750 nm 的纳秒脉冲深红色拉曼激光器",
            "abstract_cn": "<jat:p>基于由 1321nm π 偏振 Nd:YLF 激光器泵浦的声光 Q 开关腔内倍频 KGW 拉曼激光系统，演示了工作在 735 和 750nm 的波长可选纳秒脉冲深红拉曼激光器。为了补偿 π 偏振基波光束引起的强负热透镜效应，采用了正球面透镜，显着扩展了谐振器的稳定区域并提高了输出功率。在最佳脉冲重复频率4 kHz下，在735和750 nm处获得最大平均输出功率分别为2.1和2.8 W，脉冲宽度分别为5.6和6.6 ns。此外，在1 kHz重复频率下，脉冲能量分别提高到1.2和1.6 mJ，对应于3.3和5.3 ns的脉冲宽度以及高达377和308 kW的峰值功率。值得注意的是，735 和 750nm 的波长分别与荧光染料 BTPETTQ 纳米粒子和 Sulfo-Cyanine7 的吸收峰吻合良好，表明在生物医学光声成像应用中具有巨大的潜力。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.580551",
            "title": "Unifying spectrum measurements for digital twin optical networks via high-dimensional feature calibration and meta-learning",
            "link": "https://doi.org/10.1364/oe.580551",
            "published": "2026-01-22",
            "author": "Kangqi Zhu, Nan Hua, Xiaoping Zheng",
            "summary": "<jats:p>The evolution of optical networks toward higher data rates, disaggregation, and software-hardware decoupling has driven operators to adopt multi-vendor strategies, which introduce significant challenges in observability, data consistency, and interoperability. Digital twin optical networks (DTONs) rely heavily on accurate and consistent monitoring data to achieve high-fidelity modeling and autonomous operation. However, in multi-vendor environments, various optical spectrum analyzers (OSAs) produce inconsistent spectral data due to differences in principles, physical structures, and manufacturing processes. This inconsistency degrades the construction of spectral-domain digital twins for optical networks and compromises the performance of optical spectrum feature analysis. To address this issue, we firstly establish a mathematical model to theoretically analyze the impact of OSAs on spectral features. Then, we design a high-dimensional feature calibration (HDFC) tool based on the multi-layer perceptron (MLP), and propose an adaptive perceptual information calibration (APIC) method based on model-agnostic meta-learning (MAML) algorithm, enabling adaptive alignment of inconsistent spectral data to a unified reference. Simulations and experimental validations demonstrate that proposed HDFC and APIC effectively mitigate data discrepancies and enhance feature extraction accuracy. Furthermore, we define use cases and message exchange workflows to integrate APIC into multi-vendor DTON operations. This work provides a critical step toward consistent perceptual data acquisition and interoperable management in next-generation optical networks.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "通过高维特征校准和元学习统一数字孪生光网络的光谱测量",
            "abstract_cn": "<jats:p>光网络向更高数据速率、分解和软件硬件解耦的发展促使运营商采用多供应商策略，这在可观测性、数据一致性和互操作性方面带来了重大挑战。数字孪生光网络（DTON）在很大程度上依赖于准确且一致的监测数据来实现高保真建模和自主运行。然而，在多供应商环境中，各种光谱分析仪（OSA）由于原理、物理结构和制造工艺的差异，产生不一致的光谱数据。这种不一致会降低光网络谱域数字孪生的构建，并损害光谱特征分析的性能。为了解决这个问题，我们首先建立数学模型来从理论上分析OSA对光谱特征的影响。然后，我们设计了一种基于多层感知器（MLP）的高维特征校准（HDFC）工具，并提出了一种基于模型不可知元学习（MAML）算法的自适应感知信息校准（APIC）方法，能够将不一致的光谱数据自适应对齐到统一参考。仿真和实验验证表明，所提出的 HDFC 和 APIC 有效地减少了数据差异并提高了特征提取的准确性。此外，我们定义了用例和消息交换工作流程，以将 APIC 集成到多供应商 DTON 操作中。这项工作为下一代光网络中一致的感知数据采集和可互操作管理迈出了关键一步。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.581332",
            "title": "Greatly enhanced photoluminescence of an integrated WSe\n                    <sub>2</sub>\n                    monolayer by exploiting the pure magnetic resonance and localized strain induced by a hybrid Si/Si\n                    <sub>3</sub>\n                    N\n                    <sub>4</sub>\n                    /Au nanoantenna",
            "link": "https://doi.org/10.1364/oe.581332",
            "published": "2026-01-12",
            "author": "Jiancheng Xu, Yuheng Mao, Yeshun Guo, Ruizhao Yao, Shulei Li, Hiroshi Sugimoto, Minoru Fujii, Fu Deng, Guangcan Li, Sheng Lan",
            "summary": "<jats:p>\n                    Exploiting the optical resonances inherent to dielectric nanoparticles offers an effective approach for modulating light-matter interactions at the nanoscale while maintaining minimal optical losses. In this study, we introduce a hybrid nanoantenna platform composed of Si/Si\n                    <jats:sub>3</jats:sub>\n                    N\n                    <jats:sub>4</jats:sub>\n                    /Au layers, which facilitates the tuning of resonant multipolar modes and their application in enhancing the photoluminescence (PL) of WSe\n                    <jats:sub>2</jats:sub>\n                    monolayer. By systematically varying the thickness of the Si\n                    <jats:sub>3</jats:sub>\n                    N\n                    <jats:sub>4</jats:sub>\n                    spacer, we achieve modulation of both the spectral positions and spatial field distributions of the resonances associated with Si nanospheres, thereby enabling precise control over near-field confinement and far-field scattering characteristics. Optimal performance is observed with an 80 nm spacer thickness, where a distinct magnetic dipole resonance emerges near 750 nm. Additionally, fine-tuning the nanoparticle radius allows for controlled red- and blue-shifting of the resonant modes. These deliberately engineered resonances lead to a substantial enhancement of the PL emission from WSe\n                    <jats:sub>2</jats:sub>\n                    integrated onto the hybrid structure, with an enhancement factor approximating 1609. The observed enhancement is attributed to a combination of intensified local electromagnetic fields and strain-induced exciton funneling, presenting a promising methodology for the active manipulation of light emission within integrated nanophotonic devices.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "利用混合 Si/Si <sub>3</sub> N <sub>4</sub> /Au 纳米天线诱导的纯磁共振和局部应变，大大增强了集成 WSe <sub>2</sub> 单层的光致发光",
            "abstract_cn": "<贾茨：p>\n                    利用介电纳米粒子固有的光学共振提供了一种在纳米尺度上调制光与物质相互作用的有效方法，同时保持最小的光学损失。在这项研究中，我们介绍了一种由 Si/Si 组成的混合纳米天线平台\n                    <贾茨：子>3</贾茨：子>\n                    氮\n                    <贾茨：子>4</贾茨：子>\n                    /Au层，有利于谐振多极模式的调谐及其在增强WSe光致发光（PL）方面的应用\n                    <贾茨：子>2</贾茨：子>\n                    单层。通过系统地改变硅的厚度\n                    <贾茨：子>3</贾茨：子>\n                    氮\n                    <贾茨：子>4</贾茨：子>\n                    通过间隔物，我们实现了与硅纳米球相关的共振的光谱位置和空间场分布的调制，从而能够精确控制近场限制和远场散射特性。在 80 nm 间隔层厚度下观察到最佳性能，其中在 750 nm 附近出现明显的磁偶极子共振。此外，微调纳米粒子半径可以控制谐振模式的红移和蓝移。这些精心设计的共振导致 WSe 的 PL 发射显着增强\n                    <贾茨：子>2</贾茨：子>\n                    集成到混合结构上，增强因子约为 1609。观察到的增强归因于增强的局部电磁场和应变诱导激子漏斗的组合，为集成纳米光子器件内的光发射主动操纵提供了一种有前途的方法。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.578272",
            "title": "Enhanced nonlinear tunability and bistable response in an all-dielectric metamaterial",
            "link": "https://doi.org/10.1364/oe.578272",
            "published": "2026-01-05",
            "author": "Lei Hao, Weiqi Cai, Yuancheng Fan, Qing Zhang, Qingdong Zhang, Fuli Zhang",
            "summary": "<jats:p>The coupling between closely spaced resonators as well as the resonant characteristics of metamaterials can effectively enhance the local fields, which can be employed for essential enhancement of nonlinear electromagnetic or optical resonance. Here, we demonstrate experimentally that the reinforced local field intensity can effectively enhance the nonlinear effect considering the coupling of a metamaterial made of asymmetric and nonlinear ceramic structure. Bistable behavior on the transmission is also demonstrated by modulating the input power. This study is promising for tunable meta-devices in practical applications considering the enhanced nonlinear light-matter interactions in dielectric metamaterials.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "全电介质超材料中增强的非线性可调谐性和双稳态响应",
            "abstract_cn": "<jats:p>紧密间隔的谐振器之间的耦合以及超材料的谐振特性可以有效增强局域场，这可用于本质上增强非线性电磁或光学谐振。在这里，我们通过实验证明，考虑到由不对称和非线性陶瓷结构制成的超材料的耦合，增强的局部场强可以有效增强非线性效应。传输的双稳态行为也可以通过调制输入功率来证明。考虑到介电超材料中增强的非线性光-物质相互作用，这项研究对于可调谐超器件在实际应用中具有广阔的前景。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.584056",
            "title": "High-performance PGC algorithm for a Φ-OTDR system based on multi-carrier mixing",
            "link": "https://doi.org/10.1364/oe.584056",
            "published": "2026-01-12",
            "author": "Teng Ma, Xuping Zhang, Bangwei Liu, Nasheeta Mazhar, Ningmu Zou, Yuanyuan Shan, Yixin Zhang",
            "summary": "<jats:p>\n                    The conventional phase-generated carrier (PGC) demodulation algorithm is often susceptible to three major disturbances in practical distributed fiber sensing applications, namely modulation depth, carrier phase delay, and laser intensity disturbance. These disturbances significantly render the Φ-OTDR system less capable of achieving high-accuracy vibration sensing under complex environmental conditions. To address these limitations, this study proposes a high-performance PGC demodulation algorithm based on multi-carrier mixing (PGC-MCM). By establishing mathematical logic operations between multiple mixed carrier signals and the intrinsic interference signal, the proposed method enables accurate reconstruction of the measured phase signal while effectively suppressing the influence of the aforementioned disturbances. Experimental results verify that the algorithm can precisely demodulate vibration signals with varying frequencies and amplitudes at different locations along the sensing fiber, achieving high fidelity recovery of the original signal. The proposed approach demonstrates excellent linearity and noise immunity. It yields a total harmonic distortion (THD) of −66.32 dB, a signal-to-noise and distortion ratio (SINAD) of 54.74 dB, with an amplitude error rate (\n                    <jats:italic>\n                      R\n                      <jats:sub>error</jats:sub>\n                    </jats:italic>\n                    ). as low as 0.46%, highlighting its strong potential for high-accuracy distributed optical fiber sensing applications.\n                  </jats:p>",
            "journal": "Optics Express",
            "title_cn": "基于多载波混合的Φ-OTDR系统高性能PGC算法",
            "abstract_cn": "<贾茨：p>\n                    在实际的分布式光纤传感应用中，传统的相位生成载波（PGC）解调算法往往容易受到三大干扰的影响，即调制深度、载波相位延迟和激光强度干扰。这些干扰显着降低了 Φ-OTDR 系统在复杂环境条件下实现高精度振动传感的能力。为了解决这些限制，本研究提出了一种基于多载波混合的高性能PGC解调算法（PGC-MCM）。该方法通过在多个混合载波信号和固有干扰信号之间建立数学逻辑运算，能够准确重建测量相位信号，同时有效抑制上述干扰的影响。实验结果验证了该算法能够精确解调传感光纤上不同位置的不同频率和幅度的振动信号，实现对原始信号的高保真恢复。所提出的方法表现出出色的线性度和抗噪性。它产生的总谐波失真 (THD) 为 -66.32 dB，信噪比和失真比 (SINAD) 为 54.74 dB，幅度误差率 (\n                    <贾茨：斜体>\n                      右\n                      <jats:sub>错误</jats:sub>\n                    </贾茨：斜体>\n                    ）。低至0.46%，凸显其在高精度分布式光纤传感应用中的强大潜力。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/oe.582080",
            "title": "Heterogeneously integrated Vernier laser with 10-nm BCB bonding and their thermal analysis",
            "link": "https://doi.org/10.1364/oe.582080",
            "published": "2026-01-09",
            "author": "Sangmin Oh, Jaeseong Jeon, Sushil Tandukar, Juwon Kim, Baekhyeong Lee, Sangeon Park, Wongon Lee, Il-Sug Chung",
            "summary": "<jats:p>We report heterogeneously integrated Si/III-V two-ring Vernier lasers featuring a 10-nm divinylsiloxane-bis-benzocyclobutene (BCB) bonding layer, which is the thinnest to our knowledge. The fabricated laser device demonstrates a double-facet output power of 13.6 mW, a linewidth of 2.6 kHz, a free spectral range (FSR) of 40 nm, and a side mode suppression ratio (SMSR) of 46 dB. These values are comparable to those of a directly bonded Vernier laser structure, which is thermally ideal. The comparability is attributed to a small thermal impedance value of 45.1 K/W, which was experimentally measured with what we believe to be a new method developed for lasers with extensive passive sections. A laser model calibrated with experimental inputs predicts that the output power of a 10-nm BCB bonded Vernier laser with a 4-µm current aperture differs from that of a directly bonded one by less than 10% even beyond a thermal rollover. It is also anticipated that the 10-nm BCB bonded laser can emit a few mW even at an ambient temperature of 120 °C. Such a high-temperature operation capability is desirable for light detection and ranging (LiDAR) chip applications. The investigated 10-nm BCB bonding approach can be an attractive alternative for cases where a relaxed surface roughness condition is beneficial.</jats:p>",
            "journal": "Optics Express",
            "title_cn": "采用 10 nm BCB 键合的异质集成游标激光器及其热分析",
            "abstract_cn": "<jats:p>我们报告了异构集成的 Si/III-V 双环游标激光器，具有 10 nm 二乙烯基硅氧烷-双苯并环丁烯 (BCB) 键合层，这是我们所知的最薄的键合层。所制造的激光器件的双面输出功率为13.6 mW，线宽为2.6 kHz，自由光谱范围（FSR）为40 nm，边模抑制比（SMSR）为46 dB。这些值与热学理想的直接粘合游标激光器结构的值相当。这种可比性归因于 45.1 K/W 的小热阻抗值，该值是通过我们认为是为具有广泛无源部分的激光器开发的新方法进行实验测量的。用实验输入校准的激光模型预测，具有 4 µm 电流孔径的 10 nm BCB 粘合游标激光器的输出功率与直接粘合激光器的输出功率相差不到 10%，甚至超过热翻转。预计 10 nm BCB 键合激光器即使在 120°C 的环境温度下也能发射几 mW 的功率。这种高温工作能力对于光探测和测距（LiDAR）芯片应用来说是理想的。对于宽松的表面粗糙度条件有利的情况，所研究的 10 纳米 BCB 接合方法可能是一种有吸引力的替代方案。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/boe.581641",
            "title": "Speckle tweezers near water-oil and water-air interfaces",
            "link": "https://doi.org/10.1364/boe.581641",
            "published": "2026-01-07",
            "author": "Ramin Jamali, Sabareesh K. P. Velu, Ali-Reza Moradi",
            "summary": "<jats:p>Contemporary approaches for multiple optical micro-manipulation typically involve careful pre-engineering of the laser beam shape. In various biomedical and microfluidic scenarios, especially those necessitating unconventional specimen chambers, there is a demand for controlling the collection of micro-objects near fluid-fluid interfaces. For many of these cases, a regular array of trap sites as well as tight confinement are not essential. For such applications near interfaces, we expand on the concept of speckle tweezers (ST), which incorporate randomly distributed light fields for quasi-2D optical manipulation. The proposed technique is demonstrated experimentally by applying ST to govern the movement of polystyrene micro-particles near water-oil and water-air interfaces. The efficacy of the method is validated through the temporal characterization of micro-particle motions, and the confinement of the micro-particles near the interfaces is verified using digital holographic microscopy. However, the methodology has the potential for applications in living cell manipulation, soft functional matter creation, and various industrial processes.</jats:p>",
            "journal": "Biomedical Optics Express",
            "title_cn": "水-油和水-空气界面附近的斑点镊子",
            "abstract_cn": "<jats:p>当代的多重光学微操作方法通常涉及对激光束形状的仔细预先设计。在各种生物医学和微流体场景中，特别是那些需要非常规标本室的场景，需要控制流体-流体界面附近的微观物体的收集。对于许多这样的情况，规则的陷阱位点阵列以及严格的限制并不是必需的。对于界面附近的此类应用，我们扩展了散斑镊子 (ST) 的概念，它结合了用于准二维光学操纵的随机分布光场。通过应用 ST 来控制水-油和水-空气界面附近聚苯乙烯微粒的运动，对所提出的技术进行了实验证明。该方法的有效性通过微粒运动的时间表征得到验证，并且使用数字全息显微镜验证界面附近微粒的限制。然而，该方法在活细胞操作、软功能物质创造和各种工业过程中具有应用潜力。</jats:p>"
        },
        {
            "id": "https://doi.org/10.1364/optcon.582107",
            "title": "Smartphone near-UV colorimeter for low-cost detection of adulteration of edible oils",
            "link": "https://doi.org/10.1364/optcon.582107",
            "published": "2025-12-23",
            "author": "Mohiminur Rahman Ifty, Md. Sadik Al Rayhan, Khaled Bin Easin, Arnab Talukder, Md Arafat Hossain, Protik Chandra Biswas",
            "summary": "<jats:p>\n                    A smartphone-based near ultraviolet (UV) colorimeter is demonstrated for the first time using an external UV LED source (\n                    <jats:italic toggle=\"yes\">Δλ</jats:italic>\n                     ≈  365 − 415 nm) and the inbuilt CMOS camera of a smartphone. The UV LED is powered directly via a micro-USB on-the-go (OTG) cable, while a customized 3D-printed PLA enclosure ensures precise alignment of optical elements and sample positioning. The transmitted UV light through the sample is captured by different smartphone cameras, and a custom app processes the image to quantify absorbance. The ultra-low-cost (∼$4) and lightweight (∼198 g) colorimeter is compatible with both Android and iOS platforms and requires no external computing hardware. Beyond local computation, the system integrates a cloud-assisted reporting feature that transmits test results, including GPS coordinates and captured images, for geospatial visualization and remote monitoring, enabling large-scale traceability of food samples. Performance of the instrument is evaluated through determination of extra virgin olive oil (EVO) adulteration in blends with refined olive oil, soybean oil, and palm oil, showing a strong correlation with commercial UV–Vis spectroscopy and an average detection accuracy of 94.98% relative to standard measurements. Cross-adulteration in cases such as palm oil in soybean oil and soybean oil in refined olive oil was also effectively identified by the device. Furthermore, pigment degradation under sunlight exposure is effectively monitored, highlighting the system’s potential in food authentication and quality monitoring.\n                  </jats:p>",
            "journal": "Optics Continuum",
            "title_cn": "用于低成本检测食用油掺假的智能手机近紫外比色计",
            "abstract_cn": "<贾茨：p>\n                    首次使用外部 UV LED 光源演示了基于智能手机的近紫外 (UV) 色度计（\n                    <jats：斜体切换=“是”>Δλ</ jats：斜体>\n                     ≈  365 − 415 nm）和智能手机的内置 CMOS 摄像头。 UV LED 通过微型 USB 移动 (OTG) 电缆直接供电，而定制的 3D 打印 PLA 外壳可确保光学元件和样品定位的精确对准。透过样品的紫外光由不同的智能手机摄像头捕获，定制应用程序处理图像以量化吸光度。这款超低成本（约 4 美元）且重量轻（约 198 g）的色度计与 Android 和 iOS 平台兼容，无需外部计算硬件。除了本地计算之外，该系统还集成了云辅助报告功能，可传输测试结果，包括 GPS 坐标和捕获的图像，用于地理空间可视化和远程监控，从而实现食品样本的大规模可追溯性。通过测定与精炼橄榄油、大豆油和棕榈油的混合物中的特级初榨橄榄油 (EVO) 掺假来评估仪器的性能，结果显示与商业紫外-可见光谱具有很强的相关性，并且相对于标准测量的平均检测精度为 94.98%。大豆油中棕榈油、精炼橄榄油中大豆油等交叉掺假情况也被该装置有效识别。此外，有效监测阳光照射下的色素降解，凸显了该系统在食品认证和质量监测方面的潜力。\n                  </贾茨：p>"
        },
        {
            "id": "https://doi.org/10.1364/optcon.577358",
            "title": "Three-dimensional shape-aware measurement of choroidal thickness in OCT images",
            "link": "https://doi.org/10.1364/optcon.577358",
            "published": "2025-12-23",
            "author": "Shingo Tamachi, Takayuki Okamoto, Takehito Iwase, Tomohiro Niizawa, Yuto Kawamata, Hirotaka Yokouchi, Takayuki Baba, Hideaki Haneishi",
            "summary": "<jats:p>The choroid is a dense vascular layer located between the retina and sclera. Recent advances in optical coherence tomography (OCT), which enables non-invasive visualization of three-dimensional (3D) internal structures, have revealed associations between morphological changes and ocular diseases. Among these, choroidal thickness has been extensively investigated as a particularly important parameter. Choroidal thickness is typically measured perpendicularly from the upper to lower boundaries of the choroid, but most conventional measurement methods rely on two-dimensional cross-sectional OCT images and do not sufficiently account for 3D deformation of the choroidal morphology or the curvature of the eye, which may lead to discrepancies from the true anatomical structure. In this study, we propose a method for automatically measuring choroidal thickness from 3D OCT. The proposed method calculates thickness by estimating a normal vector from an arbitrary point on the upper choroidal boundary while considering the surrounding surface geometry using a principal component analysis-based approach. Experimental results using clinical data from patients with central serous chorioretinopathy (CSC) before and after photodynamic therapy show that the proposed method provides anatomically reasonable measurements, as qualitatively verified by ophthalmologists. Choroidal thickness maps generated by integrating the measurement results across all points demonstrated post-treatment reductions in choroidal thickness in patients with CSC before and after photodynamic therapy.</jats:p>",
            "journal": "Optics Continuum",
            "title_cn": "OCT 图像中脉络膜厚度的三维形状感知测量",
            "abstract_cn": "<jats:p>脉络膜是位于视网膜和巩膜之间的致密血管层。光学相干断层扫描 (OCT) 的最新进展可以实现三维 (3D) 内部结构的非侵入性可视化，揭示了形态变化与眼部疾病之间的关联。其中，脉络膜厚度作为一个特别重要的参数已被广泛研究。脉络膜厚度通常从脉络膜的上边界到下边界垂直测量，但大多数传统测量方法依赖于二维横截面 OCT 图像，并不能充分考虑脉络膜形态或眼睛曲率的 3D 变形，这可能导致与真实解剖结构的差异。在本研究中，我们提出了一种通过 3D OCT 自动测量脉络膜厚度的方法。该方法通过估计脉络膜上边界上任意点的法向矢量来计算厚度，同时使用基于主成分分析的方法考虑周围表面的几何形状。使用光动力治疗前后中心性浆液性脉络膜视网膜病变（CSC）患者的临床数据进行的实验结果表明，所提出的方法提供了解剖学上合理的测量结果，并得到了眼科医生的定性验证。通过整合所有点的测量结果生成的脉络膜厚度图表明，CSC 患者在光动力治疗前后脉络膜厚度减少。</jats:p>"
        }
    ]
}