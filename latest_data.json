[
    {
        "id": "https://doi.org/10.1364/prj.582266",
        "title": "40 Tbps classical communication coexistence with quantum key distribution over hundred-kilometer hollow-core fiber",
        "link": "https://doi.org/10.1364/prj.582266",
        "published": "2026-01-21",
        "author": "Tianqi Dou, Song Gao, Zhenhua Li, Jianjun Tang, Yuheng Xie, Lipeng Feng, Zhang Lei, Peng Li, Nan Lu, Xuewei Kan, Hai-Qiang Ma, Weiwen Kong, Shi-biao Tang",
        "summary": "(Abstract pending update from publisher...)",
        "journal": "Photonics Research",
        "title_cn": "40 Tbps 经典通信与百公里空心光纤量子密钥分发共存",
        "abstract_cn": "（摘要暂缺，系统已记录，待官方补全后会再次提醒）"
    },
    {
        "id": "https://doi.org/10.1364/prj.583471",
        "title": "Tunable band-pass microwave photonic filter with ultra-wide bandwidth and frequency tuning range based on cascaded tunable high-Q silicon micro-ring resonators",
        "link": "https://doi.org/10.1364/prj.583471",
        "published": "2026-01-21",
        "author": "Pengfei Wang, Cheng Wei, shangqing shi, Nuoyi Zhou, Chen Guo, Rui Ma, Junhao Ni, Guohua Hu, Bin Yun",
        "summary": "(Abstract pending update from publisher...)",
        "journal": "Photonics Research",
        "title_cn": "基于级联可调谐高Q硅微环谐振器的具有超宽带宽和频率调谐范围的可调谐带通微波光子滤波器",
        "abstract_cn": "（摘要暂缺，系统已记录，待官方补全后会再次提醒）"
    },
    {
        "id": "https://doi.org/10.1364/prj.579096",
        "title": "Hertz-Integral-Linewidth Lasers based on Portable Solid-state Microresonators",
        "link": "https://doi.org/10.1364/prj.579096",
        "published": "2026-01-21",
        "author": "Xing Jin, Xuanyi Zhang, Fangxing Zhang, Zhenyu Xie, Shuijing Tang, Qi-Fan Yang",
        "summary": "(Abstract pending update from publisher...)",
        "journal": "Photonics Research",
        "title_cn": "基于便携式固态微谐振器的赫兹积分线宽激光器",
        "abstract_cn": "（摘要暂缺，系统已记录，待官方补全后会再次提醒）"
    },
    {
        "title": "PGgraf: Pose-Guided generative radiance field for novel-views on X-ray",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "PGgraf: Pose-Guided generative radiance field for novel-views on X-ray"
        },
        "summary": "Publication date: April 2026Source: Displays, Volume 92Author(s): Hangyu Li, Moquan Liu, Nan Wang, Mengcheng Sun, Yu Zhu",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "<p>Publication date: April 2026</p><p><b>Source:</b> Displays, Volume 92</p><p>Author(s): Hangyu Li, Moquan Liu, Nan Wang, Mengcheng Sun, Yu Zhu</p>"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.sciencedirect.com/science/article/pii/S014193822600017X?dgcid=rss_sd_all"
            }
        ],
        "link": "https://www.sciencedirect.com/science/article/pii/S014193822600017X",
        "id": "https://www.sciencedirect.com/science/article/pii/S014193822600017X",
        "guidislink": false,
        "journal": "Displays",
        "title_cn": "PGgraf：用于 X 射线新颖视图的姿势引导生成辐射场",
        "abstract_cn": "Publication date: April 2026Source: Displays, Volume 92Author(s): Hangyu Li, Moquan Liu, Nan Wang, Mengcheng Sun, Yu Zhu"
    },
    {
        "title": "Harnessing differentiable geometry and orientation attention for semi-supervised vessel segmentation with limited annotations",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Harnessing differentiable geometry and orientation attention for semi-supervised vessel segmentation with limited annotations"
        },
        "summary": "Publication date: April 2026Source: Displays, Volume 92Author(s): Yan Liu, Yan Yang, Yongquan Jiang, Xiaole Zhao, Liang Fan",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "<p>Publication date: April 2026</p><p><b>Source:</b> Displays, Volume 92</p><p>Author(s): Yan Liu, Yan Yang, Yongquan Jiang, Xiaole Zhao, Liang Fan</p>"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.sciencedirect.com/science/article/pii/S0141938226000107?dgcid=rss_sd_all"
            }
        ],
        "link": "https://www.sciencedirect.com/science/article/pii/S0141938226000107",
        "id": "https://www.sciencedirect.com/science/article/pii/S0141938226000107",
        "guidislink": false,
        "journal": "Displays",
        "title_cn": "利用可微几何和方向注意力进行有限注释的半监督血管分割",
        "abstract_cn": "Publication date: April 2026Source: Displays, Volume 92Author(s): Yan Liu, Yan Yang, Yongquan Jiang, Xiaole Zhao, Liang Fan"
    },
    {
        "id": "https://doi.org/10.1364/oe.586748",
        "title": "Dual-plane wavefront sensing using a vision transformer.",
        "link": "https://doi.org/10.1364/oe.586748",
        "published": "2026-01-21",
        "author": "Evan O'Rourke, Kevin OKeeffe",
        "summary": "(Abstract pending update from publisher...)",
        "journal": "Optics Express",
        "title_cn": "使用视觉变换器的双平面波前传感。",
        "abstract_cn": "（摘要暂缺，系统已记录，待官方补全后会再次提醒）"
    },
    {
        "id": "https://doi.org/10.1364/oe.581013",
        "title": "Chromatic Focus Variation with Projected Pattern Illumination for Wide Range Surface Measurements",
        "link": "https://doi.org/10.1364/oe.581013",
        "published": "2026-01-21",
        "author": "Aalim Mustafa, Hussam Muhamedsalih, Dawei Tang, PRASHANT KUMAR, Xiangqian Jiang",
        "summary": "(Abstract pending update from publisher...)",
        "journal": "Optics Express",
        "title_cn": "具有投影图案照明的色焦变化，适用于宽范围表面测量",
        "abstract_cn": "（摘要暂缺，系统已记录，待官方补全后会再次提醒）"
    },
    {
        "id": "https://doi.org/10.1364/oe.587567",
        "title": "Study on Multilayered Coatings of Macroscopic Optical Force Transducer",
        "link": "https://doi.org/10.1364/oe.587567",
        "published": "2026-01-21",
        "author": "Siyu Huang, Chunyang Gu, Tan Chen, Fengzhou Fang",
        "summary": "(Abstract pending update from publisher...)",
        "journal": "Optics Express",
        "title_cn": "宏观光学力传感器多层涂层的研究",
        "abstract_cn": "（摘要暂缺，系统已记录，待官方补全后会再次提醒）"
    },
    {
        "id": "https://doi.org/10.1364/oe.584385",
        "title": "Reconfigurable folded reflectarray based on an active 1-bit metasurface and its application in microwave hyperthermia",
        "link": "https://doi.org/10.1364/oe.584385",
        "published": "2026-01-21",
        "author": "xi Gao, Ke Yan Li, Shu Kun Wang",
        "summary": "(Abstract pending update from publisher...)",
        "journal": "Optics Express",
        "title_cn": "基于有源1位超表面的可重构折叠反射阵列及其在微波热疗中的应用",
        "abstract_cn": "（摘要暂缺，系统已记录，待官方补全后会再次提醒）"
    },
    {
        "id": "https://doi.org/10.1364/oe.582377",
        "title": "Fast, efficient piston correction of deployable space telescopes using machine learning",
        "link": "https://doi.org/10.1364/oe.582377",
        "published": "2026-01-21",
        "author": "Daniel Martin, cyril Bourgenot, Andrew Reeves, Hubert P H Shum",
        "summary": "(Abstract pending update from publisher...)",
        "journal": "Optics Express",
        "title_cn": "使用机器学习对可部署太空望远镜进行快速、高效的活塞校正",
        "abstract_cn": "（摘要暂缺，系统已记录，待官方补全后会再次提醒）"
    },
    {
        "id": "https://doi.org/10.1364/oe.581303",
        "title": "Improved Theoretical Model for Differential Wavefront Sensing Based on Complex Gaussian Decomposition with Hard-Edge Apertures",
        "link": "https://doi.org/10.1364/oe.581303",
        "published": "2026-01-21",
        "author": "Yisong Chen, xianyue meng, liu chang liu, Xiong Xinkang, Ziqiao Wang, Dong Yisi, Liang Yu, Ruitao Yang, Haijin Fu, Peng-Cheng Hu",
        "summary": "(Abstract pending update from publisher...)",
        "journal": "Optics Express",
        "title_cn": "基于硬边孔径复杂高斯分解的差分波前传感改进理论模型",
        "abstract_cn": "（摘要暂缺，系统已记录，待官方补全后会再次提醒）"
    },
    {
        "id": "https://doi.org/10.1364/oe.580362",
        "title": "Absolute testing of weakly aspheric surfaces with pixel-level resolution and subnanometer accuracy",
        "link": "https://doi.org/10.1364/oe.580362",
        "published": "2026-01-21",
        "author": "XuPeng Li, Haitao Zhang, Wentao Gong, Xiangfu Xiao, Mingxiang Zhou, Chun-shui Jin",
        "summary": "(Abstract pending update from publisher...)",
        "journal": "Optics Express",
        "title_cn": "具有像素级分辨率和亚纳米精度的弱非球面绝对测试",
        "abstract_cn": "（摘要暂缺，系统已记录，待官方补全后会再次提醒）"
    },
    {
        "id": "https://doi.org/10.1364/oe.586647",
        "title": "Concentration and Thickness Dependent Optical Transparency in Biological Tissues via Refractive Index Modulation",
        "link": "https://doi.org/10.1364/oe.586647",
        "published": "2026-01-21",
        "author": "Paz Toledano, Guy Zimmerman, Yaakov Tischler",
        "summary": "(Abstract pending update from publisher...)",
        "journal": "Optics Express",
        "title_cn": "通过折射率调制实现生物组织中浓度和厚度相关的光学透明度",
        "abstract_cn": "（摘要暂缺，系统已记录，待官方补全后会再次提醒）"
    },
    {
        "id": "https://doi.org/10.1364/boe.582188",
        "title": "Two-lens telecentric model eyes for image distortion measurement in adaptive optics ophthalmoscopes",
        "link": "https://doi.org/10.1364/boe.582188",
        "published": "2026-01-22",
        "author": "Yuning Xia, Gastón Ayubi, Julie Bentley, Alfredo Dubra",
        "summary": "(Abstract pending update from publisher...)",
        "journal": "Biomedical Optics Express",
        "title_cn": "用于自适应光学检眼镜中图像失真测量的双镜头远心模型眼",
        "abstract_cn": "（摘要暂缺，系统已记录，待官方补全后会再次提醒）"
    },
    {
        "id": "https://doi.org/10.29026/oea.2026.250269",
        "title": "Timeshare surface-enhanced Raman scattering platform with sensitive and quantitative mode",
        "link": "https://doi.org/10.29026/oea.2026.250269",
        "published": "2026",
        "author": "Qianqian Ding, Xueyan Chen, Yunlu Jia, Hong Liu, Xiaochen Zhang, Ningtao Cheng, Shikuan Yang",
        "summary": "(Abstract pending update from publisher...)",
        "journal": "Opto-Electronic Advances",
        "title_cn": "具有敏感和定量模式的分时表面增强拉曼散射平台",
        "abstract_cn": "（摘要暂缺，系统已记录，待官方补全后会再次提醒）"
    },
    {
        "id": "https://doi.org/10.29026/oea.2026.250177",
        "title": "Soft chiral superstructure enabled dynamic polychromatic holography",
        "link": "https://doi.org/10.29026/oea.2026.250177",
        "published": "2026",
        "author": "Chun-Ting Xu, Lu Li, Quan-Ming Chen, Guang-Yao Wang, Wei Hu",
        "summary": "(Abstract pending update from publisher...)",
        "journal": "Opto-Electronic Advances",
        "title_cn": "软手性上部结构实现动态多色全息术",
        "abstract_cn": "（摘要暂缺，系统已记录，待官方补全后会再次提醒）"
    },
    {
        "title": "Ultrafast VISAR velocity field reconstruction via deep unfolding networks and hardware-optimized deployment",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Ultrafast VISAR velocity field reconstruction via deep unfolding networks and hardware-optimized deployment"
        },
        "summary": "Publication date: June 2026Source: Optics and Lasers in Engineering, Volume 201Author(s): Miao Li, Chaorui Chen, Xi Wang, Xinru Zhang, Youwei Dai, Longwu Luo",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "<p>Publication date: June 2026</p><p><b>Source:</b> Optics and Lasers in Engineering, Volume 201</p><p>Author(s): Miao Li, Chaorui Chen, Xi Wang, Xinru Zhang, Youwei Dai, Longwu Luo</p>"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.sciencedirect.com/science/article/pii/S0143816626000230?dgcid=rss_sd_all"
            }
        ],
        "link": "https://www.sciencedirect.com/science/article/pii/S0143816626000230",
        "id": "https://www.sciencedirect.com/science/article/pii/S0143816626000230",
        "guidislink": false,
        "journal": "Optics and Lasers in Engineering",
        "title_cn": "通过深度展开网络和硬件优化部署进行超快 VISAR 速度场重建",
        "abstract_cn": "Publication date: June 2026Source: Optics and Lasers in Engineering, Volume 201Author(s): Miao Li, Chaorui Chen, Xi Wang, Xinru Zhang, Youwei Dai, Longwu Luo"
    },
    {
        "title": "3D light field display with enhanced reconstruction accuracy based on distortion- suppressed compound lens array and pre-correction encoded image",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "3D light field display with enhanced reconstruction accuracy based on distortion- suppressed compound lens array and pre-correction encoded image"
        },
        "summary": "Publication date: June 2026Source: Optics and Lasers in Engineering, Volume 201Author(s): Xudong Wen, Xin Gao, Yaohe Zheng, Ziyun Lu, Jinhong He, Hanyu Li, Ningchi Li, Boyang Liu, Binbin Yan, Xunbo Yu, Xinzhu Sang",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "<p>Publication date: June 2026</p><p><b>Source:</b> Optics and Lasers in Engineering, Volume 201</p><p>Author(s): Xudong Wen, Xin Gao, Yaohe Zheng, Ziyun Lu, Jinhong He, Hanyu Li, Ningchi Li, Boyang Liu, Binbin Yan, Xunbo Yu, Xinzhu Sang</p>"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.sciencedirect.com/science/article/pii/S0143816626000308?dgcid=rss_sd_all"
            }
        ],
        "link": "https://www.sciencedirect.com/science/article/pii/S0143816626000308",
        "id": "https://www.sciencedirect.com/science/article/pii/S0143816626000308",
        "guidislink": false,
        "journal": "Optics and Lasers in Engineering",
        "title_cn": "基于畸变抑制复合透镜阵列和预校正编码图像的增强重建精度的3D光场显示",
        "abstract_cn": "Publication date: June 2026Source: Optics and Lasers in Engineering, Volume 201Author(s): Xudong Wen, Xin Gao, Yaohe Zheng, Ziyun Lu, Jinhong He, Hanyu Li, Ningchi Li, Boyang Liu, Binbin Yan, Xunbo Yu, Xinzhu Sang"
    },
    {
        "id": "https://www.nature.com/articles/s41566-026-01852-z",
        "title": "Author Correction: Stabilizing high-efficiency perovskite solar cells via strategic interfacial contact engineering",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Author Correction: Stabilizing high-efficiency perovskite solar cells via strategic interfacial contact engineering"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41566-026-01852-z"
            }
        ],
        "link": "https://www.nature.com/articles/s41566-026-01852-z",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Nature Photonics, Published online: 22 January 2026; <a href=\"https://www.nature.com/articles/s41566-026-01852-z\">doi:10.1038/s41566-026-01852-z</a></p>Author Correction: Stabilizing high-efficiency perovskite solar cells via strategic interfacial contact engineering"
            }
        ],
        "summary": "Nature Photonics, Published online: 22 January 2026; doi:10.1038/s41566-026-01852-zAuthor Correction: Stabilizing high-efficiency perovskite solar cells via strategic interfacial contact engineering",
        "authors": [
            {
                "name": "Guixiang Li"
            },
            {
                "name": "Zuhong Zhang"
            },
            {
                "name": "Benjamin Agyei-Tuffour"
            },
            {
                "name": "Luyan Wu"
            },
            {
                "name": "Thomas W. Gries"
            },
            {
                "name": "Karunanantharajah Prashanthan"
            },
            {
                "name": "Lennart Frohloff"
            },
            {
                "name": "Artem Musiienko"
            },
            {
                "name": "Jinzhao Li"
            },
            {
                "name": "Rui Zhu"
            },
            {
                "name": "Lucy J. F. Hart"
            },
            {
                "name": "Luyao Wang"
            },
            {
                "name": "Zhe Li"
            },
            {
                "name": "Bo Hou"
            },
            {
                "name": "Norbert Koch"
            },
            {
                "name": "Michele Saba"
            },
            {
                "name": "Piers R. F. Barnes"
            },
            {
                "name": "Jenny Nelson"
            },
            {
                "name": "Paul J. Dyson"
            },
            {
                "name": "Mohammad Khaja Nazeeruddin"
            },
            {
                "name": "Meng Li"
            },
            {
                "name": "Antonio Abate"
            }
        ],
        "author": "Antonio Abate",
        "author_detail": {
            "name": "Guixiang Li"
        },
        "dc_identifier": "doi:10.1038/s41566-026-01852-z",
        "dc_source": "Nature Photonics, Published online: 2026-01-22; | doi:10.1038/s41566-026-01852-z",
        "updated": "2026-01-22",
        "updated_parsed": [
            2026,
            1,
            22,
            0,
            0,
            0,
            3,
            22,
            0
        ],
        "prism_publicationname": "Nature Photonics",
        "prism_doi": "10.1038/s41566-026-01852-z",
        "prism_url": "https://www.nature.com/articles/s41566-026-01852-z",
        "journal": "Nature Photonics",
        "title_cn": "作者更正：通过战略界面接触工程稳定高效钙钛矿太阳能电池",
        "abstract_cn": "《自然光子学》，在线发布：2026 年 1 月 22 日； doi:10.1038/s41566-026-01852-z作者更正：通过战略界面接触工程稳定高效钙钛矿太阳能电池"
    },
    {
        "id": "http://arxiv.org/abs/2601.15456v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15456v1",
        "title": "Attosecond-timing millimeter waves via Kerr optical frequency division",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Attosecond-timing millimeter waves via Kerr optical frequency division"
        },
        "updated": "2026-01-21T20:52:13Z",
        "updated_parsed": [
            2026,
            1,
            21,
            20,
            52,
            13,
            2,
            21,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15456v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15456v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Millimeter-wave oscillators underpin key applications in communication, spectroscopy, radar, and astronomy, yet their achievable spectral purity remains limited. Approaches that directly generate millimeter-wave carriers are fundamentally limited by quantum and thermal phase-noise processes. Here we show that these limits can be overcome by combining Kerr-induced optical frequency division in a chip-scale microresonator with a large-spacing dual-wavelength Brillouin laser. This 3.3 THz optical reference injection-locks a Kerr soliton microcomb, with a repetition rate that becomes a coherently divided 300 GHz carrier with phase noise below the quantum limit of a corresponding 300 GHz dual-wavelength Brillouin laser and far below the thermo-refractive noise of a microring resonator. Cross-correlation phase-noise measurements were developed to show that the resulting oscillator reaches a phase-noise floor of -152 dBc/Hz at 1 MHz offset, consistent with photodetection shot noise. Integration of the measured spectrum yields an RMS timing jitter of 135 as from 1 kHz to 1 MHz. These results establish optical frequency division as a generic method for generation of sub-terahertz carriers with coherence no longer constrained by direct-generation limits.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Millimeter-wave oscillators underpin key applications in communication, spectroscopy, radar, and astronomy, yet their achievable spectral purity remains limited. Approaches that directly generate millimeter-wave carriers are fundamentally limited by quantum and thermal phase-noise processes. Here we show that these limits can be overcome by combining Kerr-induced optical frequency division in a chip-scale microresonator with a large-spacing dual-wavelength Brillouin laser. This 3.3 THz optical reference injection-locks a Kerr soliton microcomb, with a repetition rate that becomes a coherently divided 300 GHz carrier with phase noise below the quantum limit of a corresponding 300 GHz dual-wavelength Brillouin laser and far below the thermo-refractive noise of a microring resonator. Cross-correlation phase-noise measurements were developed to show that the resulting oscillator reaches a phase-noise floor of -152 dBc/Hz at 1 MHz offset, consistent with photodetection shot noise. Integration of the measured spectrum yields an RMS timing jitter of 135 as from 1 kHz to 1 MHz. These results establish optical frequency division as a generic method for generation of sub-terahertz carriers with coherence no longer constrained by direct-generation limits."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-21T20:52:13Z",
        "published_parsed": [
            2026,
            1,
            21,
            20,
            52,
            13,
            2,
            21,
            0
        ],
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "authors": [
            {
                "name": "Scott C. Egbert"
            },
            {
                "name": "Brendan M. Heffernan"
            },
            {
                "name": "James Greenberg"
            },
            {
                "name": "William F. McGrew"
            },
            {
                "name": "Antoine Rolland"
            }
        ],
        "author_detail": {
            "name": "Antoine Rolland"
        },
        "author": "Antoine Rolland",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "通过克尔光分频实现阿秒定时毫米波",
        "abstract_cn": "毫米波振荡器支撑着通信、光谱学、雷达和天文学中的关键应用，但其可实现的光谱纯度仍然有限​​。直接生成毫米波载波的方法从根本上受到量子和热相位噪声过程的限制。在这里，我们表明，可以通过将芯片级微谐振器中的克尔诱导光学分频与大间距双波长布里渊激光器相结合来克服这些限制。这种 3.3 THz 光学参考注入锁定克尔孤子微梳，其重复率成为相干分割的 300 GHz 载波，相位噪声低于相应 300 GHz 双波长布里渊激光器的量子极限，并且远低于微环谐振器的热折射噪声。开发了互相关相位噪声测量，以表明所得振荡器在 1 MHz 偏移下达到 -152 dBc/Hz 的相位噪声本底，与光电检测散粒噪声一致。测量频谱的积分产生 1kHz 至 1MHz 范围内 135 的 RMS 定时抖动。这些结果将光频分确立为一种生成亚太赫兹载波的通用方法，其相干性不再受到直接生成限制的限制。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15480v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15480v1",
        "title": "Visualization of Gaussian Mode Profile in Gigahertz Surface-Acoustic-Wave Resonators",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Visualization of Gaussian Mode Profile in Gigahertz Surface-Acoustic-Wave Resonators"
        },
        "updated": "2026-01-21T21:30:51Z",
        "updated_parsed": [
            2026,
            1,
            21,
            21,
            30,
            51,
            2,
            21,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15480v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15480v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Surface-acoustic-wave (SAW) resonators operating at gigahertz (GHz) frequencies are widely used in wireless telecommunication and quantum information processing. Successful implementation of such resonators calls for detailed microscopic understanding of their mode profiles, energy dissipation channels, and imperfections from microfabrication. In this work, we report on the visualization of acoustic waves in LiNbO3 SAW resonators by transmission-mode microwave impedance microscopy (TMIM). The Gaussian mode profile tightly confined by reflecting mirrors is vividly seen in the TMIM images, from which the linewidth of the resonator itself can be extracted. The spatially resolved acoustic profile also allows us to perform failure analysis on faulty devices. Our work establishes a pathway for further optimization of SAW resonators for classical and quantum acoustic applications.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Surface-acoustic-wave (SAW) resonators operating at gigahertz (GHz) frequencies are widely used in wireless telecommunication and quantum information processing. Successful implementation of such resonators calls for detailed microscopic understanding of their mode profiles, energy dissipation channels, and imperfections from microfabrication. In this work, we report on the visualization of acoustic waves in LiNbO3 SAW resonators by transmission-mode microwave impedance microscopy (TMIM). The Gaussian mode profile tightly confined by reflecting mirrors is vividly seen in the TMIM images, from which the linewidth of the resonator itself can be extracted. The spatially resolved acoustic profile also allows us to perform failure analysis on faulty devices. Our work establishes a pathway for further optimization of SAW resonators for classical and quantum acoustic applications."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cond-mat.other",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-21T21:30:51Z",
        "published_parsed": [
            2026,
            1,
            21,
            21,
            30,
            51,
            2,
            21,
            0
        ],
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "authors": [
            {
                "name": "Shizai Chu"
            },
            {
                "name": "Suraj Thapa Magar"
            },
            {
                "name": "John Nichol"
            },
            {
                "name": "Keji Lai"
            }
        ],
        "author_detail": {
            "name": "Keji Lai"
        },
        "author": "Keji Lai",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "千兆赫表面声波谐振器中高斯模式分布的可视化",
        "abstract_cn": "在千兆赫 (GHz) 频率下工作的表面声波 (SAW) 谐振器广泛用于无线电信和量子信息处理。成功实现此类谐振器需要对其模式分布、能量耗散通道和微加工缺陷进行详细的微观理解。在这项工作中，我们报告了通过传输模式微波阻抗显微镜 (TMIM) 对 LiNbO3 SAW 谐振器中的声波进行可视化。在 TMIM 图像中可以清楚地看到被反射镜严格限制的高斯模式轮廓，从中可以提取谐振器本身的线宽。空间分辨的声学剖面还使我们能够对故障设备进行故障分析。我们的工作为进一步优化经典和量子声学应用的声表面波谐振器建立了一条途径。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15502v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15502v1",
        "title": "Optical Manipulation of Erythrocytes via Evanescent Waves: Assessing Glucose-Induced Mobility Variations",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Optical Manipulation of Erythrocytes via Evanescent Waves: Assessing Glucose-Induced Mobility Variations"
        },
        "updated": "2026-01-21T22:18:31Z",
        "updated_parsed": [
            2026,
            1,
            21,
            22,
            18,
            31,
            2,
            21,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15502v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15502v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "This study investigates the dynamics of red blood cells (RBCs) under the influence of evanescent waves generated by total internal reflection (TIR). Using a 1064 nm laser system and a dual-chamber prism setup, we quantified the mobility of erythrocytes in different glucose environments. Our methodology integrates automated tracking via TrackMate\\c{opyright} to analyze over 60 trajectory sets. The results reveal a significant decrease in mean velocity, from 11.8 μm/s in 5 mM glucose to 8.8 μm/s in 50 mM glucose (p = 0.019). These findings suggest that evanescent waves can serve as a non-invasive tool to probe the mechanical properties of cell membranes influenced by biochemical changes.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "This study investigates the dynamics of red blood cells (RBCs) under the influence of evanescent waves generated by total internal reflection (TIR). Using a 1064 nm laser system and a dual-chamber prism setup, we quantified the mobility of erythrocytes in different glucose environments. Our methodology integrates automated tracking via TrackMate\\c{opyright} to analyze over 60 trajectory sets. The results reveal a significant decrease in mean velocity, from 11.8 μm/s in 5 mM glucose to 8.8 μm/s in 50 mM glucose (p = 0.019). These findings suggest that evanescent waves can serve as a non-invasive tool to probe the mechanical properties of cell membranes influenced by biochemical changes."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "physics.bio-ph",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "q-bio.CB",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "q-bio.QM",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-21T22:18:31Z",
        "published_parsed": [
            2026,
            1,
            21,
            22,
            18,
            31,
            2,
            21,
            0
        ],
        "arxiv_comment": "5 pages, pre-print",
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "authors": [
            {
                "name": "T. Troncoso Enríquez"
            },
            {
                "name": "J. Staforelli-Vivanco"
            },
            {
                "name": "I. Bordeu"
            },
            {
                "name": "M. González-Ortiz"
            }
        ],
        "author_detail": {
            "name": "M. González-Ortiz"
        },
        "author": "M. González-Ortiz",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "通过倏逝波对红细胞进行光学操纵：评估葡萄糖引起的迁移率变化",
        "abstract_cn": "本研究研究了全内反射 (TIR) 产生的倏逝波影响下红细胞 (RBC) 的动态变化。使用 1064 nm 激光系统和双室棱镜装置，我们量化了红细胞在不同葡萄糖环境中的迁移率。我们的方法通过 TrackMate\\c{opyright} 集成自动跟踪来分析 60 多个轨迹集。结果显示平均速度显着下降，从 5 mM 葡萄糖中的 11.8 μm/s 降至 50 mM 葡萄糖中的 8.8 μm/s (p = 0.019)。这些发现表明，倏逝波可以作为一种非侵入性工具来探测受生化变化影响的细胞膜的机械特性。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15562v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15562v1",
        "title": "An ultrafast diamond nonlinear photonic sensor",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "An ultrafast diamond nonlinear photonic sensor"
        },
        "updated": "2026-01-22T01:01:43Z",
        "updated_parsed": [
            2026,
            1,
            22,
            1,
            1,
            43,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15562v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15562v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            },
            {
                "rel": "related",
                "href": "https://doi.org/10.1038/s41467-025-63936-8",
                "title": "doi",
                "type": "text/html"
            }
        ],
        "summary": "The integration of light and materials technology is key to the creation of innovative sensing technologies. Sensing of electric and magnetic fields, and temperature with high spatio-temporal resolution is a critical task for the development of the next-generation of nanometer-scale quantum devices. Color centers in diamonds are attractive for potential applications owing to their characteristic quantum states, although they require metallic contacts for the introduction of external microwaves. Here, we build an ultrafast diamond nonlinear photonic sensor to assess the surface electric field; an electro-optic sensor based on nitrogen-vacancy centers in a diamond nanotip breaks the spatial-limit of conventional pump-probe techniques. The 10-fs near-infrared optical pulse modulates the surface electric field of a 2D transition metal dichalcogenide and we monitor the dynamics of the local electric field at nanometer-femtosecond spatio-temporal resolutions. Our nanoscopic technique will provide new horizons to the sensing of advanced nano materials.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "The integration of light and materials technology is key to the creation of innovative sensing technologies. Sensing of electric and magnetic fields, and temperature with high spatio-temporal resolution is a critical task for the development of the next-generation of nanometer-scale quantum devices. Color centers in diamonds are attractive for potential applications owing to their characteristic quantum states, although they require metallic contacts for the introduction of external microwaves. Here, we build an ultrafast diamond nonlinear photonic sensor to assess the surface electric field; an electro-optic sensor based on nitrogen-vacancy centers in a diamond nanotip breaks the spatial-limit of conventional pump-probe techniques. The 10-fs near-infrared optical pulse modulates the surface electric field of a 2D transition metal dichalcogenide and we monitor the dynamics of the local electric field at nanometer-femtosecond spatio-temporal resolutions. Our nanoscopic technique will provide new horizons to the sensing of advanced nano materials."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cond-mat.mtrl-sci",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T01:01:43Z",
        "published_parsed": [
            2026,
            1,
            22,
            1,
            1,
            43,
            3,
            22,
            0
        ],
        "arxiv_comment": "20 pages, 4 figures",
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "arxiv_journal_ref": "Nature Communications 16, 8300 (2025)",
        "authors": [
            {
                "name": "Daisuke Sato"
            },
            {
                "name": "Junjie Guo"
            },
            {
                "name": "Takuto Ichikawa"
            },
            {
                "name": "Dwi Prananto"
            },
            {
                "name": "Toshu An"
            },
            {
                "name": "Paul Fons"
            },
            {
                "name": "Shoji Yoshida"
            },
            {
                "name": "Hidemi Shigekawa"
            },
            {
                "name": "Muneaki Hase"
            }
        ],
        "author_detail": {
            "name": "Muneaki Hase"
        },
        "author": "Muneaki Hase",
        "arxiv_doi": "10.1038/s41467-025-63936-8",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "超快金刚石非线性光子传感器",
        "abstract_cn": "光和材料技术的集成是创造创新传感技术的关键。以高时空分辨率传感电场、磁场和温度是开发下一代纳米级量子器件的关键任务。钻石中的色心由于其特有的量子态而对潜在应用具有吸引力，尽管它们需要金属接触来引入外部微波。在这里，我们构建了一个超快金刚石非线性光子传感器来评估表面电场；基于金刚石纳米尖端中氮空位中心的电光传感器打破了传统泵浦探针技术的空间限制。 10-fs 近红外光脉冲调制二维过渡金属二硫属化物的表面电场，我们以纳米飞秒时空分辨率监测局部电场的动态。我们的纳米技术将为先进纳米材料的传感提供新的视野。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15565v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15565v1",
        "title": "Bright Pulsed Squeezed Light for Quantum-Enhanced Precision Microscopy",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Bright Pulsed Squeezed Light for Quantum-Enhanced Precision Microscopy"
        },
        "updated": "2026-01-22T01:07:55Z",
        "updated_parsed": [
            2026,
            1,
            22,
            1,
            7,
            55,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15565v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15565v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Squeezed states of light enable enhanced measurement precision by reducing noise below the standard quantum limit. A key application of squeezed light is nonlinear microscopy, where state-of-the-art performance is limited by photodamage and quantum-limited noise. Such microscopes require bright, pulsed light for optimal operation, yet generating and detecting bright pulsed squeezing at high levels remains challenging. In this work, we present an efficient technique to generate high levels of bright picosecond pulsed squeezed light using a $χ^2$ optical parametric amplification process in a waveguide. We measure $-3.2~\\mathrm{dB}$ of bright squeezing with optical power compatible with nonlinear microscopy, as well as $-3.6~\\mathrm{dB}$ of vacuum squeezing. Corrected for losses, these squeezing levels correspond to $-15.4^{+2.7}_{-8.7}~\\mathrm{dB}$ of squeezing generated in the waveguide. The measured level of bright amplitude pulsed squeezing is to our knowledge the highest reported to date, and will contribute to the broader adoption of quantum-enhanced nonlinear microscopy in biological studies.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Squeezed states of light enable enhanced measurement precision by reducing noise below the standard quantum limit. A key application of squeezed light is nonlinear microscopy, where state-of-the-art performance is limited by photodamage and quantum-limited noise. Such microscopes require bright, pulsed light for optimal operation, yet generating and detecting bright pulsed squeezing at high levels remains challenging. In this work, we present an efficient technique to generate high levels of bright picosecond pulsed squeezed light using a $χ^2$ optical parametric amplification process in a waveguide. We measure $-3.2~\\mathrm{dB}$ of bright squeezing with optical power compatible with nonlinear microscopy, as well as $-3.6~\\mathrm{dB}$ of vacuum squeezing. Corrected for losses, these squeezing levels correspond to $-15.4^{+2.7}_{-8.7}~\\mathrm{dB}$ of squeezing generated in the waveguide. The measured level of bright amplitude pulsed squeezing is to our knowledge the highest reported to date, and will contribute to the broader adoption of quantum-enhanced nonlinear microscopy in biological studies."
        },
        "tags": [
            {
                "term": "quant-ph",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T01:07:55Z",
        "published_parsed": [
            2026,
            1,
            22,
            1,
            7,
            55,
            3,
            22,
            0
        ],
        "arxiv_comment": "5 pages, 3 figures",
        "arxiv_primary_category": {
            "term": "quant-ph"
        },
        "authors": [
            {
                "name": "Alex Terrasson"
            },
            {
                "name": "Lars Madsen"
            },
            {
                "name": "Joel Grim"
            },
            {
                "name": "Warwick Bowen"
            }
        ],
        "author_detail": {
            "name": "Warwick Bowen"
        },
        "author": "Warwick Bowen",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "用于量子增强精密显微镜的明亮脉冲压缩光",
        "abstract_cn": "压缩光态可将噪声降低到标准量子极限以下，从而提高测量精度。压缩光的一个关键应用是非线性显微镜，其中最先进的性能受到光损伤和量子限制噪声的限制。此类显微镜需要明亮的脉冲光才能实现最佳操作，但生成和检测高水平的明亮脉冲挤压仍然具有挑战性。在这项工作中，我们提出了一种有效的技术，使用波导中的 $χ^2$ 光学参量放大过程来生成高水平的明亮皮秒脉冲压缩光。我们用与非线性显微镜兼容的光功率测量了$-3.2~\\mathrm{dB}$的明亮挤压，以及$-3.6~\\mathrm{dB}$的真空挤压。校正损耗后，这些挤压水平对应于波导中产生的挤压 $-15.4^{+2.7}_{-8.7}~\\mathrm{dB}$。据我们所知，测量到的亮振幅脉冲挤压水平是迄今为止报道的最高水平，并将有助于量子增强非线性显微镜在生物学研究中的更广泛采用。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15569v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15569v1",
        "title": "σh-Broken Induced Topological quasi-BIC",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "σh-Broken Induced Topological quasi-BIC"
        },
        "updated": "2026-01-22T01:21:57Z",
        "updated_parsed": [
            2026,
            1,
            22,
            1,
            21,
            57,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15569v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15569v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Transitions from bound states in the continuum (BICs) to quasi-BICs (qBICs) are typically realized by introducing in-plane asymmetry, including permittivity asymmetry (ε-qBICs) and geometry asymmetry (g-qBICs). Here, we demonstrate that when the in-plane symmetry is rigorously kept, the transition can also be occurred, provided the out-of-plane asymmetry is designed, which is called σh -qBICs in this work. When the {σh symmetry is gradually broken, the system undergoes a topological phase transition characterized by a Zak phase inversion, leading to a band inversion between quadrupole and dipole modes. This process not only enables controlled radiation coupling of BICs but also introduces a defect-immune qBIC regime. Our findings establish a general mechanism for engineering high-Q resonances and topologically robust plasmonic cavities.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Transitions from bound states in the continuum (BICs) to quasi-BICs (qBICs) are typically realized by introducing in-plane asymmetry, including permittivity asymmetry (ε-qBICs) and geometry asymmetry (g-qBICs). Here, we demonstrate that when the in-plane symmetry is rigorously kept, the transition can also be occurred, provided the out-of-plane asymmetry is designed, which is called σh -qBICs in this work. When the {σh symmetry is gradually broken, the system undergoes a topological phase transition characterized by a Zak phase inversion, leading to a band inversion between quadrupole and dipole modes. This process not only enables controlled radiation coupling of BICs but also introduces a defect-immune qBIC regime. Our findings establish a general mechanism for engineering high-Q resonances and topologically robust plasmonic cavities."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cond-mat.mes-hall",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T01:21:57Z",
        "published_parsed": [
            2026,
            1,
            22,
            1,
            21,
            57,
            3,
            22,
            0
        ],
        "arxiv_comment": "4 figures in article and 2 figures in SI. 22 pages including SI",
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "authors": [
            {
                "name": "Yongqi Chen"
            },
            {
                "name": "Chaofeng Xie"
            },
            {
                "name": "Tongtong Zhu"
            },
            {
                "name": "Weiqiang Ding"
            },
            {
                "name": "Yurui Fang"
            }
        ],
        "author_detail": {
            "name": "Yurui Fang"
        },
        "author": "Yurui Fang",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "σh 断裂诱导拓扑准 BIC",
        "abstract_cn": "从连续体束缚态 (BIC) 到准 BIC (qBIC) 的转变通常是通过引入面内不对称性来实现的，包括介电常数不对称性 (ε-qBICs) 和几何不对称性 (g-qBICs)。在这里，我们证明，当严格保持面内对称性时，如果设计了面外不对称性，也可以发生转变，这在本工作中称为 σh -qBICs。当{σh对称性逐渐被打破时，系统经历以Zak相反转为特征的拓扑相变，导致四极和偶极模式之间的能带反转。该过程不仅能够实现 BIC 的受控辐射耦合，而且还引入了缺陷免疫 qBIC 机制。我们的研究结果建立了一种设计高 Q 值共振和拓扑鲁棒等离子体腔的通用机制。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15581v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15581v1",
        "title": "Head-wearable Holographic Head-mounted Display with 6 Degrees of Freedom",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Head-wearable Holographic Head-mounted Display with 6 Degrees of Freedom"
        },
        "updated": "2026-01-22T02:02:53Z",
        "updated_parsed": [
            2026,
            1,
            22,
            2,
            2,
            53,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15581v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15581v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "A head-mounted display (HMD) using holography technology (holo-HMD) is expected to be the next generation of HMDs capable of reducing three-dimensional sickness. In HMDs, it is important to generate images that respond to head movement in real time. However, in holo-HMDs, generation of hologram data in real time is difficult due to the large computational resources required. This paper proposes a fast calculation algorithm for generating hologram data for holo-HMDs, which requires low computational power. A holo-HMD supporting six degrees of freedom was also developed using this algorithm and it was confirmed that it obtained reconstructed images with six degrees of freedom in real time (30 fps or more).",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "A head-mounted display (HMD) using holography technology (holo-HMD) is expected to be the next generation of HMDs capable of reducing three-dimensional sickness. In HMDs, it is important to generate images that respond to head movement in real time. However, in holo-HMDs, generation of hologram data in real time is difficult due to the large computational resources required. This paper proposes a fast calculation algorithm for generating hologram data for holo-HMDs, which requires low computational power. A holo-HMD supporting six degrees of freedom was also developed using this algorithm and it was confirmed that it obtained reconstructed images with six degrees of freedom in real time (30 fps or more)."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T02:02:53Z",
        "published_parsed": [
            2026,
            1,
            22,
            2,
            2,
            53,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "authors": [
            {
                "name": "Taichi Sakakihara"
            },
            {
                "name": "Teppei Jodo"
            },
            {
                "name": "Seok Kang"
            },
            {
                "name": "Yuji Sakamoto"
            }
        ],
        "author_detail": {
            "name": "Yuji Sakamoto"
        },
        "author": "Yuji Sakamoto",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "6 自由度头戴式全息头戴显示器",
        "abstract_cn": "采用全息技术的头戴式显示器（HMD）（holo-HMD）有望成为能够减少三维眩晕的下一代头戴式显示器。在 HMD 中，生成实时响应头部运动的图像非常重要。然而，在全息头显中，由于需要大量的计算资源，实时生成全息图数据很困难。本文提出了一种为全息头戴式显示器生成全息图数据的快速计算算法，该算法需要较低的计算能力。利用该算法还开发了支持六自由度的holo-HMD，并证实其实时获得了六自由度的重建图像（30 fps或更高）。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15604v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15604v1",
        "title": "Adaptive information-maximization encoding for ghost imaging--A general Bayesian framework under experimental physical constraints",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Adaptive information-maximization encoding for ghost imaging--A general Bayesian framework under experimental physical constraints"
        },
        "updated": "2026-01-22T03:05:50Z",
        "updated_parsed": [
            2026,
            1,
            22,
            3,
            5,
            50,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15604v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15604v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "[New Paper] Abstract not indexed yet. Please visit the official website.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Ghost imaging (GI) has demonstrated diverse imaging capabilities enabled by its encoding-decoding-based computational imaging mechanism. Accordingly, information-theoretic studies have emerged as a promising avenue for probing the fundamental performance bounds of of GI and related computational imaging paradigms. However, the design of information-theoretically optimal encoding strategies remains largely unexplored, primarily due to the intractability of the prior probability density function (PDF) of an unknown scene. Here, by leveraging the ability of recursively estimating the PDF of the object to be imaged via Bayesian filtering, we propose to establish an adaptive information-maximization encoding (AIME) design framework. Based on the adaptively estimated posterior PDF from previously acquired measurements, the expected information gain of subsequent detections is evaluated and maximized to design the corresponding encoding patterns in a closed-loop manner. Within this framework, the theoretical form of the information-optimal encoding under representative physical constraints is analytically derived. Corresponding experimental results show that, GI systems employing information-optimal encoding achieve markedly improved imaging performance compared with conventional fixed point-to-point imaging without relying on additional heuristic regularization schemes, particularly in low signal-to-noise ratio regimes. Moreover, the proposed strategy consistently enables significantly enhanced information acquisition capability compared with existing encoding strategies, leading to substantially improved imaging quality. These results establish a principled information-theoretic foundation for optimal encoding design in computational imaging paradigms,provided that the forward model can be accurately characterized."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T03:05:50Z",
        "published_parsed": [
            2026,
            1,
            22,
            3,
            5,
            50,
            3,
            22,
            0
        ],
        "arxiv_comment": "37 pages, 15 figures",
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "authors": [
            {
                "name": "Jianshuo Sun"
            },
            {
                "name": "Chenyu Hu"
            },
            {
                "name": "Zynwang Bo"
            },
            {
                "name": "Zhentao Liu"
            },
            {
                "name": "Mengyu Chen"
            },
            {
                "name": "Longkun Du"
            },
            {
                "name": "Weitao Liu"
            },
            {
                "name": "Shensheng Han"
            }
        ],
        "author_detail": {
            "name": "Shensheng Han"
        },
        "author": "Shensheng Han",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "鬼影成像的自适应信息最大化编码--实验物理约束下的通用贝叶斯框架",
        "abstract_cn": "【摘要未收录】新文章暂无数据库记录，请点击链接直达官网。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15629v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15629v1",
        "title": "Burst Mode Ultrafast Laser Welding of Sapphire and Fe-36Ni Alloy with Non-optical Contact Condition",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Burst Mode Ultrafast Laser Welding of Sapphire and Fe-36Ni Alloy with Non-optical Contact Condition"
        },
        "updated": "2026-01-22T03:59:28Z",
        "updated_parsed": [
            2026,
            1,
            22,
            3,
            59,
            28,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15629v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15629v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Ultrafast laser welding provides a promising approach for high precision integration of transparent and metallic materials. However, its practical application remains constrained by the precise regulation of the interfacial gap. This study investigates the interfacial response and bonding mechanism of sapphire and Fe-36Ni alloy joints under controlled non-optical contact conditions using burst mode ultrafast laser irradiation. A polymer interlayer was introduced between naturally stacked samples to establish a variable interfacial gap, allowing systematic evaluation of gap-dependent morphology, melting behavior, and elemental transport. By redistributing the pulse energy into sequential sub-pulses, the burst mode reconstructs the temporal energy-deposition process, yielding enhanced plasma-material coupling and stable thermal accumulation. Compared with single pulse irradiation, burst mode sustains continuous bonding across gaps exceeding 10 um--far beyond the failure threshold of the single pulse mode--and forms a fusion zone 82% larger. Fracture surface and cross-sectional analyses of SEM and EDS results confirm that sequential sub-pulses promote extensive sapphire melting, droplet-driven gap bridging, and enhanced Al-Fe interdiffusion at the interface. These results provide a scientific basis for high-gap-tolerance ultrafast laser welding and scalable integration of transparent-metal hybrid components in advanced optoelectronic and precision engineering applications.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Ultrafast laser welding provides a promising approach for high precision integration of transparent and metallic materials. However, its practical application remains constrained by the precise regulation of the interfacial gap. This study investigates the interfacial response and bonding mechanism of sapphire and Fe-36Ni alloy joints under controlled non-optical contact conditions using burst mode ultrafast laser irradiation. A polymer interlayer was introduced between naturally stacked samples to establish a variable interfacial gap, allowing systematic evaluation of gap-dependent morphology, melting behavior, and elemental transport. By redistributing the pulse energy into sequential sub-pulses, the burst mode reconstructs the temporal energy-deposition process, yielding enhanced plasma-material coupling and stable thermal accumulation. Compared with single pulse irradiation, burst mode sustains continuous bonding across gaps exceeding 10 um--far beyond the failure threshold of the single pulse mode--and forms a fusion zone 82% larger. Fracture surface and cross-sectional analyses of SEM and EDS results confirm that sequential sub-pulses promote extensive sapphire melting, droplet-driven gap bridging, and enhanced Al-Fe interdiffusion at the interface. These results provide a scientific basis for high-gap-tolerance ultrafast laser welding and scalable integration of transparent-metal hybrid components in advanced optoelectronic and precision engineering applications."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T03:59:28Z",
        "published_parsed": [
            2026,
            1,
            22,
            3,
            59,
            28,
            3,
            22,
            0
        ],
        "arxiv_comment": "11 pages, 6 figures",
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "authors": [
            {
                "name": "Yu Wang"
            },
            {
                "name": "Nan Li"
            },
            {
                "name": "Yuxuan Li"
            },
            {
                "name": "Yitong Chen"
            },
            {
                "name": "Qingwei Zhang"
            },
            {
                "name": "Jianing Zhao"
            },
            {
                "name": "Zhe Lin"
            },
            {
                "name": "Zihui Dong"
            },
            {
                "name": "Guochang Jiang"
            },
            {
                "name": "Zhengqiang Zhu"
            },
            {
                "name": "Shanglu Yang"
            }
        ],
        "author_detail": {
            "name": "Shanglu Yang"
        },
        "author": "Shanglu Yang",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "非光学接触条件下蓝宝石与 Fe-36Ni 合金的突发模式超快激光焊接",
        "abstract_cn": "超快激光焊接为透明材料和金属材料的高精度集成提供了一种有前途的方法。然而，其实际应用仍然受到界面间隙精确调节的限制。本研究利用突发模式超快激光照射，研究了在受控非光学接触条件下蓝宝石和 Fe-36Ni 合金接头的界面响应和结合机制。在自然堆叠的样品之间引入聚合物夹层，以建立可变的界面间隙，从而可以系统地评估间隙相关的形态、熔化行为和元素传输。通过将脉冲能量重新分配为连续的子脉冲，突发模式重建了时间能量沉积过程，从而产生增强的等离子体-材料耦合和稳定的热积累。与单脉冲照射相比，突发模式可以在超过 10 微米的间隙中维持连续键合（远远超出单脉冲模式的失效阈值），并形成大 82% 的熔合区。 SEM 和 EDS 结果的断裂表面和横截面分析证实，连续子脉冲促进了广泛的蓝宝石熔化、液滴驱动的间隙桥接以及界面处增强的 Al-Fe 相互扩散。这些结果为先进光电和精密工程应用中的高间隙公差超快激光焊接和透明金属混合元件的可扩展集成提供了科学依据。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15631v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15631v1",
        "title": "Anomalous valley Hall dynamics of exciton-polaritons",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Anomalous valley Hall dynamics of exciton-polaritons"
        },
        "updated": "2026-01-22T04:09:25Z",
        "updated_parsed": [
            2026,
            1,
            22,
            4,
            9,
            25,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15631v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15631v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "The valley degree of freedom in atomically thin transition-metal dichalcogenides provides a natural binary index for information processing. Exciton-polaritons formed under strong light-matter coupling offer a promising route to overcome the limited lifetime and transport of bare valley excitons. Here we report an anomalous optical valley Hall effect in a monolayer WS2 exciton-polariton system. Using polarization- and time-resolved real-space imaging, we directly visualize a symmetry-breaking spatial separation of polaritons from opposite valleys under linearly polarized excitation, accompanied by an ultrafast Hall drift velocity on the order of 10^5 m/s. This behaviour cannot be accounted for by conventional cavity-induced mechanisms and instead points to a strain-induced synthetic pseudomagnetic field acting on the excitonic component of polaritons. Our results establish exciton-polaritons as a high-speed and optically accessible platform for valley transport, opening pathways towards tunable valleytronic and topological photonic devices.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "The valley degree of freedom in atomically thin transition-metal dichalcogenides provides a natural binary index for information processing. Exciton-polaritons formed under strong light-matter coupling offer a promising route to overcome the limited lifetime and transport of bare valley excitons. Here we report an anomalous optical valley Hall effect in a monolayer WS2 exciton-polariton system. Using polarization- and time-resolved real-space imaging, we directly visualize a symmetry-breaking spatial separation of polaritons from opposite valleys under linearly polarized excitation, accompanied by an ultrafast Hall drift velocity on the order of 10^5 m/s. This behaviour cannot be accounted for by conventional cavity-induced mechanisms and instead points to a strain-induced synthetic pseudomagnetic field acting on the excitonic component of polaritons. Our results establish exciton-polaritons as a high-speed and optically accessible platform for valley transport, opening pathways towards tunable valleytronic and topological photonic devices."
        },
        "tags": [
            {
                "term": "cond-mat.mes-hall",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T04:09:25Z",
        "published_parsed": [
            2026,
            1,
            22,
            4,
            9,
            25,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cond-mat.mes-hall"
        },
        "authors": [
            {
                "name": "Xingzhou Chen"
            },
            {
                "name": "Yuanjun Guan"
            },
            {
                "name": "Areg Ghazaryan"
            },
            {
                "name": "Shiran Sun"
            },
            {
                "name": "Lingxiao Yu"
            },
            {
                "name": "Ruitao Lv"
            },
            {
                "name": "Artem Volosniev"
            },
            {
                "name": "Zheng Sun"
            },
            {
                "name": "Jian Wu"
            }
        ],
        "author_detail": {
            "name": "Jian Wu"
        },
        "author": "Jian Wu",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "激子极化子的反常谷霍尔动力学",
        "abstract_cn": "原子薄过渡金属二硫属化物的谷自由度为信息处理提供了天然的二元索引。在强光-物质耦合下形成的激子极化子为克服裸谷激子的有限寿命和传输提供了一条有前途的途径。在这里，我们报告了单层 WS2 激子-极化系统中的反常光谷霍尔效应。使用偏振和时间分辨的实空间成像，我们直接可视化线性偏振激励下来自相反谷的极化激元的对称破缺空间分离，并伴随着 10^5 m/s 量级的超快霍尔漂移速度。这种行为不能用传统的空腔诱发机制来解释，而是表明应变诱发的合成赝磁场作用于极化激元的激子成分。我们的研究结果将激子极化子确立为用于谷传输的高速且光学可访问的平台，为可调谐谷电子和拓扑光子器件开辟了道路。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15638v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15638v1",
        "title": "An optical transistor of the nonlinear resonant structure",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "An optical transistor of the nonlinear resonant structure"
        },
        "updated": "2026-01-22T04:31:34Z",
        "updated_parsed": [
            2026,
            1,
            22,
            4,
            31,
            34,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15638v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15638v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "An optical transistor capable of simultaneous amplification and switching is theoretically proposed via cascaded second-order nonlinear interactions in a resonant structure. Two distinct operational schemes are analyzed. A single frequency scheme employs cascaded second harmonic generation and inverse second harmonic generation (SHG/iSHG) using two Type-I SHG interactions, whereas a dual frequency scheme employs cascaded SHG and optical parametric amplification (SHG/OPA). Exact theoretical solutions and numerical calculations show cascadable amplification and digital on/off switching. A new optical phenomenon of nonlinear transparency is predicted by the theoretical solutions and confirmed by the numerical solutions in each scheme of the cascaded SHG/iSHG and SHG/OPA. The single and dual frequency configurations satisfy the cascadability and fan-out criteria with power transfer ratios of 4.838 and 52.26 and power amplification factors of 48.38 and 522.6, respectively. These results indicate transistor-like performance at input powers in the milliwatt range, readily supplied by laser diodes. The proposed structure establishes a physically feasible and practically scalable route to optical transistors operating at high speed and low power for integrated photonic circuits, with broad applications in all optical communication and computing.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "An optical transistor capable of simultaneous amplification and switching is theoretically proposed via cascaded second-order nonlinear interactions in a resonant structure. Two distinct operational schemes are analyzed. A single frequency scheme employs cascaded second harmonic generation and inverse second harmonic generation (SHG/iSHG) using two Type-I SHG interactions, whereas a dual frequency scheme employs cascaded SHG and optical parametric amplification (SHG/OPA). Exact theoretical solutions and numerical calculations show cascadable amplification and digital on/off switching. A new optical phenomenon of nonlinear transparency is predicted by the theoretical solutions and confirmed by the numerical solutions in each scheme of the cascaded SHG/iSHG and SHG/OPA. The single and dual frequency configurations satisfy the cascadability and fan-out criteria with power transfer ratios of 4.838 and 52.26 and power amplification factors of 48.38 and 522.6, respectively. These results indicate transistor-like performance at input powers in the milliwatt range, readily supplied by laser diodes. The proposed structure establishes a physically feasible and practically scalable route to optical transistors operating at high speed and low power for integrated photonic circuits, with broad applications in all optical communication and computing."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T04:31:34Z",
        "published_parsed": [
            2026,
            1,
            22,
            4,
            31,
            34,
            3,
            22,
            0
        ],
        "arxiv_comment": "Submitted to Japanese Journal of Applied Physics. 14 pages, 4 figures",
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "authors": [
            {
                "name": "Jongbae Kim"
            }
        ],
        "author_detail": {
            "name": "Jongbae Kim"
        },
        "author": "Jongbae Kim",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "一种非线性谐振结构的光晶体管",
        "abstract_cn": "理论上通过谐振结构中的级联二阶非线性相互作用提出了一种能够同时放大和开关的光学晶体管。分析了两种不同的操作方案。单频方案采用级联二次谐波产生和逆二次谐波产生（SHG/iSHG），使用两个I型SHG相互作用，而双频方案采用级联SHG和光参量放大（SHG/OPA）。精确的理论解决方案和数值计算显示了级联放大和数字开/关切换。在级联SHG/iSHG和SHG/OPA的每个方案中，通过理论解预测了一种新的非线性透明光学现象，并通过数值解证实了这一现象。单频和双频配置满足级联性和扇出标准，功率传输比分别为 4.838 和 52.26，功率放大系数分别为 48.38 和 522.6。这些结果表明在毫瓦范围内的输入功率下具有类似晶体管的性能，很容易由激光二极管提供。所提出的结构为集成光子电路的高速和低功率运行的光学晶体管建立了一条物理上可行且实际上可扩展的路线，在所有光通信和计算中具有广泛的应用。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15654v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15654v1",
        "title": "Enhancing the Size of Phase-Space States Containing Sub-Planck-Scale Structures via Non-Gaussian Operations",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Enhancing the Size of Phase-Space States Containing Sub-Planck-Scale Structures via Non-Gaussian Operations"
        },
        "updated": "2026-01-22T05:02:56Z",
        "updated_parsed": [
            2026,
            1,
            22,
            5,
            2,
            56,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15654v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15654v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "We observe a metrological advantage in phase-space sensitivity for photon-added cat and kitten states over their original forms, due to phase-space broadening from increased amplitude via photon addition, albeit with higher energy cost. Using accessible non-classical resources, weak squeezing and displacement, we construct a squeezed state and two superposed states: the squeezed cat state and the symmetrically squeezed state. Their photon-added variants are compared with parity-matched cat and KSs using quantum Fisher information and fidelity. The QFI isocontours reveal regimes where KS exhibit high fidelity and large amplitude, enabling their preparation via Gaussian operations and photon addition. Similar regimes are identified for cat states enhanced by squeezing and photon addition, demonstrating improved metrological performance. Moreover, increased amplitude and thus larger phase-space area reduces the size of interferometric fringes, enhancing the effectiveness of quantum error correction in cat codes.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "We observe a metrological advantage in phase-space sensitivity for photon-added cat and kitten states over their original forms, due to phase-space broadening from increased amplitude via photon addition, albeit with higher energy cost. Using accessible non-classical resources, weak squeezing and displacement, we construct a squeezed state and two superposed states: the squeezed cat state and the symmetrically squeezed state. Their photon-added variants are compared with parity-matched cat and KSs using quantum Fisher information and fidelity. The QFI isocontours reveal regimes where KS exhibit high fidelity and large amplitude, enabling their preparation via Gaussian operations and photon addition. Similar regimes are identified for cat states enhanced by squeezing and photon addition, demonstrating improved metrological performance. Moreover, increased amplitude and thus larger phase-space area reduces the size of interferometric fringes, enhancing the effectiveness of quantum error correction in cat codes."
        },
        "tags": [
            {
                "term": "quant-ph",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T05:02:56Z",
        "published_parsed": [
            2026,
            1,
            22,
            5,
            2,
            56,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "quant-ph"
        },
        "authors": [
            {
                "name": "Arman"
            },
            {
                "name": "Prasanta K. Panigrahi"
            }
        ],
        "author_detail": {
            "name": "Prasanta K. Panigrahi"
        },
        "author": "Prasanta K. Panigrahi",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "通过非高斯运算增强包含亚普朗克尺度结构的相空间状态的大小",
        "abstract_cn": "我们观察到添加光子的猫和小猫态在相空间灵敏度方面比其原始形式具有计量优势，这是由于通过光子添加增加了振幅而导致相空间变宽，尽管能量成本更高。使用可访问的非经典资源、弱挤压和位移，我们构造了一个挤压状态和两个叠加状态：挤压猫状态和对称挤压状态。使用量子费希尔信息和保真度将它们的光子添加变体与奇偶匹配的猫和 KS 进行比较。 QFI 等值线揭示了 KS 表现出高保真度和大振幅的状态，使其能够通过高斯运算和光子加法进行准备。通过挤压和光子添加增强的猫状态也发现了类似的机制，证明了计量性能的提高。此外，增加的幅度和更大的相空间面积减少了干涉条纹的尺寸，增强了cat码中量子纠错的有效性。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15695v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15695v1",
        "title": "Blue to Near-IR Integrated PZT Silicon Nitride Modulators for Quantum and Atomic Applications",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Blue to Near-IR Integrated PZT Silicon Nitride Modulators for Quantum and Atomic Applications"
        },
        "updated": "2026-01-22T06:47:25Z",
        "updated_parsed": [
            2026,
            1,
            22,
            6,
            47,
            25,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15695v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15695v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Modulation and control of lasers and optical signals is necessary for trapped-ion and cold neutral atom quantum systems. Given the diversity of atomic species, experimental modalities, and architectures, integrated optical modulators designed to operate across the visible to near-infrared spectrum are a key step towards portable, robust, and compact quantum computers, clocks, and sensors. Integrated optical modulators that are wavelength-independent, CMOS-compatible, and capable of maintaining low waveguide losses and a high resonator quality factor, DC-coupled broadband frequency response, and low power consumption, are essential for scalable photonic integration. Yet progress towards these goals has remained limited. Here we demonstrate four types of integrated stress-optic lead zirconate titanate (PZT) silicon nitride modulators: a coil Mach-Zehnder modulator, a coil pure phase modulator, and bus-coupled and add-drop ring resonator modulators, with operation from 493 nm to 780 nm. The coil MZM operates at 532 nm with a V$π$ of 2.8V, a 0.4 MHz 3-dB bandwidth, and an extinction ratio of 21.5dB. The coil phase modulator operates at 493 nm with a V$π$ of 2.8V and low residual amplitude modulation of -34 dB at a 1kHz offset. The bus-coupled ring resonator modulator operates at 493 nm and the add-drop ring resonator modulator operates at 780 nm. The ring-based modulators have an intrinsic quality factor of 3.4 million and 1.9 million, a linear tuning strength of 0.9 GHz/V and 1 GHz/V, and a 3-dB bandwidth of 2.6 MHz and 10 MHz, respectively. All four modulator designs maintain the low optical waveguide loss of SiN, are DC coupled with broadband frequency response, operate independent of wavelength, and consume only tens of nW per actuator. Such solutions unlock the potential for further integration with other precision SiN components to realize chip-scale atomic and quantum systems.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Modulation and control of lasers and optical signals is necessary for trapped-ion and cold neutral atom quantum systems. Given the diversity of atomic species, experimental modalities, and architectures, integrated optical modulators designed to operate across the visible to near-infrared spectrum are a key step towards portable, robust, and compact quantum computers, clocks, and sensors. Integrated optical modulators that are wavelength-independent, CMOS-compatible, and capable of maintaining low waveguide losses and a high resonator quality factor, DC-coupled broadband frequency response, and low power consumption, are essential for scalable photonic integration. Yet progress towards these goals has remained limited. Here we demonstrate four types of integrated stress-optic lead zirconate titanate (PZT) silicon nitride modulators: a coil Mach-Zehnder modulator, a coil pure phase modulator, and bus-coupled and add-drop ring resonator modulators, with operation from 493 nm to 780 nm. The coil MZM operates at 532 nm with a V$π$ of 2.8V, a 0.4 MHz 3-dB bandwidth, and an extinction ratio of 21.5dB. The coil phase modulator operates at 493 nm with a V$π$ of 2.8V and low residual amplitude modulation of -34 dB at a 1kHz offset. The bus-coupled ring resonator modulator operates at 493 nm and the add-drop ring resonator modulator operates at 780 nm. The ring-based modulators have an intrinsic quality factor of 3.4 million and 1.9 million, a linear tuning strength of 0.9 GHz/V and 1 GHz/V, and a 3-dB bandwidth of 2.6 MHz and 10 MHz, respectively. All four modulator designs maintain the low optical waveguide loss of SiN, are DC coupled with broadband frequency response, operate independent of wavelength, and consume only tens of nW per actuator. Such solutions unlock the potential for further integration with other precision SiN components to realize chip-scale atomic and quantum systems."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T06:47:25Z",
        "published_parsed": [
            2026,
            1,
            22,
            6,
            47,
            25,
            3,
            22,
            0
        ],
        "arxiv_comment": "10 pages, 6 figures",
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "authors": [
            {
                "name": "Nick Montifiore"
            },
            {
                "name": "Andrei Isichenko"
            },
            {
                "name": "Nitesh Chauhan"
            },
            {
                "name": "Jiawei Wang"
            },
            {
                "name": "Andrew S. Hunter"
            },
            {
                "name": "Mark W. Harrington"
            },
            {
                "name": "Rahul Chawlani"
            },
            {
                "name": "Ryan Q. Rudy"
            },
            {
                "name": "Iain Kierzewski"
            },
            {
                "name": "Michael Pushkarsky"
            },
            {
                "name": "Daniel J. Blumenthal"
            }
        ],
        "author_detail": {
            "name": "Daniel J. Blumenthal"
        },
        "author": "Daniel J. Blumenthal",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "用于量子和原子应用的蓝色至近红外集成 PZT 氮化硅调制器",
        "abstract_cn": "激光和光信号的调制和控制对于俘获离子和冷中性原子量子系统是必要的。考虑到原子种类、实验模式和架构的多样性，设计用于在可见光到近红外光谱范围内运行的集成光调制器是迈向便携式、稳健和紧凑的量子计算机、时钟和传感器的关键一步。集成光调制器与波长无关、与 CMOS 兼容，并且能够保持低波导损耗和高谐振器品质因数、直流耦合宽带频率响应和低功耗，对于可扩展的光子集成至关重要。然而，实现这些目标的进展仍然有限。在这里，我们展示了四种类型的集成应力光学锆钛酸铅 (PZT) 氮化硅调制器：线圈马赫曾德调制器、线圈纯相位调制器以及总线耦合和分插环谐振器调制器，工作波长范围为 493 nm 至 780 nm。线圈 MZM 工作波长为 532 nm，V$π$ 为 2.8V、0.4 MHz 3 dB 带宽和 21.5 dB 消光比。线圈相位调制器的工作波长为 493 nm，V$π$ 为 2.8V，1kHz 偏移时的低残余幅度调制为 -34 dB。总线耦合环形谐振器调制器的工作波长为 493 nm，分插环形谐振器调制器的工作波长为 780 nm。基于环的调制器的固有品质因数分别为 340 万和 190 万，线性调谐强度分别为 0.9 GHz/V 和 1 GHz/V，以及 3 dB 带宽分别为 2.6 MHz 和 10 MHz。所有四种调制器设计都保持了 SiN 的低光波导损耗，采用宽带频率响应进行直流耦合，工作时与波长无关，并且每个执行器的功耗仅为数十 nW。此类解决方案释放了与其他精密 SiN 组件进一步集成的潜力，以实现芯片级原子和量子系统。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15753v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15753v1",
        "title": "Monolithic tantalum pentoxide microrings with intrinsic Q factors exceeding 4X10(6)",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Monolithic tantalum pentoxide microrings with intrinsic Q factors exceeding 4X10(6)"
        },
        "updated": "2026-01-22T08:28:04Z",
        "updated_parsed": [
            2026,
            1,
            22,
            8,
            28,
            4,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15753v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15753v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Tantalum pentoxide (Ta2O5), as a silicon-photonic-compatible material platform, has garnered significant attention for high-performance integrated photonics due to its exceptional properties: a broad transparency window spanning from 0.28 um to 8 um, a moderate refractive index of 2.05 at 1550 nm, and an impressive nonlinear refractive index of 7.2X10^(-19) m^2/W. Despite these advantages, achieving low-loss fabrication of monolithic microrings on the Ta2O5 platform remains challenging due to its inherent hardness and brittleness, which often result in rough sidewalls and significant scattering losses. In this work, we successfully demonstrated monolithic Ta2O5 microring resonators with exceptionally high intrinsic and loaded quality (Q) factors. This was accomplished through the innovative application of photolithography-assisted chemo-mechanical etching (PLACE) technology. By optimizing the coupling region between the microring and the bus waveguide, as well as meticulously controlling surface roughness during fabrication, we achieved near-critical coupling in the resulting microrings. The devices exhibited loaded Q factors of 2.74X10(6) in the telecom band without employing expensive electron-beam lithography, showing an intrinsic Q factor as high as 4.47X10(6) and a low propagation loss of only 0.0732 dB/cm - representing the highest results reported for strongly confined Ta2O5-based microring resonators to date. This work paves the way for the development of advanced photonic devices on the Ta2O5 platform with low manufacturing cost, including low-threshold microlasers, highly sensitive sensors, broad bandwidth supercontinuum sources, and optical frequency combs.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Tantalum pentoxide (Ta2O5), as a silicon-photonic-compatible material platform, has garnered significant attention for high-performance integrated photonics due to its exceptional properties: a broad transparency window spanning from 0.28 um to 8 um, a moderate refractive index of 2.05 at 1550 nm, and an impressive nonlinear refractive index of 7.2X10^(-19) m^2/W. Despite these advantages, achieving low-loss fabrication of monolithic microrings on the Ta2O5 platform remains challenging due to its inherent hardness and brittleness, which often result in rough sidewalls and significant scattering losses. In this work, we successfully demonstrated monolithic Ta2O5 microring resonators with exceptionally high intrinsic and loaded quality (Q) factors. This was accomplished through the innovative application of photolithography-assisted chemo-mechanical etching (PLACE) technology. By optimizing the coupling region between the microring and the bus waveguide, as well as meticulously controlling surface roughness during fabrication, we achieved near-critical coupling in the resulting microrings. The devices exhibited loaded Q factors of 2.74X10(6) in the telecom band without employing expensive electron-beam lithography, showing an intrinsic Q factor as high as 4.47X10(6) and a low propagation loss of only 0.0732 dB/cm - representing the highest results reported for strongly confined Ta2O5-based microring resonators to date. This work paves the way for the development of advanced photonic devices on the Ta2O5 platform with low manufacturing cost, including low-threshold microlasers, highly sensitive sensors, broad bandwidth supercontinuum sources, and optical frequency combs."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T08:28:04Z",
        "published_parsed": [
            2026,
            1,
            22,
            8,
            28,
            4,
            3,
            22,
            0
        ],
        "arxiv_comment": "11 pages, 4 figures, 1 table",
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "authors": [
            {
                "name": "Xinzhi Zheng"
            },
            {
                "name": "Yixuan Yang"
            },
            {
                "name": "Renhong Gao"
            },
            {
                "name": "Lingling Qiao"
            },
            {
                "name": "Jintian Lin"
            },
            {
                "name": "Ya Cheng"
            }
        ],
        "author_detail": {
            "name": "Ya Cheng"
        },
        "author": "Ya Cheng",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "固有 Q 因子超过 4X10(6) 的单片五氧化二钽微环",
        "abstract_cn": "五氧化二钽（Ta2O5）作为一种硅光子兼容材料平台，由于其卓越的性能而在高性能集成光子学领域获得了广泛关注：跨越0.28 um至8 um的宽透明度窗口、1550 nm处2.05的中等折射率以及令人印象深刻的7.2X10^(-19) m^2/W的非线性折射率。尽管有这些优点，但由于其固有的硬度和脆性，在 Ta2O5 平台上实现整体微环的低损耗制造仍然具有挑战性，这通常会导致侧壁粗糙和显着的散射损耗。在这项工作中，我们成功演示了具有极高本征和负载质量 (Q) 因数的单片 Ta2O5 微环谐振器。这是通过光刻辅助化学机械蚀刻（PLACE）技术的创新应用实现的。通过优化微环和总线波导之间的耦合区域，以及在制造过程中精心控制表面粗糙度，我们在所得微环中实现了近临界耦合。该器件在电信频段中表现出 2.74X10(6) 的负载 Q 因数，无需使用昂贵的电子束光刻，显示出高达 4.47X10(6) 的固有 Q 因数和仅 0.0732 dB/cm 的低传播损耗 - 代表了迄今为止强约束 Ta2O5 基微环谐振器报告的最高结果。这项工作为在Ta2O5平台上开发低制造成本的先进光子器件铺平了道路，包括低阈值微型激光器、高灵敏度传感器、宽带超连续谱源和光学频率梳。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15769v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15769v1",
        "title": "Explainable deep-learning detection of microplastic fibers via polarization-resolved holographic microscopy",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Explainable deep-learning detection of microplastic fibers via polarization-resolved holographic microscopy"
        },
        "updated": "2026-01-22T08:59:55Z",
        "updated_parsed": [
            2026,
            1,
            22,
            8,
            59,
            55,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15769v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15769v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Reliable identification of microplastic fibers is crucial for environmental monitoring but remains analytically challenging. We report an explainable deep-learning framework for classifying microplastic and natural microfibers using polarization-resolved digital holographic microscopy. From multiplexed holograms, the complex Jones matrix of each fiber was reconstructed to extract polarization eigen-parameters describing optical anisotropy. Statistical descriptors of nine polarization characteristics formed a 72-dimensional feature vector for a total of 296 fibers spanning six material classes, including polyamide 6, polyethylene terephthalate, polyamide 6.6, polypropylene, cotton and wool. The designed fully connected deep neural network achieved an accuracy of 96.7 % on the validation data, surpassing that of common machine-learning classifiers. Explainable artificial intelligence analysis with Shapley additive explanations identified eigenvalue-ratio quantities as dominant predictors, revealing the physical basis for classification. An additional reduced-feature model with the preserved architecture exploiting only these most significant eigenvalue-based characteristics retained high accuracy (93.3 %), thereby confirming their dominant role while still outperforming common machine-learning classifiers. These results establish polarization-based features as distinctive optical fingerprints and demonstrate the first explainable deep-learning approach for automated microplastic fiber identification.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Reliable identification of microplastic fibers is crucial for environmental monitoring but remains analytically challenging. We report an explainable deep-learning framework for classifying microplastic and natural microfibers using polarization-resolved digital holographic microscopy. From multiplexed holograms, the complex Jones matrix of each fiber was reconstructed to extract polarization eigen-parameters describing optical anisotropy. Statistical descriptors of nine polarization characteristics formed a 72-dimensional feature vector for a total of 296 fibers spanning six material classes, including polyamide 6, polyethylene terephthalate, polyamide 6.6, polypropylene, cotton and wool. The designed fully connected deep neural network achieved an accuracy of 96.7 % on the validation data, surpassing that of common machine-learning classifiers. Explainable artificial intelligence analysis with Shapley additive explanations identified eigenvalue-ratio quantities as dominant predictors, revealing the physical basis for classification. An additional reduced-feature model with the preserved architecture exploiting only these most significant eigenvalue-based characteristics retained high accuracy (93.3 %), thereby confirming their dominant role while still outperforming common machine-learning classifiers. These results establish polarization-based features as distinctive optical fingerprints and demonstrate the first explainable deep-learning approach for automated microplastic fiber identification."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "physics.data-an",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T08:59:55Z",
        "published_parsed": [
            2026,
            1,
            22,
            8,
            59,
            55,
            3,
            22,
            0
        ],
        "arxiv_comment": "14 pages, 5 figures, 1 table",
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "authors": [
            {
                "name": "Jan Appel"
            },
            {
                "name": "Marika Valentino"
            },
            {
                "name": "Lisa Miccio"
            },
            {
                "name": "Vittorio Bianco"
            },
            {
                "name": "Raffaella Mossotti"
            },
            {
                "name": "Giulia Dalla Fontana"
            },
            {
                "name": "Miroslav Ježek"
            },
            {
                "name": "Pietro Ferraro"
            },
            {
                "name": "Jaromír Běhal"
            }
        ],
        "author_detail": {
            "name": "Jaromír Běhal"
        },
        "author": "Jaromír Běhal",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "通过偏振分辨全息显微镜对微塑料纤维进行可解释的深度学习检测",
        "abstract_cn": "可靠地识别微塑料纤维对于环境监测至关重要，但在分析上仍然具有挑战性。我们报告了一种可解释的深度学习框架，用于使用偏振分辨数字全息显微镜对微塑料和天然微纤维进行分类。从多重全息图中，重建每根光纤的复杂琼斯矩阵，以提取描述光学各向异性的偏振本征参数。九个偏振特性的统计描述符形成了跨越六种材料类别的总共 296 根纤维的 72 维特征向量，包括聚酰胺 6、聚对苯二甲酸乙二醇酯、聚酰胺 6.6、聚丙烯、棉和羊毛。设计的全连接深度神经网络在验证数据上实现了 96.7% 的准确率，超过了常见的机器学习分类器。具有沙普利附加解释的可解释人工智能分析将特征值比量确定为主要预测因子，揭示了分类的物理基础。具有保留架构的附加简化特征模型仅利用这些最重要的基于特征值的特征，保留了高精度（93.3％），从而证实了它们的主导作用，同时仍然优于常见的机器学习分类器。这些结果将基于偏振的特征建立为独特的光学指纹，并展示了第一个可解释的自动微塑料纤维识别的深度学习方法。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15776v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15776v1",
        "title": "Coherent Mode Decoupling: A Versatile Framework for High-Throughput Partially Coherent Light Transport",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Coherent Mode Decoupling: A Versatile Framework for High-Throughput Partially Coherent Light Transport"
        },
        "updated": "2026-01-22T09:06:44Z",
        "updated_parsed": [
            2026,
            1,
            22,
            9,
            6,
            44,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15776v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15776v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Accurate and efficient wave-optics simulation of partially coherent light transport systems is critical for the design of advanced optical systems, ranging from computational lithography to diffraction-limited storage rings (DLSR). However, traditional approaches based on Coherent Mode Decomposition suffer from high computational costs due to the propagating massive sets of two-dimensional modes. In this paper, we propose the Coherent Mode Decoupling (CMDC) algorithm, a high-throughput computational framework designed to accelerate these simulations by orders of magnitude without compromising physical fidelity. The method factorizes 2D modes into efficient one-dimensional (1D) components, while crucially incorporating a subspace compression strategy to capture non-separable coupling effects. We demonstrated the generality and robustness of this framework in applications ranging from computational lithography to coherent beamlines of DLSR.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Accurate and efficient wave-optics simulation of partially coherent light transport systems is critical for the design of advanced optical systems, ranging from computational lithography to diffraction-limited storage rings (DLSR). However, traditional approaches based on Coherent Mode Decomposition suffer from high computational costs due to the propagating massive sets of two-dimensional modes. In this paper, we propose the Coherent Mode Decoupling (CMDC) algorithm, a high-throughput computational framework designed to accelerate these simulations by orders of magnitude without compromising physical fidelity. The method factorizes 2D modes into efficient one-dimensional (1D) components, while crucially incorporating a subspace compression strategy to capture non-separable coupling effects. We demonstrated the generality and robustness of this framework in applications ranging from computational lithography to coherent beamlines of DLSR."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T09:06:44Z",
        "published_parsed": [
            2026,
            1,
            22,
            9,
            6,
            44,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "authors": [
            {
                "name": "Han Xu"
            },
            {
                "name": "Ming Li"
            },
            {
                "name": "Shuo Wang"
            },
            {
                "name": "Zhe Ren"
            },
            {
                "name": "Peng Liu"
            },
            {
                "name": "Yi Zhang"
            },
            {
                "name": "Yuhui Dong"
            },
            {
                "name": "Liang Zhou"
            }
        ],
        "author_detail": {
            "name": "Liang Zhou"
        },
        "author": "Liang Zhou",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "相干模式解耦：高吞吐量部分相干光传输的多功能框架",
        "abstract_cn": "部分相干光传输系统的准确高效的波动光学模拟对于先进光学系统（从计算光刻到衍射极限存储环（DLSR））的设计至关重要。然而，基于相干模态分解的传统方法由于传播大量二维模态而导致计算成本很高。在本文中，我们提出了相干模式解耦（CMDC）算法，这是一种高吞吐量计算框架，旨在在不影响物理保真度的情况下将这些模拟加速几个数量级。该方法将 2D 模式分解为有效的一维 (1D) 分量，同时关键地结合子空间压缩策略来捕获不可分离的耦合效应。我们在从计算光刻到 DLSR 相干光束线的应用中证明了该框架的通用性和鲁棒性。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15805v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15805v1",
        "title": "Distance-Independent Atmospheric Refraction Correction for Accurate Retrieval of Fireball Trajectories",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Distance-Independent Atmospheric Refraction Correction for Accurate Retrieval of Fireball Trajectories"
        },
        "updated": "2026-01-22T09:42:39Z",
        "updated_parsed": [
            2026,
            1,
            22,
            9,
            42,
            39,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15805v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15805v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Accurate determination of fireball direction is essential for retrieving trajectories and velocities. Errors in these measurements have significant implications, affecting the calculated pre-impact orbit, influencing mass estimates, and impacting the accuracy of dark flight simulations, where applicable. Here we implement a new atmospheric refraction correction technique that addresses a significant aspect previously overlooked in the field of meteor science. Traditional refraction correction techniques, originally designed for objects positioned at infinite distances, tend to overcompensate when applied to objects within the Earth's atmosphere. To rectify this issue, our study introduces the concept of the atmospheric refraction delta z correction technique, involving the artificial elevation of the observer site height above sea level. We utilize analytically derived formulas for the delta z correction in conjunction with commonly used refraction models, validating these results against a numerical solution that traces light rays through the atmosphere. This ray-tracing model is applied to finely meshed atmospheric layers, yielding precise correction values. We evaluate multiple sources of error in order to quantify the achievable accuracy of the proposed method. Our approach (1) enables the determination of fireball positions with improved astrometric accuracy, (2) removes the explicit dependence on the fireball distance from the observer or its height above Earth's surface within the limits imposed by realistic atmospheric variability, and (3) simplifies meteor data processing by providing a robust framework for analyzing low-elevation fireball observations, for which atmospheric refraction is significant and is automatically corrected by the method. As a result of this work, we provide open, publicly accessible software for calculating the delta z correction.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Accurate determination of fireball direction is essential for retrieving trajectories and velocities. Errors in these measurements have significant implications, affecting the calculated pre-impact orbit, influencing mass estimates, and impacting the accuracy of dark flight simulations, where applicable. Here we implement a new atmospheric refraction correction technique that addresses a significant aspect previously overlooked in the field of meteor science. Traditional refraction correction techniques, originally designed for objects positioned at infinite distances, tend to overcompensate when applied to objects within the Earth's atmosphere. To rectify this issue, our study introduces the concept of the atmospheric refraction delta z correction technique, involving the artificial elevation of the observer site height above sea level. We utilize analytically derived formulas for the delta z correction in conjunction with commonly used refraction models, validating these results against a numerical solution that traces light rays through the atmosphere. This ray-tracing model is applied to finely meshed atmospheric layers, yielding precise correction values. We evaluate multiple sources of error in order to quantify the achievable accuracy of the proposed method. Our approach (1) enables the determination of fireball positions with improved astrometric accuracy, (2) removes the explicit dependence on the fireball distance from the observer or its height above Earth's surface within the limits imposed by realistic atmospheric variability, and (3) simplifies meteor data processing by providing a robust framework for analyzing low-elevation fireball observations, for which atmospheric refraction is significant and is automatically corrected by the method. As a result of this work, we provide open, publicly accessible software for calculating the delta z correction."
        },
        "tags": [
            {
                "term": "astro-ph.IM",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "astro-ph.EP",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "physics.ao-ph",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "physics.geo-ph",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T09:42:39Z",
        "published_parsed": [
            2026,
            1,
            22,
            9,
            42,
            39,
            3,
            22,
            0
        ],
        "arxiv_comment": "Accepted for publication in Monthly Notices of the Royal Astronomical Society",
        "arxiv_primary_category": {
            "term": "astro-ph.IM"
        },
        "authors": [
            {
                "name": "Jaakko Visuri"
            },
            {
                "name": "Maria Gritsevich"
            },
            {
                "name": "Janne Sievinen"
            }
        ],
        "author_detail": {
            "name": "Janne Sievinen"
        },
        "author": "Janne Sievinen",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "用于精确反演火球轨迹的与距离无关的大气折射校正",
        "abstract_cn": "准确确定火球方向对于检索轨迹和速度至关重要。这些测量中的误差具有重大影响，影响计算的撞击前轨道，影响质量估计，并影响暗飞行模拟的准确性（如果适用）。在这里，我们实施了一种新的大气折射校正技术，解决了流星科学领域以前被忽视的一个重要方面。传统的折射校正技术最初是为无限远距离的物体设计的，但当应用于地球大气层内的物体时，往往会过度补偿。为了纠正这个问题，我们的研究引入了大气折射δ z 校正技术的概念，涉及人工抬高观测站海拔高度。我们利用分析得出的公式进行 delta z 校正，并结合常用的折射模型，根据追踪穿过大气的光线的数值解来验证这些结果。该光线追踪模型应用于精细网格化的大气层，产生精确的校正值。我们评估多个误差源，以量化所提出方法可实现的精度。我们的方法（1）能够以更高的天体测量精度确定火球位置，（2）在实际大气变化所施加的限制内消除对火球与观察者的距离或火球在地球表面以上高度的明确依赖，以及（3）通过提供用于分析低海拔火球观测的强大框架来简化流星数据处理，对于低海拔火球观测，大气折射很重要，并且可以通过该方法自动校正。这项工作的结果是，我们提供了开放的、可公开访问的软件来计算 delta z 校正。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15817v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15817v1",
        "title": "Photorefraction Management in Lithium Niobate Waveguides: High-Temperature vs. Cryogenic Solutions",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Photorefraction Management in Lithium Niobate Waveguides: High-Temperature vs. Cryogenic Solutions"
        },
        "updated": "2026-01-22T10:04:46Z",
        "updated_parsed": [
            2026,
            1,
            22,
            10,
            4,
            46,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15817v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15817v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Lithium niobate sees widespread use in nonlinear and quantum optical devices, such as for sum- and difference-frequency generation or spontaneous parametric down-conversion. In lithium niobate waveguides, nonlinear optical processes are often limited by the so-called photorefractive effect, which limits the maximum input or output powers and impacts the nonlinear spectral response. Therefore, strategies for the management of photorefractive damage are a key consideration in device design. Usually, the photorefractive damage threshold, i.e. the maximal permissible operating power, can be increased by high temperature operation of devices. This approach, however, is not applicable in cryogenic environments, which may be required for specialized applications. To better understand the impact of photorefraction in nonlinear optical applications, we study the impact of photorefraction on the phase-matching spectra of two nonlinear-optical sum-frequency generation experiments at 1) high temperatures and 2) cryogenic temperatures. Furthermore, we present an approach to reduce the impact of photorefraction which is compatible with cryogenic operation. This comprises an auxiliary light source, propagating in the same waveguide, which is used to restore phase-matching spectra impacted by photorefraction, as well as reduce pyroelectric effects. Our work provides an alternative route to photorefraction management applicable to cryogenic environments, as well as in situations with tight energy budgets like space applications.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Lithium niobate sees widespread use in nonlinear and quantum optical devices, such as for sum- and difference-frequency generation or spontaneous parametric down-conversion. In lithium niobate waveguides, nonlinear optical processes are often limited by the so-called photorefractive effect, which limits the maximum input or output powers and impacts the nonlinear spectral response. Therefore, strategies for the management of photorefractive damage are a key consideration in device design. Usually, the photorefractive damage threshold, i.e. the maximal permissible operating power, can be increased by high temperature operation of devices. This approach, however, is not applicable in cryogenic environments, which may be required for specialized applications. To better understand the impact of photorefraction in nonlinear optical applications, we study the impact of photorefraction on the phase-matching spectra of two nonlinear-optical sum-frequency generation experiments at 1) high temperatures and 2) cryogenic temperatures. Furthermore, we present an approach to reduce the impact of photorefraction which is compatible with cryogenic operation. This comprises an auxiliary light source, propagating in the same waveguide, which is used to restore phase-matching spectra impacted by photorefraction, as well as reduce pyroelectric effects. Our work provides an alternative route to photorefraction management applicable to cryogenic environments, as well as in situations with tight energy budgets like space applications."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T10:04:46Z",
        "published_parsed": [
            2026,
            1,
            22,
            10,
            4,
            46,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "authors": [
            {
                "name": "Nina A. Lange"
            },
            {
                "name": "René Pollmann"
            },
            {
                "name": "Michael Rüsing"
            },
            {
                "name": "Michael Stefszky"
            },
            {
                "name": "Maximilian Protte"
            },
            {
                "name": "Raimund Ricken"
            },
            {
                "name": "Laura Padberg"
            },
            {
                "name": "Christof Eigner"
            },
            {
                "name": "Tim J. Bartley"
            },
            {
                "name": "Christine Silberhorn"
            }
        ],
        "author_detail": {
            "name": "Christine Silberhorn"
        },
        "author": "Christine Silberhorn",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "铌酸锂波导中的光折射管理：高温与低温解决方案",
        "abstract_cn": "铌酸锂广泛应用于非线性和量子光学器件，例如和频和差频生成或自发参量下变频。在铌酸锂波导中，非线性光学过程通常受到所谓的光折变效应的限制，这限制了最大输入或输出功率并影响非线性光谱响应。因此，光折变损伤的管理策略是设备设计中的关键考虑因素。通常，光折变损伤阈值，即最大允许工作功率，可以通过器件的高温工作来提高。然而，这种方法不适用于低温环境，而特殊应用可能需要低温环境。为了更好地了解光折射在非线性光学应用中的影响，我们研究了光折射对 1) 高温和 2) 低温下两个非线性光学和频生成实验的相位匹配光谱的影响。此外，我们提出了一种减少光折射影响的方法，该方法与低温操作兼容。这包括在同一波导中传播的辅助光源，用于恢复受光折射影响的相位匹配光谱，并减少热释电效应。我们的工作提供了一种适用于低温环境以及能源预算紧张的情况（如太空应用）的光折射管理的替代途径。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15898v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15898v1",
        "title": "Size-dependent Dielectric Permittivity of Perovskite Nanocrystals",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Size-dependent Dielectric Permittivity of Perovskite Nanocrystals"
        },
        "updated": "2026-01-22T12:25:07Z",
        "updated_parsed": [
            2026,
            1,
            22,
            12,
            25,
            7,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15898v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15898v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Perovskite nanocrystals (PNCs) are promising building blocks for quantum photonic devices. Optical properties of PNCs can be enhanced by integration with optical cavities or nanoantennas. Designing such structures requires accurate size dependent dielectric permittivity of PNCs. However, current reports provide primarily ensemble averaged values with limited access to the intrinsic response of individual PNCs. Here we suggest a methodology to reconstruct the size dependent complex dielectric permittivity of CsPbBr3 PNCs from the measured absorbance spectrum of colloidal solution. The permittivity of PNCs is modeled as a sum of Voigt profile oscillators, with the size dependent transition energies governed by the exciton effective mass. Using a transmission electron microscopy derived size distribution of the PNCs, the solution permittivity is obtained via Maxwell Garnett effective medium approximation. This permittivity is used in a transfer matrix method to simulate and fit the absorbance spectrum, from which the permittivity of PNCs is reconstructed. The extracted spectral linewidth from the imaginary part of the permittivity (78.4 meV) is consistent with single nanocrystal emission linewidths at room temperature. Finite element simulations show enhanced absorption cross section of a single PNC coupled to a nanoantenna, demonstrating applicability of the extracted permittivity. More generally, these findings provide a route to extract intrinsic permittivity of individual nanocrystals from absorbance measurements of their ensembles.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Perovskite nanocrystals (PNCs) are promising building blocks for quantum photonic devices. Optical properties of PNCs can be enhanced by integration with optical cavities or nanoantennas. Designing such structures requires accurate size dependent dielectric permittivity of PNCs. However, current reports provide primarily ensemble averaged values with limited access to the intrinsic response of individual PNCs. Here we suggest a methodology to reconstruct the size dependent complex dielectric permittivity of CsPbBr3 PNCs from the measured absorbance spectrum of colloidal solution. The permittivity of PNCs is modeled as a sum of Voigt profile oscillators, with the size dependent transition energies governed by the exciton effective mass. Using a transmission electron microscopy derived size distribution of the PNCs, the solution permittivity is obtained via Maxwell Garnett effective medium approximation. This permittivity is used in a transfer matrix method to simulate and fit the absorbance spectrum, from which the permittivity of PNCs is reconstructed. The extracted spectral linewidth from the imaginary part of the permittivity (78.4 meV) is consistent with single nanocrystal emission linewidths at room temperature. Finite element simulations show enhanced absorption cross section of a single PNC coupled to a nanoantenna, demonstrating applicability of the extracted permittivity. More generally, these findings provide a route to extract intrinsic permittivity of individual nanocrystals from absorbance measurements of their ensembles."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cond-mat.mtrl-sci",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T12:25:07Z",
        "published_parsed": [
            2026,
            1,
            22,
            12,
            25,
            7,
            3,
            22,
            0
        ],
        "arxiv_comment": "29 pages, 4 figures",
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "authors": [
            {
                "name": "Jehyeok Ryu"
            },
            {
                "name": "Victor Krivenkov"
            },
            {
                "name": "Vitaly Goryashko"
            },
            {
                "name": "Yury Rakovich"
            },
            {
                "name": "Alexey Y. Nikitin"
            }
        ],
        "author_detail": {
            "name": "Alexey Y. Nikitin"
        },
        "author": "Alexey Y. Nikitin",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "钙钛矿纳米晶体的尺寸依赖性介电常数",
        "abstract_cn": "钙钛矿纳米晶体（PNC）是有前途的量子光子器件的构建模块。 PNC 的光学特性可以通过与光腔或纳米天线集成来增强。设计此类结构需要精确的 PNC 尺寸相关介电常数。然而，当前的报告主要提供整体平均值，对单个 PNC 的内在响应的访问有限。在这里，我们提出了一种根据测量的胶体溶液吸收光谱重建 CsPbBr3 PNC 的尺寸依赖性复介电常数的方法。 PNC 的介电常数被建模为 Voigt 剖面振荡器的总和，其尺寸相关的跃迁能量由激子有效质量控制。使用透射电子显微镜导出的 PNC 尺寸分布，通过 Maxwell Garnett 有效介质近似获得溶液介电常数。该介电常数用于传输矩阵方法来模拟和拟合吸收光谱，从中重建 PNC 的介电常数。从介电常数虚部（78.4 meV）提取的光谱线宽与室温下单纳米晶发射线宽一致。有限元模拟显示耦合到纳米天线的单个 PNC 的吸收截面增强，证明了提取的介电常数的适用性。更一般地说，这些发现提供了一种从单个纳米晶体整体的吸光度测量中提取其固有介电常数的途径。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15925v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15925v1",
        "title": "Quantitative absorption tomography",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Quantitative absorption tomography"
        },
        "updated": "2026-01-22T12:59:28Z",
        "updated_parsed": [
            2026,
            1,
            22,
            12,
            59,
            28,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15925v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15925v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Brightfield microscopy is central to wide range of biology, engineering, and histopathology; but is inherently limited to two-dimensional qualitative imaging, systematically investigating three-dimensional (3D) volumetric architecture. Here we introduce quantitative absorption tomography (QAT), a computational approach that quantitatively reconstructs high-resolution volumetric absorption coefficient distributions from brightfield focal stacks. By modeling absorption image formation in logarithmic intensity space and applying deconvolution with an absorption optical transfer function, QAT enables quantitative, spectrally resolved 3D absorption imaging without interferometry, sample rotation, or specialized hardware. We validate QAT using spectrally selective phantoms and demonstrate absorption-specific contrast complementary to refractive index tomography in living melanocytes and intact plant tissue. QAT further scales to millimeter-scale volumes of H&E-stained human tissue, revealing 3D histological microarchitecture without serial sectioning. This approach extends brightfield microscopy toward practical 3D histopathology.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Brightfield microscopy is central to wide range of biology, engineering, and histopathology; but is inherently limited to two-dimensional qualitative imaging, systematically investigating three-dimensional (3D) volumetric architecture. Here we introduce quantitative absorption tomography (QAT), a computational approach that quantitatively reconstructs high-resolution volumetric absorption coefficient distributions from brightfield focal stacks. By modeling absorption image formation in logarithmic intensity space and applying deconvolution with an absorption optical transfer function, QAT enables quantitative, spectrally resolved 3D absorption imaging without interferometry, sample rotation, or specialized hardware. We validate QAT using spectrally selective phantoms and demonstrate absorption-specific contrast complementary to refractive index tomography in living melanocytes and intact plant tissue. QAT further scales to millimeter-scale volumes of H&E-stained human tissue, revealing 3D histological microarchitecture without serial sectioning. This approach extends brightfield microscopy toward practical 3D histopathology."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T12:59:28Z",
        "published_parsed": [
            2026,
            1,
            22,
            12,
            59,
            28,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "authors": [
            {
                "name": "Yoonjae Chung"
            },
            {
                "name": "Sehyun Lee"
            },
            {
                "name": "Herve Hugonnet"
            },
            {
                "name": "Chulmin Oh"
            },
            {
                "name": "Weisun Park"
            },
            {
                "name": "Yeon Wook Kim"
            },
            {
                "name": "Seung-Mo Hong"
            },
            {
                "name": "YongKeun Park"
            }
        ],
        "author_detail": {
            "name": "YongKeun Park"
        },
        "author": "YongKeun Park",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "定量吸收断层扫描",
        "abstract_cn": "明场显微镜是广泛的生物学、工程学和组织病理学的核心。但本质上仅限于二维定性成像，系统地研究三维 (3D) 体积结构。在这里，我们介绍定量吸收断层扫描（QAT），这是一种从明场焦点堆栈定量重建高分辨率体积吸收系数分布的计算方法。通过对对数强度空间中的吸收图像形成进行建模，并应用吸收光学传递函数的反卷积，QAT 无需干涉测量、样品旋转或专用硬件即可实现定量、光谱解析的 3D 吸收成像。我们使用光谱选择性模型验证 QAT，并在活体黑素细胞和完整植物组织中证明与折射率断层扫描互补的吸收特异性对比度。 QAT 进一步将 H&E 染色的人体组织缩小到毫米级体积，无需连续切片即可揭示 3D 组织学微结构。这种方法将明场显微镜扩展到实用的 3D 组织病理学。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15947v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15947v1",
        "title": "Multimodal Imaging System Combining Hyperspectral and Laser Speckle Imaging for In Vivo Hemodynamic and Metabolic Monitoring",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Multimodal Imaging System Combining Hyperspectral and Laser Speckle Imaging for In Vivo Hemodynamic and Metabolic Monitoring"
        },
        "updated": "2026-01-22T13:32:34Z",
        "updated_parsed": [
            2026,
            1,
            22,
            13,
            32,
            34,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15947v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15947v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "We present the development and validation of a novel multimodal optical imaging platform that integrates hyperspectral imaging (HSI) and laser speckle contrast imaging (LSCI) to enable real-time, non-invasive mapping of tissue oxygenation, perfusion and metabolism, via blood flowmetry and targeting of oxy- (HbO2), deoxyhemoglobin (HHb), as well as oxidized cytochrome-c-oxidase (oxCCO). The system architecture features a single high-speed camera and dual optical path, with synchronized alternating illumination: a filtered, supercontinuum laser for HSI and a He-Ne laser for LSCI. The system performances were evaluated through in vivo experiments on rat spinal cord under normoxic and hypoxic conditions, revealing coherent physiological changes in hemodynamics, metabolism and relative blood flow index (rBFI). These results demonstrate the potential of the platform for functional tissue imaging and quantitative dynamic monitoring of both oxygen delivery and consumption.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "We present the development and validation of a novel multimodal optical imaging platform that integrates hyperspectral imaging (HSI) and laser speckle contrast imaging (LSCI) to enable real-time, non-invasive mapping of tissue oxygenation, perfusion and metabolism, via blood flowmetry and targeting of oxy- (HbO2), deoxyhemoglobin (HHb), as well as oxidized cytochrome-c-oxidase (oxCCO). The system architecture features a single high-speed camera and dual optical path, with synchronized alternating illumination: a filtered, supercontinuum laser for HSI and a He-Ne laser for LSCI. The system performances were evaluated through in vivo experiments on rat spinal cord under normoxic and hypoxic conditions, revealing coherent physiological changes in hemodynamics, metabolism and relative blood flow index (rBFI). These results demonstrate the potential of the platform for functional tissue imaging and quantitative dynamic monitoring of both oxygen delivery and consumption."
        },
        "tags": [
            {
                "term": "physics.med-ph",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "physics.app-ph",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "physics.bio-ph",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "physics.ins-det",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T13:32:34Z",
        "published_parsed": [
            2026,
            1,
            22,
            13,
            32,
            34,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "physics.med-ph"
        },
        "authors": [
            {
                "name": "Junda Wang"
            },
            {
                "name": "Luca Giannoni"
            },
            {
                "name": "Ayse Gertrude Yenicelik"
            },
            {
                "name": "Eleni Giama"
            },
            {
                "name": "Frederic Lange"
            },
            {
                "name": "Kenneth J. Smith"
            },
            {
                "name": "Ilias Tachtsidis"
            }
        ],
        "author_detail": {
            "name": "Ilias Tachtsidis"
        },
        "author": "Ilias Tachtsidis",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "结合高光谱和激光散斑成像的多模态成像系统，用于体内血流动力学和代谢监测",
        "abstract_cn": "我们展示了一种新型多模态光学成像平台的开发和验证，该平台集成了高光谱成像（HSI）和激光散斑对比成像（LSCI），通过血流量测定和靶向氧合（HbO2）、脱氧血红蛋白（HHb）以及氧化细胞色素-c-氧化酶（oxCCO），实现组织氧合、灌注和代谢的实时、非侵入性绘图。该系统架构具有单个高速相机和双光路，具有同步交替照明：用于 HSI 的过滤超连续谱激光器和用于 LSCI 的 He-Ne 激光器。通过在常氧和低氧条件下对大鼠脊髓进行体内实验来评估系统性能，揭示血流动力学、代谢和相对血流指数（rBFI）的连贯生理变化。这些结果证明了该平台在功能组织成像和氧气输送和消耗的定量动态监测方面的潜力。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15971v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15971v1",
        "title": "Reaching the intrinsic performance limits of superconducting strip photon detectors up to 0.1 mm wide",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Reaching the intrinsic performance limits of superconducting strip photon detectors up to 0.1 mm wide"
        },
        "updated": "2026-01-22T13:51:49Z",
        "updated_parsed": [
            2026,
            1,
            22,
            13,
            51,
            49,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15971v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15971v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Superconducting nanowire single-photon detectors (SNSPDs) have emerged as the highest performing photon-counting detectors, making them a critical technology in quantum photonics and photon-starved optical sensing. However, the performance of SNSPDs is limited not by the intrinsic properties of the superconducting film, but by edge-induced current crowding. Despite extensive materials optimization and increasingly demanding fabrication strategies aimed at mitigating this edge-limited behavior, the device edges continue to limit the maximum device operating current, thereby degrading key performance metrics. Here, we demonstrate for the first time in situ tuning of a detector from an edge-limited to a bulk-limited regime, allowing the device to reach its intrinsic performance limit. Our approach is based on current-biased superconducting \"rails\" placed on either side of the detector to suppress current crowding at the edges. We show that activation of the rails reduces the dark count rate by nine orders of magnitude and extends the photon detection plateau at 1550 nm by more than 40%. These results are demonstrated on detectors up to 0.1 mm wide, establishing an entirely new class of ultra-wide strip detectors that we call superconducting strip photon detectors (SSPD). Moreover, the ability to suppress edge current crowding using the rails provides a pathway toward SSPDs with strip widths extending into the mm-scale. Such devices will enable large-area, high efficiency SSPD arrays with infrared sensitivity and open new opportunities in applications ranging from biomedical imaging to deep space optical communication.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Superconducting nanowire single-photon detectors (SNSPDs) have emerged as the highest performing photon-counting detectors, making them a critical technology in quantum photonics and photon-starved optical sensing. However, the performance of SNSPDs is limited not by the intrinsic properties of the superconducting film, but by edge-induced current crowding. Despite extensive materials optimization and increasingly demanding fabrication strategies aimed at mitigating this edge-limited behavior, the device edges continue to limit the maximum device operating current, thereby degrading key performance metrics. Here, we demonstrate for the first time in situ tuning of a detector from an edge-limited to a bulk-limited regime, allowing the device to reach its intrinsic performance limit. Our approach is based on current-biased superconducting \"rails\" placed on either side of the detector to suppress current crowding at the edges. We show that activation of the rails reduces the dark count rate by nine orders of magnitude and extends the photon detection plateau at 1550 nm by more than 40%. These results are demonstrated on detectors up to 0.1 mm wide, establishing an entirely new class of ultra-wide strip detectors that we call superconducting strip photon detectors (SSPD). Moreover, the ability to suppress edge current crowding using the rails provides a pathway toward SSPDs with strip widths extending into the mm-scale. Such devices will enable large-area, high efficiency SSPD arrays with infrared sensitivity and open new opportunities in applications ranging from biomedical imaging to deep space optical communication."
        },
        "tags": [
            {
                "term": "cond-mat.supr-con",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "physics.app-ph",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "physics.ins-det",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "quant-ph",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T13:51:49Z",
        "published_parsed": [
            2026,
            1,
            22,
            13,
            51,
            49,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cond-mat.supr-con"
        },
        "authors": [
            {
                "name": "Kristen M. Parzuchowski"
            },
            {
                "name": "Eli Mueller"
            },
            {
                "name": "Bakhrom G. Oripov"
            },
            {
                "name": "Benedikt Hampel"
            },
            {
                "name": "Ravin A. Chowdhury"
            },
            {
                "name": "Sahil R. Patel"
            },
            {
                "name": "Daniel Kuznesof"
            },
            {
                "name": "Emma K. Batson"
            },
            {
                "name": "Ryan Morgenstern"
            },
            {
                "name": "Robert H. Hadfield"
            },
            {
                "name": "Varun B. Verma"
            },
            {
                "name": "Matthew D. Shaw"
            },
            {
                "name": "Jason P. Allmaras"
            },
            {
                "name": "Martin J. Stevens"
            },
            {
                "name": "Alex Gurevich"
            },
            {
                "name": "Adam N. McCaughan"
            }
        ],
        "author_detail": {
            "name": "Adam N. McCaughan"
        },
        "author": "Adam N. McCaughan",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "达到宽度达 0.1 毫米的超导带状光子探测器的固有性能极限",
        "abstract_cn": "超导纳米线单光子探测器（SNSPD）已成为性能最高的光子计数探测器，使其成为量子光子学和光子匮乏光学传感领域的关键技术。然而，SNSPD 的性能不仅受到超导薄膜固有特性的限制，还受到边缘感应电流拥挤的限制。尽管为了减轻这种边缘限制行为而进行了广泛的材料优化和日益严格的制造策略，但器件边缘仍然限制了最大器件工作电流，从而降低了关键性能指标。在这里，我们首次演示了探测器从边缘限制到体限制状态的原位调谐，使设备能够达到其固有的性能极限。我们的方法基于放置在探测器两侧的电流偏置超导“轨道”，以抑制边缘的电流拥挤。我们表明，轨道的激活将暗计数率降低了 9 个数量级，并将 1550 nm 处的光子检测平台延长了 40% 以上。这些结果在宽度达 0.1 毫米的探测器上得到了证明，建立了一种全新的超宽带状探测器，我们称之为超导带状光子探测器 (SSPD)。此外，使用导轨抑制边缘电流拥挤的能力为带宽度延伸至毫米级的 SSPD 提供了一条途径。此类器件将实现具有红外灵敏度的大面积、高效 SSPD 阵列，并为从生物医学成像到深空光通信等应用领域开辟新的机遇。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15981v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15981v1",
        "title": "Mid-infrared high-sensitive cavity-free in-situ CO gas sensing based on up-conversion detection",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Mid-infrared high-sensitive cavity-free in-situ CO gas sensing based on up-conversion detection"
        },
        "updated": "2026-01-22T14:03:56Z",
        "updated_parsed": [
            2026,
            1,
            22,
            14,
            3,
            56,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15981v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15981v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Carbon monoxide (CO) is a significant indicator gas with considerable application value in atmospheric monitoring, industrial production and medical diagnosis. Its fundamental vibrational band locates around 4.6 $\\upmu$m and has larger absorption line strength than that of overtone band, which is more suitable for the precise identification and concentration detection of CO. In this paper, the up-conversion detection is employed to convert the mid-infrared absorption signal obtained by TDLAS to the visible light band, then a silicon-based detector is utilized for detection. By which, we can achieve the highest sensitivity of 79.6 ppb under the condition of cavity-free in-situ with an absorption range length of only 0.14 m. Furthermore, the single-photon level real-time detection of CO concentration after the diffuse reflection is realized by using SPAD. This work demonstrates the merits of the up-conversion detection in terms of its functionality at room temperature and capacity for sensitivity detection. Furthermore, it presents a design and optimization methodology that has the potential to underpin the advancement of the method towards more practical applications, like industrial process monitoring, medical diagnosis and so on.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Carbon monoxide (CO) is a significant indicator gas with considerable application value in atmospheric monitoring, industrial production and medical diagnosis. Its fundamental vibrational band locates around 4.6 $\\upmu$m and has larger absorption line strength than that of overtone band, which is more suitable for the precise identification and concentration detection of CO. In this paper, the up-conversion detection is employed to convert the mid-infrared absorption signal obtained by TDLAS to the visible light band, then a silicon-based detector is utilized for detection. By which, we can achieve the highest sensitivity of 79.6 ppb under the condition of cavity-free in-situ with an absorption range length of only 0.14 m. Furthermore, the single-photon level real-time detection of CO concentration after the diffuse reflection is realized by using SPAD. This work demonstrates the merits of the up-conversion detection in terms of its functionality at room temperature and capacity for sensitivity detection. Furthermore, it presents a design and optimization methodology that has the potential to underpin the advancement of the method towards more practical applications, like industrial process monitoring, medical diagnosis and so on."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "physics.ins-det",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T14:03:56Z",
        "published_parsed": [
            2026,
            1,
            22,
            14,
            3,
            56,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "authors": [
            {
                "name": "Zhao-Qi-Zhi Han"
            },
            {
                "name": "He Zhang"
            },
            {
                "name": "Fan Yang"
            },
            {
                "name": "Xiao-Hua Wang"
            },
            {
                "name": "Bo-Wen Liu"
            },
            {
                "name": "Jin-Peng Li"
            },
            {
                "name": "Zheng-He Zhou"
            },
            {
                "name": "Yin-Hai Li"
            },
            {
                "name": "Yan Li"
            },
            {
                "name": "Zhi-Yuan Zhou"
            },
            {
                "name": "Bao-Sen Shi"
            }
        ],
        "author_detail": {
            "name": "Bao-Sen Shi"
        },
        "author": "Bao-Sen Shi",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "基于上转换检测的中红外高灵敏无腔原位CO气体传感",
        "abstract_cn": "一氧化碳（CO）是一种重要的指示气体，在大气监测、工业生产和医疗诊断等方面具有相当大的应用价值。其基振谱带位于4.6 $\\upmu$m附近，比泛谱带具有更大的吸收线强度，更适合CO的精确识别和浓度检测。本文采用上转换检测将TDLAS获得的中红外吸收信号转换到可见光波段，然后利用硅基探测器进行检测。由此，我们可以在无空腔原位条件下实现最高79.6 ppb的灵敏度，吸收范围长度仅为0.14 m。此外，利用SPAD实现了漫反射后CO浓度的单光子级实时检测。这项工作证明了上转换检测在室温下的功能和灵敏度检测能力方面的优点。此外，它还提出了一种设计和优化方法，有可能支持该方法向更实际的应用发展，例如工业过程监控、医疗诊断等。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15989v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15989v1",
        "title": "On-chip Multimode Opto-electronic Neural Network",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "On-chip Multimode Opto-electronic Neural Network"
        },
        "updated": "2026-01-22T14:12:39Z",
        "updated_parsed": [
            2026,
            1,
            22,
            14,
            12,
            39,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15989v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15989v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Opto-electronic computing combines the complementary strengths of photonics and electronics to deliver ultrahigh computational throughput with high energy efficiency. However, its practical deployment for real-world applications has been limited by architectures that rely on delicate wavelength management or phase-sensitive coherent detection. Here, we demonstrate the first multimode opto-electronic neural network (MOENN) on a silicon-on-insulator platform. By utilizing orthogonal waveguide eigenmodes as independent information carriers, our architecture achieves robust single-wavelength computation that is inherently immune to spectral crosstalk and phase noise. The fabricated MOENN chip monolithically integrates all functional components, including input encoders, programmable mode-division fan-in/-out units, and most importantly, the nonlinear multimode activation functions. We report the system's versatility through in-situ training via a genetic algorithm, successfully resolving the nonlinear decision boundaries of a two-class dataset and achieving 92.1% accuracy on the Iris classification benchmark. Furthermore, we reconfigure the MOENN into a one-dimensional convolutional neural network, attaining an accuracy of 90.7% on the electrocardiogram-based emotion recognition task. This work establishes a new opto-electronic computing paradigm of simple control and excellent robustness, providing a compelling path toward scalable, deployable photonic intelligence.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Opto-electronic computing combines the complementary strengths of photonics and electronics to deliver ultrahigh computational throughput with high energy efficiency. However, its practical deployment for real-world applications has been limited by architectures that rely on delicate wavelength management or phase-sensitive coherent detection. Here, we demonstrate the first multimode opto-electronic neural network (MOENN) on a silicon-on-insulator platform. By utilizing orthogonal waveguide eigenmodes as independent information carriers, our architecture achieves robust single-wavelength computation that is inherently immune to spectral crosstalk and phase noise. The fabricated MOENN chip monolithically integrates all functional components, including input encoders, programmable mode-division fan-in/-out units, and most importantly, the nonlinear multimode activation functions. We report the system's versatility through in-situ training via a genetic algorithm, successfully resolving the nonlinear decision boundaries of a two-class dataset and achieving 92.1% accuracy on the Iris classification benchmark. Furthermore, we reconfigure the MOENN into a one-dimensional convolutional neural network, attaining an accuracy of 90.7% on the electrocardiogram-based emotion recognition task. This work establishes a new opto-electronic computing paradigm of simple control and excellent robustness, providing a compelling path toward scalable, deployable photonic intelligence."
        },
        "tags": [
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T14:12:39Z",
        "published_parsed": [
            2026,
            1,
            22,
            14,
            12,
            39,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "physics.optics"
        },
        "authors": [
            {
                "name": "Jinlong Xiang"
            },
            {
                "name": "Youlve Chen"
            },
            {
                "name": "Chaojun Xu"
            },
            {
                "name": "Yuchen Yin"
            },
            {
                "name": "Yufeng Zhang"
            },
            {
                "name": "Yikai Su"
            },
            {
                "name": "Zhipei Sun"
            },
            {
                "name": "Xuhan Guo"
            }
        ],
        "author_detail": {
            "name": "Xuhan Guo"
        },
        "author": "Xuhan Guo",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "片上多模光电神经网络",
        "abstract_cn": "光电计算结合了光子学和电子学的互补优势，可提供超高计算吞吐量和高能效。然而，其在实际应用中的实际部署受到依赖于精密波长管理或相敏相干检测的架构的限制。在这里，我们展示了绝缘体上硅平台上的第一个多模光电神经网络（MOENN）。通过利用正交波导本征模作为独立的信息载体，我们的架构实现了鲁棒的单波长计算，该计算本质上不受光谱串扰和相位噪声的影响。所制造的 MOENN 芯片单片集成了所有功能组件，包括输入编码器、可编程模分扇入/出单元，以及最重要的非线性多模激活功能。我们通过遗传算法进行原位训练来报告系统的多功能性，成功解决了两类数据集的非线性决策边界，并在鸢尾花分类基准上实现了 92.1% 的准确率。此外，我们将 MOENN 重新配置为一维卷积神经网络，在基于心电图的情绪识别任务上达到 90.7% 的准确率。这项工作建立了一种控制简单、鲁棒性优异的新型光电计算范式，为实现可扩展、可部署的光子智能提供了一条引人注目的道路。"
    },
    {
        "id": "http://arxiv.org/abs/2601.16005v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.16005v1",
        "title": "Critical speed of a binary superfuid of light",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Critical speed of a binary superfuid of light"
        },
        "updated": "2026-01-22T14:30:17Z",
        "updated_parsed": [
            2026,
            1,
            22,
            14,
            30,
            17,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.16005v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.16005v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "We theoretically study the critical speed for superfluid flow of a two-dimensional (2D) binary superfluid of light past a polarization-sensitive optical obstacle. This speed corresponds to the maximum mean flow velocity below which dissipation is absent. In the weak-obstacle regime, linear-response theory shows that the critical speed is set by Landau's criterion applied to the density and spin Bogoliubov modes, whose relative ordering can be inverted due to saturation of the optical nonlinearity. For obstacles of arbitrary strength and large spatial extent, we determine the critical speed from the conditions for strong ellipticity of the stationary hydrodynamic equations within the hydraulic and incompressible approximations. Numerical simulations in this regime reveal that the breakdown of superfluidity is initiated by the nucleation of vortex-antivortex pairs for an impenetrable obstacle, and of Jones-Roberts soliton-type structures for a penetrable obstacle. Beyond superfluids of light, our results provide a general framework for the critical speed of 2D binary nonlinear Schrödinger superflows, including Bose-Bose quantum mixtures.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "We theoretically study the critical speed for superfluid flow of a two-dimensional (2D) binary superfluid of light past a polarization-sensitive optical obstacle. This speed corresponds to the maximum mean flow velocity below which dissipation is absent. In the weak-obstacle regime, linear-response theory shows that the critical speed is set by Landau's criterion applied to the density and spin Bogoliubov modes, whose relative ordering can be inverted due to saturation of the optical nonlinearity. For obstacles of arbitrary strength and large spatial extent, we determine the critical speed from the conditions for strong ellipticity of the stationary hydrodynamic equations within the hydraulic and incompressible approximations. Numerical simulations in this regime reveal that the breakdown of superfluidity is initiated by the nucleation of vortex-antivortex pairs for an impenetrable obstacle, and of Jones-Roberts soliton-type structures for a penetrable obstacle. Beyond superfluids of light, our results provide a general framework for the critical speed of 2D binary nonlinear Schrödinger superflows, including Bose-Bose quantum mixtures."
        },
        "tags": [
            {
                "term": "cond-mat.quant-gas",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "nlin.PS",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "physics.optics",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T14:30:17Z",
        "published_parsed": [
            2026,
            1,
            22,
            14,
            30,
            17,
            3,
            22,
            0
        ],
        "arxiv_comment": "Submitted to the Topical Collection \"Paraxial Fluids of Light\" in Eur. Phys. J. D",
        "arxiv_primary_category": {
            "term": "cond-mat.quant-gas"
        },
        "authors": [
            {
                "name": "Pierre-Élie Larré"
            },
            {
                "name": "Claire Michel"
            },
            {
                "name": "Nicolas Cherroret"
            }
        ],
        "author_detail": {
            "name": "Nicolas Cherroret"
        },
        "author": "Nicolas Cherroret",
        "journal": "arXiv: Physics - Optics",
        "title_cn": "二元光超流体的临界速度",
        "abstract_cn": "我们从理论上研究了二维（2D）二元超流体光通过偏振敏感光学障碍物的超流体流动的临界速度。该速度对应于最大平均流速，低于该速度则不存在耗散。在弱障碍物状态下，线性响应理论表明，临界速度是由应用于密度和自旋 Bogoliubov 模式的朗道准则设定的，由于光学非线性的饱和，其相对顺序可以反转。对于任意强度和大空间范围的障碍物，我们根据水力和不可压缩近似内的稳态流体动力学方程的强椭圆性条件来确定临界速度。该状态下的数值模拟表明，对于不可穿透的障碍物，超流性的破坏是由涡旋-反涡对的成核引发的，对于可穿透的障碍物，是由琼斯-罗伯茨孤子型结构的成核引发的。除了光的超流体之外，我们的结果还为二维二元非线性薛定谔超流（包括玻色-玻色量子混合物）的临界速度提供了通用框架。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15368v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15368v1",
        "title": "Aligned Stable Inpainting: Mitigating Unwanted Object Insertion and Preserving Color Consistency",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Aligned Stable Inpainting: Mitigating Unwanted Object Insertion and Preserving Color Consistency"
        },
        "updated": "2026-01-21T17:57:18Z",
        "updated_parsed": [
            2026,
            1,
            21,
            17,
            57,
            18,
            2,
            21,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15368v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15368v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Generative image inpainting can produce realistic, high-fidelity results even with large, irregular masks. However, existing methods still face key issues that make inpainted images look unnatural. In this paper, we identify two main problems: (1) Unwanted object insertion: generative models may hallucinate arbitrary objects in the masked region that do not match the surrounding context. (2) Color inconsistency: inpainted regions often exhibit noticeable color shifts, leading to smeared textures and degraded image quality. We analyze the underlying causes of these issues and propose efficient post-hoc solutions for pre-trained inpainting models. Specifically, we introduce the principled framework of Aligned Stable inpainting with UnKnown Areas prior (ASUKA). To reduce unwanted object insertion, we use reconstruction-based priors to guide the generative model, suppressing hallucinated objects while preserving generative flexibility. To address color inconsistency, we design a specialized VAE decoder that formulates latent-to-image decoding as a local harmonization task. This design significantly reduces color shifts and produces more color-consistent results. We implement ASUKA on two representative inpainting architectures: a U-Net-based model and a DiT-based model. We analyze and propose lightweight injection strategies that minimize interference with the model's original generation capacity while ensuring the mitigation of the two issues. We evaluate ASUKA using the Places2 dataset and MISATO, our proposed diverse benchmark. Experiments show that ASUKA effectively suppresses object hallucination and improves color consistency, outperforming standard diffusion, rectified flow models, and other inpainting methods. Dataset, models and codes will be released in github.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Generative image inpainting can produce realistic, high-fidelity results even with large, irregular masks. However, existing methods still face key issues that make inpainted images look unnatural. In this paper, we identify two main problems: (1) Unwanted object insertion: generative models may hallucinate arbitrary objects in the masked region that do not match the surrounding context. (2) Color inconsistency: inpainted regions often exhibit noticeable color shifts, leading to smeared textures and degraded image quality. We analyze the underlying causes of these issues and propose efficient post-hoc solutions for pre-trained inpainting models. Specifically, we introduce the principled framework of Aligned Stable inpainting with UnKnown Areas prior (ASUKA). To reduce unwanted object insertion, we use reconstruction-based priors to guide the generative model, suppressing hallucinated objects while preserving generative flexibility. To address color inconsistency, we design a specialized VAE decoder that formulates latent-to-image decoding as a local harmonization task. This design significantly reduces color shifts and produces more color-consistent results. We implement ASUKA on two representative inpainting architectures: a U-Net-based model and a DiT-based model. We analyze and propose lightweight injection strategies that minimize interference with the model's original generation capacity while ensuring the mitigation of the two issues. We evaluate ASUKA using the Places2 dataset and MISATO, our proposed diverse benchmark. Experiments show that ASUKA effectively suppresses object hallucination and improves color consistency, outperforming standard diffusion, rectified flow models, and other inpainting methods. Dataset, models and codes will be released in github."
        },
        "tags": [
            {
                "term": "eess.IV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-21T17:57:18Z",
        "published_parsed": [
            2026,
            1,
            21,
            17,
            57,
            18,
            2,
            21,
            0
        ],
        "arxiv_comment": "Extension of our CVPR 2025 highlight paper: arXiv:2312.04831",
        "arxiv_primary_category": {
            "term": "eess.IV"
        },
        "authors": [
            {
                "name": "Yikai Wang"
            },
            {
                "name": "Junqiu Yu"
            },
            {
                "name": "Chenjie Cao"
            },
            {
                "name": "Xiangyang Xue"
            },
            {
                "name": "Yanwei Fu"
            }
        ],
        "author_detail": {
            "name": "Yanwei Fu"
        },
        "author": "Yanwei Fu",
        "journal": "arXiv: Computational Imaging",
        "title_cn": "对齐稳定修复：减少不需要的对象插入并保持颜色一致性",
        "abstract_cn": "即使使用大的、不规则的蒙版，生成图像修复也可以产生逼真的高保真结果。然而，现有方法仍然面临一些关键问题，导致修复后的图像看起来不自然。在本文中，我们确定了两个主要问题：（1）不需要的对象插入：生成模型可能会产生与周围上下文不匹配的屏蔽区域中的任意对象的幻觉。 (2) 颜色不一致：修复区域通常表现出明显的颜色变化，导致纹理模糊和图像质量下降。我们分析这些问题的根本原因，并为预训练的修复模型提出有效的事后解决方案。具体来说，我们介绍了带有未知区域先验的对齐稳定修复（ASUKA）的原则框架。为了减少不需要的对象插入，我们使用基于重建的先验来指导生成模型，抑制幻觉对象，同时保留生成灵活性。为了解决颜色不一致问题，我们设计了一个专门的 VAE 解码器，将潜在图像解码制定为本地协调任务。这种设计显着减少了颜色偏移并产生颜色更加一致的结果。我们在两种代表性的修复架构上实现了 ASUKA：基于 U-Net 的模型和基于 DiT 的模型。我们分析并提出了轻量级注入策略，最大限度地减少对模型原始发电能力的干扰，同时确保缓解这两个问题。我们使用 Places2 数据集和 MISATO（我们提出的多样化基准）来评估 ASUKA。实验表明，ASUKA 有效抑制物体幻觉并提高颜色一致性，优于标准扩散、整流流模型和其他修复方法。数据集、模型和代码将在github上发布。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15369v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15369v1",
        "title": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation"
        },
        "updated": "2026-01-21T18:47:12Z",
        "updated_parsed": [
            2026,
            1,
            21,
            18,
            47,
            12,
            2,
            21,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15369v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15369v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "This paper presents a family of advanced vision encoder, named OpenVision 3, that learns a single, unified visual representation that can serve both image understanding and image generation. Our core architecture is simple: we feed VAE-compressed image latents to a ViT encoder and train its output to support two complementary roles. First, the encoder output is passed to the ViT-VAE decoder to reconstruct the original image, encouraging the representation to capture generative structure. Second, the same representation is optimized with contrastive learning and image-captioning objectives, strengthening semantic features. By jointly optimizing reconstruction- and semantics-driven signals in a shared latent space, the encoder learns representations that synergize and generalize well across both regimes. We validate this unified design through extensive downstream evaluations with the encoder frozen. For multimodal understanding, we plug the encoder into the LLaVA-1.5 framework: it performs comparably with a standard CLIP vision encoder (e.g., 62.4 vs 62.2 on SeedBench, and 83.7 vs 82.9 on POPE). For generation, we test it under the RAE framework: ours substantially surpasses the standard CLIP-based encoder (e.g., gFID: 1.89 vs 2.54 on ImageNet). We hope this work can spur future research on unified modeling.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "This paper presents a family of advanced vision encoder, named OpenVision 3, that learns a single, unified visual representation that can serve both image understanding and image generation. Our core architecture is simple: we feed VAE-compressed image latents to a ViT encoder and train its output to support two complementary roles. First, the encoder output is passed to the ViT-VAE decoder to reconstruct the original image, encouraging the representation to capture generative structure. Second, the same representation is optimized with contrastive learning and image-captioning objectives, strengthening semantic features. By jointly optimizing reconstruction- and semantics-driven signals in a shared latent space, the encoder learns representations that synergize and generalize well across both regimes. We validate this unified design through extensive downstream evaluations with the encoder frozen. For multimodal understanding, we plug the encoder into the LLaVA-1.5 framework: it performs comparably with a standard CLIP vision encoder (e.g., 62.4 vs 62.2 on SeedBench, and 83.7 vs 82.9 on POPE). For generation, we test it under the RAE framework: ours substantially surpasses the standard CLIP-based encoder (e.g., gFID: 1.89 vs 2.54 on ImageNet). We hope this work can spur future research on unified modeling."
        },
        "tags": [
            {
                "term": "eess.IV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.AI",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-21T18:47:12Z",
        "published_parsed": [
            2026,
            1,
            21,
            18,
            47,
            12,
            2,
            21,
            0
        ],
        "arxiv_primary_category": {
            "term": "eess.IV"
        },
        "authors": [
            {
                "name": "Letian Zhang"
            },
            {
                "name": "Sucheng Ren"
            },
            {
                "name": "Yanqing Liu"
            },
            {
                "name": "Xianhang Li"
            },
            {
                "name": "Zeyu Wang"
            },
            {
                "name": "Yuyin Zhou"
            },
            {
                "name": "Huaxiu Yao"
            },
            {
                "name": "Zeyu Zheng"
            },
            {
                "name": "Weili Nie"
            },
            {
                "name": "Guilin Liu"
            },
            {
                "name": "Zhiding Yu"
            },
            {
                "name": "Cihang Xie"
            }
        ],
        "author_detail": {
            "name": "Cihang Xie"
        },
        "author": "Cihang Xie",
        "journal": "arXiv: Computational Imaging",
        "title_cn": "OpenVision 3：用于理解和生成的统一视觉编码器系列",
        "abstract_cn": "本文提出了一系列先进的视觉编码器，名为 OpenVision 3，它学习单一、统一的视觉表示，可以服务于图像理解和图像生成。我们的核心架构很简单：我们将 VAE 压缩的潜在图像提供给 ViT 编码器，并训练其输出以支持两个互补的角色。首先，编码器输出被传递到 ViT-VAE 解码器以重建原始图像，从而鼓励表示捕获生成结构。其次，通过对比学习和图像描述目标优化相同的表示，从而加强语义特征。通过在共享潜在空间中联合优化重建和语义驱动的信号，编码器学习在两种机制之间协同和泛化的表示。我们通过冻结编码器的广泛下游评估来验证这种统一设计。为了实现多模态理解，我们将编码器插入 LLaVA-1.5 框架中：它的性能与标准 CLIP 视觉编码器相当（例如，SeedBench 上的 62.4 与 62.2，以及 POPE 上的 83.7 与 82.9）。对于生成，我们在 RAE 框架下对其进行测试：我们的编码器大大超过了标准的基于 CLIP 的编码器（例如，gFID：ImageNet 上的 1.89 与 2.54）。我们希望这项工作能够促进未来统一建模的研究。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15539v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15539v1",
        "title": "A Machine Vision Approach to Preliminary Skin Lesion Assessments",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "A Machine Vision Approach to Preliminary Skin Lesion Assessments"
        },
        "updated": "2026-01-21T23:48:59Z",
        "updated_parsed": [
            2026,
            1,
            21,
            23,
            48,
            59,
            2,
            21,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15539v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15539v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Early detection of malignant skin lesions is critical for improving patient outcomes in aggressive, metastatic skin cancers. This study evaluates a comprehensive system for preliminary skin lesion assessment that combines the clinically established ABCD rule of dermoscopy (analyzing Asymmetry, Borders, Color, and Dermoscopic Structures) with machine learning classification. Using a 1,000-image subset of the HAM10000 dataset, the system implements an automated, rule-based pipeline to compute a Total Dermoscopy Score (TDS) for each lesion. This handcrafted approach is compared against various machine learning solutions, including traditional classifiers (Logistic Regression, Random Forest, and SVM) and deep learning models. While the rule-based system provides high clinical interpretability, results indicate a performance bottleneck when reducing complex morphology to five numerical features. Experimental findings show that transfer learning with EfficientNet-B0 failed significantly due to domain shift between natural and medical images. In contrast, a custom three-layer Convolutional Neural Network (CNN) trained from scratch achieved 78.5% accuracy and 86.5% recall on median-filtered images, representing a 19-point accuracy improvement over traditional methods. The results demonstrate that direct pixel-level learning captures diagnostic patterns beyond handcrafted features and that purpose-built lightweight architectures can outperform large pretrained models for small, domain-specific medical datasets.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Early detection of malignant skin lesions is critical for improving patient outcomes in aggressive, metastatic skin cancers. This study evaluates a comprehensive system for preliminary skin lesion assessment that combines the clinically established ABCD rule of dermoscopy (analyzing Asymmetry, Borders, Color, and Dermoscopic Structures) with machine learning classification. Using a 1,000-image subset of the HAM10000 dataset, the system implements an automated, rule-based pipeline to compute a Total Dermoscopy Score (TDS) for each lesion. This handcrafted approach is compared against various machine learning solutions, including traditional classifiers (Logistic Regression, Random Forest, and SVM) and deep learning models. While the rule-based system provides high clinical interpretability, results indicate a performance bottleneck when reducing complex morphology to five numerical features. Experimental findings show that transfer learning with EfficientNet-B0 failed significantly due to domain shift between natural and medical images. In contrast, a custom three-layer Convolutional Neural Network (CNN) trained from scratch achieved 78.5% accuracy and 86.5% recall on median-filtered images, representing a 19-point accuracy improvement over traditional methods. The results demonstrate that direct pixel-level learning captures diagnostic patterns beyond handcrafted features and that purpose-built lightweight architectures can outperform large pretrained models for small, domain-specific medical datasets."
        },
        "tags": [
            {
                "term": "eess.IV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.AI",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.LG",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-21T23:48:59Z",
        "published_parsed": [
            2026,
            1,
            21,
            23,
            48,
            59,
            2,
            21,
            0
        ],
        "arxiv_comment": "6 pages, 2 figures, 2 tables",
        "arxiv_primary_category": {
            "term": "eess.IV"
        },
        "authors": [
            {
                "name": "Ali Khreis"
            },
            {
                "name": "Ro'Yah Radaideh"
            },
            {
                "name": "Quinn McGill"
            }
        ],
        "author_detail": {
            "name": "Quinn McGill"
        },
        "author": "Quinn McGill",
        "journal": "arXiv: Computational Imaging",
        "title_cn": "初步皮肤病变评估的机器视觉方法",
        "abstract_cn": "早期发现恶性皮肤病变对于改善侵袭性、转移性皮肤癌的患者预后至关重要。本研究评估了一个用于初步皮肤病变评估的综合系统，该系统将临床建立的皮肤镜检查 ABCD 规则（分析不对称性、边界、颜色和皮肤镜结构）与机器学习分类相结合。该系统使用 HAM10000 数据集的 1,000 个图像子集，实现一个基于规则的自动化管道来计算每个病变的总皮肤镜评分 (TDS)。将这种手工方法与各种机器学习解决方案进行比较，包括传统分类器（逻辑回归、随机森林和 SVM）和深度学习模型。虽然基于规则的系统提供了较高的临床可解释性，但结果表明，将复杂的形态学简化为五个数字特征时存在性能瓶颈。实验结果表明，由于自然图像和医学图像之间的域转移，EfficientNet-B0 的迁移学习明显失败。相比之下，从头开始训练的定制三层卷积神经网络 (CNN) 在中值滤波图像上实现了 78.5% 的准确率和 86.5% 的召回率，比传统方法提高了 19 个点的准确度。结果表明，直接像素级学习可以捕获超出手工特征的诊断模式，并且针对小型、特定领域的医疗数据集，专门构建的轻量级架构可以优于大型预训练模型。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15572v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15572v1",
        "title": "FUGC: Benchmarking Semi-Supervised Learning Methods for Cervical Segmentation",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "FUGC: Benchmarking Semi-Supervised Learning Methods for Cervical Segmentation"
        },
        "updated": "2026-01-22T01:34:39Z",
        "updated_parsed": [
            2026,
            1,
            22,
            1,
            34,
            39,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15572v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15572v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Accurate segmentation of cervical structures in transvaginal ultrasound (TVS) is critical for assessing the risk of spontaneous preterm birth (PTB), yet the scarcity of labeled data limits the performance of supervised learning approaches. This paper introduces the Fetal Ultrasound Grand Challenge (FUGC), the first benchmark for semi-supervised learning in cervical segmentation, hosted at ISBI 2025. FUGC provides a dataset of 890 TVS images, including 500 training images, 90 validation images, and 300 test images. Methods were evaluated using the Dice Similarity Coefficient (DSC), Hausdorff Distance (HD), and runtime (RT), with a weighted combination of 0.4/0.4/0.2. The challenge attracted 10 teams with 82 participants submitting innovative solutions. The best-performing methods for each individual metric achieved 90.26\\% mDSC, 38.88 mHD, and 32.85 ms RT, respectively. FUGC establishes a standardized benchmark for cervical segmentation, demonstrates the efficacy of semi-supervised methods with limited labeled data, and provides a foundation for AI-assisted clinical PTB risk assessment.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Accurate segmentation of cervical structures in transvaginal ultrasound (TVS) is critical for assessing the risk of spontaneous preterm birth (PTB), yet the scarcity of labeled data limits the performance of supervised learning approaches. This paper introduces the Fetal Ultrasound Grand Challenge (FUGC), the first benchmark for semi-supervised learning in cervical segmentation, hosted at ISBI 2025. FUGC provides a dataset of 890 TVS images, including 500 training images, 90 validation images, and 300 test images. Methods were evaluated using the Dice Similarity Coefficient (DSC), Hausdorff Distance (HD), and runtime (RT), with a weighted combination of 0.4/0.4/0.2. The challenge attracted 10 teams with 82 participants submitting innovative solutions. The best-performing methods for each individual metric achieved 90.26\\% mDSC, 38.88 mHD, and 32.85 ms RT, respectively. FUGC establishes a standardized benchmark for cervical segmentation, demonstrates the efficacy of semi-supervised methods with limited labeled data, and provides a foundation for AI-assisted clinical PTB risk assessment."
        },
        "tags": [
            {
                "term": "eess.IV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.CE",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T01:34:39Z",
        "published_parsed": [
            2026,
            1,
            22,
            1,
            34,
            39,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "eess.IV"
        },
        "authors": [
            {
                "name": "Jieyun Bai"
            },
            {
                "name": "Yitong Tang"
            },
            {
                "name": "Zihao Zhou"
            },
            {
                "name": "Mahdi Islam"
            },
            {
                "name": "Musarrat Tabassum"
            },
            {
                "name": "Enrique Almar-Munoz"
            },
            {
                "name": "Hongyu Liu"
            },
            {
                "name": "Hui Meng"
            },
            {
                "name": "Nianjiang Lv"
            },
            {
                "name": "Bo Deng"
            },
            {
                "name": "Yu Chen"
            },
            {
                "name": "Zilun Peng"
            },
            {
                "name": "Yusong Xiao"
            },
            {
                "name": "Li Xiao"
            },
            {
                "name": "Nam-Khanh Tran"
            },
            {
                "name": "Dac-Phu Phan-Le"
            },
            {
                "name": "Hai-Dang Nguyen"
            },
            {
                "name": "Xiao Liu"
            },
            {
                "name": "Jiale Hu"
            },
            {
                "name": "Mingxu Huang"
            },
            {
                "name": "Jitao Liang"
            },
            {
                "name": "Chaolu Feng"
            },
            {
                "name": "Xuezhi Zhang"
            },
            {
                "name": "Lyuyang Tong"
            },
            {
                "name": "Bo Du"
            },
            {
                "name": "Ha-Hieu Pham"
            },
            {
                "name": "Thanh-Huy Nguyen"
            },
            {
                "name": "Min Xu"
            },
            {
                "name": "Juntao Jiang"
            },
            {
                "name": "Jiangning Zhang"
            },
            {
                "name": "Yong Liu"
            },
            {
                "name": "Md. Kamrul Hasan"
            },
            {
                "name": "Jie Gan"
            },
            {
                "name": "Zhuonan Liang"
            },
            {
                "name": "Weidong Cai"
            },
            {
                "name": "Yuxin Huang"
            },
            {
                "name": "Gongning Luo"
            },
            {
                "name": "Mohammad Yaqub"
            },
            {
                "name": "Karim Lekadir"
            }
        ],
        "author_detail": {
            "name": "Karim Lekadir"
        },
        "author": "Karim Lekadir",
        "journal": "arXiv: Computational Imaging",
        "title_cn": "FUGC：宫颈分割半监督学习方法的基准测试",
        "abstract_cn": "经阴道超声 (TVS) 中宫颈结构的准确分割对于评估自发性早产 (PTB) 的风险至关重要，但标记数据的缺乏限制了监督学习方法的性能。本文介绍了胎儿超声大挑战赛 (FUGC)，这是在 ISBI 2025 上主办的第一个宫颈分割半监督学习基准。FUGC 提供了 890 张 TVS 图像的数据集，其中包括 500 张训练图像、90 张验证图像和 300 张测试图像。使用 Dice 相似系数 (DSC)、豪斯多夫距离 (HD) 和运行时间 (RT) 评估方法，加权组合为 0.4/0.4/0.2。本次挑战赛吸引了 10 个团队、82 名参赛者提交创新解决方案。每个指标的最佳性能方法分别达到 90.26% mDSC、38.88 mHD 和 32.85 ms RT。 FUGC 建立了宫颈分割的标准化基准，证明了有限标记数据的半监督方法的有效性，并为人工智能辅助临床 PTB 风险评估提供了基础。"
    },
    {
        "id": "http://arxiv.org/abs/2601.16011v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.16011v1",
        "title": "THOR: A Versatile Foundation Model for Earth Observation Climate and Society Applications",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "THOR: A Versatile Foundation Model for Earth Observation Climate and Society Applications"
        },
        "updated": "2026-01-22T14:38:00Z",
        "updated_parsed": [
            2026,
            1,
            22,
            14,
            38,
            0,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.16011v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.16011v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Current Earth observation foundation models are architecturally rigid, struggle with heterogeneous sensors and are constrained to fixed patch sizes. This limits their deployment in real-world scenarios requiring flexible computeaccuracy trade-offs. We propose THOR, a \"computeadaptive\" foundation model that solves both input heterogeneity and deployment rigidity. THOR is the first architecture to unify data from Copernicus Sentinel-1, -2, and -3 (OLCI & SLSTR) satellites, processing their native 10 m to 1000 m resolutions in a single model. We pre-train THOR with a novel randomized patch and input image size strategy. This allows a single set of pre-trained weights to be deployed at inference with any patch size, enabling a dynamic trade-off between computational cost and feature resolution without retraining. We pre-train THOR on THOR Pretrain, a new, large-scale multi-sensor dataset and demonstrate state-of-the-art performance on downstream benchmarks, particularly in data-limited regimes like the PANGAEA 10% split, validating that THOR's flexible feature generation excels for diverse climate and society applications.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Current Earth observation foundation models are architecturally rigid, struggle with heterogeneous sensors and are constrained to fixed patch sizes. This limits their deployment in real-world scenarios requiring flexible computeaccuracy trade-offs. We propose THOR, a \"computeadaptive\" foundation model that solves both input heterogeneity and deployment rigidity. THOR is the first architecture to unify data from Copernicus Sentinel-1, -2, and -3 (OLCI & SLSTR) satellites, processing their native 10 m to 1000 m resolutions in a single model. We pre-train THOR with a novel randomized patch and input image size strategy. This allows a single set of pre-trained weights to be deployed at inference with any patch size, enabling a dynamic trade-off between computational cost and feature resolution without retraining. We pre-train THOR on THOR Pretrain, a new, large-scale multi-sensor dataset and demonstrate state-of-the-art performance on downstream benchmarks, particularly in data-limited regimes like the PANGAEA 10% split, validating that THOR's flexible feature generation excels for diverse climate and society applications."
        },
        "tags": [
            {
                "term": "eess.IV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.AI",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T14:38:00Z",
        "published_parsed": [
            2026,
            1,
            22,
            14,
            38,
            0,
            3,
            22,
            0
        ],
        "arxiv_comment": "25 pages",
        "arxiv_primary_category": {
            "term": "eess.IV"
        },
        "authors": [
            {
                "name": "Theodor Forgaard"
            },
            {
                "name": "Jarle H. Reksten"
            },
            {
                "name": "Anders U. Waldeland"
            },
            {
                "name": "Valerio Marsocci"
            },
            {
                "name": "Nicolas Longépé"
            },
            {
                "name": "Michael Kampffmeyer"
            },
            {
                "name": "Arnt-Børre Salberg"
            }
        ],
        "author_detail": {
            "name": "Arnt-Børre Salberg"
        },
        "author": "Arnt-Børre Salberg",
        "journal": "arXiv: Computational Imaging",
        "title_cn": "THOR：地球观测气候和社会应用的多功能基础模型",
        "abstract_cn": "当前的地球观测基础模型在架构上是僵化的，难以应对异构传感器，并且受限于固定的斑块尺寸。这限制了它们在需要灵活计算精度权衡的现实场景中的部署。我们提出了 THOR，一种“计算自适应”基础模型，可以解决输入异构性和部署刚性问题。 THOR 是第一个统一来自 Copernicus Sentinel-1、-2 和 -3 (OLCI & SLSTR) 卫星数据的架构，在单个模型中处理其原始 10 m 至 1000 m 分辨率。我们使用新颖的随机补丁和输入图像大小策略对 THOR 进行预训练。这允许在任何补丁大小的推理中部署一组预训练的权重，从而无需重新训练即可在计算成本和特征分辨率之间进行动态权衡。我们在 THOR Pretrain（一种新的大规模多传感器数据集）上对 THOR 进行预训练，并在下游基准测试中展示了最先进的性能，特别是在 PANGEA 10% split 等数据有限的情况下，验证了 THOR 灵活的特征生成在不同的气候和社会应用中表现出色。"
    },
    {
        "id": "http://arxiv.org/abs/2601.16064v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.16064v1",
        "title": "Phi-SegNet: Phase-Integrated Supervision for Medical Image Segmentation",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Phi-SegNet: Phase-Integrated Supervision for Medical Image Segmentation"
        },
        "updated": "2026-01-22T16:00:41Z",
        "updated_parsed": [
            2026,
            1,
            22,
            16,
            0,
            41,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.16064v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.16064v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Deep learning has substantially advanced medical image segmentation, yet achieving robust generalization across diverse imaging modalities and anatomical structures remains a major challenge. A key contributor to this limitation lies in how existing architectures, ranging from CNNs to Transformers and their hybrids, primarily encode spatial information while overlooking frequency-domain representations that capture rich structural and textural cues. Although few recent studies have begun exploring spectral information at the feature level, supervision-level integration of frequency cues-crucial for fine-grained object localization-remains largely untapped. To this end, we propose Phi-SegNet, a CNN-based architecture that incorporates phase-aware information at both architectural and optimization levels. The network integrates Bi-Feature Mask Former (BFMF) modules that blend neighboring encoder features to reduce semantic gaps, and Reverse Fourier Attention (RFA) blocks that refine decoder outputs using phase-regularized features. A dedicated phase-aware loss aligns these features with structural priors, forming a closed feedback loop that emphasizes boundary precision. Evaluated on five public datasets spanning X-ray, US, histopathology, MRI, and colonoscopy, Phi-SegNet consistently achieved state-of-the-art performance, with an average relative improvement of 1.54+/-1.26% in IoU and 0.98+/-0.71% in F1-score over the next best-performing model. In cross-dataset generalization scenarios involving unseen datasets from the known domain, Phi-SegNet also exhibits robust and superior performance, highlighting its adaptability and modality-agnostic design. These findings demonstrate the potential of leveraging spectral priors in both feature representation and supervision, paving the way for generalized segmentation frameworks that excel in fine-grained object localization.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Deep learning has substantially advanced medical image segmentation, yet achieving robust generalization across diverse imaging modalities and anatomical structures remains a major challenge. A key contributor to this limitation lies in how existing architectures, ranging from CNNs to Transformers and their hybrids, primarily encode spatial information while overlooking frequency-domain representations that capture rich structural and textural cues. Although few recent studies have begun exploring spectral information at the feature level, supervision-level integration of frequency cues-crucial for fine-grained object localization-remains largely untapped. To this end, we propose Phi-SegNet, a CNN-based architecture that incorporates phase-aware information at both architectural and optimization levels. The network integrates Bi-Feature Mask Former (BFMF) modules that blend neighboring encoder features to reduce semantic gaps, and Reverse Fourier Attention (RFA) blocks that refine decoder outputs using phase-regularized features. A dedicated phase-aware loss aligns these features with structural priors, forming a closed feedback loop that emphasizes boundary precision. Evaluated on five public datasets spanning X-ray, US, histopathology, MRI, and colonoscopy, Phi-SegNet consistently achieved state-of-the-art performance, with an average relative improvement of 1.54+/-1.26% in IoU and 0.98+/-0.71% in F1-score over the next best-performing model. In cross-dataset generalization scenarios involving unseen datasets from the known domain, Phi-SegNet also exhibits robust and superior performance, highlighting its adaptability and modality-agnostic design. These findings demonstrate the potential of leveraging spectral priors in both feature representation and supervision, paving the way for generalized segmentation frameworks that excel in fine-grained object localization."
        },
        "tags": [
            {
                "term": "eess.IV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T16:00:41Z",
        "published_parsed": [
            2026,
            1,
            22,
            16,
            0,
            41,
            3,
            22,
            0
        ],
        "arxiv_comment": "10 pages, 7 figures",
        "arxiv_primary_category": {
            "term": "eess.IV"
        },
        "authors": [
            {
                "name": "Shams Nafisa Ali"
            },
            {
                "name": "Taufiq Hasan"
            }
        ],
        "author_detail": {
            "name": "Taufiq Hasan"
        },
        "author": "Taufiq Hasan",
        "journal": "arXiv: Computational Imaging",
        "title_cn": "Phi-SegNet：医学图像分割的相位集成监督",
        "abstract_cn": "深度学习极大地推进了医学图像分割，但在不同的成像模式和解剖结构之间实现稳健的泛化仍然是一个重大挑战。造成这一限制的一个关键因素在于现有的架构（从 CNN 到 Transformer 及其混合体）主要编码空间信息，而忽略了捕获丰富结构和纹理线索的频域表示。尽管最近很少有研究开始探索特征级别的光谱信息，但频率线索的监督级别整合（对于细粒度对象定位至关重要）仍然很大程度上尚未开发。为此，我们提出了 Phi-SegNet，这是一种基于 CNN 的架构，在架构和优化级别上融合了阶段感知信息。该网络集成了双特征掩模形成器 (BFMF) 模块和反向傅里叶注意 (RFA) 模块，前者混合相邻编码器特征以减少语义间隙，后者使用相位正则化特征细化解码器输出。专用的相位感知损失将这些特征与结构先验保持一致，形成强调边界精度的闭合反馈环。在涵盖 X 射线、US、组织病理学、MRI 和结肠镜检查的五个公共数据集上进行评估后，Phi-SegNet 始终实现了最先进的性能，与下一个表现最佳的模型相比，IoU 平均相对提高了 1.54+/-1.26%，F1 分数平均相对提高了 0.98+/-0.71%。在涉及已知领域未见过的数据集的跨数据集泛化场景中，Phi-SegNet 还表现出稳健且卓越的性能，突出了其适应性和模态不可知的设计。这些发现证明了在特征表示和监督中利用光谱先验的潜力，为擅长细粒度对象定位的广义分割框架铺平了道路。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15392v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15392v1",
        "title": "GeMM-GAN: A Multimodal Generative Model Conditioned on Histopathology Images and Clinical Descriptions for Gene Expression Profile Generation",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "GeMM-GAN: A Multimodal Generative Model Conditioned on Histopathology Images and Clinical Descriptions for Gene Expression Profile Generation"
        },
        "updated": "2026-01-21T19:03:54Z",
        "updated_parsed": [
            2026,
            1,
            21,
            19,
            3,
            54,
            2,
            21,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15392v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15392v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            },
            {
                "rel": "related",
                "href": "https://doi.org/10.1007/978-3-032-11317-7_33",
                "title": "doi",
                "type": "text/html"
            }
        ],
        "summary": "Biomedical research increasingly relies on integrating diverse data modalities, including gene expression profiles, medical images, and clinical metadata. While medical images and clinical metadata are routinely collected in clinical practice, gene expression data presents unique challenges for widespread research use, mainly due to stringent privacy regulations and costly laboratory experiments. To address these limitations, we present GeMM-GAN, a novel Generative Adversarial Network conditioned on histopathology tissue slides and clinical metadata, designed to synthesize realistic gene expression profiles. GeMM-GAN combines a Transformer Encoder for image patches with a final Cross Attention mechanism between patches and text tokens, producing a conditioning vector to guide a generative model in generating biologically coherent gene expression profiles. We evaluate our approach on the TCGA dataset and demonstrate that our framework outperforms standard generative models and generates more realistic and functionally meaningful gene expression profiles, improving by more than 11\\% the accuracy on downstream disease type prediction compared to current state-of-the-art generative models. Code will be available at: https://github.com/francescapia/GeMM-GAN",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Biomedical research increasingly relies on integrating diverse data modalities, including gene expression profiles, medical images, and clinical metadata. While medical images and clinical metadata are routinely collected in clinical practice, gene expression data presents unique challenges for widespread research use, mainly due to stringent privacy regulations and costly laboratory experiments. To address these limitations, we present GeMM-GAN, a novel Generative Adversarial Network conditioned on histopathology tissue slides and clinical metadata, designed to synthesize realistic gene expression profiles. GeMM-GAN combines a Transformer Encoder for image patches with a final Cross Attention mechanism between patches and text tokens, producing a conditioning vector to guide a generative model in generating biologically coherent gene expression profiles. We evaluate our approach on the TCGA dataset and demonstrate that our framework outperforms standard generative models and generates more realistic and functionally meaningful gene expression profiles, improving by more than 11\\% the accuracy on downstream disease type prediction compared to current state-of-the-art generative models. Code will be available at: https://github.com/francescapia/GeMM-GAN"
        },
        "tags": [
            {
                "term": "cs.AI",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.LG",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-21T19:03:54Z",
        "published_parsed": [
            2026,
            1,
            21,
            19,
            3,
            54,
            2,
            21,
            0
        ],
        "arxiv_comment": "12 pages, 2 figures. Published at Image Analysis and Processing - ICIAP 2025 Workshops",
        "arxiv_primary_category": {
            "term": "cs.AI"
        },
        "authors": [
            {
                "name": "Francesca Pia Panaccione"
            },
            {
                "name": "Carlo Sgaravatti"
            },
            {
                "name": "Pietro Pinoli"
            }
        ],
        "author_detail": {
            "name": "Pietro Pinoli"
        },
        "author": "Pietro Pinoli",
        "arxiv_doi": "10.1007/978-3-032-11317-7_33",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "GeMM-GAN：以组织病理学图像和临床描述为条件的多模态生成模型，用于生成基因表达谱",
        "abstract_cn": "生物医学研究越来越依赖于整合不同的数据模式，包括基因表达谱、医学图像和临床元数据。虽然医学图像和临床元数据是在临床实践中常规收集的，但基因表达数据对广泛的研究使用提出了独特的挑战，这主要是由于严格的隐私法规和昂贵的实验室实验。为了解决这些局限性，我们提出了 GeMM-GAN，这是一种以组织病理学组织切片和临床元数据为条件的新型生成对抗网络，旨在合成真实的基因表达谱。 GeMM-GAN 将图像补丁的 Transformer 编码器与补丁和文本标记之间的最终交叉注意力机制相结合，生成条件向量来指导生成模型生成生物相干的基因表达谱。我们在 TCGA 数据集上评估了我们的方法，并证明我们的框架优于标准生成模型，并生成更真实且具有功能意义的基因表达谱，与当前最先进的生成模型相比，下游疾病类型预测的准确性提高了 11% 以上。代码位于：https://github.com/francescapia/GeMM-GAN"
    },
    {
        "id": "http://arxiv.org/abs/2601.15406v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15406v1",
        "title": "Evaluating Multimodal Large Language Models for Heterogeneous Face Recognition",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Evaluating Multimodal Large Language Models for Heterogeneous Face Recognition"
        },
        "updated": "2026-01-21T19:17:21Z",
        "updated_parsed": [
            2026,
            1,
            21,
            19,
            17,
            21,
            2,
            21,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15406v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15406v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Multimodal Large Language Models (MLLMs) have recently demonstrated strong performance on a wide range of vision-language tasks, raising interest in their potential use for biometric applications. In this paper, we conduct a systematic evaluation of state-of-the-art MLLMs for heterogeneous face recognition (HFR), where enrollment and probe images are from different sensing modalities, including visual (VIS), near infrared (NIR), short-wave infrared (SWIR), and thermal camera. We benchmark multiple open-source MLLMs across several cross-modality scenarios, including VIS-NIR, VIS-SWIR, and VIS-THERMAL face recognition. The recognition performance of MLLMs is evaluated using biometric protocols and based on different metrics, including Acquire Rate, Equal Error Rate (EER), and True Accept Rate (TAR). Our results reveal substantial performance gaps between MLLMs and classical face recognition systems, particularly under challenging cross-spectral conditions, in spite of recent advances in MLLMs. Our findings highlight the limitations of current MLLMs for HFR and also the importance of rigorous biometric evaluation when considering their deployment in face recognition systems.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Multimodal Large Language Models (MLLMs) have recently demonstrated strong performance on a wide range of vision-language tasks, raising interest in their potential use for biometric applications. In this paper, we conduct a systematic evaluation of state-of-the-art MLLMs for heterogeneous face recognition (HFR), where enrollment and probe images are from different sensing modalities, including visual (VIS), near infrared (NIR), short-wave infrared (SWIR), and thermal camera. We benchmark multiple open-source MLLMs across several cross-modality scenarios, including VIS-NIR, VIS-SWIR, and VIS-THERMAL face recognition. The recognition performance of MLLMs is evaluated using biometric protocols and based on different metrics, including Acquire Rate, Equal Error Rate (EER), and True Accept Rate (TAR). Our results reveal substantial performance gaps between MLLMs and classical face recognition systems, particularly under challenging cross-spectral conditions, in spite of recent advances in MLLMs. Our findings highlight the limitations of current MLLMs for HFR and also the importance of rigorous biometric evaluation when considering their deployment in face recognition systems."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-21T19:17:21Z",
        "published_parsed": [
            2026,
            1,
            21,
            19,
            17,
            21,
            2,
            21,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Hatef Otroshi Shahreza"
            },
            {
                "name": "Anjith George"
            },
            {
                "name": "Sébastien Marcel"
            }
        ],
        "author_detail": {
            "name": "Sébastien Marcel"
        },
        "author": "Sébastien Marcel",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "评估异构人脸识别的多模态大语言模型",
        "abstract_cn": "多模态大型语言模型 (MLLM) 最近在各种视觉语言任务中表现出了强大的性能，引起了人们对其在生物识别应用中的潜在用途的兴趣。在本文中，我们对用于异构人脸识别 (HFR) 的最先进的 MLLM 进行了系统评估，其中登记和探测图像来自不同的传感模式，包括视觉 (VIS)、近红外 (NIR)、短波红外 (SWIR) 和热像仪。我们在多个跨模态场景中对多个开源 MLLM 进行基准测试，包括 VIS-NIR、VIS-SWIR 和 VIS-THERMAL 人脸识别。 MLLM 的识别性能使用生物识别协议并基于不同的指标进行评估，包括获取率、等错误率 (EER) 和真实接受率 (TAR)。我们的结果揭示了 MLLM 和经典人脸识别系统之间存在巨大的性能差距，特别是在具有挑战性的跨光谱条件下，尽管 MLLM 最近取得了进展。我们的研究结果强调了当前 MLLM 在 HFR 方面的局限性，以及在考虑将其部署在人脸识别系统中时严格的生物识别评估的重要性。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15416v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15416v1",
        "title": "DuFal: Dual-Frequency-Aware Learning for High-Fidelity Extremely Sparse-view CBCT Reconstruction",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "DuFal: Dual-Frequency-Aware Learning for High-Fidelity Extremely Sparse-view CBCT Reconstruction"
        },
        "updated": "2026-01-21T19:27:47Z",
        "updated_parsed": [
            2026,
            1,
            21,
            19,
            27,
            47,
            2,
            21,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15416v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15416v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Sparse-view Cone-Beam Computed Tomography reconstruction from limited X-ray projections remains a challenging problem in medical imaging due to the inherent undersampling of fine-grained anatomical details, which correspond to high-frequency components. Conventional CNN-based methods often struggle to recover these fine structures, as they are typically biased toward learning low-frequency information. To address this challenge, this paper presents DuFal (Dual-Frequency-Aware Learning), a novel framework that integrates frequency-domain and spatial-domain processing via a dual-path architecture. The core innovation lies in our High-Local Factorized Fourier Neural Operator, which comprises two complementary branches: a Global High-Frequency Enhanced Fourier Neural Operator that captures global frequency patterns and a Local High-Frequency Enhanced Fourier Neural Operator that processes spatially partitioned patches to preserve spatial locality that might be lost in global frequency analysis. To improve efficiency, we design a Spectral-Channel Factorization scheme that reduces the Fourier Neural Operator parameter count. We also design a Cross-Attention Frequency Fusion module to integrate spatial and frequency features effectively. The fused features are then decoded through a Feature Decoder to produce projection representations, which are subsequently processed through an Intensity Field Decoding pipeline to reconstruct a final Computed Tomography volume. Experimental results on the LUNA16 and ToothFairy datasets demonstrate that DuFal significantly outperforms existing state-of-the-art methods in preserving high-frequency anatomical features, particularly under extremely sparse-view settings.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Sparse-view Cone-Beam Computed Tomography reconstruction from limited X-ray projections remains a challenging problem in medical imaging due to the inherent undersampling of fine-grained anatomical details, which correspond to high-frequency components. Conventional CNN-based methods often struggle to recover these fine structures, as they are typically biased toward learning low-frequency information. To address this challenge, this paper presents DuFal (Dual-Frequency-Aware Learning), a novel framework that integrates frequency-domain and spatial-domain processing via a dual-path architecture. The core innovation lies in our High-Local Factorized Fourier Neural Operator, which comprises two complementary branches: a Global High-Frequency Enhanced Fourier Neural Operator that captures global frequency patterns and a Local High-Frequency Enhanced Fourier Neural Operator that processes spatially partitioned patches to preserve spatial locality that might be lost in global frequency analysis. To improve efficiency, we design a Spectral-Channel Factorization scheme that reduces the Fourier Neural Operator parameter count. We also design a Cross-Attention Frequency Fusion module to integrate spatial and frequency features effectively. The fused features are then decoded through a Feature Decoder to produce projection representations, which are subsequently processed through an Intensity Field Decoding pipeline to reconstruct a final Computed Tomography volume. Experimental results on the LUNA16 and ToothFairy datasets demonstrate that DuFal significantly outperforms existing state-of-the-art methods in preserving high-frequency anatomical features, particularly under extremely sparse-view settings."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.AI",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-21T19:27:47Z",
        "published_parsed": [
            2026,
            1,
            21,
            19,
            27,
            47,
            2,
            21,
            0
        ],
        "arxiv_comment": "Published with J2C Certification in Transactions on Machine Learning Research (TMLR)",
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Cuong Tran Van"
            },
            {
                "name": "Trong-Thang Pham"
            },
            {
                "name": "Ngoc-Son Nguyen"
            },
            {
                "name": "Duy Minh Ho Nguyen"
            },
            {
                "name": "Ngan Le"
            }
        ],
        "author_detail": {
            "name": "Ngan Le"
        },
        "author": "Ngan Le",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "DuFal：用于高保真极稀疏视图 CBCT 重建的双频感知学习",
        "abstract_cn": "由于与高频分量相对应的细粒度解剖细节固有的欠采样，基于有限 X 射线投影的稀疏视图锥形束计算机断层扫描重建仍然是医学成像中的一个具有挑战性的问题。传统的基于 CNN 的方法通常很难恢复这些精细结构，因为它们通常偏向于学习低频信息。为了应对这一挑战，本文提出了 DuFal（双频感知学习），这是一种通过双路径架构集成频域和空间域处理的新颖框架。核心创新在于我们的高局部分解傅里叶神经算子，它由两个互补的分支组成：捕获全局频率模式的全局高频增强傅里叶神经算子和处理空间分区补丁以保留全局频率分析中可能丢失的空间局部性的局部高频增强傅里叶神经算子。为了提高效率，我们设计了一种频谱通道分解方案，以减少傅立叶神经算子参数数量。我们还设计了一个交叉注意力频率融合模块来有效地整合空间和频率特征。然后，融合的特征通过特征解码器进行解码，以产生投影表示，随后通过强度场解码管道进行处理，以重建最终的计算机断层扫描体积。 LUNA16 和 ToothFairy 数据集上的实验结果表明，DuFal 在保留高频解剖特征方面显着优于现有的最先进方法，特别是在极其稀疏的视图设置下。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15441v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15441v1",
        "title": "CASL: Concept-Aligned Sparse Latents for Interpreting Diffusion Models",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "CASL: Concept-Aligned Sparse Latents for Interpreting Diffusion Models"
        },
        "updated": "2026-01-21T20:14:17Z",
        "updated_parsed": [
            2026,
            1,
            21,
            20,
            14,
            17,
            2,
            21,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15441v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15441v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Internal activations of diffusion models encode rich semantic information, but interpreting such representations remains challenging. While Sparse Autoencoders (SAEs) have shown promise in disentangling latent representations, existing SAE-based methods for diffusion model understanding rely on unsupervised approaches that fail to align sparse features with human-understandable concepts. This limits their ability to provide reliable semantic control over generated images. We introduce CASL (Concept-Aligned Sparse Latents), a supervised framework that aligns sparse latent dimensions of diffusion models with semantic concepts. CASL first trains an SAE on frozen U-Net activations to obtain disentangled latent representations, and then learns a lightweight linear mapping that associates each concept with a small set of relevant latent dimensions. To validate the semantic meaning of these aligned directions, we propose CASL-Steer, a controlled latent intervention that shifts activations along the learned concept axis. Unlike editing methods, CASL-Steer is used solely as a causal probe to reveal how concept-aligned latents influence generated content. We further introduce the Editing Precision Ratio (EPR), a metric that jointly measures concept specificity and the preservation of unrelated attributes. Experiments show that our method achieves superior editing precision and interpretability compared to existing approaches. To the best of our knowledge, this is the first work to achieve supervised alignment between latent representations and semantic concepts in diffusion models.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Internal activations of diffusion models encode rich semantic information, but interpreting such representations remains challenging. While Sparse Autoencoders (SAEs) have shown promise in disentangling latent representations, existing SAE-based methods for diffusion model understanding rely on unsupervised approaches that fail to align sparse features with human-understandable concepts. This limits their ability to provide reliable semantic control over generated images. We introduce CASL (Concept-Aligned Sparse Latents), a supervised framework that aligns sparse latent dimensions of diffusion models with semantic concepts. CASL first trains an SAE on frozen U-Net activations to obtain disentangled latent representations, and then learns a lightweight linear mapping that associates each concept with a small set of relevant latent dimensions. To validate the semantic meaning of these aligned directions, we propose CASL-Steer, a controlled latent intervention that shifts activations along the learned concept axis. Unlike editing methods, CASL-Steer is used solely as a causal probe to reveal how concept-aligned latents influence generated content. We further introduce the Editing Precision Ratio (EPR), a metric that jointly measures concept specificity and the preservation of unrelated attributes. Experiments show that our method achieves superior editing precision and interpretability compared to existing approaches. To the best of our knowledge, this is the first work to achieve supervised alignment between latent representations and semantic concepts in diffusion models."
        },
        "tags": [
            {
                "term": "cs.LG",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-21T20:14:17Z",
        "published_parsed": [
            2026,
            1,
            21,
            20,
            14,
            17,
            2,
            21,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.LG"
        },
        "authors": [
            {
                "name": "Zhenghao He"
            },
            {
                "name": "Guangzhi Xiong"
            },
            {
                "name": "Boyang Wang"
            },
            {
                "name": "Sanchit Sinha"
            },
            {
                "name": "Aidong Zhang"
            }
        ],
        "author_detail": {
            "name": "Aidong Zhang"
        },
        "author": "Aidong Zhang",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "CASL：用于解释扩散模型的概念对齐稀疏潜伏",
        "abstract_cn": "扩散模型的内部激活编码丰富的语义信息，但解释此类表示仍然具有挑战性。虽然稀疏自动编码器 (SAE) 在解开潜在表示方面表现出了良好的前景，但现有的基于 SAE 的扩散模型理解方法依赖于无监督方法，而这些方法无法将稀疏特征与人类可理解的概念结合起来。这限制了他们对生成的图像提供可靠的语义控制的能力。我们引入了 CASL（概念对齐稀疏潜在），这是一种监督框架，它将扩散模型的稀疏潜在维度与语义概念对齐。 CASL 首先在冻结的 U-Net 激活上训练 SAE，以获得解开的潜在表示，然后学习轻量级线性映射，将每个概念与一小组相关潜在维度相关联。为了验证这些对齐方向的语义意义，我们提出了 CASL-Steer，这是一种受控的潜在干预，可以沿着学习的概念轴改变激活。与编辑方法不同，CASL-Steer 仅用作因果探测，以揭示概念对齐的潜在因素如何影响生成的内容。我们进一步介绍了编辑精确率（EPR），这是一种联合衡量概念特异性和不相关属性保留的指标。实验表明，与现有方法相比，我们的方法实现了卓越的编辑精度和可解释性。据我们所知，这是第一个在扩散模型中实现潜在表示和语义概念之间的监督对齐的工作。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15453v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15453v1",
        "title": "DevPrompt: Deviation-Based Prompt Learning for One-Normal ShotImage Anomaly Detection",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "DevPrompt: Deviation-Based Prompt Learning for One-Normal ShotImage Anomaly Detection"
        },
        "updated": "2026-01-21T20:35:51Z",
        "updated_parsed": [
            2026,
            1,
            21,
            20,
            35,
            51,
            2,
            21,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15453v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15453v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Few-normal shot anomaly detection (FNSAD) aims to detect abnormal regions in images using only a few normal training samples, making the task highly challenging due to limited supervision and the diversity of potential defects. Recent approaches leverage vision-language models such as CLIP with prompt-based learning to align image and text features. However, existing methods often exhibit weak discriminability between normal and abnormal prompts and lack principled scoring mechanisms for patch-level anomalies. We propose a deviation-guided prompt learning framework that integrates the semantic power of vision-language models with the statistical reliability of deviation-based scoring. Specifically, we replace fixed prompt prefixes with learnable context vectors shared across normal and abnormal prompts, while anomaly-specific suffix tokens enable class-aware alignment. To enhance separability, we introduce a deviation loss with Top-K Multiple Instance Learning (MIL), modeling patch-level features as Gaussian deviations from the normal distribution. This allows the network to assign higher anomaly scores to patches with statistically significant deviations, improving localization and interpretability. Experiments on the MVTecAD and VISA benchmarks demonstrate superior pixel-level detection performance compared to PromptAD and other baselines. Ablation studies further validate the effectiveness of learnable prompts, deviation-based scoring, and the Top-K MIL strategy.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Few-normal shot anomaly detection (FNSAD) aims to detect abnormal regions in images using only a few normal training samples, making the task highly challenging due to limited supervision and the diversity of potential defects. Recent approaches leverage vision-language models such as CLIP with prompt-based learning to align image and text features. However, existing methods often exhibit weak discriminability between normal and abnormal prompts and lack principled scoring mechanisms for patch-level anomalies. We propose a deviation-guided prompt learning framework that integrates the semantic power of vision-language models with the statistical reliability of deviation-based scoring. Specifically, we replace fixed prompt prefixes with learnable context vectors shared across normal and abnormal prompts, while anomaly-specific suffix tokens enable class-aware alignment. To enhance separability, we introduce a deviation loss with Top-K Multiple Instance Learning (MIL), modeling patch-level features as Gaussian deviations from the normal distribution. This allows the network to assign higher anomaly scores to patches with statistically significant deviations, improving localization and interpretability. Experiments on the MVTecAD and VISA benchmarks demonstrate superior pixel-level detection performance compared to PromptAD and other baselines. Ablation studies further validate the effectiveness of learnable prompts, deviation-based scoring, and the Top-K MIL strategy."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-21T20:35:51Z",
        "published_parsed": [
            2026,
            1,
            21,
            20,
            35,
            51,
            2,
            21,
            0
        ],
        "arxiv_comment": "8 pages",
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Morteza Poudineh"
            },
            {
                "name": "Marc Lalonde"
            }
        ],
        "author_detail": {
            "name": "Marc Lalonde"
        },
        "author": "Marc Lalonde",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "DevPrompt：用于单法线镜头图像异常检测的基于偏差的提示学习",
        "abstract_cn": "少正常镜头异常检测（FNSAD）旨在仅使用少量正常训练样本来检测图像中的异常区域，由于有限的监督和潜在缺陷的多样性，使得该任务极具挑战性。最近的方法利用视觉语言模型（例如 CLIP）和基于提示的学习来对齐图像和文本特征。然而，现有方法通常对正常和异常提示的区分能力较弱，并且缺乏针对补丁级异常的原则性评分机制。我们提出了一种偏差引导的即时学习框架，它将视觉语言模型的语义能力与基于偏差的评分的统计可靠性相结合。具体来说，我们用在正常和异常提示之间共享的可学习上下文向量替换固定提示前缀，而特定于异常的后缀标记启用类感知对齐。为了增强可分离性，我们引入了 Top-K 多实例学习 (MIL) 的偏差损失，将块级特征建模为与正态分布的高斯偏差。这使得网络能够为具有统计显着偏差的补丁分配更高的异常分数，从而提高定位和可解释性。 MVTecAD 和 VISA 基准测试的实验表明，与 PromptAD 和其他基准相比，具有卓越的像素级检测性能。消融研究进一步验证了可学习提示、基于偏差的评分和 Top-K MIL 策略的有效性。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15475v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15475v1",
        "title": "Seeing through Light and Darkness: Sensor-Physics Grounded Deblurring HDR NeRF from Single-Exposure Images and Events",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Seeing through Light and Darkness: Sensor-Physics Grounded Deblurring HDR NeRF from Single-Exposure Images and Events"
        },
        "updated": "2026-01-21T21:25:58Z",
        "updated_parsed": [
            2026,
            1,
            21,
            21,
            25,
            58,
            2,
            21,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15475v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15475v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Novel view synthesis from low dynamic range (LDR) blurry images, which are common in the wild, struggles to recover high dynamic range (HDR) and sharp 3D representations in extreme lighting conditions. Although existing methods employ event data to address this issue, they ignore the sensor-physics mismatches between the camera output and physical world radiance, resulting in suboptimal HDR and deblurring results. To cope with this problem, we propose a unified sensor-physics grounded NeRF framework for sharp HDR novel view synthesis from single-exposure blurry LDR images and corresponding events. We employ NeRF to directly represent the actual radiance of the 3D scene in the HDR domain and model raw HDR scene rays hitting the sensor pixels as in the physical world. A pixel-wise RGB mapping field is introduced to align the above rendered pixel values with the sensor-recorded LDR pixel values of the input images. A novel event mapping field is also designed to bridge the physical scene dynamics and actual event sensor output. The two mapping fields are jointly optimized with the NeRF network, leveraging the spatial and temporal dynamic information in events to enhance the sharp HDR 3D representation learning. Experiments on the collected and public datasets demonstrate that our method can achieve state-of-the-art deblurring HDR novel view synthesis results with single-exposure blurry LDR images and corresponding events.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Novel view synthesis from low dynamic range (LDR) blurry images, which are common in the wild, struggles to recover high dynamic range (HDR) and sharp 3D representations in extreme lighting conditions. Although existing methods employ event data to address this issue, they ignore the sensor-physics mismatches between the camera output and physical world radiance, resulting in suboptimal HDR and deblurring results. To cope with this problem, we propose a unified sensor-physics grounded NeRF framework for sharp HDR novel view synthesis from single-exposure blurry LDR images and corresponding events. We employ NeRF to directly represent the actual radiance of the 3D scene in the HDR domain and model raw HDR scene rays hitting the sensor pixels as in the physical world. A pixel-wise RGB mapping field is introduced to align the above rendered pixel values with the sensor-recorded LDR pixel values of the input images. A novel event mapping field is also designed to bridge the physical scene dynamics and actual event sensor output. The two mapping fields are jointly optimized with the NeRF network, leveraging the spatial and temporal dynamic information in events to enhance the sharp HDR 3D representation learning. Experiments on the collected and public datasets demonstrate that our method can achieve state-of-the-art deblurring HDR novel view synthesis results with single-exposure blurry LDR images and corresponding events."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-21T21:25:58Z",
        "published_parsed": [
            2026,
            1,
            21,
            21,
            25,
            58,
            2,
            21,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Yunshan Qi"
            },
            {
                "name": "Lin Zhu"
            },
            {
                "name": "Nan Bao"
            },
            {
                "name": "Yifan Zhao"
            },
            {
                "name": "Jia Li"
            }
        ],
        "author_detail": {
            "name": "Jia Li"
        },
        "author": "Jia Li",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "透视光明与黑暗：基于传感器物理的单次曝光图像和事件去模糊 HDR NeRF",
        "abstract_cn": "在野外常见的低动态范围 (LDR) 模糊图像的新颖视图合成很难在极端照明条件下恢复高动态范围 (HDR) 和清晰的 3D 表示。尽管现有方法采用事件数据来解决此问题，但它们忽略了相机输出和物理世界辐射亮度之间的传感器物理不匹配，从而导致 HDR 和去模糊结果不理想。为了解决这个问题，我们提出了一个基于传感器物理的统一 NeRF 框架，用于从单曝光模糊 LDR 图像和相应事件合成清晰的 HDR 新颖视图。我们使用 NeRF 直接表示 HDR 域中 3D 场景的实际辐射亮度，并对照射到传感器像素的原始 HDR 场景光线进行建模，就像在物理世界中一样。引入逐像素 RGB 映射字段，将上述渲染的像素值与传感器记录的输入图像的 LDR 像素值对齐。还设计了一个新颖的事件映射字段来桥接物理场景动态和实际事件传感器输出。这两个映射领域与 NeRF 网络联合优化，利用事件中的空间和时间动态信息来增强锐利的 HDR 3D 表示学习。对收集的公共数据集进行的实验表明，我们的方法可以通过单曝光模糊 LDR 图像和相应事件实现最先进的去模糊 HDR 新颖视图合成结果。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15490v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15490v1",
        "title": "Hybrid Vision Transformer_GAN Attribute Neutralizer for Mitigating Bias in Chest X_Ray Diagnosis",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Hybrid Vision Transformer_GAN Attribute Neutralizer for Mitigating Bias in Chest X_Ray Diagnosis"
        },
        "updated": "2026-01-21T21:43:19Z",
        "updated_parsed": [
            2026,
            1,
            21,
            21,
            43,
            19,
            2,
            21,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15490v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15490v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Bias in chest X-ray classifiers frequently stems from sex- and age-related shortcuts, leading to systematic underdiagnosis of minority subgroups. Previous pixel-space attribute neutralizers, which rely on convolutional encoders, lessen but do not fully remove this attribute leakage at clinically usable edit strengths. This study evaluates whether substituting the U-Net convolutional encoder with a Vision Transformer backbone in the Attribute-Neutral Framework can reduce demographic attribute leakage while preserving diagnostic accuracy. A data-efficient Image Transformer Small (DeiT-S) neutralizer was trained on the ChestX-ray14 dataset. Its edited images, generated across eleven edit-intensity levels, were evaluated with an independent AI judge for attribute leakage and with a convolutional neural network (ConvNet) for disease prediction. At a moderate edit level (alpha = 0.5), the Vision Transformer (ViT) neutralizer reduces patient sex-recognition area under the curve (AUC) to approximately 0.80, about 10 percentage points below the original framework's convolutional U-Net encoder, despite being trained for only half as many epochs. Meanwhile, macro receiver operating characteristic area under the curve (ROC AUC) across 15 findings stays within five percentage points of the unedited baseline, and the worst-case subgroup AUC remains near 0.70. These results indicate that global self-attention vision models can further suppress attribute leakage without sacrificing clinical utility, suggesting a practical route toward fairer chest X-ray AI.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Bias in chest X-ray classifiers frequently stems from sex- and age-related shortcuts, leading to systematic underdiagnosis of minority subgroups. Previous pixel-space attribute neutralizers, which rely on convolutional encoders, lessen but do not fully remove this attribute leakage at clinically usable edit strengths. This study evaluates whether substituting the U-Net convolutional encoder with a Vision Transformer backbone in the Attribute-Neutral Framework can reduce demographic attribute leakage while preserving diagnostic accuracy. A data-efficient Image Transformer Small (DeiT-S) neutralizer was trained on the ChestX-ray14 dataset. Its edited images, generated across eleven edit-intensity levels, were evaluated with an independent AI judge for attribute leakage and with a convolutional neural network (ConvNet) for disease prediction. At a moderate edit level (alpha = 0.5), the Vision Transformer (ViT) neutralizer reduces patient sex-recognition area under the curve (AUC) to approximately 0.80, about 10 percentage points below the original framework's convolutional U-Net encoder, despite being trained for only half as many epochs. Meanwhile, macro receiver operating characteristic area under the curve (ROC AUC) across 15 findings stays within five percentage points of the unedited baseline, and the worst-case subgroup AUC remains near 0.70. These results indicate that global self-attention vision models can further suppress attribute leakage without sacrificing clinical utility, suggesting a practical route toward fairer chest X-ray AI."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-21T21:43:19Z",
        "published_parsed": [
            2026,
            1,
            21,
            21,
            43,
            19,
            2,
            21,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Jobeal Solomon"
            },
            {
                "name": "Ali Mohammed Mansoor Alsahag"
            },
            {
                "name": "Seyed Sahand Mohammadi Ziabari"
            }
        ],
        "author_detail": {
            "name": "Seyed Sahand Mohammadi Ziabari"
        },
        "author": "Seyed Sahand Mohammadi Ziabari",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "混合视觉 Transformer_GAN 属性中和器，用于减轻胸部 X 射线诊断中的偏差",
        "abstract_cn": "胸部 X 光分类器的偏差常常源于与性别和年龄相关的捷径，导致少数亚组的系统性诊断不足。以前的像素空间属性中和器依赖于卷积编码器，在临床可用的编辑强度下减少但没有完全消除这种属性泄漏。本研究评估在属性中性框架中用 Vision Transformer 主干替代 U-Net 卷积编码器是否可以减少人口统计属性泄漏，同时保持诊断准确性。在 ChestX-ray14 数据集上训练了数据高效的 Image Transformer Small (DeiT-S) 中和器。其编辑后的图像在 11 个编辑强度级别上生成，并由独立的人工智能法官评估属性泄漏，并使用卷积神经网络 (ConvNet) 进行疾病预测。在中等编辑水平（alpha = 0.5）下，Vision Transformer (ViT) 中和器将患者性别识别曲线下面积 (AUC) 降低至约 0.80，比原始框架的卷积 U-Net 编码器低约 10 个百分点，尽管训练次数仅为原来框架的一半。与此同时，15 个研究结果的宏观受试者工作特征曲线下面积 (ROC AUC) 与未经编辑的基线相比保持在 5 个百分点以内，最坏情况亚组 AUC 仍接近 0.70。这些结果表明，全局自注意力视觉模型可以在不牺牲临床实用性的情况下进一步抑制属性泄漏，这为实现更公平的胸部 X 射线人工智能提供了一条实用途径。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15507v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15507v1",
        "title": "Controllable Layered Image Generation for Real-World Editing",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Controllable Layered Image Generation for Real-World Editing"
        },
        "updated": "2026-01-21T22:29:33Z",
        "updated_parsed": [
            2026,
            1,
            21,
            22,
            29,
            33,
            2,
            21,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15507v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15507v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Recent image generation models have shown impressive progress, yet they often struggle to yield controllable and consistent results when users attempt to edit specific elements within an existing image. Layered representations enable flexible, user-driven content creation, but existing approaches often fail to produce layers with coherent compositing relationships, and their object layers typically lack realistic visual effects such as shadows and reflections. To overcome these limitations, we propose LASAGNA, a novel, unified framework that generates an image jointly with its composing layers--a photorealistic background and a high-quality transparent foreground with compelling visual effects. Unlike prior work, LASAGNA efficiently learns correct image composition from a wide range of conditioning inputs--text prompts, foreground, background, and location masks--offering greater controllability for real-world applications. To enable this, we introduce LASAGNA-48K, a new dataset composed of clean backgrounds and RGBA foregrounds with physically grounded visual effects. We also propose LASAGNABENCH, the first benchmark for layer editing. We demonstrate that LASAGNA excels in generating highly consistent and coherent results across multiple image layers simultaneously, enabling diverse post-editing applications that accurately preserve identity and visual effects. LASAGNA-48K and LASAGNABENCH will be publicly released to foster open research in the community. The project page is https://rayjryang.github.io/LASAGNA-Page/.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Recent image generation models have shown impressive progress, yet they often struggle to yield controllable and consistent results when users attempt to edit specific elements within an existing image. Layered representations enable flexible, user-driven content creation, but existing approaches often fail to produce layers with coherent compositing relationships, and their object layers typically lack realistic visual effects such as shadows and reflections. To overcome these limitations, we propose LASAGNA, a novel, unified framework that generates an image jointly with its composing layers--a photorealistic background and a high-quality transparent foreground with compelling visual effects. Unlike prior work, LASAGNA efficiently learns correct image composition from a wide range of conditioning inputs--text prompts, foreground, background, and location masks--offering greater controllability for real-world applications. To enable this, we introduce LASAGNA-48K, a new dataset composed of clean backgrounds and RGBA foregrounds with physically grounded visual effects. We also propose LASAGNABENCH, the first benchmark for layer editing. We demonstrate that LASAGNA excels in generating highly consistent and coherent results across multiple image layers simultaneously, enabling diverse post-editing applications that accurately preserve identity and visual effects. LASAGNA-48K and LASAGNABENCH will be publicly released to foster open research in the community. The project page is https://rayjryang.github.io/LASAGNA-Page/."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-21T22:29:33Z",
        "published_parsed": [
            2026,
            1,
            21,
            22,
            29,
            33,
            2,
            21,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Jinrui Yang"
            },
            {
                "name": "Qing Liu"
            },
            {
                "name": "Yijun Li"
            },
            {
                "name": "Mengwei Ren"
            },
            {
                "name": "Letian Zhang"
            },
            {
                "name": "Zhe Lin"
            },
            {
                "name": "Cihang Xie"
            },
            {
                "name": "Yuyin Zhou"
            }
        ],
        "author_detail": {
            "name": "Yuyin Zhou"
        },
        "author": "Yuyin Zhou",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "用于现实世界编辑的可控分层图像生成",
        "abstract_cn": "最近的图像生成模型已经显示出令人印象深刻的进步，但当用户尝试编辑现有图像中的特定元素时，它们通常难以产生可控且一致的结果。分层表示可以实现灵活的、用户驱动的内容创建，但现有方法通常无法生成具有连贯合成关系的图层，并且它们的对象图层通常缺乏真实的视觉效果，例如阴影和反射。为了克服这些限制，我们提出了 LASAGNA，这是一种新颖的、统一的框架，可以与其合成层联合生成图像——逼真的背景和具有引人注目的视觉效果的高质量透明前景。与之前的工作不同，LASAGNA 可以从各种条件输入（文本提示、前景、背景和位置蒙版）中有效地学习正确的图像构成，为现实世界的应用提供更大的可控性。为了实现这一点，我们引入了 LASAGNA-48K，这是一个由干净背景和 RGBA 前景组成的新数据集，具有物理基础的视觉效果。我们还提出了 LASAGNABENCH，这是图层编辑的第一个基准。我们证明，LASAGNA 擅长同时跨多个图像层生成高度一致和连贯的结果，从而支持准确保留身份和视觉效果的各种后期编辑应用程序。 LASAGNA-48K 和 LASAGNABENCH 将公开发布，以促进社区的开放研究。项目页面为 https://rayjryang.github.io/LASAGNA-Page/。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15516v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15516v1",
        "title": "DeltaDorsal: Enhancing Hand Pose Estimation with Dorsal Features in Egocentric Views",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "DeltaDorsal: Enhancing Hand Pose Estimation with Dorsal Features in Egocentric Views"
        },
        "updated": "2026-01-21T23:00:43Z",
        "updated_parsed": [
            2026,
            1,
            21,
            23,
            0,
            43,
            2,
            21,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15516v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15516v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "The proliferation of XR devices has made egocentric hand pose estimation a vital task, yet this perspective is inherently challenged by frequent finger occlusions. To address this, we propose a novel approach that leverages the rich information in dorsal hand skin deformation, unlocked by recent advances in dense visual featurizers. We introduce a dual-stream delta encoder that learns pose by contrasting features from a dynamic hand with a baseline relaxed position. Our evaluation demonstrates that, using only cropped dorsal images, our method reduces the Mean Per Joint Angle Error (MPJAE) by 18% in self-occluded scenarios (fingers >=50% occluded) compared to state-of-the-art techniques that depend on the whole hand's geometry and large model backbones. Consequently, our method not only enhances the reliability of downstream tasks like index finger pinch and tap estimation in occluded scenarios but also unlocks new interaction paradigms, such as detecting isometric force for a surface \"click\" without visible movement while minimizing model size.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "The proliferation of XR devices has made egocentric hand pose estimation a vital task, yet this perspective is inherently challenged by frequent finger occlusions. To address this, we propose a novel approach that leverages the rich information in dorsal hand skin deformation, unlocked by recent advances in dense visual featurizers. We introduce a dual-stream delta encoder that learns pose by contrasting features from a dynamic hand with a baseline relaxed position. Our evaluation demonstrates that, using only cropped dorsal images, our method reduces the Mean Per Joint Angle Error (MPJAE) by 18% in self-occluded scenarios (fingers >=50% occluded) compared to state-of-the-art techniques that depend on the whole hand's geometry and large model backbones. Consequently, our method not only enhances the reliability of downstream tasks like index finger pinch and tap estimation in occluded scenarios but also unlocks new interaction paradigms, such as detecting isometric force for a surface \"click\" without visible movement while minimizing model size."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.HC",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.LG",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-21T23:00:43Z",
        "published_parsed": [
            2026,
            1,
            21,
            23,
            0,
            43,
            2,
            21,
            0
        ],
        "arxiv_comment": "16 pages, 11 figures, Presented at ACM CHI 2026. For associated codebase, see https://github.com/hilab-open-source/deltadorsal",
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "William Huang"
            },
            {
                "name": "Siyou Pei"
            },
            {
                "name": "Leyi Zou"
            },
            {
                "name": "Eric J. Gonzalez"
            },
            {
                "name": "Ishan Chatterjee"
            },
            {
                "name": "Yang Zhang"
            }
        ],
        "author_detail": {
            "name": "Yang Zhang"
        },
        "author": "Yang Zhang",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "DeltaDorsal：利用自我中心视图中的背部特征增强手部姿势估计",
        "abstract_cn": "XR 设备的激增使得以自我为中心的手势估计成为一项重要任务，但这种观点本质上受到频繁的手指遮挡的挑战。为了解决这个问题，我们提出了一种新颖的方法，利用密集视觉特征器的最新进展解锁的手背皮肤变形的丰富信息。我们引入了一种双流增量编码器，它通过对比动态手与基线放松位置的特征来学习姿势。我们的评估表明，与依赖于整个手的几何形状和大型模型主干的最先进技术相比，仅使用裁剪的背部图像，我们的方法在自遮挡场景（手指 >= 50% 遮挡）中将平均每关节角度误差 (MPJAE) 降低了 18%。因此，我们的方法不仅增强了下游任务的可靠性，例如在遮挡场景中食指捏合和敲击估计，而且还解锁了新的交互范例，例如在没有可见移动的情况下检测表面“点击”的等距力，同时最小化模型尺寸。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15560v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15560v1",
        "title": "Relative Classification Accuracy: A Calibrated Metric for Identity Consistency in Fine-Grained K-pop Face Generation",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Relative Classification Accuracy: A Calibrated Metric for Identity Consistency in Fine-Grained K-pop Face Generation"
        },
        "updated": "2026-01-22T00:58:59Z",
        "updated_parsed": [
            2026,
            1,
            22,
            0,
            58,
            59,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15560v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15560v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Denoising Diffusion Probabilistic Models (DDPMs) have achieved remarkable success in high-fidelity image generation. However, evaluating their semantic controllability-specifically for fine-grained, single-domain tasks-remains challenging. Standard metrics like FID and Inception Score (IS) often fail to detect identity misalignment in such specialized contexts. In this work, we investigate Class-Conditional DDPMs for K-pop idol face generation (32x32), a domain characterized by high inter-class similarity. We propose a calibrated metric, Relative Classification Accuracy (RCA), which normalizes generative performance against an oracle classifier's baseline. Our evaluation reveals a critical trade-off: while the model achieves high visual quality (FID 8.93), it suffers from severe semantic mode collapse (RCA 0.27), particularly for visually ambiguous identities. We analyze these failure modes through confusion matrices and attribute them to resolution constraints and intra-gender ambiguity. Our framework provides a rigorous standard for verifying identity consistency in conditional generative models.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Denoising Diffusion Probabilistic Models (DDPMs) have achieved remarkable success in high-fidelity image generation. However, evaluating their semantic controllability-specifically for fine-grained, single-domain tasks-remains challenging. Standard metrics like FID and Inception Score (IS) often fail to detect identity misalignment in such specialized contexts. In this work, we investigate Class-Conditional DDPMs for K-pop idol face generation (32x32), a domain characterized by high inter-class similarity. We propose a calibrated metric, Relative Classification Accuracy (RCA), which normalizes generative performance against an oracle classifier's baseline. Our evaluation reveals a critical trade-off: while the model achieves high visual quality (FID 8.93), it suffers from severe semantic mode collapse (RCA 0.27), particularly for visually ambiguous identities. We analyze these failure modes through confusion matrices and attribute them to resolution constraints and intra-gender ambiguity. Our framework provides a rigorous standard for verifying identity consistency in conditional generative models."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T00:58:59Z",
        "published_parsed": [
            2026,
            1,
            22,
            0,
            58,
            59,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Sylvey Lin"
            },
            {
                "name": "Eranki Vasistha"
            }
        ],
        "author_detail": {
            "name": "Eranki Vasistha"
        },
        "author": "Eranki Vasistha",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "相对分类准确性：细粒度 K-pop 人脸生成中身份一致性的校准指标",
        "abstract_cn": "去噪扩散概率模型（DDPM）在高保真图像生成方面取得了显着的成功。然而，评估它们的语义可控性（特别是针对细粒度、单域任务）仍然具有挑战性。 FID 和初始分数 (IS) 等标准指标通常无法检测此类专门环境中的身份错位。在这项工作中，我们研究了用于 K-pop 偶像脸部生成 (32x32) 的类条件 DDPM，这是一个以类间高度相似性为特征的领域。我们提出了一个校准指标，即相对分类精度（RCA），它根据预言机分类器的基线标准化生成性能。我们的评估揭示了一个关键的权衡：虽然该模型实现了高视觉质量（FID 8.93），但它遭受了严重的语义模式崩溃（RCA 0.27），特别是对于视觉上模糊的身份。我们通过混淆矩阵分析这些失败模式，并将其归因于分辨率限制和性别内部模糊性。我们的框架为验证条件生成模型中的身份一致性提供了严格的标准。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15624v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15624v1",
        "title": "Explainable Deepfake Detection with RL Enhanced Self-Blended Images",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Explainable Deepfake Detection with RL Enhanced Self-Blended Images"
        },
        "updated": "2026-01-22T03:55:46Z",
        "updated_parsed": [
            2026,
            1,
            22,
            3,
            55,
            46,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15624v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15624v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Most prior deepfake detection methods lack explainable outputs. With the growing interest in multimodal large language models (MLLMs), researchers have started exploring their use in interpretable deepfake detection. However, a major obstacle in applying MLLMs to this task is the scarcity of high-quality datasets with detailed forgery attribution annotations, as textual annotation is both costly and challenging - particularly for high-fidelity forged images or videos. Moreover, multiple studies have shown that reinforcement learning (RL) can substantially enhance performance in visual tasks, especially in improving cross-domain generalization. To facilitate the adoption of mainstream MLLM frameworks in deepfake detection with reduced annotation cost, and to investigate the potential of RL in this context, we propose an automated Chain-of-Thought (CoT) data generation framework based on Self-Blended Images, along with an RL-enhanced deepfake detection framework. Extensive experiments validate the effectiveness of our CoT data construction pipeline, tailored reward mechanism, and feedback-driven synthetic data generation approach. Our method achieves performance competitive with state-of-the-art (SOTA) approaches across multiple cross-dataset benchmarks. Implementation details are available at https://github.com/deon1219/rlsbi.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Most prior deepfake detection methods lack explainable outputs. With the growing interest in multimodal large language models (MLLMs), researchers have started exploring their use in interpretable deepfake detection. However, a major obstacle in applying MLLMs to this task is the scarcity of high-quality datasets with detailed forgery attribution annotations, as textual annotation is both costly and challenging - particularly for high-fidelity forged images or videos. Moreover, multiple studies have shown that reinforcement learning (RL) can substantially enhance performance in visual tasks, especially in improving cross-domain generalization. To facilitate the adoption of mainstream MLLM frameworks in deepfake detection with reduced annotation cost, and to investigate the potential of RL in this context, we propose an automated Chain-of-Thought (CoT) data generation framework based on Self-Blended Images, along with an RL-enhanced deepfake detection framework. Extensive experiments validate the effectiveness of our CoT data construction pipeline, tailored reward mechanism, and feedback-driven synthetic data generation approach. Our method achieves performance competitive with state-of-the-art (SOTA) approaches across multiple cross-dataset benchmarks. Implementation details are available at https://github.com/deon1219/rlsbi."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T03:55:46Z",
        "published_parsed": [
            2026,
            1,
            22,
            3,
            55,
            46,
            3,
            22,
            0
        ],
        "arxiv_comment": "Accepted at ICASSP 2026",
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Ning Jiang"
            },
            {
                "name": "Dingheng Zeng"
            },
            {
                "name": "Yanhong Liu"
            },
            {
                "name": "Haiyang Yi"
            },
            {
                "name": "Shijie Yu"
            },
            {
                "name": "Minghe Weng"
            },
            {
                "name": "Haifeng Shen"
            },
            {
                "name": "Ying Li"
            }
        ],
        "author_detail": {
            "name": "Ying Li"
        },
        "author": "Ying Li",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "使用 RL 增强型自混合图像进行可解释的 Deepfake 检测",
        "abstract_cn": "大多数现有的深度伪造检测方法缺乏可解释的输出。随着人们对多模态大语言模型（MLLM）的兴趣日益浓厚，研究人员开始探索它们在可解释的深度伪造检测中的应用。然而，将 MLLM 应用于此任务的一个主要障碍是缺乏具有详细伪造属性注释的高质量数据集，因为文本注释既昂贵又具有挑战性 - 特别是对于高保真伪造图像或视频。此外，多项研究表明强化学习（RL）可以显着提高视觉任务的表现，特别是在提高跨领域泛化能力方面。为了促进在 Deepfake 检测中采用主流 MLLM 框架并降低注释成本，并研究 RL 在这方面的潜力，我们提出了一种基于自混合图像的自动化思想链（CoT）数据生成框架，以及 RL 增强的 Deepfake 检测框架。大量的实验验证了我们的 CoT 数据构建管道、定制奖励机制和反馈驱动的合成数据生成方法的有效性。我们的方法在多个跨数据集基准测试中实现了与最先进 (SOTA) 方法相媲美的性能。实施细节可在 https://github.com/deon1219/rlsbi 获取。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15643v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15643v1",
        "title": "Evolving Without Ending: Unifying Multimodal Incremental Learning for Continual Panoptic Perception",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Evolving Without Ending: Unifying Multimodal Incremental Learning for Continual Panoptic Perception"
        },
        "updated": "2026-01-22T04:45:28Z",
        "updated_parsed": [
            2026,
            1,
            22,
            4,
            45,
            28,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15643v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15643v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Continual learning (CL) is a great endeavour in developing intelligent perception AI systems. However, the pioneer research has predominantly focus on single-task CL, which restricts the potential in multi-task and multimodal scenarios. Beyond the well-known issue of catastrophic forgetting, the multi-task CL also brings semantic obfuscation across multimodal alignment, leading to severe model degradation during incremental training steps. In this paper, we extend CL to continual panoptic perception (CPP), integrating multimodal and multi-task CL to enhance comprehensive image perception through pixel-level, instance-level, and image-level joint interpretation. We formalize the CL task in multimodal scenarios and propose an end-to-end continual panoptic perception model. Concretely, CPP model features a collaborative cross-modal encoder (CCE) for multimodal embedding. We also propose a malleable knowledge inheritance module via contrastive feature distillation and instance distillation, addressing catastrophic forgetting from task-interactive boosting manner. Furthermore, we propose a cross-modal consistency constraint and develop CPP+, ensuring multimodal semantic alignment for model updating under multi-task incremental scenarios. Additionally, our proposed model incorporates an asymmetric pseudo-labeling manner, enabling model evolving without exemplar replay. Extensive experiments on multimodal datasets and diverse CL tasks demonstrate the superiority of the proposed model, particularly in fine-grained CL tasks.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Continual learning (CL) is a great endeavour in developing intelligent perception AI systems. However, the pioneer research has predominantly focus on single-task CL, which restricts the potential in multi-task and multimodal scenarios. Beyond the well-known issue of catastrophic forgetting, the multi-task CL also brings semantic obfuscation across multimodal alignment, leading to severe model degradation during incremental training steps. In this paper, we extend CL to continual panoptic perception (CPP), integrating multimodal and multi-task CL to enhance comprehensive image perception through pixel-level, instance-level, and image-level joint interpretation. We formalize the CL task in multimodal scenarios and propose an end-to-end continual panoptic perception model. Concretely, CPP model features a collaborative cross-modal encoder (CCE) for multimodal embedding. We also propose a malleable knowledge inheritance module via contrastive feature distillation and instance distillation, addressing catastrophic forgetting from task-interactive boosting manner. Furthermore, we propose a cross-modal consistency constraint and develop CPP+, ensuring multimodal semantic alignment for model updating under multi-task incremental scenarios. Additionally, our proposed model incorporates an asymmetric pseudo-labeling manner, enabling model evolving without exemplar replay. Extensive experiments on multimodal datasets and diverse CL tasks demonstrate the superiority of the proposed model, particularly in fine-grained CL tasks."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T04:45:28Z",
        "published_parsed": [
            2026,
            1,
            22,
            4,
            45,
            28,
            3,
            22,
            0
        ],
        "arxiv_comment": "arXiv admin note: substantial text overlap with arXiv:2407.14242",
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Bo Yuan"
            },
            {
                "name": "Danpei Zhao"
            },
            {
                "name": "Wentao Li"
            },
            {
                "name": "Tian Li"
            },
            {
                "name": "Zhiguo Jiang"
            }
        ],
        "author_detail": {
            "name": "Zhiguo Jiang"
        },
        "author": "Zhiguo Jiang",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "不断进化：统一多模态增量学习以实现持续的全景感知",
        "abstract_cn": "持续学习（CL）是开发智能感知人工智能系统的伟大努力。然而，先驱研究主要集中在单任务 CL 上，这限制了多任务和多模式场景中的潜力。除了众所周知的灾难性遗忘问题之外，多任务 CL 还带来了多模态对齐的语义混淆，导致增量训练步骤中模型严重退化。在本文中，我们将 CL 扩展到连续全景感知（CPP），集成多模态和多任务 CL，通过像素级、实例级和图像级联合解释来增强综合图像感知。我们在多模态场景中形式化了 CL 任务，并提出了一种端到端的连续全景感知模型。具体来说，CPP 模型具有用于多模态嵌入的协作跨模态编码器（CCE）。我们还通过对比特征蒸馏和实例蒸馏提出了可延展的知识继承模块，解决任务交互提升方式中的灾难性遗忘问题。此外，我们提出了跨模态一致性约束并开发了CPP+，确保多任务增量场景下模型更新的多模态语义对齐。此外，我们提出的模型采用了非对称伪标记方式，使模型能够在没有样本重放的情况下进化。对多模态数据集和各种 CL 任务的大量实验证明了所提出模型的优越性，特别是在细粒度 CL 任务中。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15664v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15664v1",
        "title": "Skywork UniPic 3.0: Unified Multi-Image Composition via Sequence Modeling",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Skywork UniPic 3.0: Unified Multi-Image Composition via Sequence Modeling"
        },
        "updated": "2026-01-22T05:23:20Z",
        "updated_parsed": [
            2026,
            1,
            22,
            5,
            23,
            20,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15664v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15664v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "The recent surge in popularity of Nano-Banana and Seedream 4.0 underscores the community's strong interest in multi-image composition tasks. Compared to single-image editing, multi-image composition presents significantly greater challenges in terms of consistency and quality, yet existing models have not disclosed specific methodological details for achieving high-quality fusion. Through statistical analysis, we identify Human-Object Interaction (HOI) as the most sought-after category by the community. We therefore systematically analyze and implement a state-of-the-art solution for multi-image composition with a primary focus on HOI-centric tasks. We present Skywork UniPic 3.0, a unified multimodal framework that integrates single-image editing and multi-image composition. Our model supports an arbitrary (1~6) number and resolution of input images, as well as arbitrary output resolutions (within a total pixel budget of 1024x1024). To address the challenges of multi-image composition, we design a comprehensive data collection, filtering, and synthesis pipeline, achieving strong performance with only 700K high-quality training samples. Furthermore, we introduce a novel training paradigm that formulates multi-image composition as a sequence-modeling problem, transforming conditional generation into unified sequence synthesis. To accelerate inference, we integrate trajectory mapping and distribution matching into the post-training stage, enabling the model to produce high-fidelity samples in just 8 steps and achieve a 12.5x speedup over standard synthesis sampling. Skywork UniPic 3.0 achieves state-of-the-art performance on single-image editing benchmark and surpasses both Nano-Banana and Seedream 4.0 on multi-image composition benchmark, thereby validating the effectiveness of our data pipeline and training paradigm. Code, models and dataset are publicly available.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "The recent surge in popularity of Nano-Banana and Seedream 4.0 underscores the community's strong interest in multi-image composition tasks. Compared to single-image editing, multi-image composition presents significantly greater challenges in terms of consistency and quality, yet existing models have not disclosed specific methodological details for achieving high-quality fusion. Through statistical analysis, we identify Human-Object Interaction (HOI) as the most sought-after category by the community. We therefore systematically analyze and implement a state-of-the-art solution for multi-image composition with a primary focus on HOI-centric tasks. We present Skywork UniPic 3.0, a unified multimodal framework that integrates single-image editing and multi-image composition. Our model supports an arbitrary (1~6) number and resolution of input images, as well as arbitrary output resolutions (within a total pixel budget of 1024x1024). To address the challenges of multi-image composition, we design a comprehensive data collection, filtering, and synthesis pipeline, achieving strong performance with only 700K high-quality training samples. Furthermore, we introduce a novel training paradigm that formulates multi-image composition as a sequence-modeling problem, transforming conditional generation into unified sequence synthesis. To accelerate inference, we integrate trajectory mapping and distribution matching into the post-training stage, enabling the model to produce high-fidelity samples in just 8 steps and achieve a 12.5x speedup over standard synthesis sampling. Skywork UniPic 3.0 achieves state-of-the-art performance on single-image editing benchmark and surpasses both Nano-Banana and Seedream 4.0 on multi-image composition benchmark, thereby validating the effectiveness of our data pipeline and training paradigm. Code, models and dataset are publicly available."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.AI",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T05:23:20Z",
        "published_parsed": [
            2026,
            1,
            22,
            5,
            23,
            20,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Hongyang Wei"
            },
            {
                "name": "Hongbo Liu"
            },
            {
                "name": "Zidong Wang"
            },
            {
                "name": "Yi Peng"
            },
            {
                "name": "Baixin Xu"
            },
            {
                "name": "Size Wu"
            },
            {
                "name": "Xuying Zhang"
            },
            {
                "name": "Xianglong He"
            },
            {
                "name": "Zexiang Liu"
            },
            {
                "name": "Peiyu Wang"
            },
            {
                "name": "Xuchen Song"
            },
            {
                "name": "Yangguang Li"
            },
            {
                "name": "Yang Liu"
            },
            {
                "name": "Yahui Zhou"
            }
        ],
        "author_detail": {
            "name": "Yahui Zhou"
        },
        "author": "Yahui Zhou",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "Skywork UniPic 3.0：通过序列建模统一多图像合成",
        "abstract_cn": "Nano-Banana 和 Seedream 4.0 最近的流行度突显了社区对多图像合成任务的浓厚兴趣。与单图像编辑相比，多图像合成在一致性和质量方面提出了更大的挑战，但现有模型尚未公开实现高质量融合的具体方法细节。通过统计分析，我们将人机交互（HOI）确定为社区最抢手的类别。因此，我们系统地分析和实施了最先进的多图像合成解决方案，主要关注以 HOI 为中心的任务。我们推出了 Skywork UniPic 3.0，这是一个集成了单图像编辑和多图像合成的统一多模式框架。我们的模型支持任意 (1~6) 数量和分辨率的输入图像，以及任意输出分辨率（在 1024x1024 的总像素预算内）。为了解决多图像合成的挑战，我们设计了全面的数据收集、过滤和合成管道，仅用 70 万个高质量训练样本即可实现强大的性能。此外，我们引入了一种新颖的训练范例，将多图像合成表述为序列建模问题，将条件生成转化为统一的序列合成。为了加速推理，我们将轨迹映射和分布匹配集成到训练后阶段，使模型只需 8 个步骤即可生成高保真样本，并比标准合成采样实现 12.5 倍的加速。 Skywork UniPic 3.0 在单图像编辑基准上实现了最先进的性能，并在多图像合成基准上超越了 Nano-Banana 和 Seedream 4.0，从而验证了我们的数据管道和训练范例的有效性。代码、模型和数据集是公开的。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15698v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15698v1",
        "title": "Beyond Visual Safety: Jailbreaking Multimodal Large Language Models for Harmful Image Generation via Semantic-Agnostic Inputs",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Beyond Visual Safety: Jailbreaking Multimodal Large Language Models for Harmful Image Generation via Semantic-Agnostic Inputs"
        },
        "updated": "2026-01-22T06:56:27Z",
        "updated_parsed": [
            2026,
            1,
            22,
            6,
            56,
            27,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15698v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15698v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "The rapid advancement of Multimodal Large Language Models (MLLMs) has introduced complex security challenges, particularly at the intersection of textual and visual safety. While existing schemes have explored the security vulnerabilities of MLLMs, the investigation into their visual safety boundaries remains insufficient. In this paper, we propose Beyond Visual Safety (BVS), a novel image-text pair jailbreaking framework specifically designed to probe the visual safety boundaries of MLLMs. BVS employs a \"reconstruction-then-generation\" strategy, leveraging neutralized visual splicing and inductive recomposition to decouple malicious intent from raw inputs, thereby leading MLLMs to be induced into generating harmful images. Experimental results demonstrate that BVS achieves a remarkable jailbreak success rate of 98.21\\% against GPT-5 (12 January 2026 release). Our findings expose critical vulnerabilities in the visual safety alignment of current MLLMs.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "The rapid advancement of Multimodal Large Language Models (MLLMs) has introduced complex security challenges, particularly at the intersection of textual and visual safety. While existing schemes have explored the security vulnerabilities of MLLMs, the investigation into their visual safety boundaries remains insufficient. In this paper, we propose Beyond Visual Safety (BVS), a novel image-text pair jailbreaking framework specifically designed to probe the visual safety boundaries of MLLMs. BVS employs a \"reconstruction-then-generation\" strategy, leveraging neutralized visual splicing and inductive recomposition to decouple malicious intent from raw inputs, thereby leading MLLMs to be induced into generating harmful images. Experimental results demonstrate that BVS achieves a remarkable jailbreak success rate of 98.21\\% against GPT-5 (12 January 2026 release). Our findings expose critical vulnerabilities in the visual safety alignment of current MLLMs."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.AI",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T06:56:27Z",
        "published_parsed": [
            2026,
            1,
            22,
            6,
            56,
            27,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Mingyu Yu"
            },
            {
                "name": "Lana Liu"
            },
            {
                "name": "Zhehao Zhao"
            },
            {
                "name": "Wei Wang"
            },
            {
                "name": "Sujuan Qin"
            }
        ],
        "author_detail": {
            "name": "Sujuan Qin"
        },
        "author": "Sujuan Qin",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "超越视觉安全：通过与语义无关的输入生成有害图像的越狱多模态大型语言模型",
        "abstract_cn": "多模态大型语言模型 (MLLM) 的快速发展带来了复杂的安全挑战，特别是在文本和视觉安全的交叉点。虽然现有方案已经探索了 MLLM 的安全漏洞，但对其视觉安全边界的调查仍然不足。在本文中，我们提出了超越视觉安全（BVS），这是一种新颖的图像文本对越狱框架，专门用于探测 MLLM 的视觉安全边界。 BVS 采用“重建然后生成”策略，利用中和视觉拼接和归纳重组将恶意意图与原始输入分离，从而导致 MLLM 被诱导生成有害图像。实验结果表明，BVS 对 GPT-5（2026 年 1 月 12 日发布）的越狱成功率达到了 98.21%。我们的研究结果暴露了当前 MLLM 视觉安全调整中的关键漏洞。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15711v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15711v1",
        "title": "Zero-Shot Product Attribute Labeling with Vision-Language Models: A Three-Tier Evaluation Framework",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Zero-Shot Product Attribute Labeling with Vision-Language Models: A Three-Tier Evaluation Framework"
        },
        "updated": "2026-01-22T07:33:41Z",
        "updated_parsed": [
            2026,
            1,
            22,
            7,
            33,
            41,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15711v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15711v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Fine-grained attribute prediction is essential for fashion retail applications including catalog enrichment, visual search, and recommendation systems. Vision-Language Models (VLMs) offer zero-shot prediction without task-specific training, yet their systematic evaluation on multi-attribute fashion tasks remains underexplored. A key challenge is that fashion attributes are often conditional. For example, \"outer fabric\" is undefined when no outer garment is visible. This requires models to detect attribute applicability before attempting classification. We introduce a three-tier evaluation framework that decomposes this challenge: (1) overall task performance across all classes (including NA class: suggesting attribute is not applicable) for all attributes, (2) attribute applicability detection, and (3) fine-grained classification when attributes are determinable. Using DeepFashion-MultiModal, which explicitly defines NA (meaning attribute doesn't exist or is not visible) within attribute label spaces, we benchmark nine VLMs spanning flagship (GPT-5, Gemini 2.5 Pro), efficient (GPT-5 Mini, Gemini 2.5 Flash), and ultra-efficient tiers (GPT-5 Nano, Gemini 2.5 Flash-Lite) against classifiers trained on pretrained Fashion-CLIP embeddings on 5,000 images across 18 attributes. Our findings reveal that: (1) zero-shot VLMs achieve 64.0% macro-F1, a threefold improvement over logistic regression on pretrained Fashion-CLIP embeddings; (2) VLMs excel at fine-grained classification (Tier 3: 70.8% F1) but struggle with applicability detection (Tier 2: 34.1% NA-F1), identifying a key bottleneck; (3) efficient models achieve over 90% of flagship performance at lower cost, offering practical deployment paths. This diagnostic framework enables practitioners to pinpoint whether errors stem from visibility detection or classification, guiding targeted improvements for production systems.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Fine-grained attribute prediction is essential for fashion retail applications including catalog enrichment, visual search, and recommendation systems. Vision-Language Models (VLMs) offer zero-shot prediction without task-specific training, yet their systematic evaluation on multi-attribute fashion tasks remains underexplored. A key challenge is that fashion attributes are often conditional. For example, \"outer fabric\" is undefined when no outer garment is visible. This requires models to detect attribute applicability before attempting classification. We introduce a three-tier evaluation framework that decomposes this challenge: (1) overall task performance across all classes (including NA class: suggesting attribute is not applicable) for all attributes, (2) attribute applicability detection, and (3) fine-grained classification when attributes are determinable. Using DeepFashion-MultiModal, which explicitly defines NA (meaning attribute doesn't exist or is not visible) within attribute label spaces, we benchmark nine VLMs spanning flagship (GPT-5, Gemini 2.5 Pro), efficient (GPT-5 Mini, Gemini 2.5 Flash), and ultra-efficient tiers (GPT-5 Nano, Gemini 2.5 Flash-Lite) against classifiers trained on pretrained Fashion-CLIP embeddings on 5,000 images across 18 attributes. Our findings reveal that: (1) zero-shot VLMs achieve 64.0% macro-F1, a threefold improvement over logistic regression on pretrained Fashion-CLIP embeddings; (2) VLMs excel at fine-grained classification (Tier 3: 70.8% F1) but struggle with applicability detection (Tier 2: 34.1% NA-F1), identifying a key bottleneck; (3) efficient models achieve over 90% of flagship performance at lower cost, offering practical deployment paths. This diagnostic framework enables practitioners to pinpoint whether errors stem from visibility detection or classification, guiding targeted improvements for production systems."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T07:33:41Z",
        "published_parsed": [
            2026,
            1,
            22,
            7,
            33,
            41,
            3,
            22,
            0
        ],
        "arxiv_comment": "Accepted to WACV 2026 Workshop on Physical Retail AI (PRAW)",
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Shubham Shukla"
            },
            {
                "name": "Kunal Sonalkar"
            }
        ],
        "author_detail": {
            "name": "Kunal Sonalkar"
        },
        "author": "Kunal Sonalkar",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "使用视觉语言模型进行零样本产品属性标记：三层评估框架",
        "abstract_cn": "细粒度的属性预测对于时尚零售应用至关重要，包括目录丰富、视觉搜索和推荐系统。视觉语言模型（VLM）无需特定任务训练即可提供零样本预测，但其对多属性时尚任务的系统评估仍未得到充分探索。一个关键的挑战是时尚属性通常是有条件的。例如，当没有可见的外衣时，“外层织物”是未定义的。这需要模型在尝试分类之前检测属性的适用性。我们引入了一个三层评估框架来分解这一挑战：（1）所有属性的所有类（包括 NA 类：建议属性不适用）的总体任务性能，（2）属性适用性检测，以及（3）当属性可确定时的细粒度分类。使用 DeepFashion-MultiModal 在属性标签空间中明确定义 NA（表示属性不存在或不可见），我们对涵盖旗舰（GPT-5、Gemini 2.5 Pro）、高效（GPT-5 Mini、Gemini 2.5 Flash）和超高效层（GPT-5 Nano、Gemini 2.5 Flash-Lite）的 9 个 VLM 与在预训练的 Fashion-CLIP 嵌入上训练的分类器进行了基准测试涵盖 18 个属性的 5,000 张图像。我们的研究结果表明：(1) 零样本 VLM 实现了 64.0% 的宏 F1，比预训练 Fashion-CLIP 嵌入的逻辑回归提高了三倍； (2) VLM 擅长细粒度分类（第 3 层：70.8% F1），但在适用性检测方面遇到困难（第 2 层：34.1% NA-F1），识别关键瓶颈； (3)高效机型以更低的成本实现旗舰机90%以上的性能，提供实用的部署路径。该诊断框架使从业人员能够查明错误是否源于可见性检测或分类，从而指导生产系统的有针对性的改进。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15731v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15731v1",
        "title": "FAIR-ESI: Feature Adaptive Importance Refinement for Electrophysiological Source Imaging",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "FAIR-ESI: Feature Adaptive Importance Refinement for Electrophysiological Source Imaging"
        },
        "updated": "2026-01-22T07:57:27Z",
        "updated_parsed": [
            2026,
            1,
            22,
            7,
            57,
            27,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15731v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15731v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "An essential technique for diagnosing brain disorders is electrophysiological source imaging (ESI). While model-based optimization and deep learning methods have achieved promising results in this field, the accurate selection and refinement of features remains a central challenge for precise ESI. This paper proposes FAIR-ESI, a novel framework that adaptively refines feature importance across different views, including FFT-based spectral feature refinement, weighted temporal feature refinement, and self-attention-based patch-wise feature refinement. Extensive experiments on two simulation datasets with diverse configurations and two real-world clinical datasets validate our framework's efficacy, highlighting its potential to advance brain disorder diagnosis and offer new insights into brain function.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "An essential technique for diagnosing brain disorders is electrophysiological source imaging (ESI). While model-based optimization and deep learning methods have achieved promising results in this field, the accurate selection and refinement of features remains a central challenge for precise ESI. This paper proposes FAIR-ESI, a novel framework that adaptively refines feature importance across different views, including FFT-based spectral feature refinement, weighted temporal feature refinement, and self-attention-based patch-wise feature refinement. Extensive experiments on two simulation datasets with diverse configurations and two real-world clinical datasets validate our framework's efficacy, highlighting its potential to advance brain disorder diagnosis and offer new insights into brain function."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.AI",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T07:57:27Z",
        "published_parsed": [
            2026,
            1,
            22,
            7,
            57,
            27,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Linyong Zou"
            },
            {
                "name": "Liang Zhang"
            },
            {
                "name": "Xiongfei Wang"
            },
            {
                "name": "Jia-Hong Gao"
            },
            {
                "name": "Yi Sun"
            },
            {
                "name": "Shurong Sheng"
            },
            {
                "name": "Kuntao Xiao"
            },
            {
                "name": "Wanli Yang"
            },
            {
                "name": "Pengfei Teng"
            },
            {
                "name": "Guoming Luan"
            },
            {
                "name": "Zhao Lv"
            },
            {
                "name": "Zikang Xu"
            }
        ],
        "author_detail": {
            "name": "Zikang Xu"
        },
        "author": "Zikang Xu",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "FAIR-ESI：电生理源成像的特征自适应重要性细化",
        "abstract_cn": "诊断脑部疾病的一项重要技术是电生理源成像（ESI）。虽然基于模型的优化和深度学习方法在该领域取得了可喜的成果，但特征的准确选择和细化仍然是精确 ESI 的核心挑战。本文提出了 FAIR-ESI，这是一种新颖的框架，可以在不同视图中自适应地细化特征重要性，包括基于 FFT 的频谱特征细化、加权时间特征细化和基于自注意力的 patch-wise 特征细化。对两个具有不同配置的模拟数据集和两个真实世界的临床数据集进行的广泛实验验证了我们的框架的功效，突出了其推进脑部疾病诊断并提供对大脑功能的新见解的潜力。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15734v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15734v1",
        "title": "Sub-Region-Aware Modality Fusion and Adaptive Prompting for Multi-Modal Brain Tumor Segmentation",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Sub-Region-Aware Modality Fusion and Adaptive Prompting for Multi-Modal Brain Tumor Segmentation"
        },
        "updated": "2026-01-22T08:03:17Z",
        "updated_parsed": [
            2026,
            1,
            22,
            8,
            3,
            17,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15734v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15734v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "The successful adaptation of foundation models to multi-modal medical imaging is a critical yet unresolved challenge. Existing models often struggle to effectively fuse information from multiple sources and adapt to the heterogeneous nature of pathological tissues. To address this, we introduce a novel framework for adapting foundation models to multi-modal medical imaging, featuring two key technical innovations: sub-region-aware modality attention and adaptive prompt engineering. The attention mechanism enables the model to learn the optimal combination of modalities for each tumor sub-region, while the adaptive prompting strategy leverages the inherent capabilities of foundation models to refine segmentation accuracy. We validate our framework on the BraTS 2020 brain tumor segmentation dataset, demonstrating that our approach significantly outperforms baseline methods, particularly in the challenging necrotic core sub-region. Our work provides a principled and effective approach to multi-modal fusion and prompting, paving the way for more accurate and robust foundation model-based solutions in medical imaging.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "The successful adaptation of foundation models to multi-modal medical imaging is a critical yet unresolved challenge. Existing models often struggle to effectively fuse information from multiple sources and adapt to the heterogeneous nature of pathological tissues. To address this, we introduce a novel framework for adapting foundation models to multi-modal medical imaging, featuring two key technical innovations: sub-region-aware modality attention and adaptive prompt engineering. The attention mechanism enables the model to learn the optimal combination of modalities for each tumor sub-region, while the adaptive prompting strategy leverages the inherent capabilities of foundation models to refine segmentation accuracy. We validate our framework on the BraTS 2020 brain tumor segmentation dataset, demonstrating that our approach significantly outperforms baseline methods, particularly in the challenging necrotic core sub-region. Our work provides a principled and effective approach to multi-modal fusion and prompting, paving the way for more accurate and robust foundation model-based solutions in medical imaging."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T08:03:17Z",
        "published_parsed": [
            2026,
            1,
            22,
            8,
            3,
            17,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Shadi Alijani"
            },
            {
                "name": "Fereshteh Aghaee Meibodi"
            },
            {
                "name": "Homayoun Najjaran"
            }
        ],
        "author_detail": {
            "name": "Homayoun Najjaran"
        },
        "author": "Homayoun Najjaran",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "多模态脑肿瘤分割的子区域感知模态融合和自适应提示",
        "abstract_cn": "基础模型成功适应多模态医学成像是一个关键但尚未解决的挑战。现有模型通常难以有效地融合多个来源的信息并适应病理组织的异质性。为了解决这个问题，我们引入了一种使基础模型适应多模态医学成像的新颖框架，具有两项关键技术创新：子区域感知模态注意和自适应提示工程。注意力机制使模型能够学习每个肿瘤子区域的最佳模式组合，而自适应提示策略则利用基础模型的固有功能来提高分割精度。我们在 BraTS 2020 脑肿瘤分割数据集上验证了我们的框架，证明我们的方法显着优于基线方法，特别是在具有挑战性的坏死核心子区域。我们的工作为多模态融合和提示提供了一种有原则且有效的方法，为医学成像中更准确、更强大的基于基础模型的解决方案铺平了道路。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15739v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15739v1",
        "title": "Breaking the Resolution Barrier: Arbitrary-resolution Deep Image Steganography Framework",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Breaking the Resolution Barrier: Arbitrary-resolution Deep Image Steganography Framework"
        },
        "updated": "2026-01-22T08:07:10Z",
        "updated_parsed": [
            2026,
            1,
            22,
            8,
            7,
            10,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15739v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15739v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Deep image steganography (DIS) has achieved significant results in capacity and invisibility. However, current paradigms enforce the secret image to maintain the same resolution as the cover image during hiding and revealing. This leads to two challenges: secret images with inconsistent resolutions must undergo resampling beforehand which results in detail loss during recovery, and the secret image cannot be recovered to its original resolution when the resolution value is unknown. To address these, we propose ARDIS, the first Arbitrary Resolution DIS framework, which shifts the paradigm from discrete mapping to reference-guided continuous signal reconstruction. Specifically, to minimize the detail loss caused by resolution mismatch, we first design a Frequency Decoupling Architecture in hiding stage. It disentangles the secret into a resolution-aligned global basis and a resolution-agnostic high-frequency latent to hide in a fixed-resolution cover. Second, for recovery, we propose a Latent-Guided Implicit Reconstructor to perform deterministic restoration. The recovered detail latent code modulates a continuous implicit function to accurately query and render high-frequency residuals onto the recovered global basis, ensuring faithful restoration of original details. Furthermore, to achieve blind recovery, we introduce an Implicit Resolution Coding strategy. By transforming discrete resolution values into dense feature maps and hiding them in the redundant space of the feature domain, the reconstructor can correctly decode the secret's resolution directly from the steganographic representation. Experimental results demonstrate that ARDIS significantly outperforms state-of-the-art methods in both invisibility and cross-resolution recovery fidelity.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Deep image steganography (DIS) has achieved significant results in capacity and invisibility. However, current paradigms enforce the secret image to maintain the same resolution as the cover image during hiding and revealing. This leads to two challenges: secret images with inconsistent resolutions must undergo resampling beforehand which results in detail loss during recovery, and the secret image cannot be recovered to its original resolution when the resolution value is unknown. To address these, we propose ARDIS, the first Arbitrary Resolution DIS framework, which shifts the paradigm from discrete mapping to reference-guided continuous signal reconstruction. Specifically, to minimize the detail loss caused by resolution mismatch, we first design a Frequency Decoupling Architecture in hiding stage. It disentangles the secret into a resolution-aligned global basis and a resolution-agnostic high-frequency latent to hide in a fixed-resolution cover. Second, for recovery, we propose a Latent-Guided Implicit Reconstructor to perform deterministic restoration. The recovered detail latent code modulates a continuous implicit function to accurately query and render high-frequency residuals onto the recovered global basis, ensuring faithful restoration of original details. Furthermore, to achieve blind recovery, we introduce an Implicit Resolution Coding strategy. By transforming discrete resolution values into dense feature maps and hiding them in the redundant space of the feature domain, the reconstructor can correctly decode the secret's resolution directly from the steganographic representation. Experimental results demonstrate that ARDIS significantly outperforms state-of-the-art methods in both invisibility and cross-resolution recovery fidelity."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T08:07:10Z",
        "published_parsed": [
            2026,
            1,
            22,
            8,
            7,
            10,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Xinjue Hu"
            },
            {
                "name": "Chi Wang"
            },
            {
                "name": "Boyu Wang"
            },
            {
                "name": "Xiang Zhang"
            },
            {
                "name": "Zhenshan Tan"
            },
            {
                "name": "Zhangjie Fu"
            }
        ],
        "author_detail": {
            "name": "Zhangjie Fu"
        },
        "author": "Zhangjie Fu",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "打破分辨率障碍：任意分辨率深度图像隐写框架",
        "abstract_cn": "深度图像隐写术（DIS）在容量和隐秘性方面取得了显着的成果。然而，当前的范例强制秘密图像在隐藏和显示期间保持与封面图像相同的分辨率。这带来了两个挑战：分辨率不一致的秘密图像必须事先进行重采样，这会导致恢复过程中细节丢失；并且当分辨率值未知时，秘密图像无法恢复到原始分辨率。为了解决这些问题，我们提出了 ARDIS，这是第一个任意分辨率 DIS 框架，它将范式从离散映射转变为参考引导的连续信号重建。具体来说，为了最大限度地减少分辨率不匹配造成的细节损失，我们首先在隐藏阶段设计了频率解耦架构。它将秘密分解为与分辨率一致的全局基础和隐藏在固定分辨率覆盖物中的与分辨率无关的高频潜力。其次，对于恢复，我们提出了一个潜在引导隐式重建器来执行确定性恢复。恢复的细节潜在代码调制连续隐式函数，以准确查询高频残差并将其渲染到恢复的全局基础上，确保忠实恢复原始细节。此外，为了实现盲恢复，我们引入了隐式解析编码策略。通过将离散分辨率值转换为密集特征图并将其隐藏在特征域的冗余空间中，重建器可以直接从隐写表示中正确解码秘密的分辨率。实验结果表明，ARDIS 在隐形性和跨分辨率恢复保真度方面均显着优于最先进的方法。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15757v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15757v1",
        "title": "White-Box mHC: Electromagnetic Spectrum-Aware and Interpretable Stream Interactions for Hyperspectral Image Classification",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "White-Box mHC: Electromagnetic Spectrum-Aware and Interpretable Stream Interactions for Hyperspectral Image Classification"
        },
        "updated": "2026-01-22T08:48:01Z",
        "updated_parsed": [
            2026,
            1,
            22,
            8,
            48,
            1,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15757v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15757v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "In hyperspectral image classification (HSIC), most deep learning models rely on opaque spectral-spatial feature mixing, limiting their interpretability and hindering understanding of internal decision mechanisms. We present physical spectrum-aware white-box mHC, named ES-mHC, a hyper-connection framework that explicitly models interactions among different electromagnetic spectrum groupings (residual stream in mHC) interactions using structured, directional matrices. By separating feature representation from interaction structure, ES-mHC promotes electromagnetic spectrum grouping specialization, reduces redundancy, and exposes internal information flow that can be directly visualized and spatially analyzed. Using hyperspectral image classification as a representative testbed, we demonstrate that the learned hyper-connection matrices exhibit coherent spatial patterns and asymmetric interaction behaviors, providing mechanistic insight into the model internal dynamics. Furthermore, we find that increasing the expansion rate accelerates the emergence of structured interaction patterns. These results suggest that ES-mHC transforms HSIC from a purely black-box prediction task into a structurally transparent, partially white-box learning process.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "In hyperspectral image classification (HSIC), most deep learning models rely on opaque spectral-spatial feature mixing, limiting their interpretability and hindering understanding of internal decision mechanisms. We present physical spectrum-aware white-box mHC, named ES-mHC, a hyper-connection framework that explicitly models interactions among different electromagnetic spectrum groupings (residual stream in mHC) interactions using structured, directional matrices. By separating feature representation from interaction structure, ES-mHC promotes electromagnetic spectrum grouping specialization, reduces redundancy, and exposes internal information flow that can be directly visualized and spatially analyzed. Using hyperspectral image classification as a representative testbed, we demonstrate that the learned hyper-connection matrices exhibit coherent spatial patterns and asymmetric interaction behaviors, providing mechanistic insight into the model internal dynamics. Furthermore, we find that increasing the expansion rate accelerates the emergence of structured interaction patterns. These results suggest that ES-mHC transforms HSIC from a purely black-box prediction task into a structurally transparent, partially white-box learning process."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T08:48:01Z",
        "published_parsed": [
            2026,
            1,
            22,
            8,
            48,
            1,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Yimin Zhu"
            },
            {
                "name": "Lincoln Linlin Xu"
            },
            {
                "name": "Zhengsen Xu"
            },
            {
                "name": "Zack Dewis"
            },
            {
                "name": "Mabel Heffring"
            },
            {
                "name": "Saeid Taleghanidoozdoozan"
            },
            {
                "name": "Motasem Alkayid"
            },
            {
                "name": "Quinn Ledingham"
            },
            {
                "name": "Megan Greenwood"
            }
        ],
        "author_detail": {
            "name": "Megan Greenwood"
        },
        "author": "Megan Greenwood",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "白盒 mHC：用于高光谱图像分类的电磁频谱感知和可解释流交互",
        "abstract_cn": "在高光谱图像分类（HSIC）中，大多数深度学习模型依赖于不透明的光谱空间特征混合，限制了它们的可解释性并阻碍了对内部决策机制的理解。我们提出了物理频谱感知白盒 mHC，名为 ES-mHC，这是一个超连接框架，它使用结构化的方向矩阵显式地模拟不同电磁频谱分组（mHC 中的剩余流）之间的交互。通过将特征表示与交互结构分离，ES-mHC促进电磁频谱分组专业化，减少冗余，并暴露可直接可视化和空间分析的内部信息流。使用高光谱图像分类作为代表性测试平台，我们证明了学习的超连接矩阵表现出连贯的空间模式和不对称的交互行为，为模型内部动态提供了机制洞察。此外，我们发现增加扩张率加速了结构化交互模式的出现。这些结果表明，ES-mHC 将 HSIC 从纯粹的黑盒预测任务转变为结构透明、部分白盒的学习过程。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15759v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15759v1",
        "title": "Atlas-Assisted Segment Anything Model for Fetal Brain MRI (FeTal-SAM)",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Atlas-Assisted Segment Anything Model for Fetal Brain MRI (FeTal-SAM)"
        },
        "updated": "2026-01-22T08:49:33Z",
        "updated_parsed": [
            2026,
            1,
            22,
            8,
            49,
            33,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15759v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15759v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "This paper presents FeTal-SAM, a novel adaptation of the Segment Anything Model (SAM) tailored for fetal brain MRI segmentation. Traditional deep learning methods often require large annotated datasets for a fixed set of labels, making them inflexible when clinical or research needs change. By integrating atlas-based prompts and foundation-model principles, FeTal-SAM addresses two key limitations in fetal brain MRI segmentation: (1) the need to retrain models for varying label definitions, and (2) the lack of insight into whether segmentations are driven by genuine image contrast or by learned spatial priors. We leverage multi-atlas registration to generate spatially aligned label templates that serve as dense prompts, alongside a bounding-box prompt, for SAM's segmentation decoder. This strategy enables binary segmentation on a per-structure basis, which is subsequently fused to reconstruct the full 3D segmentation volumes. Evaluations on two datasets, the dHCP dataset and an in-house dataset demonstrate FeTal-SAM's robust performance across gestational ages. Notably, it achieves Dice scores comparable to state-of-the-art baselines which were trained for each dataset and label definition for well-contrasted structures like cortical plate and cerebellum, while maintaining the flexibility to segment any user-specified anatomy. Although slightly lower accuracy is observed for subtle, low-contrast structures (e.g., hippocampus, amygdala), our results highlight FeTal-SAM's potential to serve as a general-purpose segmentation model without exhaustive retraining. This method thus constitutes a promising step toward clinically adaptable fetal brain MRI analysis tools.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "This paper presents FeTal-SAM, a novel adaptation of the Segment Anything Model (SAM) tailored for fetal brain MRI segmentation. Traditional deep learning methods often require large annotated datasets for a fixed set of labels, making them inflexible when clinical or research needs change. By integrating atlas-based prompts and foundation-model principles, FeTal-SAM addresses two key limitations in fetal brain MRI segmentation: (1) the need to retrain models for varying label definitions, and (2) the lack of insight into whether segmentations are driven by genuine image contrast or by learned spatial priors. We leverage multi-atlas registration to generate spatially aligned label templates that serve as dense prompts, alongside a bounding-box prompt, for SAM's segmentation decoder. This strategy enables binary segmentation on a per-structure basis, which is subsequently fused to reconstruct the full 3D segmentation volumes. Evaluations on two datasets, the dHCP dataset and an in-house dataset demonstrate FeTal-SAM's robust performance across gestational ages. Notably, it achieves Dice scores comparable to state-of-the-art baselines which were trained for each dataset and label definition for well-contrasted structures like cortical plate and cerebellum, while maintaining the flexibility to segment any user-specified anatomy. Although slightly lower accuracy is observed for subtle, low-contrast structures (e.g., hippocampus, amygdala), our results highlight FeTal-SAM's potential to serve as a general-purpose segmentation model without exhaustive retraining. This method thus constitutes a promising step toward clinically adaptable fetal brain MRI analysis tools."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.LG",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T08:49:33Z",
        "published_parsed": [
            2026,
            1,
            22,
            8,
            49,
            33,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Qi Zeng"
            },
            {
                "name": "Weide Liu"
            },
            {
                "name": "Bo Li"
            },
            {
                "name": "Ryne Didier"
            },
            {
                "name": "P. Ellen Grant"
            },
            {
                "name": "Davood Karimi"
            }
        ],
        "author_detail": {
            "name": "Davood Karimi"
        },
        "author": "Davood Karimi",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "用于胎儿脑 MRI 的 Atlas 辅助分段任意模型 (FeTal-SAM)",
        "abstract_cn": "本文介绍了 FeTal-SAM，这是一种针对胎儿大脑 MRI 分割而定制的分段任意模型 (SAM) 的新型改编版本。传统的深度学习方法通​​常需要大量带注释的数据集来表示一组固定的标签，这使得它们在临床或研究需求发生变化时变得不灵活。通过整合基于图谱的提示和基础模型原则，FeTal-SAM 解决了胎儿大脑 MRI 分割的两个关键限制：(1) 需要针对不同的标签定义重新训练模型，(2) 缺乏对分割是由真实图像对比度驱动还是由学习的空间先验驱动的洞察力。我们利用多图集配准来生成空间对齐的标签模板，这些模板作为密集提示以及边界框提示，用于 SAM 的分段解码器。该策略能够在每个结构的基础上进行二元分割，随后将其融合以重建完整的 3D 分割体积。对两个数据集（dHCP 数据集和内部数据集）的评估证明了 FeTal-SAM 在各个孕龄期间的稳健性能。值得注意的是，它获得的 Dice 分数与最先进的基线相当，这些基线针对每个数据集进行了训练，并针对皮质板和小脑等对比度良好的结构进行了标签定义，同时保持了分割任何用户指定的解剖结构的灵活性。尽管对于细微的、低对比度的结构（例如海马体、杏仁核）观察到的准确度略低，但我们的结果凸显了 FeTal-SAM 无需彻底再训练即可用作通用分割模型的潜力。因此，该方法为临床适用的胎儿脑 MRI 分析工具迈出了有希望的一步。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15766v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15766v1",
        "title": "LL-GaussianMap: Zero-shot Low-Light Image Enhancement via 2D Gaussian Splatting Guided Gain Maps",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "LL-GaussianMap: Zero-shot Low-Light Image Enhancement via 2D Gaussian Splatting Guided Gain Maps"
        },
        "updated": "2026-01-22T08:57:36Z",
        "updated_parsed": [
            2026,
            1,
            22,
            8,
            57,
            36,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15766v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15766v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Significant progress has been made in low-light image enhancement with respect to visual quality. However, most existing methods primarily operate in the pixel domain or rely on implicit feature representations. As a result, the intrinsic geometric structural priors of images are often neglected. 2D Gaussian Splatting (2DGS) has emerged as a prominent explicit scene representation technique characterized by superior structural fitting capabilities and high rendering efficiency. Despite these advantages, the utilization of 2DGS in low-level vision tasks remains unexplored. To bridge this gap, LL-GaussianMap is proposed as the first unsupervised framework incorporating 2DGS into low-light image enhancement. Distinct from conventional methodologies, the enhancement task is formulated as a gain map generation process guided by 2DGS primitives. The proposed method comprises two primary stages. First, high-fidelity structural reconstruction is executed utilizing 2DGS. Then, data-driven enhancement dictionary coefficients are rendered via the rasterization mechanism of Gaussian splatting through an innovative unified enhancement module. This design effectively incorporates the structural perception capabilities of 2DGS into gain map generation, thereby preserving edges and suppressing artifacts during enhancement. Additionally, the reliance on paired data is circumvented through unsupervised learning. Experimental results demonstrate that LL-GaussianMap achieves superior enhancement performance with an extremely low storage footprint, highlighting the effectiveness of explicit Gaussian representations for image enhancement.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Significant progress has been made in low-light image enhancement with respect to visual quality. However, most existing methods primarily operate in the pixel domain or rely on implicit feature representations. As a result, the intrinsic geometric structural priors of images are often neglected. 2D Gaussian Splatting (2DGS) has emerged as a prominent explicit scene representation technique characterized by superior structural fitting capabilities and high rendering efficiency. Despite these advantages, the utilization of 2DGS in low-level vision tasks remains unexplored. To bridge this gap, LL-GaussianMap is proposed as the first unsupervised framework incorporating 2DGS into low-light image enhancement. Distinct from conventional methodologies, the enhancement task is formulated as a gain map generation process guided by 2DGS primitives. The proposed method comprises two primary stages. First, high-fidelity structural reconstruction is executed utilizing 2DGS. Then, data-driven enhancement dictionary coefficients are rendered via the rasterization mechanism of Gaussian splatting through an innovative unified enhancement module. This design effectively incorporates the structural perception capabilities of 2DGS into gain map generation, thereby preserving edges and suppressing artifacts during enhancement. Additionally, the reliance on paired data is circumvented through unsupervised learning. Experimental results demonstrate that LL-GaussianMap achieves superior enhancement performance with an extremely low storage footprint, highlighting the effectiveness of explicit Gaussian representations for image enhancement."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T08:57:36Z",
        "published_parsed": [
            2026,
            1,
            22,
            8,
            57,
            36,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Yuhan Chen"
            },
            {
                "name": "Ying Fang"
            },
            {
                "name": "Guofa Li"
            },
            {
                "name": "Wenxuan Yu"
            },
            {
                "name": "Yicui Shi"
            },
            {
                "name": "Jingrui Zhang"
            },
            {
                "name": "Kefei Qian"
            },
            {
                "name": "Wenbo Chu"
            },
            {
                "name": "Keqiang Li"
            }
        ],
        "author_detail": {
            "name": "Keqiang Li"
        },
        "author": "Keqiang Li",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "LL-GaussianMap：通过 2D 高斯泼溅引导增益图进行零样本低光图像增强",
        "abstract_cn": "低光图像增强在视觉质量方面取得了重大进展。然而，大多数现有方法主要在像素域中操作或依赖于隐式特征表示。因此，图像的内在几何结构先验常常被忽视。二维高斯分布（2DGS）已成为一种突出的显式场景表示技术，其特点是卓越的结构拟合能力和高渲染效率。尽管有这些优点，2DGS 在低级视觉任务中的应用仍未得到探索。为了弥补这一差距，LL-GaussianMap 被提出作为第一个将 2DGS 纳入低光图像增强的无监督框架。与传统方法不同，增强任务被制定为由 2DGS 原语引导的增益图生成过程。所提出的方法包括两个主要阶段。首先，利用 2DGS 执行高保真结构重建。然后，通过创新的统一增强模块，通过高斯泼溅的光栅化机制渲染数据驱动的增强字典系数。该设计有效地将 2DGS 的结构感知能力融入增益图生成中，从而在增强过程中保留边缘并抑制伪影。此外，通过无监督学习避免了对配对数据的依赖。实验结果表明，LL-GaussianMap 以极低的存储占用实现了卓越的增强性能，凸显了显式高斯表示对于图像增强的有效性。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15772v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15772v1",
        "title": "LL-GaussianImage: Efficient Image Representation for Zero-shot Low-Light Enhancement with 2D Gaussian Splatting",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "LL-GaussianImage: Efficient Image Representation for Zero-shot Low-Light Enhancement with 2D Gaussian Splatting"
        },
        "updated": "2026-01-22T09:01:08Z",
        "updated_parsed": [
            2026,
            1,
            22,
            9,
            1,
            8,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15772v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15772v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "2D Gaussian Splatting (2DGS) is an emerging explicit scene representation method with significant potential for image compression due to high fidelity and high compression ratios. However, existing low-light enhancement algorithms operate predominantly within the pixel domain. Processing 2DGS-compressed images necessitates a cumbersome decompression-enhancement-recompression pipeline, which compromises efficiency and introduces secondary degradation. To address these limitations, we propose LL-GaussianImage, the first zero-shot unsupervised framework designed for low-light enhancement directly within the 2DGS compressed representation domain. Three primary advantages are offered by this framework. First, a semantic-guided Mixture-of-Experts enhancement framework is designed. Dynamic adaptive transformations are applied to the sparse attribute space of 2DGS using rendered images as guidance to enable compression-as-enhancement without full decompression to a pixel grid. Second, a multi-objective collaborative loss function system is established to strictly constrain smoothness and fidelity during enhancement, suppressing artifacts while improving visual quality. Third, a two-stage optimization process is utilized to achieve reconstruction-as-enhancement. The accuracy of the base representation is ensured through single-scale reconstruction and network robustness is enhanced. High-quality enhancement of low-light images is achieved while high compression ratios are maintained. The feasibility and superiority of the paradigm for direct processing within the compressed representation domain are validated through experimental results.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "2D Gaussian Splatting (2DGS) is an emerging explicit scene representation method with significant potential for image compression due to high fidelity and high compression ratios. However, existing low-light enhancement algorithms operate predominantly within the pixel domain. Processing 2DGS-compressed images necessitates a cumbersome decompression-enhancement-recompression pipeline, which compromises efficiency and introduces secondary degradation. To address these limitations, we propose LL-GaussianImage, the first zero-shot unsupervised framework designed for low-light enhancement directly within the 2DGS compressed representation domain. Three primary advantages are offered by this framework. First, a semantic-guided Mixture-of-Experts enhancement framework is designed. Dynamic adaptive transformations are applied to the sparse attribute space of 2DGS using rendered images as guidance to enable compression-as-enhancement without full decompression to a pixel grid. Second, a multi-objective collaborative loss function system is established to strictly constrain smoothness and fidelity during enhancement, suppressing artifacts while improving visual quality. Third, a two-stage optimization process is utilized to achieve reconstruction-as-enhancement. The accuracy of the base representation is ensured through single-scale reconstruction and network robustness is enhanced. High-quality enhancement of low-light images is achieved while high compression ratios are maintained. The feasibility and superiority of the paradigm for direct processing within the compressed representation domain are validated through experimental results."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T09:01:08Z",
        "published_parsed": [
            2026,
            1,
            22,
            9,
            1,
            8,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Yuhan Chen"
            },
            {
                "name": "Wenxuan Yu"
            },
            {
                "name": "Guofa Li"
            },
            {
                "name": "Yijun Xu"
            },
            {
                "name": "Ying Fang"
            },
            {
                "name": "Yicui Shi"
            },
            {
                "name": "Long Cao"
            },
            {
                "name": "Wenbo Chu"
            },
            {
                "name": "Keqiang Li"
            }
        ],
        "author_detail": {
            "name": "Keqiang Li"
        },
        "author": "Keqiang Li",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "LL-GaussianImage：通过 2D 高斯分布实现零样本低光增强的高效图像表示",
        "abstract_cn": "2D 高斯分布 (2DGS) 是一种新兴的显式场景表示方法，由于高保真度和高压缩比，在图像压缩方面具有巨大的潜力。然而，现有的低光增强算法主要在像素域内运行。处理 2DGS 压缩图像需要繁琐的解压-增强-再压缩流程，这会降低效率并引入二次降级。为了解决这些限制，我们提出了 LL-GaussianImage，这是第一个零样本无监督框架，专为直接在 2DGS 压缩表示域内进行低光增强而设计。该框架提供了三个主要优点。首先，设计了一个语义引导的 Mixture-of-Experts 增强框架。使用渲染图像作为指导，将动态自适应变换应用于 2DGS 的稀疏属性空间，以实现压缩增强，而无需完全解压缩到像素网格。其次，建立多目标协同损失函数系统，严格约束增强过程中的平滑度和保真度，在提高视觉质量的同时抑制伪影。第三，利用两阶段优化过程来实现重建增强。通过单尺度重建保证了基础表示的准确性，增强了网络的鲁棒性。在保持高压缩比的同时实现低光图像的高质量增强。通过实验结果验证了压缩表示域内直接处理范例的可行性和优越性。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15779v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15779v1",
        "title": "Diffusion Model-Based Data Augmentation for Enhanced Neuron Segmentation",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Diffusion Model-Based Data Augmentation for Enhanced Neuron Segmentation"
        },
        "updated": "2026-01-22T09:12:05Z",
        "updated_parsed": [
            2026,
            1,
            22,
            9,
            12,
            5,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15779v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15779v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Neuron segmentation in electron microscopy (EM) aims to reconstruct the complete neuronal connectome; however, current deep learning-based methods are limited by their reliance on large-scale training data and extensive, time-consuming manual annotations. Traditional methods augment the training set through geometric and photometric transformations; however, the generated samples remain highly correlated with the original images and lack structural diversity. To address this limitation, we propose a diffusion-based data augmentation framework capable of generating diverse and structurally plausible image-label pairs for neuron segmentation. Specifically, the framework employs a resolution-aware conditional diffusion model with multi-scale conditioning and EM resolution priors to enable voxel-level image synthesis from 3D masks. It further incorporates a biology-guided mask remodeling module that produces augmented masks with enhanced structural realism. Together, these components effectively enrich the training set and improve segmentation performance. On the AC3 and AC4 datasets under low-annotation regimes, our method improves the ARAND metric by 32.1% and 30.7%, respectively, when combined with two different post-processing methods. Our code is available at https://github.com/HeadLiuYun/NeuroDiff.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Neuron segmentation in electron microscopy (EM) aims to reconstruct the complete neuronal connectome; however, current deep learning-based methods are limited by their reliance on large-scale training data and extensive, time-consuming manual annotations. Traditional methods augment the training set through geometric and photometric transformations; however, the generated samples remain highly correlated with the original images and lack structural diversity. To address this limitation, we propose a diffusion-based data augmentation framework capable of generating diverse and structurally plausible image-label pairs for neuron segmentation. Specifically, the framework employs a resolution-aware conditional diffusion model with multi-scale conditioning and EM resolution priors to enable voxel-level image synthesis from 3D masks. It further incorporates a biology-guided mask remodeling module that produces augmented masks with enhanced structural realism. Together, these components effectively enrich the training set and improve segmentation performance. On the AC3 and AC4 datasets under low-annotation regimes, our method improves the ARAND metric by 32.1% and 30.7%, respectively, when combined with two different post-processing methods. Our code is available at https://github.com/HeadLiuYun/NeuroDiff."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T09:12:05Z",
        "published_parsed": [
            2026,
            1,
            22,
            9,
            12,
            5,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Liuyun Jiang"
            },
            {
                "name": "Yanchao Zhang"
            },
            {
                "name": "Jinyue Guo"
            },
            {
                "name": "Yizhuo Lu"
            },
            {
                "name": "Ruining Zhou"
            },
            {
                "name": "Hua Han"
            }
        ],
        "author_detail": {
            "name": "Hua Han"
        },
        "author": "Hua Han",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "基于扩散模型的数据增强增强神经元分割",
        "abstract_cn": "电子显微镜（EM）中的神经元分割旨在重建完整的神经元连接组；然而，当前基于深度学习的方法由于依赖大规模训练数据和大量耗时的手动注释而受到限制。传统方法通过几何和光度变换来扩充训练集；然而，生成的样本仍然与原始图像高度相关，并且缺乏结构多样性。为了解决这个限制，我们提出了一种基于扩散的数据增强框架，能够为神经元分割生成多样化且结构合理的图像标签对。具体来说，该框架采用具有多尺度调节和 EM 分辨率先验的分辨率感知条件扩散模型，以实现从 3D 掩模合成体素级图像。它还包含一个生物学引导的面具重塑模块，可生成具有增强结构真实性的增强面具。这些组件共同有效地丰富了训练集并提高了分割性能。在低注释机制下的 AC3 和 AC4 数据集上，当与两种不同的后处理方法相结合时，我们的方法将 ARAND 指标分别提高了 32.1% 和 30.7%。我们的代码可在 https://github.com/HeadLiuYun/NeuroDiff 获取。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15813v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15813v1",
        "title": "Beyond Off-the-Shelf Models: A Lightweight and Accessible Machine Learning Pipeline for Ecologists Working with Image Data",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Beyond Off-the-Shelf Models: A Lightweight and Accessible Machine Learning Pipeline for Ecologists Working with Image Data"
        },
        "updated": "2026-01-22T10:01:01Z",
        "updated_parsed": [
            2026,
            1,
            22,
            10,
            1,
            1,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15813v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15813v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "We introduce a lightweight experimentation pipeline designed to lower the barrier for applying machine learning (ML) methods for classifying images in ecological research. We enable ecologists to experiment with ML models independently, thus they can move beyond off-the-shelf models and generate insights tailored to local datasets and specific classification tasks and target variables. Our tool combines a simple command-line interface for preprocessing, training, and evaluation with a graphical interface for annotation, error analysis, and model comparison. This design enables ecologists to build and iterate on compact, task-specific classifiers without requiring advanced ML expertise. As a proof of concept, we apply the pipeline to classify red deer (Cervus elaphus) by age and sex from 3392 camera trap images collected in the Veldenstein Forest, Germany. Using 4352 cropped images containing individual deer labeled by experts, we trained and evaluated multiple backbone architectures with a wide variety of parameters and data augmentation strategies. Our best-performing models achieved 90.77% accuracy for age classification and 96.15% for sex classification. These results demonstrate that reliable demographic classification is feasible even with limited data to answer narrow, well-defined ecological problems. More broadly, the framework provides ecologists with an accessible tool for developing ML models tailored to specific research questions, paving the way for broader adoption of ML in wildlife monitoring and demographic analysis.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "We introduce a lightweight experimentation pipeline designed to lower the barrier for applying machine learning (ML) methods for classifying images in ecological research. We enable ecologists to experiment with ML models independently, thus they can move beyond off-the-shelf models and generate insights tailored to local datasets and specific classification tasks and target variables. Our tool combines a simple command-line interface for preprocessing, training, and evaluation with a graphical interface for annotation, error analysis, and model comparison. This design enables ecologists to build and iterate on compact, task-specific classifiers without requiring advanced ML expertise. As a proof of concept, we apply the pipeline to classify red deer (Cervus elaphus) by age and sex from 3392 camera trap images collected in the Veldenstein Forest, Germany. Using 4352 cropped images containing individual deer labeled by experts, we trained and evaluated multiple backbone architectures with a wide variety of parameters and data augmentation strategies. Our best-performing models achieved 90.77% accuracy for age classification and 96.15% for sex classification. These results demonstrate that reliable demographic classification is feasible even with limited data to answer narrow, well-defined ecological problems. More broadly, the framework provides ecologists with an accessible tool for developing ML models tailored to specific research questions, paving the way for broader adoption of ML in wildlife monitoring and demographic analysis."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.LG",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T10:01:01Z",
        "published_parsed": [
            2026,
            1,
            22,
            10,
            1,
            1,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Clare Chemery"
            },
            {
                "name": "Hendrik Edelhoff"
            },
            {
                "name": "Ludwig Bothmann"
            }
        ],
        "author_detail": {
            "name": "Ludwig Bothmann"
        },
        "author": "Ludwig Bothmann",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "超越现成模型：为生态学家处理图像数据提供轻量级且可访问的机器学习管道",
        "abstract_cn": "我们引入了一种轻量级实验流程，旨在降低在生态研究中应用机器学习（ML）方法对图像进行分类的障碍。我们使生态学家能够独立试验机器学习模型，因此他们可以超越现成的模型，并生成针对本地数据集和特定分类任务和目标变量的见解。我们的工具将用于预处理、训练和评估的简单命令行界面与用于注释、错误分析和模型比较的图形界面相结合。这种设计使生态学家能够构建和迭代紧凑的、特定于任务的分类器，而无需高级的机器学习专业知识。作为概念验证，我们应用该管道根据在德国 Veldenstein 森林收集的 3392 张相机陷阱图像中的年龄和性别对马鹿 (Cervus elaphus) 进行分类。使用 4352 张包含由专家标记的个体鹿的裁剪图像，我们使用各种参数和数据增强策略来训练和评估多个骨干架构。我们表现​​最好的模型的年龄分类准确率达到 90.77%，性别分类准确率达到 96.15%。这些结果表明，即使数据有限，也可以进行可靠的人口统计分类来回答狭窄的、明确的生态问题。更广泛地说，该框架为生态学家提供了一个易于使用的工具，用于开发针对特定研究问题的机器学习模型，为在野生动物监测和人口分析中更广泛地采用机器学习铺平了道路。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15829v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15829v1",
        "title": "Towards Realistic Remote Sensing Dataset Distillation with Discriminative Prototype-guided Diffusion",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Towards Realistic Remote Sensing Dataset Distillation with Discriminative Prototype-guided Diffusion"
        },
        "updated": "2026-01-22T10:30:32Z",
        "updated_parsed": [
            2026,
            1,
            22,
            10,
            30,
            32,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15829v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15829v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Recent years have witnessed the remarkable success of deep learning in remote sensing image interpretation, driven by the availability of large-scale benchmark datasets. However, this reliance on massive training data also brings two major challenges: (1) high storage and computational costs, and (2) the risk of data leakage, especially when sensitive categories are involved. To address these challenges, this study introduces the concept of dataset distillation into the field of remote sensing image interpretation for the first time. Specifically, we train a text-to-image diffusion model to condense a large-scale remote sensing dataset into a compact and representative distilled dataset. To improve the discriminative quality of the synthesized samples, we propose a classifier-driven guidance by injecting a classification consistency loss from a pre-trained model into the diffusion training process. Besides, considering the rich semantic complexity of remote sensing imagery, we further perform latent space clustering on training samples to select representative and diverse prototypes as visual style guidance, while using a visual language model to provide aggregated text descriptions. Experiments on three high-resolution remote sensing scene classification benchmarks show that the proposed method can distill realistic and diverse samples for downstream model training. Code and pre-trained models are available online (https://github.com/YonghaoXu/DPD).",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Recent years have witnessed the remarkable success of deep learning in remote sensing image interpretation, driven by the availability of large-scale benchmark datasets. However, this reliance on massive training data also brings two major challenges: (1) high storage and computational costs, and (2) the risk of data leakage, especially when sensitive categories are involved. To address these challenges, this study introduces the concept of dataset distillation into the field of remote sensing image interpretation for the first time. Specifically, we train a text-to-image diffusion model to condense a large-scale remote sensing dataset into a compact and representative distilled dataset. To improve the discriminative quality of the synthesized samples, we propose a classifier-driven guidance by injecting a classification consistency loss from a pre-trained model into the diffusion training process. Besides, considering the rich semantic complexity of remote sensing imagery, we further perform latent space clustering on training samples to select representative and diverse prototypes as visual style guidance, while using a visual language model to provide aggregated text descriptions. Experiments on three high-resolution remote sensing scene classification benchmarks show that the proposed method can distill realistic and diverse samples for downstream model training. Code and pre-trained models are available online (https://github.com/YonghaoXu/DPD)."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T10:30:32Z",
        "published_parsed": [
            2026,
            1,
            22,
            10,
            30,
            32,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Yonghao Xu"
            },
            {
                "name": "Pedram Ghamisi"
            },
            {
                "name": "Qihao Weng"
            }
        ],
        "author_detail": {
            "name": "Qihao Weng"
        },
        "author": "Qihao Weng",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "通过判别原型引导扩散实现现实遥感数据集蒸馏",
        "abstract_cn": "近年来，在大规模基准数据集的推动下，深度学习在遥感图像解释方面取得了巨大成功。然而，这种对海量训练数据的依赖也带来了两大挑战：（1）高昂的存储和计算成本，以及（2）数据泄露的风险，尤其是涉及敏感类别时。为了应对这些挑战，本研究首次将数据集蒸馏的概念引入遥感图像解译领域。具体来说，我们训练文本到图像的扩散模型，将大规模遥感数据集压缩为紧凑且具有代表性的蒸馏数据集。为了提高合成样本的判别质量，我们提出了一种分类器驱动的指导，通过将预训练模型的分类一致性损失注入到扩散训练过程中。此外，考虑到遥感图像丰富的语义复杂性，我们进一步对训练样本进行潜在空间聚类，以选择具有代表性和多样性的原型作为视觉风格指导，同时使用视觉语言模型提供聚合的文本描述。在三个高分辨率遥感场景分类基准上的实验表明，该方法可以提取真实且多样化的样本用于下游模型训练。代码和预训练模型可在线获取（https://github.com/YonghaoXu/DPD）。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15859v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15859v1",
        "title": "Uncertainty-guided Generation of Dark-field Radiographs",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Uncertainty-guided Generation of Dark-field Radiographs"
        },
        "updated": "2026-01-22T11:07:19Z",
        "updated_parsed": [
            2026,
            1,
            22,
            11,
            7,
            19,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15859v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15859v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "X-ray dark-field radiography provides complementary diagnostic information to conventional attenuation imaging by visualizing microstructural tissue changes through small-angle scattering. However, the limited availability of such data poses challenges for developing robust deep learning models. In this work, we present the first framework for generating dark-field images directly from standard attenuation chest X-rays using an Uncertainty-Guided Progressive Generative Adversarial Network. The model incorporates both aleatoric and epistemic uncertainty to improve interpretability and reliability. Experiments demonstrate high structural fidelity of the generated images, with consistent improvement of quantitative metrics across stages. Furthermore, out-of-distribution evaluation confirms that the proposed model generalizes well. Our results indicate that uncertainty-guided generative modeling enables realistic dark-field image synthesis and provides a reliable foundation for future clinical applications.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "X-ray dark-field radiography provides complementary diagnostic information to conventional attenuation imaging by visualizing microstructural tissue changes through small-angle scattering. However, the limited availability of such data poses challenges for developing robust deep learning models. In this work, we present the first framework for generating dark-field images directly from standard attenuation chest X-rays using an Uncertainty-Guided Progressive Generative Adversarial Network. The model incorporates both aleatoric and epistemic uncertainty to improve interpretability and reliability. Experiments demonstrate high structural fidelity of the generated images, with consistent improvement of quantitative metrics across stages. Furthermore, out-of-distribution evaluation confirms that the proposed model generalizes well. Our results indicate that uncertainty-guided generative modeling enables realistic dark-field image synthesis and provides a reliable foundation for future clinical applications."
        },
        "tags": [
            {
                "term": "cs.LG",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T11:07:19Z",
        "published_parsed": [
            2026,
            1,
            22,
            11,
            7,
            19,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.LG"
        },
        "authors": [
            {
                "name": "Lina Felsner"
            },
            {
                "name": "Henriette Bast"
            },
            {
                "name": "Tina Dorosti"
            },
            {
                "name": "Florian Schaff"
            },
            {
                "name": "Franz Pfeiffer"
            },
            {
                "name": "Daniela Pfeiffer"
            },
            {
                "name": "Julia Schnabel"
            }
        ],
        "author_detail": {
            "name": "Julia Schnabel"
        },
        "author": "Julia Schnabel",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "不确定性引导的暗场射线照片生成",
        "abstract_cn": "X 射线暗场放射成像通过小角度散射可视化微观结构组织变化，为传统衰减成像提供补充诊断信息。然而，此类数据的可用性有限，给开发强大的深度学习模型带来了挑战。在这项工作中，我们提出了第一个使用不确定性引导渐进生成对抗网络直接从标准衰减胸部 X 射线生成暗场图像的框架。该模型结合了任意和认知不确定性，以提高可解释性和可靠性。实验证明生成的图像具有高结构保真度，并且各个阶段的定量指标得到了一致的改进。此外，分布外评估证实所提出的模型具有良好的泛化性。我们的结果表明，不确定性引导的生成模型可以实现逼真的暗场图像合成，并为未来的临床应用提供可靠的基础。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15865v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15865v1",
        "title": "A Lightweight Brain-Inspired Machine Learning Framework for Coronary Angiography: Hybrid Neural Representation and Robust Learning Strategies",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "A Lightweight Brain-Inspired Machine Learning Framework for Coronary Angiography: Hybrid Neural Representation and Robust Learning Strategies"
        },
        "updated": "2026-01-22T11:14:37Z",
        "updated_parsed": [
            2026,
            1,
            22,
            11,
            14,
            37,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15865v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15865v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Background: Coronary angiography (CAG) is a cornerstone imaging modality for assessing coronary artery disease and guiding interventional treatment decisions. However, in real-world clinical settings, angiographic images are often characterized by complex lesion morphology, severe class imbalance, label uncertainty, and limited computational resources, posing substantial challenges to conventional deep learning approaches in terms of robustness and generalization.Methods: The proposed framework is built upon a pretrained convolutional neural network to construct a lightweight hybrid neural representation. A selective neural plasticity training strategy is introduced to enable efficient parameter adaptation. Furthermore, a brain-inspired attention-modulated loss function, combining Focal Loss with label smoothing, is employed to enhance sensitivity to hard samples and uncertain annotations. Class-imbalance-aware sampling and cosine annealing with warm restarts are adopted to mimic rhythmic regulation and attention allocation mechanisms observed in biological neural systems.Results: Experimental results demonstrate that the proposed lightweight brain-inspired model achieves strong and stable performance in binary coronary angiography classification, yielding competitive accuracy, recall, F1-score, and AUC metrics while maintaining high computational efficiency.Conclusion: This study validates the effectiveness of brain-inspired learning mechanisms in lightweight medical image analysis and provides a biologically plausible and deployable solution for intelligent clinical decision support under limited computational resources.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Background: Coronary angiography (CAG) is a cornerstone imaging modality for assessing coronary artery disease and guiding interventional treatment decisions. However, in real-world clinical settings, angiographic images are often characterized by complex lesion morphology, severe class imbalance, label uncertainty, and limited computational resources, posing substantial challenges to conventional deep learning approaches in terms of robustness and generalization.Methods: The proposed framework is built upon a pretrained convolutional neural network to construct a lightweight hybrid neural representation. A selective neural plasticity training strategy is introduced to enable efficient parameter adaptation. Furthermore, a brain-inspired attention-modulated loss function, combining Focal Loss with label smoothing, is employed to enhance sensitivity to hard samples and uncertain annotations. Class-imbalance-aware sampling and cosine annealing with warm restarts are adopted to mimic rhythmic regulation and attention allocation mechanisms observed in biological neural systems.Results: Experimental results demonstrate that the proposed lightweight brain-inspired model achieves strong and stable performance in binary coronary angiography classification, yielding competitive accuracy, recall, F1-score, and AUC metrics while maintaining high computational efficiency.Conclusion: This study validates the effectiveness of brain-inspired learning mechanisms in lightweight medical image analysis and provides a biologically plausible and deployable solution for intelligent clinical decision support under limited computational resources."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.LG",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T11:14:37Z",
        "published_parsed": [
            2026,
            1,
            22,
            11,
            14,
            37,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Jingsong Xia"
            },
            {
                "name": "Siqi Wang"
            }
        ],
        "author_detail": {
            "name": "Siqi Wang"
        },
        "author": "Siqi Wang",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "用于冠状动脉造影的轻量级脑启发机器学习框架：混合神经表示和鲁棒学习策略",
        "abstract_cn": "背景：冠状动脉造影（CAG）是评估冠状动脉疾病和指导介入治疗决策的基础成像方式。然而，在现实临床环境中，血管造影图像通常具有复杂的病变形态、严重的类别不平衡、标签不确定性和有限的计算资源等特点，这对传统深度学习方法在鲁棒性和泛化性方面提出了巨大的挑战。 方法：所提出的框架建立在预训练的卷积神经网络的基础上，以构建轻量级的混合神经表示。引入选择性神经可塑性训练策略以实现有效的参数适应。此外，采用受大脑启发的注意力调制损失函数，将焦点损失与标签平滑相结合，以增强对硬样本和不确定注释的敏感性。采用类不平衡感知采样和热重启余弦退火来模拟生物神经系统中观察到的节律调节和注意力分配机制。结果：实验结果表明，所提出的轻量级类脑启发模型在二元冠状动脉造影分类中实现了强大而稳定的性能，在保持高计算效率的同时产生了有竞争力的准确性、召回率、F1分数和AUC指标。结论：本研究验证了类脑启发学习机制在轻量级医学图像分析中的有效性，并提供了一种在有限的计算资源下为智能临床决策支持提供生物学上合理且可部署的解决方案。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15867v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15867v1",
        "title": "Out-of-Distribution Detection Based on Total Variation Estimation",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Out-of-Distribution Detection Based on Total Variation Estimation"
        },
        "updated": "2026-01-22T11:15:16Z",
        "updated_parsed": [
            2026,
            1,
            22,
            11,
            15,
            16,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15867v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15867v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "This paper introduces a novel approach to securing machine learning model deployments against potential distribution shifts in practical applications, the Total Variation Out-of-Distribution (TV-OOD) detection method. Existing methods have produced satisfactory results, but TV-OOD improves upon these by leveraging the Total Variation Network Estimator to calculate each input's contribution to the overall total variation. By defining this as the total variation score, TV-OOD discriminates between in- and out-of-distribution data. The method's efficacy was tested across a range of models and datasets, consistently yielding results in image classification tasks that were either comparable or superior to those achieved by leading-edge out-of-distribution detection techniques across all evaluation metrics.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "This paper introduces a novel approach to securing machine learning model deployments against potential distribution shifts in practical applications, the Total Variation Out-of-Distribution (TV-OOD) detection method. Existing methods have produced satisfactory results, but TV-OOD improves upon these by leveraging the Total Variation Network Estimator to calculate each input's contribution to the overall total variation. By defining this as the total variation score, TV-OOD discriminates between in- and out-of-distribution data. The method's efficacy was tested across a range of models and datasets, consistently yielding results in image classification tasks that were either comparable or superior to those achieved by leading-edge out-of-distribution detection techniques across all evaluation metrics."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T11:15:16Z",
        "published_parsed": [
            2026,
            1,
            22,
            11,
            15,
            16,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Dabiao Ma"
            },
            {
                "name": "Zhiba Su"
            },
            {
                "name": "Jian Yang"
            },
            {
                "name": "Haojun Fei"
            }
        ],
        "author_detail": {
            "name": "Haojun Fei"
        },
        "author": "Haojun Fei",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "基于总变异估计的分布外检测",
        "abstract_cn": "本文介绍了一种确保机器学习模型部署免受实际应用中潜在分布变化影响的新方法，即总变异分布外 (TV-OOD) 检测方法。现有方法已经产生了令人满意的结果，但 TV-OOD 通过利用总变异网络估计器来计算每个输入对总体总变异的贡献，从而对这些方法进行了改进。通过将其定义为总变异分数，TV-OOD 可以区分分布内和分布外的数据。该方法的功效在一系列模型和数据集上进行了测试，在图像分类任务中始终产生与所有评估指标中领先的分布外检测技术所获得的结果相当或优于的结果。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15884v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15884v1",
        "title": "PMPBench: A Paired Multi-Modal Pan-Cancer Benchmark for Medical Image Synthesis",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "PMPBench: A Paired Multi-Modal Pan-Cancer Benchmark for Medical Image Synthesis"
        },
        "updated": "2026-01-22T11:58:37Z",
        "updated_parsed": [
            2026,
            1,
            22,
            11,
            58,
            37,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15884v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15884v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Contrast medium plays a pivotal role in radiological imaging, as it amplifies lesion conspicuity and improves detection for the diagnosis of tumor-related diseases. However, depending on the patient's health condition or the medical resources available, the use of contrast medium is not always feasible. Recent work has explored AI-based image translation to synthesize contrast-enhanced images directly from non-contrast scans, aims to reduce side effects and streamlines clinical workflows. Progress in this direction has been constrained by data limitations: (1) existing public datasets focus almost exclusively on brain-related paired MR modalities; (2) other collections include partially paired data but suffer from missing modalities/timestamps and imperfect spatial alignment; (3) explicit labeling of CT vs. CTC or DCE phases is often absent; (4) substantial resources remain private. To bridge this gap, we introduce the first public, fully paired, pan-cancer medical imaging dataset spanning 11 human organs. The MR data include complete dynamic contrast-enhanced (DCE) sequences covering all three phases (DCE1-DCE3), while the CT data provide paired non-contrast and contrast-enhanced acquisitions (CTC). The dataset is curated for anatomical correspondence, enabling rigorous evaluation of 1-to-1, N-to-1, and N-to-N translation settings (e.g., predicting DCE phases from non-contrast inputs). Built upon this resource, we establish a comprehensive benchmark. We report results from representative baselines of contemporary image-to-image translation. We release the dataset and benchmark to catalyze research on safe, effective contrast synthesis, with direct relevance to multi-organ oncology imaging workflows. Our code and dataset are publicly available at https://github.com/YifanChen02/PMPBench.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Contrast medium plays a pivotal role in radiological imaging, as it amplifies lesion conspicuity and improves detection for the diagnosis of tumor-related diseases. However, depending on the patient's health condition or the medical resources available, the use of contrast medium is not always feasible. Recent work has explored AI-based image translation to synthesize contrast-enhanced images directly from non-contrast scans, aims to reduce side effects and streamlines clinical workflows. Progress in this direction has been constrained by data limitations: (1) existing public datasets focus almost exclusively on brain-related paired MR modalities; (2) other collections include partially paired data but suffer from missing modalities/timestamps and imperfect spatial alignment; (3) explicit labeling of CT vs. CTC or DCE phases is often absent; (4) substantial resources remain private. To bridge this gap, we introduce the first public, fully paired, pan-cancer medical imaging dataset spanning 11 human organs. The MR data include complete dynamic contrast-enhanced (DCE) sequences covering all three phases (DCE1-DCE3), while the CT data provide paired non-contrast and contrast-enhanced acquisitions (CTC). The dataset is curated for anatomical correspondence, enabling rigorous evaluation of 1-to-1, N-to-1, and N-to-N translation settings (e.g., predicting DCE phases from non-contrast inputs). Built upon this resource, we establish a comprehensive benchmark. We report results from representative baselines of contemporary image-to-image translation. We release the dataset and benchmark to catalyze research on safe, effective contrast synthesis, with direct relevance to multi-organ oncology imaging workflows. Our code and dataset are publicly available at https://github.com/YifanChen02/PMPBench."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T11:58:37Z",
        "published_parsed": [
            2026,
            1,
            22,
            11,
            58,
            37,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Yifan Chen"
            },
            {
                "name": "Fei Yin"
            },
            {
                "name": "Hao Chen"
            },
            {
                "name": "Jia Wu"
            },
            {
                "name": "Chao Li"
            }
        ],
        "author_detail": {
            "name": "Chao Li"
        },
        "author": "Chao Li",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "PMPBench：用于医学图像合成的配对多模态泛癌症基准",
        "abstract_cn": "造影剂在放射成像中发挥着关键作用，因为它可以增强病变的清晰度并改善肿瘤相关疾病诊断的检测。然而，根据患者的健康状况或可用的医疗资源，使用造影剂并不总是可行的。最近的工作探索了基于人工智能的图像翻译，直接从非对比扫描合成对比增强图像，旨在减少副作用并简化临床工作流程。这一方向的进展受到数据限制的限制：（1）现有的公共数据集几乎完全关注与大脑相关的配对 MR 模式； (2) 其他集合包括部分配对的数据，但存在模式/时间戳缺失和空间对齐不完善的问题； (3) 通常缺乏 CT 与 CTC 或 DCE 相位的明确标记； (4)大量资源仍然是私人的。为了弥补这一差距，我们引入了第一个公开的、完全配对的、涵盖 11 个人体器官的泛癌症医学成像数据集。 MR 数据包括覆盖所有三个阶段 (DCE1-DCE3) 的完整动态对比增强 (DCE) 序列，而 CT 数据提供配对的非对比和对比增强采集 (CTC)。该数据集针对解剖对应进行整理，能够对 1 对 1、N 对 1 和 N 对 N 转换设置进行严格评估（例如，根据非对比输入预测 DCE 相位）。在此资源的基础上，我们建立了一个全面的基准。我们报告了当代图像到图像翻译的代表性基线的结果。我们发布数据集和基准，以促进安全、有效的对比合成研究，与多器官肿瘤成像工作流程直接相关。我们的代码和数据集可在 https://github.com/YifanChen02/PMPBench 上公开获取。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15888v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15888v1",
        "title": "Understanding the Transfer Limits of Vision Foundation Models",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Understanding the Transfer Limits of Vision Foundation Models"
        },
        "updated": "2026-01-22T12:07:56Z",
        "updated_parsed": [
            2026,
            1,
            22,
            12,
            7,
            56,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15888v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15888v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Foundation models leverage large-scale pretraining to capture extensive knowledge, demonstrating generalization in a wide range of language tasks. By comparison, vision foundation models (VFMs) often exhibit uneven improvements across downstream tasks, despite substantial computational investment. We postulate that this limitation arises from a mismatch between pretraining objectives and the demands of downstream vision-and-imaging tasks. Pretraining strategies like masked image reconstruction or contrastive learning shape representations for tasks such as recovery of generic visual patterns or global semantic structures, which may not align with the task-specific requirements of downstream applications including segmentation, classification, or image synthesis. To investigate this in a concrete real-world clinical area, we assess two VFMs, a reconstruction-focused MAE-based model (ProFound) and a contrastive-learning-based model (ProViCNet), on five prostate multiparametric MR imaging tasks, examining how such task alignment influences transfer performance, i.e., from pretraining to fine-tuning. Our findings indicate that better alignment between pretraining and downstream tasks, measured by simple divergence metrics such as maximum-mean-discrepancy (MMD) between the same features before and after fine-tuning, correlates with greater performance improvements and faster convergence, emphasizing the importance of designing and analyzing pretraining objectives with downstream applicability in mind.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Foundation models leverage large-scale pretraining to capture extensive knowledge, demonstrating generalization in a wide range of language tasks. By comparison, vision foundation models (VFMs) often exhibit uneven improvements across downstream tasks, despite substantial computational investment. We postulate that this limitation arises from a mismatch between pretraining objectives and the demands of downstream vision-and-imaging tasks. Pretraining strategies like masked image reconstruction or contrastive learning shape representations for tasks such as recovery of generic visual patterns or global semantic structures, which may not align with the task-specific requirements of downstream applications including segmentation, classification, or image synthesis. To investigate this in a concrete real-world clinical area, we assess two VFMs, a reconstruction-focused MAE-based model (ProFound) and a contrastive-learning-based model (ProViCNet), on five prostate multiparametric MR imaging tasks, examining how such task alignment influences transfer performance, i.e., from pretraining to fine-tuning. Our findings indicate that better alignment between pretraining and downstream tasks, measured by simple divergence metrics such as maximum-mean-discrepancy (MMD) between the same features before and after fine-tuning, correlates with greater performance improvements and faster convergence, emphasizing the importance of designing and analyzing pretraining objectives with downstream applicability in mind."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.AI",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T12:07:56Z",
        "published_parsed": [
            2026,
            1,
            22,
            12,
            7,
            56,
            3,
            22,
            0
        ],
        "arxiv_comment": "accepted in ISBI 2026",
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Shiqi Huang"
            },
            {
                "name": "Yipei Wang"
            },
            {
                "name": "Natasha Thorley"
            },
            {
                "name": "Alexander Ng"
            },
            {
                "name": "Shaheer Saeed"
            },
            {
                "name": "Mark Emberton"
            },
            {
                "name": "Shonit Punwani"
            },
            {
                "name": "Veeru Kasivisvanathan"
            },
            {
                "name": "Dean Barratt"
            },
            {
                "name": "Daniel Alexander"
            },
            {
                "name": "Yipeng Hu"
            }
        ],
        "author_detail": {
            "name": "Yipeng Hu"
        },
        "author": "Yipeng Hu",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "了解视觉基础模型的传输限制",
        "abstract_cn": "基础模型利用大规模预训练来捕获广泛的知识，展示各种语言任务的泛化能力。相比之下，尽管计算投入巨大，但视觉基础模型 (VFM) 在下游任务中通常表现出不均匀的改进。我们假设这种限制是由于预训练目标与下游视觉和成像任务的需求之间的不匹配造成的。用于恢复通用视觉模式或全局语义结构等任务的预训练策略（例如掩模图像重建或对比学习形状表示）可能与下游应用程序（包括分割、分类或图像合成）的特定任务要求不一致。为了在具体的现实世界临床领域中研究这一点，我们在五个前列腺多参数 MR 成像任务上评估了两个 VFM，一个专注于重建的基于 MAE 的模型 (ProFound) 和一个基于对比学习的模型 (ProViCNet)，检查此类任务对齐如何影响传输性能，即从预训练到微调。我们的研究结果表明，通过简单的分歧指标（例如微调前后相同特征之间的最大均值差异（MMD））来衡量预训练和下游任务之间的更好一致性，与更大的性能改进和更快的收敛相关，强调了设计和分析预训练目标时考虑下游适用性的重要性。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15891v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15891v1",
        "title": "RadJEPA: Radiology Encoder for Chest X-Rays via Joint Embedding Predictive Architecture",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "RadJEPA: Radiology Encoder for Chest X-Rays via Joint Embedding Predictive Architecture"
        },
        "updated": "2026-01-22T12:11:53Z",
        "updated_parsed": [
            2026,
            1,
            22,
            12,
            11,
            53,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15891v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15891v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Recent advances in medical vision language models guide the learning of visual representations; however, this form of supervision is constrained by the availability of paired image text data, raising the question of whether robust radiology encoders can be learned without relying on language supervision. In this work, we introduce RadJEPA, a self-supervised framework built on a Joint Embedding Predictive Architecture that learns without language supervision. Pre-trained solely on unlabeled chest X-ray images, the model learns to predict latent representations of masked image regions. This predictive objective differs fundamentally from both image text pre-training and DINO-style self-distillation: rather than aligning global representations across views or modalities, RadJEPA explicitly models latent-space prediction. We evaluate the learned encoder on disease classification, semantic segmentation, and report generation tasks. Across benchmarks, RadJEPA achieves performance exceeding state-of-the-art approaches, including Rad-DINO.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Recent advances in medical vision language models guide the learning of visual representations; however, this form of supervision is constrained by the availability of paired image text data, raising the question of whether robust radiology encoders can be learned without relying on language supervision. In this work, we introduce RadJEPA, a self-supervised framework built on a Joint Embedding Predictive Architecture that learns without language supervision. Pre-trained solely on unlabeled chest X-ray images, the model learns to predict latent representations of masked image regions. This predictive objective differs fundamentally from both image text pre-training and DINO-style self-distillation: rather than aligning global representations across views or modalities, RadJEPA explicitly models latent-space prediction. We evaluate the learned encoder on disease classification, semantic segmentation, and report generation tasks. Across benchmarks, RadJEPA achieves performance exceeding state-of-the-art approaches, including Rad-DINO."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T12:11:53Z",
        "published_parsed": [
            2026,
            1,
            22,
            12,
            11,
            53,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Anas Anwarul Haq Khan"
            },
            {
                "name": "Mariam Husain"
            },
            {
                "name": "Kshitij Jadhav"
            }
        ],
        "author_detail": {
            "name": "Kshitij Jadhav"
        },
        "author": "Kshitij Jadhav",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "RadJEPA：通过联合嵌入预测架构进行胸部 X 光放射学编码器",
        "abstract_cn": "医学视觉语言模型的最新进展指导了视觉表征的学习；然而，这种形式的监督受到配对图像文本数据的可用性的限制，这就提出了一个问题：是否可以在不依赖语言监督的情况下学习鲁棒的放射学编码器。在这项工作中，我们介绍了 RadJEPA，这是一个基于联合嵌入预测架构构建的自监督框架，无需语言监督即可学习。该模型仅针对未标记的胸部 X 射线图像进行预训练，学习预测屏蔽图像区域的潜在表示。这种预测目标与图像文本预训练和 DINO 式自蒸馏都有根本的不同：​​RadJEPA 不是跨视图或模态对齐全局表示，而是显式地对潜在空间预测进行建模。我们在疾病分类、语义分割和报告生成任务上评估学习的编码器。在各个基准测试中，RadJEPA 的性能超过了最先进的方法，包括 Rad-DINO。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15909v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15909v1",
        "title": "Transfer Learning from ImageNet for MEG-Based Decoding of Imagined Speech",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Transfer Learning from ImageNet for MEG-Based Decoding of Imagined Speech"
        },
        "updated": "2026-01-22T12:38:20Z",
        "updated_parsed": [
            2026,
            1,
            22,
            12,
            38,
            20,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15909v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15909v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Non-invasive decoding of imagined speech remains challenging due to weak, distributed signals and limited labeled data. Our paper introduces an image-based approach that transforms magnetoencephalography (MEG) signals into time-frequency representations compatible with pretrained vision models. MEG data from 21 participants performing imagined speech tasks were projected into three spatial scalogram mixtures via a learnable sensor-space convolution, producing compact image-like inputs for ImageNet-pretrained vision architectures. These models outperformed classical and non-pretrained models, achieving up to 90.4% balanced accuracy for imagery vs. silence, 81.0% vs. silent reading, and 60.6% for vowel decoding. Cross-subject evaluation confirmed that pretrained models capture shared neural representations, and temporal analyses localized discriminative information to imagery-locked intervals. These findings show that pretrained vision models applied to image-based MEG representations can effectively capture the structure of imagined speech in non-invasive neural signals.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Non-invasive decoding of imagined speech remains challenging due to weak, distributed signals and limited labeled data. Our paper introduces an image-based approach that transforms magnetoencephalography (MEG) signals into time-frequency representations compatible with pretrained vision models. MEG data from 21 participants performing imagined speech tasks were projected into three spatial scalogram mixtures via a learnable sensor-space convolution, producing compact image-like inputs for ImageNet-pretrained vision architectures. These models outperformed classical and non-pretrained models, achieving up to 90.4% balanced accuracy for imagery vs. silence, 81.0% vs. silent reading, and 60.6% for vowel decoding. Cross-subject evaluation confirmed that pretrained models capture shared neural representations, and temporal analyses localized discriminative information to imagery-locked intervals. These findings show that pretrained vision models applied to image-based MEG representations can effectively capture the structure of imagined speech in non-invasive neural signals."
        },
        "tags": [
            {
                "term": "cs.CL",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.AI",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T12:38:20Z",
        "published_parsed": [
            2026,
            1,
            22,
            12,
            38,
            20,
            3,
            22,
            0
        ],
        "arxiv_comment": "Accepted at IEEE ISBI 2026",
        "arxiv_primary_category": {
            "term": "cs.CL"
        },
        "authors": [
            {
                "name": "Soufiane Jhilal"
            },
            {
                "name": "Stéphanie Martin"
            },
            {
                "name": "Anne-Lise Giraud"
            }
        ],
        "author_detail": {
            "name": "Anne-Lise Giraud"
        },
        "author": "Anne-Lise Giraud",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "用于基于 MEG 的想象语音解码的 ImageNet 迁移学习",
        "abstract_cn": "由于微弱的分布式信号和有限的标记数据，对想象语音的非侵入式解码仍然具有挑战性。我们的论文介绍了一种基于图像的方法，可将脑磁图（MEG）信号转换为与预训练视觉模型兼容的时频表示。来自执行想象语音任务的 21 名参与者的 MEG 数据通过可学习的传感器空间卷积投影到三个空间尺度图混合物中，为 ImageNet 预训练的视觉架构生成紧凑的类似图像的输入。这些模型的性能优于经典模型和非预训练模型，图像与静音的平衡准确率高达 90.4%，默读的平衡准确率为 81.0%，元音解码的平衡准确率为 60.6%。跨受试者评估证实，预训练模型捕获共享神经表征，并针对图像锁定间隔进行局部判别信息的时间分析。这些发现表明，应用于基于图像的 MEG 表示的预训练视觉模型可以有效地捕获非侵入性神经信号中想象的语音结构。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15951v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15951v1",
        "title": "EVolSplat4D: Efficient Volume-based Gaussian Splatting for 4D Urban Scene Synthesis",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "EVolSplat4D: Efficient Volume-based Gaussian Splatting for 4D Urban Scene Synthesis"
        },
        "updated": "2026-01-22T13:39:29Z",
        "updated_parsed": [
            2026,
            1,
            22,
            13,
            39,
            29,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15951v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15951v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Novel view synthesis (NVS) of static and dynamic urban scenes is essential for autonomous driving simulation, yet existing methods often struggle to balance reconstruction time with quality. While state-of-the-art neural radiance fields and 3D Gaussian Splatting approaches achieve photorealism, they often rely on time-consuming per-scene optimization. Conversely, emerging feed-forward methods frequently adopt per-pixel Gaussian representations, which lead to 3D inconsistencies when aggregating multi-view predictions in complex, dynamic environments. We propose EvolSplat4D, a feed-forward framework that moves beyond existing per-pixel paradigms by unifying volume-based and pixel-based Gaussian prediction across three specialized branches. For close-range static regions, we predict consistent geometry of 3D Gaussians over multiple frames directly from a 3D feature volume, complemented by a semantically-enhanced image-based rendering module for predicting their appearance. For dynamic actors, we utilize object-centric canonical spaces and a motion-adjusted rendering module to aggregate temporal features, ensuring stable 4D reconstruction despite noisy motion priors. Far-Field scenery is handled by an efficient per-pixel Gaussian branch to ensure full-scene coverage. Experimental results on the KITTI-360, KITTI, Waymo, and PandaSet datasets show that EvolSplat4D reconstructs both static and dynamic environments with superior accuracy and consistency, outperforming both per-scene optimization and state-of-the-art feed-forward baselines.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Novel view synthesis (NVS) of static and dynamic urban scenes is essential for autonomous driving simulation, yet existing methods often struggle to balance reconstruction time with quality. While state-of-the-art neural radiance fields and 3D Gaussian Splatting approaches achieve photorealism, they often rely on time-consuming per-scene optimization. Conversely, emerging feed-forward methods frequently adopt per-pixel Gaussian representations, which lead to 3D inconsistencies when aggregating multi-view predictions in complex, dynamic environments. We propose EvolSplat4D, a feed-forward framework that moves beyond existing per-pixel paradigms by unifying volume-based and pixel-based Gaussian prediction across three specialized branches. For close-range static regions, we predict consistent geometry of 3D Gaussians over multiple frames directly from a 3D feature volume, complemented by a semantically-enhanced image-based rendering module for predicting their appearance. For dynamic actors, we utilize object-centric canonical spaces and a motion-adjusted rendering module to aggregate temporal features, ensuring stable 4D reconstruction despite noisy motion priors. Far-Field scenery is handled by an efficient per-pixel Gaussian branch to ensure full-scene coverage. Experimental results on the KITTI-360, KITTI, Waymo, and PandaSet datasets show that EvolSplat4D reconstructs both static and dynamic environments with superior accuracy and consistency, outperforming both per-scene optimization and state-of-the-art feed-forward baselines."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T13:39:29Z",
        "published_parsed": [
            2026,
            1,
            22,
            13,
            39,
            29,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Sheng Miao"
            },
            {
                "name": "Sijin Li"
            },
            {
                "name": "Pan Wang"
            },
            {
                "name": "Dongfeng Bai"
            },
            {
                "name": "Bingbing Liu"
            },
            {
                "name": "Yue Wang"
            },
            {
                "name": "Andreas Geiger"
            },
            {
                "name": "Yiyi Liao"
            }
        ],
        "author_detail": {
            "name": "Yiyi Liao"
        },
        "author": "Yiyi Liao",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "EVolSplat4D：用于 4D 城市场景合成的高效基于体积的高斯分布",
        "abstract_cn": "静态和动态城市场景的新颖视图合成（NVS）对于自动驾驶模拟至关重要，但现有方法往往难以平衡重建时间和质量。虽然最先进的神经辐射场和 3D 高斯喷射方法可以实现照片级真实感，但它们通常依赖于耗时的每个场景优化。相反，新兴的前馈方法经常采用每像素高斯表示，这会导致在复杂、动态环境中聚合多视图预测时出现 3D 不一致。我们提出了 EvolSplat4D，这是一种前馈框架，通过统一三个专门分支中基于体积和基于像素的高斯预测，超越了现有的每像素范式。对于近距离静态区域，我们直接从 3D 特征体积预测多个帧上 3D 高斯的一致几何形状，并辅以语义增强的基于图像的渲染模块来预测其外观。对于动态演员，我们利用以对象为中心的规范空间和运动调整渲染模块来聚合时间特征，确保稳定的 4D 重建，尽管运动先验存在噪声。远场场景由高效的每像素高斯分支处理，以确保全场景覆盖。 KITTI-360、KITTI、Waymo 和 PandaSet 数据集上的实验结果表明，EvolSplat4D 能够以卓越的准确性和一致性重建静态和动态环境，优于按场景优化和最先进的前馈基线。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15968v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15968v1",
        "title": "HyperAlign: Hypernetwork for Efficient Test-Time Alignment of Diffusion Models",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "HyperAlign: Hypernetwork for Efficient Test-Time Alignment of Diffusion Models"
        },
        "updated": "2026-01-22T13:49:47Z",
        "updated_parsed": [
            2026,
            1,
            22,
            13,
            49,
            47,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15968v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15968v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Diffusion models achieve state-of-the-art performance but often fail to generate outputs that align with human preferences and intentions, resulting in images with poor aesthetic quality and semantic inconsistencies. Existing alignment methods present a difficult trade-off: fine-tuning approaches suffer from loss of diversity with reward over-optimization, while test-time scaling methods introduce significant computational overhead and tend to under-optimize. To address these limitations, we propose HyperAlign, a novel framework that trains a hypernetwork for efficient and effective test-time alignment. Instead of modifying latent states, HyperAlign dynamically generates low-rank adaptation weights to modulate the diffusion model's generation operators. This allows the denoising trajectory to be adaptively adjusted based on input latents, timesteps and prompts for reward-conditioned alignment. We introduce multiple variants of HyperAlign that differ in how frequently the hypernetwork is applied, balancing between performance and efficiency. Furthermore, we optimize the hypernetwork using a reward score objective regularized with preference data to reduce reward hacking. We evaluate HyperAlign on multiple extended generative paradigms, including Stable Diffusion and FLUX. It significantly outperforms existing fine-tuning and test-time scaling baselines in enhancing semantic consistency and visual appeal.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Diffusion models achieve state-of-the-art performance but often fail to generate outputs that align with human preferences and intentions, resulting in images with poor aesthetic quality and semantic inconsistencies. Existing alignment methods present a difficult trade-off: fine-tuning approaches suffer from loss of diversity with reward over-optimization, while test-time scaling methods introduce significant computational overhead and tend to under-optimize. To address these limitations, we propose HyperAlign, a novel framework that trains a hypernetwork for efficient and effective test-time alignment. Instead of modifying latent states, HyperAlign dynamically generates low-rank adaptation weights to modulate the diffusion model's generation operators. This allows the denoising trajectory to be adaptively adjusted based on input latents, timesteps and prompts for reward-conditioned alignment. We introduce multiple variants of HyperAlign that differ in how frequently the hypernetwork is applied, balancing between performance and efficiency. Furthermore, we optimize the hypernetwork using a reward score objective regularized with preference data to reduce reward hacking. We evaluate HyperAlign on multiple extended generative paradigms, including Stable Diffusion and FLUX. It significantly outperforms existing fine-tuning and test-time scaling baselines in enhancing semantic consistency and visual appeal."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T13:49:47Z",
        "published_parsed": [
            2026,
            1,
            22,
            13,
            49,
            47,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Xin Xie"
            },
            {
                "name": "Jiaxian Guo"
            },
            {
                "name": "Dong Gong"
            }
        ],
        "author_detail": {
            "name": "Dong Gong"
        },
        "author": "Dong Gong",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "HyperAlign：用于扩散模型的高效测试时对齐的超网络",
        "abstract_cn": "扩散模型实现了最先进的性能，但通常无法生成符合人类偏好和意图的输出，导致图像的审美质量较差和语义不一致。现有的对齐方法存在一个困难的权衡：微调方法会因奖励过度优化而损失多样性，而测试时间缩放方法会引入大量的计算开销，并且往往会优化不足。为了解决这些限制，我们提出了 HyperAlign，这是一种新颖的框架，可以训练超网络以实现高效且有效的测试时间对齐。 HyperAlign 不是修改潜在状态，而是动态生成低秩适应权重来调节扩散模型的生成算子。这使得去噪轨迹能够根据输入潜伏、时间步长和奖励条件对齐的提示进行自适应调整。我们引入了 HyperAlign 的多个变体，这些变体的不同之处在于超网络的应用频率，以平衡性能和效率。此外，我们使用偏好数据规范化的奖励分数目标来优化超网络，以减少奖励黑客行为。我们在多种扩展生成范式上评估 HyperAlign，包括稳定扩散和通量。它在增强语义一致性和视觉吸引力方面显着优于现有的微调和测试时间缩放基线。"
    },
    {
        "id": "http://arxiv.org/abs/2601.16007v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.16007v1",
        "title": "PhysicsMind: Sim and Real Mechanics Benchmarking for Physical Reasoning and Prediction in Foundational VLMs and World Models",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "PhysicsMind: Sim and Real Mechanics Benchmarking for Physical Reasoning and Prediction in Foundational VLMs and World Models"
        },
        "updated": "2026-01-22T14:33:01Z",
        "updated_parsed": [
            2026,
            1,
            22,
            14,
            33,
            1,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.16007v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.16007v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Modern foundational Multimodal Large Language Models (MLLMs) and video world models have advanced significantly in mathematical, common-sense, and visual reasoning, but their grasp of the underlying physics remains underexplored. Existing benchmarks attempting to measure this matter rely on synthetic, Visual Question Answer templates or focus on perceptual video quality that is tangential to measuring how well the video abides by physical laws. To address this fragmentation, we introduce PhysicsMind, a unified benchmark with both real and simulation environments that evaluates law-consistent reasoning and generation over three canonical principles: Center of Mass, Lever Equilibrium, and Newton's First Law. PhysicsMind comprises two main tasks: i) VQA tasks, testing whether models can reason and determine physical quantities and values from images or short videos, and ii) Video Generation(VG) tasks, evaluating if predicted motion trajectories obey the same center-of-mass, torque, and inertial constraints as the ground truth. A broad range of recent models and video generation models is evaluated on PhysicsMind and found to rely on appearance heuristics while often violating basic mechanics. These gaps indicate that current scaling and training are still insufficient for robust physical understanding, underscoring PhysicsMind as a focused testbed for physics-aware multimodal models. Our data will be released upon acceptance.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Modern foundational Multimodal Large Language Models (MLLMs) and video world models have advanced significantly in mathematical, common-sense, and visual reasoning, but their grasp of the underlying physics remains underexplored. Existing benchmarks attempting to measure this matter rely on synthetic, Visual Question Answer templates or focus on perceptual video quality that is tangential to measuring how well the video abides by physical laws. To address this fragmentation, we introduce PhysicsMind, a unified benchmark with both real and simulation environments that evaluates law-consistent reasoning and generation over three canonical principles: Center of Mass, Lever Equilibrium, and Newton's First Law. PhysicsMind comprises two main tasks: i) VQA tasks, testing whether models can reason and determine physical quantities and values from images or short videos, and ii) Video Generation(VG) tasks, evaluating if predicted motion trajectories obey the same center-of-mass, torque, and inertial constraints as the ground truth. A broad range of recent models and video generation models is evaluated on PhysicsMind and found to rely on appearance heuristics while often violating basic mechanics. These gaps indicate that current scaling and training are still insufficient for robust physical understanding, underscoring PhysicsMind as a focused testbed for physics-aware multimodal models. Our data will be released upon acceptance."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.AI",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T14:33:01Z",
        "published_parsed": [
            2026,
            1,
            22,
            14,
            33,
            1,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Chak-Wing Mak"
            },
            {
                "name": "Guanyu Zhu"
            },
            {
                "name": "Boyi Zhang"
            },
            {
                "name": "Hongji Li"
            },
            {
                "name": "Xiaowei Chi"
            },
            {
                "name": "Kevin Zhang"
            },
            {
                "name": "Yichen Wu"
            },
            {
                "name": "Yangfan He"
            },
            {
                "name": "Chun-Kai Fan"
            },
            {
                "name": "Wentao Lu"
            },
            {
                "name": "Kuangzhi Ge"
            },
            {
                "name": "Xinyu Fang"
            },
            {
                "name": "Hongyang He"
            },
            {
                "name": "Kuan Lu"
            },
            {
                "name": "Tianxiang Xu"
            },
            {
                "name": "Li Zhang"
            },
            {
                "name": "Yongxin Ni"
            },
            {
                "name": "Youhua Li"
            },
            {
                "name": "Shanghang Zhang"
            }
        ],
        "author_detail": {
            "name": "Shanghang Zhang"
        },
        "author": "Shanghang Zhang",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "PhysicsMind：基础 VLM 和世界模型中物理推理和预测的模拟和真实力学基准测试",
        "abstract_cn": "现代基础多模态大语言模型 (MLLM) 和视频世界模型在数学、常识和视觉推理方面取得了显着进步，但它们对底层物理的掌握仍然有待探索。试图衡量这个问题的现有基准依赖于合成的视觉问答模板或关注感知视频质量，这与衡量视频遵守物理定律的程度无关。为了解决这种碎片化问题，我们引入了PhysicsMind，这是一个具有真实和模拟环境的统一基准，可根据三个规范原理（质心、杠杆平衡和牛顿第一定律）评估规律一致的推理和生成。 PhysicsMind 包括两个主要任务：i）VQA 任务，测试模型是否可以推理并确定图像或短视频中的物理量和值；ii）视频生成（VG）任务，评估预测的运动轨迹是否遵循与地面真实情况相同的质心、扭矩和惯性约束。在PhysicsMind 上评估了一系列最新的模型和视频生成模型，发现它们依赖于外观启发法，同时经常违反基本力学。这些差距表明，当前的扩展和训练仍然不足以实现强大的物理理解，这凸显了PhysicsMind作为物理感知多模态模型的重点测试平台。我们的数据将在接受后发布。"
    },
    {
        "id": "http://arxiv.org/abs/2601.16020v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.16020v1",
        "title": "Keyframe-Based Feed-Forward Visual Odometry",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Keyframe-Based Feed-Forward Visual Odometry"
        },
        "updated": "2026-01-22T14:45:42Z",
        "updated_parsed": [
            2026,
            1,
            22,
            14,
            45,
            42,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.16020v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.16020v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "The emergence of visual foundation models has revolutionized visual odometry~(VO) and SLAM, enabling pose estimation and dense reconstruction within a single feed-forward network. However, unlike traditional pipelines that leverage keyframe methods to enhance efficiency and accuracy, current foundation model based methods, such as VGGT-Long, typically process raw image sequences indiscriminately. This leads to computational redundancy and degraded performance caused by low inter-frame parallax, which provides limited contextual stereo information. Integrating traditional geometric heuristics into these methods is non-trivial, as their performance depends on high-dimensional latent representations rather than explicit geometric metrics. To bridge this gap, we propose a novel keyframe-based feed-forward VO. Instead of relying on hand-crafted rules, our approach employs reinforcement learning to derive an adaptive keyframe policy in a data-driven manner, aligning selection with the intrinsic characteristics of the underlying foundation model. We train our agent on TartanAir dataset and conduct extensive evaluations across several real-world datasets. Experimental results demonstrate that the proposed method achieves consistent and substantial improvements over state-of-the-art feed-forward VO methods.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "The emergence of visual foundation models has revolutionized visual odometry~(VO) and SLAM, enabling pose estimation and dense reconstruction within a single feed-forward network. However, unlike traditional pipelines that leverage keyframe methods to enhance efficiency and accuracy, current foundation model based methods, such as VGGT-Long, typically process raw image sequences indiscriminately. This leads to computational redundancy and degraded performance caused by low inter-frame parallax, which provides limited contextual stereo information. Integrating traditional geometric heuristics into these methods is non-trivial, as their performance depends on high-dimensional latent representations rather than explicit geometric metrics. To bridge this gap, we propose a novel keyframe-based feed-forward VO. Instead of relying on hand-crafted rules, our approach employs reinforcement learning to derive an adaptive keyframe policy in a data-driven manner, aligning selection with the intrinsic characteristics of the underlying foundation model. We train our agent on TartanAir dataset and conduct extensive evaluations across several real-world datasets. Experimental results demonstrate that the proposed method achieves consistent and substantial improvements over state-of-the-art feed-forward VO methods."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.RO",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T14:45:42Z",
        "published_parsed": [
            2026,
            1,
            22,
            14,
            45,
            42,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Weichen Dai"
            },
            {
                "name": "Wenhan Su"
            },
            {
                "name": "Da Kong"
            },
            {
                "name": "Yuhang Ming"
            },
            {
                "name": "Wanzeng Kong"
            }
        ],
        "author_detail": {
            "name": "Wanzeng Kong"
        },
        "author": "Wanzeng Kong",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "基于关键帧的前馈视觉里程计",
        "abstract_cn": "视觉基础模型的出现彻底改变了视觉里程计（VO）和 SLAM，在单个前馈网络中实现姿态估计和密集重建。然而，与利用关键帧方法来提高效率和准确性的传统流程不同，当前基于基础模型的方法（例如 VGGT-Long）通常不加区别地处理原始图像序列。这会导致计算冗余和低帧间视差导致的性能下降，从而提供有限的上下文立体信息。将传统的几何启发式集成到这些方法中并非易事，因为它们的性能取决于高维潜在表示而不是显式几何度量。为了弥补这一差距，我们提出了一种新颖的基于关键帧的前馈 VO。我们的方法不依赖手工制定的规则，而是采用强化学习以数据驱动的方式导出自适应关键帧策略，使选择与底层基础模型的内在特征保持一致。我们在 TartanAir 数据集上训练我们的代理，并在几个现实世界的数据集上进行广泛的评估。实验结果表明，所提出的方法比最先进的前馈 VO 方法取得了一致且实质性的改进。"
    },
    {
        "id": "http://arxiv.org/abs/2601.16024v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.16024v1",
        "title": "PAINT: Pathology-Aware Integrated Next-Scale Transformation for Virtual Immunohistochemistry",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "PAINT: Pathology-Aware Integrated Next-Scale Transformation for Virtual Immunohistochemistry"
        },
        "updated": "2026-01-22T14:49:30Z",
        "updated_parsed": [
            2026,
            1,
            22,
            14,
            49,
            30,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.16024v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.16024v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Virtual immunohistochemistry (IHC) aims to computationally synthesize molecular staining patterns from routine Hematoxylin and Eosin (H\\&E) images, offering a cost-effective and tissue-efficient alternative to traditional physical staining. However, this task is particularly challenging: H\\&E morphology provides ambiguous cues about protein expression, and similar tissue structures may correspond to distinct molecular states. Most existing methods focus on direct appearance synthesis to implicitly achieve cross-modal generation, often resulting in semantic inconsistencies due to insufficient structural priors. In this paper, we propose Pathology-Aware Integrated Next-Scale Transformation (PAINT), a visual autoregressive framework that reformulates the synthesis process as a structure-first conditional generation task. Unlike direct image translation, PAINT enforces a causal order by resolving molecular details conditioned on a global structural layout. Central to this approach is the introduction of a Spatial Structural Start Map (3S-Map), which grounds the autoregressive initialization in observed morphology, ensuring deterministic, spatially aligned synthesis. Experiments on the IHC4BC and MIST datasets demonstrate that PAINT outperforms state-of-the-art methods in structural fidelity and clinical downstream tasks, validating the potential of structure-guided autoregressive modeling.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Virtual immunohistochemistry (IHC) aims to computationally synthesize molecular staining patterns from routine Hematoxylin and Eosin (H\\&E) images, offering a cost-effective and tissue-efficient alternative to traditional physical staining. However, this task is particularly challenging: H\\&E morphology provides ambiguous cues about protein expression, and similar tissue structures may correspond to distinct molecular states. Most existing methods focus on direct appearance synthesis to implicitly achieve cross-modal generation, often resulting in semantic inconsistencies due to insufficient structural priors. In this paper, we propose Pathology-Aware Integrated Next-Scale Transformation (PAINT), a visual autoregressive framework that reformulates the synthesis process as a structure-first conditional generation task. Unlike direct image translation, PAINT enforces a causal order by resolving molecular details conditioned on a global structural layout. Central to this approach is the introduction of a Spatial Structural Start Map (3S-Map), which grounds the autoregressive initialization in observed morphology, ensuring deterministic, spatially aligned synthesis. Experiments on the IHC4BC and MIST datasets demonstrate that PAINT outperforms state-of-the-art methods in structural fidelity and clinical downstream tasks, validating the potential of structure-guided autoregressive modeling."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T14:49:30Z",
        "published_parsed": [
            2026,
            1,
            22,
            14,
            49,
            30,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Rongze Ma"
            },
            {
                "name": "Mengkang Lu"
            },
            {
                "name": "Zhenyu Xiang"
            },
            {
                "name": "Yongsheng Pan"
            },
            {
                "name": "Yicheng Wu"
            },
            {
                "name": "Qingjie Zeng"
            },
            {
                "name": "Yong Xia"
            }
        ],
        "author_detail": {
            "name": "Yong Xia"
        },
        "author": "Yong Xia",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "PAINT：虚拟免疫组织化学的病理学感知集成下一代转化",
        "abstract_cn": "虚拟免疫组织化学 (IHC) 旨在通过常规苏木精和曙红 (H\\&E) 图像通过计算合成分子染色模式，为传统物理染色提供一种经济有效且组织高效的替代方案。然而，这项任务特别具有挑战性：H\\&E 形态提供了有关蛋白质表达的模糊线索，而相似的组织结构可能对应于不同的分子状态。大多数现有方法侧重于直接外观合成以隐式实现跨模态生成，通常由于结构先验不足而导致语义不一致。在本文中，我们提出了病理学感知集成下一尺度转换（PAINT），这是一种视觉自回归框架，它将合成过程重新表述为结构优先的条件生成任务。与直接图像翻译不同，PAINT 通过解析以全局结构布局为条件的分子细节来强制执行因果顺序。该方法的核心是引入空间结构起始图（3S-Map），它将自回归初始化基于观察到的形态，确保确定性、空间对齐的合成。 IHC4BC 和 MIST 数据集上的实验表明，PAINT 在结构保真度和临床下游任务方面优于最先进的方法，验证了结构引导自回归建模的潜力。"
    },
    {
        "id": "http://arxiv.org/abs/2601.16060v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.16060v1",
        "title": "ProGiDiff: Prompt-Guided Diffusion-Based Medical Image Segmentation",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "ProGiDiff: Prompt-Guided Diffusion-Based Medical Image Segmentation"
        },
        "updated": "2026-01-22T15:56:21Z",
        "updated_parsed": [
            2026,
            1,
            22,
            15,
            56,
            21,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.16060v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.16060v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Widely adopted medical image segmentation methods, although efficient, are primarily deterministic and remain poorly amenable to natural language prompts. Thus, they lack the capability to estimate multiple proposals, human interaction, and cross-modality adaptation. Recently, text-to-image diffusion models have shown potential to bridge the gap. However, training them from scratch requires a large dataset-a limitation for medical image segmentation. Furthermore, they are often limited to binary segmentation and cannot be conditioned on a natural language prompt. To this end, we propose a novel framework called ProGiDiff that leverages existing image generation models for medical image segmentation purposes. Specifically, we propose a ControlNet-style conditioning mechanism with a custom encoder, suitable for image conditioning, to steer a pre-trained diffusion model to output segmentation masks. It naturally extends to a multi-class setting simply by prompting the target organ. Our experiment on organ segmentation from CT images demonstrates strong performance compared to previous methods and could greatly benefit from an expert-in-the-loop setting to leverage multiple proposals. Importantly, we demonstrate that the learned conditioning mechanism can be easily transferred through low-rank, few-shot adaptation to segment MR images.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Widely adopted medical image segmentation methods, although efficient, are primarily deterministic and remain poorly amenable to natural language prompts. Thus, they lack the capability to estimate multiple proposals, human interaction, and cross-modality adaptation. Recently, text-to-image diffusion models have shown potential to bridge the gap. However, training them from scratch requires a large dataset-a limitation for medical image segmentation. Furthermore, they are often limited to binary segmentation and cannot be conditioned on a natural language prompt. To this end, we propose a novel framework called ProGiDiff that leverages existing image generation models for medical image segmentation purposes. Specifically, we propose a ControlNet-style conditioning mechanism with a custom encoder, suitable for image conditioning, to steer a pre-trained diffusion model to output segmentation masks. It naturally extends to a multi-class setting simply by prompting the target organ. Our experiment on organ segmentation from CT images demonstrates strong performance compared to previous methods and could greatly benefit from an expert-in-the-loop setting to leverage multiple proposals. Importantly, we demonstrate that the learned conditioning mechanism can be easily transferred through low-rank, few-shot adaptation to segment MR images."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T15:56:21Z",
        "published_parsed": [
            2026,
            1,
            22,
            15,
            56,
            21,
            3,
            22,
            0
        ],
        "arxiv_comment": "5 pages, 4 figures. It has been accepted by IEEE ISBI",
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Yuan Lin"
            },
            {
                "name": "Murong Xu"
            },
            {
                "name": "Marc Hölle"
            },
            {
                "name": "Chinmay Prabhakar"
            },
            {
                "name": "Andreas Maier"
            },
            {
                "name": "Vasileios Belagiannis"
            },
            {
                "name": "Bjoern Menze"
            },
            {
                "name": "Suprosanna Shit"
            }
        ],
        "author_detail": {
            "name": "Suprosanna Shit"
        },
        "author": "Suprosanna Shit",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "ProGiDiff：基于即时引导扩散的医学图像分割",
        "abstract_cn": "广泛采用的医学图像分割方法虽然有效，但主要是确定性的，并且仍然很难适应自然语言提示。因此，它们缺乏估计多个提议、人类交互和跨模态适应的能力。最近，文本到图像的扩散模型已显示出弥补这一差距的潜力。然而，从头开始训练它们需要一个大的数据集——这是医学图像分割的限制。此外，它们通常仅限于二进制分割，并且不能以自然语言提示为条件。为此，我们提出了一种名为 ProGiDiff 的新颖框架，该框架利用现有的图像生成模型进行医学图像分割。具体来说，我们提出了一种带有自定义编码器的 ControlNet 式调节机制，适用于图像调节，以引导预训练的扩散模型输出分割掩模。只需通过提示目标器官，它就可以自然地扩展到多类别设置。与以前的方法相比，我们对 CT 图像器官分割的实验展示了强大的性能，并且可以极大地受益于专家在环设置中利用多个建议。重要的是，我们证明了学习到的调节机制可以通过低秩、少样本适应轻松转移以分割 MR 图像。"
    },
    {
        "id": "http://arxiv.org/abs/2601.16065v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.16065v1",
        "title": "DTP: A Simple yet Effective Distracting Token Pruning Framework for Vision-Language Action Models",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "DTP: A Simple yet Effective Distracting Token Pruning Framework for Vision-Language Action Models"
        },
        "updated": "2026-01-22T16:02:56Z",
        "updated_parsed": [
            2026,
            1,
            22,
            16,
            2,
            56,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.16065v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.16065v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Vision-Language Action (VLA) models have shown remarkable progress in robotic manipulation by leveraging the powerful perception abilities of Vision-Language Models (VLMs) to understand environments and directly output actions. However, by default, VLA models may overly attend to image tokens in the task-irrelevant region, which we describe as 'distracting tokens'. This behavior can disturb the model from the generation of the desired action tokens in each step, affecting the success rate of tasks. In this paper, we introduce a simple yet effective plug-and-play Distracting Token Pruning (DTP) framework, which dynamically detects and prunes these distracting image tokens. By correcting the model's visual attention patterns, we aim to improve the task success rate, as well as exploring the performance upper boundaries of the model without altering its original architecture or adding additional inputs. Experiments on the SIMPLER Benchmark (Li et al., 2024) show that our method consistently achieving relative improvements in task success rates across different types of novel VLA models, demonstrating generalizability to transformer-based VLAs. Further analysis reveals a negative correlation between the task success rate and the amount of attentions in the task-irrelevant region for all models tested, highlighting a common phenomenon of VLA models that could guide future research. We also publish our code at: https://anonymous.4open.science/r/CBD3.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Vision-Language Action (VLA) models have shown remarkable progress in robotic manipulation by leveraging the powerful perception abilities of Vision-Language Models (VLMs) to understand environments and directly output actions. However, by default, VLA models may overly attend to image tokens in the task-irrelevant region, which we describe as 'distracting tokens'. This behavior can disturb the model from the generation of the desired action tokens in each step, affecting the success rate of tasks. In this paper, we introduce a simple yet effective plug-and-play Distracting Token Pruning (DTP) framework, which dynamically detects and prunes these distracting image tokens. By correcting the model's visual attention patterns, we aim to improve the task success rate, as well as exploring the performance upper boundaries of the model without altering its original architecture or adding additional inputs. Experiments on the SIMPLER Benchmark (Li et al., 2024) show that our method consistently achieving relative improvements in task success rates across different types of novel VLA models, demonstrating generalizability to transformer-based VLAs. Further analysis reveals a negative correlation between the task success rate and the amount of attentions in the task-irrelevant region for all models tested, highlighting a common phenomenon of VLA models that could guide future research. We also publish our code at: https://anonymous.4open.science/r/CBD3."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.RO",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T16:02:56Z",
        "published_parsed": [
            2026,
            1,
            22,
            16,
            2,
            56,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Chenyang Li"
            },
            {
                "name": "Jieyuan Liu"
            },
            {
                "name": "Bin Li"
            },
            {
                "name": "Bo Gao"
            },
            {
                "name": "Yilin Yuan"
            },
            {
                "name": "Yangfan He"
            },
            {
                "name": "Yuchen Li"
            },
            {
                "name": "Jingqun Tang"
            }
        ],
        "author_detail": {
            "name": "Jingqun Tang"
        },
        "author": "Jingqun Tang",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "DTP：一种简单而有效的视觉语言动作模型分散标记修剪框架",
        "abstract_cn": "视觉语言动作（VLA）模型利用视觉语言模型（VLM）强大的感知能力来理解环境并直接输出动作，在机器人操作方面取得了显着的进展。然而，默认情况下，VLA 模型可能会过度关注与任务无关区域中的图像标记，我们将其描述为“分散注意力的标记”。这种行为可能会干扰模型在每个步骤中生成所需操作标记，从而影响任务的成功率。在本文中，我们介绍了一种简单而有效的即插即用分散注意力标记修剪（DTP）框架，该框架可以动态检测和修剪这些分散注意力的图像标记。通过纠正模型的视觉注意模式，我们的目标是提高任务成功率，并在不改变其原始架构或添加额外输入的情况下探索模型的性能上限。 SIMPLER Benchmark（Li 等人，2024）上的实验表明，我们的方法在不同类型的新型 VLA 模型中始终实现了任务成功率的相对提高，证明了基于 Transformer 的 VLA 的通用性。进一步的分析揭示了所有测试模型的任务成功率与任务无关区域的关注量之间存在负相关，这凸显了 VLA 模型的普遍现象，可以指导未来的研究。我们还将我们的代码发布在：https://anonymous.4open.science/r/CBD3。"
    },
    {
        "id": "http://arxiv.org/abs/2601.16073v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.16073v1",
        "title": "DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models"
        },
        "updated": "2026-01-22T16:18:02Z",
        "updated_parsed": [
            2026,
            1,
            22,
            16,
            18,
            2,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.16073v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.16073v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Foundation Models (FMs) have demonstrated strong generalization across diverse vision tasks. However, their deployment in federated settings is hindered by high computational demands, substantial communication overhead, and significant inference costs. We propose DSFedMed, a dual-scale federated framework that enables mutual knowledge distillation between a centralized foundation model and lightweight client models for medical image segmentation. To support knowledge distillation, a set of high-quality medical images is generated to replace real public datasets, and a learnability-guided sample selection strategy is proposed to enhance efficiency and effectiveness in dual-scale distillation. This mutual distillation enables the foundation model to transfer general knowledge to lightweight clients, while also incorporating client-specific insights to refine the foundation model. Evaluations on five medical imaging segmentation datasets show that DSFedMed achieves an average 2 percent improvement in Dice score while reducing communication costs and inference time by nearly 90 percent compared to existing federated foundation model baselines. These results demonstrate significant efficiency gains and scalability for resource-limited federated deployments.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Foundation Models (FMs) have demonstrated strong generalization across diverse vision tasks. However, their deployment in federated settings is hindered by high computational demands, substantial communication overhead, and significant inference costs. We propose DSFedMed, a dual-scale federated framework that enables mutual knowledge distillation between a centralized foundation model and lightweight client models for medical image segmentation. To support knowledge distillation, a set of high-quality medical images is generated to replace real public datasets, and a learnability-guided sample selection strategy is proposed to enhance efficiency and effectiveness in dual-scale distillation. This mutual distillation enables the foundation model to transfer general knowledge to lightweight clients, while also incorporating client-specific insights to refine the foundation model. Evaluations on five medical imaging segmentation datasets show that DSFedMed achieves an average 2 percent improvement in Dice score while reducing communication costs and inference time by nearly 90 percent compared to existing federated foundation model baselines. These results demonstrate significant efficiency gains and scalability for resource-limited federated deployments."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.DC",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T16:18:02Z",
        "published_parsed": [
            2026,
            1,
            22,
            16,
            18,
            2,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Hanwen Zhang"
            },
            {
                "name": "Qiaojin Shen"
            },
            {
                "name": "Yuxi Liu"
            },
            {
                "name": "Yuesheng Zhu"
            },
            {
                "name": "Guibo Luo"
            }
        ],
        "author_detail": {
            "name": "Guibo Luo"
        },
        "author": "Guibo Luo",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "DSFedMed：通过基础模型和轻量级模型之间的相互蒸馏进行双尺度联合医学图像分割",
        "abstract_cn": "基础模型（FM）在不同的视觉任务中表现出了很强的泛化能力。然而，它们在联合设置中的部署受到高计算需求、大量通信开销和巨大推理成本的阻碍。我们提出了 DSFedMed，这是一个双尺度联合框架，可以实现集中式基础模型和轻量级客户端模型之间的相互知识蒸馏，以进行医学图像分割。为了支持知识蒸馏，生成了一组高质量的医学图像来替换真实的公共数据集，并提出了一种可学习性引导的样本选择策略来提高双尺度蒸馏的效率和有效性。这种相互蒸馏使基础模型能够将一般知识传递给轻量级客户端，同时还结合特定于客户端的见解来完善基础模型。对五个医学成像分割数据集的评估表明，与现有的联合基础模型基线相比，DSFedMed 的 Dice 分数平均提高了 2%，同时将通信成本和推理时间减少了近 90%。这些结果证明了资源有限的联合部署的显着效率提升和可扩展性。"
    },
    {
        "id": "http://arxiv.org/abs/2601.16079v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.16079v1",
        "title": "Masked Modeling for Human Motion Recovery Under Occlusions",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Masked Modeling for Human Motion Recovery Under Occlusions"
        },
        "updated": "2026-01-22T16:22:20Z",
        "updated_parsed": [
            2026,
            1,
            22,
            16,
            22,
            20,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.16079v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.16079v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Human motion reconstruction from monocular videos is a fundamental challenge in computer vision, with broad applications in AR/VR, robotics, and digital content creation, but remains challenging under frequent occlusions in real-world settings.Existing regression-based methods are efficient but fragile to missing observations, while optimization- and diffusion-based approaches improve robustness at the cost of slow inference speed and heavy preprocessing steps. To address these limitations, we leverage recent advances in generative masked modeling and present MoRo: Masked Modeling for human motion Recovery under Occlusions. MoRo is an occlusion-robust, end-to-end generative framework that formulates motion reconstruction as a video-conditioned task, and efficiently recover human motion in a consistent global coordinate system from RGB videos. By masked modeling, MoRo naturally handles occlusions while enabling efficient, end-to-end inference. To overcome the scarcity of paired video-motion data, we design a cross-modality learning scheme that learns multi-modal priors from a set of heterogeneous datasets: (i) a trajectory-aware motion prior trained on MoCap datasets, (ii) an image-conditioned pose prior trained on image-pose datasets, capturing diverse per-frame poses, and (iii) a video-conditioned masked transformer that fuses motion and pose priors, finetuned on video-motion datasets to integrate visual cues with motion dynamics for robust inference. Extensive experiments on EgoBody and RICH demonstrate that MoRo substantially outperforms state-of-the-art methods in accuracy and motion realism under occlusions, while performing on-par in non-occluded scenarios. MoRo achieves real-time inference at 70 FPS on a single H200 GPU.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Human motion reconstruction from monocular videos is a fundamental challenge in computer vision, with broad applications in AR/VR, robotics, and digital content creation, but remains challenging under frequent occlusions in real-world settings.Existing regression-based methods are efficient but fragile to missing observations, while optimization- and diffusion-based approaches improve robustness at the cost of slow inference speed and heavy preprocessing steps. To address these limitations, we leverage recent advances in generative masked modeling and present MoRo: Masked Modeling for human motion Recovery under Occlusions. MoRo is an occlusion-robust, end-to-end generative framework that formulates motion reconstruction as a video-conditioned task, and efficiently recover human motion in a consistent global coordinate system from RGB videos. By masked modeling, MoRo naturally handles occlusions while enabling efficient, end-to-end inference. To overcome the scarcity of paired video-motion data, we design a cross-modality learning scheme that learns multi-modal priors from a set of heterogeneous datasets: (i) a trajectory-aware motion prior trained on MoCap datasets, (ii) an image-conditioned pose prior trained on image-pose datasets, capturing diverse per-frame poses, and (iii) a video-conditioned masked transformer that fuses motion and pose priors, finetuned on video-motion datasets to integrate visual cues with motion dynamics for robust inference. Extensive experiments on EgoBody and RICH demonstrate that MoRo substantially outperforms state-of-the-art methods in accuracy and motion realism under occlusions, while performing on-par in non-occluded scenarios. MoRo achieves real-time inference at 70 FPS on a single H200 GPU."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T16:22:20Z",
        "published_parsed": [
            2026,
            1,
            22,
            16,
            22,
            20,
            3,
            22,
            0
        ],
        "arxiv_comment": "Project page: https://mikeqzy.github.io/MoRo",
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Zhiyin Qian"
            },
            {
                "name": "Siwei Zhang"
            },
            {
                "name": "Bharat Lal Bhatnagar"
            },
            {
                "name": "Federica Bogo"
            },
            {
                "name": "Siyu Tang"
            }
        ],
        "author_detail": {
            "name": "Siyu Tang"
        },
        "author": "Siyu Tang",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "遮挡下人体运动恢复的掩蔽建模",
        "abstract_cn": "单目视频的人体运动重建是计算机视觉领域的一项基本挑战，在 AR/VR、机器人技术和数字内容创建领域有着广泛的应用，但在现实环境中频繁遮挡的情况下仍然具有挑战性。现有的基于回归的方法虽然高效，但容易丢失观察结果，而基于优化和扩散的方法则以缓慢的推理速度和繁重的预处理步骤为代价提高了鲁棒性。为了解决这些限制，我们利用生成掩模建模的最新进展，并提出了 MoRo：遮挡下人体运动恢复的掩模建模。 MoRo 是一种遮挡稳健的端到端生成框架，它将运动重建制定为视频条件任务，并在一致的全局坐标系中从 RGB 视频中有效地恢复人体运动。通过屏蔽建模，MoRo 自然地处理遮挡，同时实现高效的端到端推理。为了克服成对视频运动数据的稀缺性，我们设计了一种跨模态学习方案，从一组异构数据集中学习多模态先验：（i）在MoCap数据集上训练的轨迹感知运动，（ii）在图像姿势数据集上训练的图像条件姿势，捕获不同的每帧姿势，以及（iii）融合运动和姿势先验的视频条件掩模变换器，在视频运动数据集上进行微调，以将视觉线索与运动动力学相结合为了稳健的推理。在 EgoBody 和 RICH 上进行的大量实验表明，MoRo 在遮挡情况下的准确性和运动真实感方面远远优于最先进的方法，而在非遮挡场景中的表现则相当。 MoRo 在单个 H200 GPU 上实现了 70 FPS 的实时推理。"
    },
    {
        "id": "http://arxiv.org/abs/2601.16098v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.16098v1",
        "title": "Clustering-Guided Spatial-Spectral Mamba for Hyperspectral Image Classification",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Clustering-Guided Spatial-Spectral Mamba for Hyperspectral Image Classification"
        },
        "updated": "2026-01-22T16:47:07Z",
        "updated_parsed": [
            2026,
            1,
            22,
            16,
            47,
            7,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.16098v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.16098v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Although Mamba models greatly improve Hyperspectral Image (HSI) classification, they have critical challenges in terms defining efficient and adaptive token sequences for improve performance. This paper therefore presents CSSMamba (Clustering-guided Spatial-Spectral Mamba) framework to better address the challenges, with the following contributions. First, to achieve efficient and adaptive token sequences for improved Mamba performance, we integrate the clustering mechanism into a spatial Mamba architecture, leading to a cluster-guided spatial Mamba module (CSpaMamba) that reduces the Mamba sequence length and improves Mamba feature learning capability. Second, to improve the learning of both spatial and spectral information, we integrate the CSpaMamba module with a spectral mamba module (SpeMamba), leading to a complete clustering-guided spatial-spectral Mamba framework. Third, to further improve feature learning capability, we introduce an Attention-Driven Token Selection mechanism to optimize Mamba token sequencing. Last, to seamlessly integrate clustering into the Mamba model in a coherent manner, we design a Learnable Clustering Module that learns the cluster memberships in an adaptive manner. Experiments on the Pavia University, Indian Pines, and Liao-Ning 01 datasets demonstrate that CSSMamba achieves higher accuracy and better boundary preservation compared to state-of-the-art CNN, Transformer, and Mamba-based methods.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Although Mamba models greatly improve Hyperspectral Image (HSI) classification, they have critical challenges in terms defining efficient and adaptive token sequences for improve performance. This paper therefore presents CSSMamba (Clustering-guided Spatial-Spectral Mamba) framework to better address the challenges, with the following contributions. First, to achieve efficient and adaptive token sequences for improved Mamba performance, we integrate the clustering mechanism into a spatial Mamba architecture, leading to a cluster-guided spatial Mamba module (CSpaMamba) that reduces the Mamba sequence length and improves Mamba feature learning capability. Second, to improve the learning of both spatial and spectral information, we integrate the CSpaMamba module with a spectral mamba module (SpeMamba), leading to a complete clustering-guided spatial-spectral Mamba framework. Third, to further improve feature learning capability, we introduce an Attention-Driven Token Selection mechanism to optimize Mamba token sequencing. Last, to seamlessly integrate clustering into the Mamba model in a coherent manner, we design a Learnable Clustering Module that learns the cluster memberships in an adaptive manner. Experiments on the Pavia University, Indian Pines, and Liao-Ning 01 datasets demonstrate that CSSMamba achieves higher accuracy and better boundary preservation compared to state-of-the-art CNN, Transformer, and Mamba-based methods."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.LG",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T16:47:07Z",
        "published_parsed": [
            2026,
            1,
            22,
            16,
            47,
            7,
            3,
            22,
            0
        ],
        "arxiv_comment": "5 pages, 3 figures",
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Zack Dewis"
            },
            {
                "name": "Yimin Zhu"
            },
            {
                "name": "Zhengsen Xu"
            },
            {
                "name": "Mabel Heffring"
            },
            {
                "name": "Saeid Taleghanidoozdoozan"
            },
            {
                "name": "Quinn Ledingham"
            },
            {
                "name": "Lincoln Linlin Xu"
            }
        ],
        "author_detail": {
            "name": "Lincoln Linlin Xu"
        },
        "author": "Lincoln Linlin Xu",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "用于高光谱图像分类的聚类引导空间光谱 Mamba",
        "abstract_cn": "尽管 Mamba 模型极大地改进了高光谱图像 (HSI) 分类，但它们在定义高效和自适应标记序列以提高性能方面面临着严峻的挑战。因此，本文提出了CSSMamba（聚类引导的空间频谱Mamba）框架，以更好地应对这些挑战，并做出以下贡献。首先，为了实现高效和自适应的令牌序列以提高 Mamba 性能，我们将聚类机制集成到空间 Mamba 架构中，形成了聚类引导的空间 Mamba 模块（CSpaMamba），可以减少 Mamba 序列长度并提高 Mamba 特征学习能力。其次，为了提高空间和光谱信息的学习，我们将 CSpaMamba 模块与光谱曼巴模块 (SpeMamba) 集成，形成一个完整的聚类引导的空间光谱 Mamba 框架。第三，为了进一步提高特征学习能力，我们引入了注意力驱动的令牌选择机制来优化 Mamba 令牌排序。最后，为了以一致的方式将聚类无缝集成到 Mamba 模型中，我们设计了一个可学习聚类模块，以自适应方式学习聚类成员资格。在 Pavia University、Indian Pines 和 Liao-Ning 01 数据集上的实验表明，与最先进的 CNN、Transformer 和基于 Mamba 的方法相比，CSSMamba 实现了更高的精度和更好的边界保留。"
    },
    {
        "id": "http://arxiv.org/abs/2601.16113v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.16113v1",
        "title": "synthocr-gen: A synthetic ocr dataset generator for low-resource languages- breaking the data barrier",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "synthocr-gen: A synthetic ocr dataset generator for low-resource languages- breaking the data barrier"
        },
        "updated": "2026-01-22T17:01:33Z",
        "updated_parsed": [
            2026,
            1,
            22,
            17,
            1,
            33,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.16113v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.16113v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Optical Character Recognition (OCR) for low-resource languages remains a significant challenge due to the scarcity of large-scale annotated training datasets. Languages such as Kashmiri, with approximately 7 million speakers and a complex Perso-Arabic script featuring unique diacritical marks, currently lack support in major OCR systems including Tesseract, TrOCR, and PaddleOCR. Manual dataset creation for such languages is prohibitively expensive, time-consuming, and error-prone, often requiring word by word transcription of printed or handwritten text.\n  We present SynthOCR-Gen, an open-source synthetic OCR dataset generator specifically designed for low-resource languages. Our tool addresses the fundamental bottleneck in OCR development by transforming digital Unicode text corpora into ready-to-use training datasets. The system implements a comprehensive pipeline encompassing text segmentation (character, word, n-gram, sentence, and line levels), Unicode normalization with script purity enforcement, multi-font rendering with configurable distribution, and 25+ data augmentation techniques simulating real-world document degradations including rotation, blur, noise, and scanner artifacts.\n  We demonstrate the efficacy of our approach by generating a 600,000-sample word-segmented Kashmiri OCR dataset, which we release publicly on HuggingFace. This work provides a practical pathway for bringing low-resource languages into the era of vision-language AI models, and the tool is openly available for researchers and practitioners working with underserved writing systems worldwide.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Optical Character Recognition (OCR) for low-resource languages remains a significant challenge due to the scarcity of large-scale annotated training datasets. Languages such as Kashmiri, with approximately 7 million speakers and a complex Perso-Arabic script featuring unique diacritical marks, currently lack support in major OCR systems including Tesseract, TrOCR, and PaddleOCR. Manual dataset creation for such languages is prohibitively expensive, time-consuming, and error-prone, often requiring word by word transcription of printed or handwritten text.\n  We present SynthOCR-Gen, an open-source synthetic OCR dataset generator specifically designed for low-resource languages. Our tool addresses the fundamental bottleneck in OCR development by transforming digital Unicode text corpora into ready-to-use training datasets. The system implements a comprehensive pipeline encompassing text segmentation (character, word, n-gram, sentence, and line levels), Unicode normalization with script purity enforcement, multi-font rendering with configurable distribution, and 25+ data augmentation techniques simulating real-world document degradations including rotation, blur, noise, and scanner artifacts.\n  We demonstrate the efficacy of our approach by generating a 600,000-sample word-segmented Kashmiri OCR dataset, which we release publicly on HuggingFace. This work provides a practical pathway for bringing low-resource languages into the era of vision-language AI models, and the tool is openly available for researchers and practitioners working with underserved writing systems worldwide."
        },
        "tags": [
            {
                "term": "cs.CL",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T17:01:33Z",
        "published_parsed": [
            2026,
            1,
            22,
            17,
            1,
            33,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CL"
        },
        "authors": [
            {
                "name": "Haq Nawaz Malik"
            },
            {
                "name": "Kh Mohmad Shafi"
            },
            {
                "name": "Tanveer Ahmad Reshi"
            }
        ],
        "author_detail": {
            "name": "Tanveer Ahmad Reshi"
        },
        "author": "Tanveer Ahmad Reshi",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "Synthocr-gen：用于低资源语言的合成 OCR 数据集生成器 - 打破数据障碍",
        "abstract_cn": "由于缺乏大规模带注释的训练数据集，低资源语言的光学字符识别 (OCR) 仍然是一个重大挑战。克什米尔语等语言拥有大约 700 万使用者，其复杂的波斯阿拉伯语文字具有独特的变音符号，目前缺乏 Tesseract、TrOCR 和 PaddleOCR 等主要 OCR 系统的支持。为此类语言手动创建数据集非常昂贵、耗时且容易出错，通常需要逐字转录打印或手写文本。\n  我们推出 SynthOCR-Gen，这是一款专为低资源语言设计的开源合成 OCR 数据集生成器。我们的工具通过将数字 Unicode 文本语料库转换为即用型训练数据集，解决了 OCR 开发的根本瓶颈。该系统实现了一个全面的管道，包括文本分段（字符、单词、n-gram、句子和行级别）、具有脚本纯度强制的 Unicode 规范化、具有可配置分布的多字体渲染，以及模拟真实世界文档降级（包括旋转、模糊、噪声和扫描仪伪影）的 25 多种数据增强技术。\n  我们通过生成包含 600,000 个样本的分词克什米尔 OCR 数据集来展示我们方法的有效性，该数据集已在 HuggingFace 上公开发布。这项工作为将资源匮乏的语言带入视觉语言人工智能模型时代提供了一条实用途径，并且该工具可供全球使用服务不足的书写系统的研究人员和从业者公开使用。"
    },
    {
        "id": "http://arxiv.org/abs/2601.16125v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.16125v1",
        "title": "Rethinking Composed Image Retrieval Evaluation: A Fine-Grained Benchmark from Image Editing",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Rethinking Composed Image Retrieval Evaluation: A Fine-Grained Benchmark from Image Editing"
        },
        "updated": "2026-01-22T17:26:52Z",
        "updated_parsed": [
            2026,
            1,
            22,
            17,
            26,
            52,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.16125v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.16125v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Composed Image Retrieval (CIR) is a pivotal and complex task in multimodal understanding. Current CIR benchmarks typically feature limited query categories and fail to capture the diverse requirements of real-world scenarios. To bridge this evaluation gap, we leverage image editing to achieve precise control over modification types and content, enabling a pipeline for synthesizing queries across a broad spectrum of categories. Using this pipeline, we construct EDIR, a novel fine-grained CIR benchmark. EDIR encompasses 5,000 high-quality queries structured across five main categories and fifteen subcategories. Our comprehensive evaluation of 13 multimodal embedding models reveals a significant capability gap; even state-of-the-art models (e.g., RzenEmbed and GME) struggle to perform consistently across all subcategories, highlighting the rigorous nature of our benchmark. Through comparative analysis, we further uncover inherent limitations in existing benchmarks, such as modality biases and insufficient categorical coverage. Furthermore, an in-domain training experiment demonstrates the feasibility of our benchmark. This experiment clarifies the task challenges by distinguishing between categories that are solvable with targeted data and those that expose intrinsic limitations of current model architectures.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Composed Image Retrieval (CIR) is a pivotal and complex task in multimodal understanding. Current CIR benchmarks typically feature limited query categories and fail to capture the diverse requirements of real-world scenarios. To bridge this evaluation gap, we leverage image editing to achieve precise control over modification types and content, enabling a pipeline for synthesizing queries across a broad spectrum of categories. Using this pipeline, we construct EDIR, a novel fine-grained CIR benchmark. EDIR encompasses 5,000 high-quality queries structured across five main categories and fifteen subcategories. Our comprehensive evaluation of 13 multimodal embedding models reveals a significant capability gap; even state-of-the-art models (e.g., RzenEmbed and GME) struggle to perform consistently across all subcategories, highlighting the rigorous nature of our benchmark. Through comparative analysis, we further uncover inherent limitations in existing benchmarks, such as modality biases and insufficient categorical coverage. Furthermore, an in-domain training experiment demonstrates the feasibility of our benchmark. This experiment clarifies the task challenges by distinguishing between categories that are solvable with targeted data and those that expose intrinsic limitations of current model architectures."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.CL",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.IR",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T17:26:52Z",
        "published_parsed": [
            2026,
            1,
            22,
            17,
            26,
            52,
            3,
            22,
            0
        ],
        "arxiv_comment": "Under review",
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Tingyu Song"
            },
            {
                "name": "Yanzhao Zhang"
            },
            {
                "name": "Mingxin Li"
            },
            {
                "name": "Zhuoning Guo"
            },
            {
                "name": "Dingkun Long"
            },
            {
                "name": "Pengjun Xie"
            },
            {
                "name": "Siyue Zhang"
            },
            {
                "name": "Yilun Zhao"
            },
            {
                "name": "Shu Wu"
            }
        ],
        "author_detail": {
            "name": "Shu Wu"
        },
        "author": "Shu Wu",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "重新思考组合图像检索评估：图像编辑的细粒度基准",
        "abstract_cn": "组合图像检索（CIR）是多模态理解中的一项关键而复杂的任务。当前的 CIR 基准通常具有有限的查询类别，无法捕获现实场景的多样化需求。为了弥补这一评估差距，我们利用图像编辑来实现对修改类型和内容的精确控制，从而实现跨广泛类别综合查询的管道。使用此管道，我们构建了 EDIR，一种新颖的细粒度 CIR 基准。 EDIR 包含 5,000 个高质量查询，涵盖五个主要类别和十五个子类别。我们对 13 个多模态嵌入模型的综合评估揭示了显着的能力差距；即使是最先进的模型（例如 RzenEmbed 和 GME）也很难在所有子类别中保持一致的表现，这凸显了我们基准的严格性。通过比较分析，我们进一步揭示了现有基准的固有局限性，例如模态偏差和分类覆盖范围不足。此外，域内训练实验证明了我们基准的可行性。该实验通过区分可使用目标数据解决的类别和暴露当前模型架构内在局限性的类别，阐明了任务挑战。"
    },
    {
        "id": "http://arxiv.org/abs/2601.16140v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.16140v1",
        "title": "Learning to Watermark in the Latent Space of Generative Models",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Learning to Watermark in the Latent Space of Generative Models"
        },
        "updated": "2026-01-22T17:34:30Z",
        "updated_parsed": [
            2026,
            1,
            22,
            17,
            34,
            30,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.16140v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.16140v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Existing approaches for watermarking AI-generated images often rely on post-hoc methods applied in pixel space, introducing computational overhead and potential visual artifacts. In this work, we explore latent space watermarking and introduce DistSeal, a unified approach for latent watermarking that works across both diffusion and autoregressive models. Our approach works by training post-hoc watermarking models in the latent space of generative models. We demonstrate that these latent watermarkers can be effectively distilled either into the generative model itself or into the latent decoder, enabling in-model watermarking. The resulting latent watermarks achieve competitive robustness while offering similar imperceptibility and up to 20x speedup compared to pixel-space baselines. Our experiments further reveal that distilling latent watermarkers outperforms distilling pixel-space ones, providing a solution that is both more efficient and more robust.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Existing approaches for watermarking AI-generated images often rely on post-hoc methods applied in pixel space, introducing computational overhead and potential visual artifacts. In this work, we explore latent space watermarking and introduce DistSeal, a unified approach for latent watermarking that works across both diffusion and autoregressive models. Our approach works by training post-hoc watermarking models in the latent space of generative models. We demonstrate that these latent watermarkers can be effectively distilled either into the generative model itself or into the latent decoder, enabling in-model watermarking. The resulting latent watermarks achieve competitive robustness while offering similar imperceptibility and up to 20x speedup compared to pixel-space baselines. Our experiments further reveal that distilling latent watermarkers outperforms distilling pixel-space ones, providing a solution that is both more efficient and more robust."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.AI",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            },
            {
                "term": "cs.CR",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T17:34:30Z",
        "published_parsed": [
            2026,
            1,
            22,
            17,
            34,
            30,
            3,
            22,
            0
        ],
        "arxiv_comment": "Code and models are available at https://github.com/facebookresearch/distseal",
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Sylvestre-Alvise Rebuffi"
            },
            {
                "name": "Tuan Tran"
            },
            {
                "name": "Valeriu Lacatusu"
            },
            {
                "name": "Pierre Fernandez"
            },
            {
                "name": "Tomáš Souček"
            },
            {
                "name": "Nikola Jovanović"
            },
            {
                "name": "Tom Sander"
            },
            {
                "name": "Hady Elsahar"
            },
            {
                "name": "Alexandre Mourachko"
            }
        ],
        "author_detail": {
            "name": "Alexandre Mourachko"
        },
        "author": "Alexandre Mourachko",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "学习在生成模型的潜在空间中添加水印",
        "abstract_cn": "现有的人工智能生成图像水印方法通常依赖于像素空间中应用的事后方法，从而引入计算开销和潜在的视觉伪影。在这项工作中，我们探索了潜在空间水印并引入了 DistSeal，这是一种适用于扩散模型和自回归模型的统一潜在水印方法。我们的方法通过在生成模型的潜在空间中训练事后水印模型来工作。我们证明这些潜在水印可以有效地提取到生成模型本身或潜在解码器中，从而实现模型内水印。由此产生的潜在水印实现了具有竞争力的鲁棒性，同时提供了类似的不易察觉性，并且与像素空间基线相比，速度提高了 20 倍。我们的实验进一步表明，提取潜在水印优于提取像素空间水印，提供了一种更高效、更稳健的解决方案。"
    },
    {
        "id": "http://arxiv.org/abs/2601.16192v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.16192v1",
        "title": "360Anything: Geometry-Free Lifting of Images and Videos to 360°",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "360Anything: Geometry-Free Lifting of Images and Videos to 360°"
        },
        "updated": "2026-01-22T18:45:59Z",
        "updated_parsed": [
            2026,
            1,
            22,
            18,
            45,
            59,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.16192v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.16192v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Lifting perspective images and videos to 360° panoramas enables immersive 3D world generation. Existing approaches often rely on explicit geometric alignment between the perspective and the equirectangular projection (ERP) space. Yet, this requires known camera metadata, obscuring the application to in-the-wild data where such calibration is typically absent or noisy. We propose 360Anything, a geometry-free framework built upon pre-trained diffusion transformers. By treating the perspective input and the panorama target simply as token sequences, 360Anything learns the perspective-to-equirectangular mapping in a purely data-driven way, eliminating the need for camera information. Our approach achieves state-of-the-art performance on both image and video perspective-to-360° generation, outperforming prior works that use ground-truth camera information. We also trace the root cause of the seam artifacts at ERP boundaries to zero-padding in the VAE encoder, and introduce Circular Latent Encoding to facilitate seamless generation. Finally, we show competitive results in zero-shot camera FoV and orientation estimation benchmarks, demonstrating 360Anything's deep geometric understanding and broader utility in computer vision tasks. Additional results are available at https://360anything.github.io/.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Lifting perspective images and videos to 360° panoramas enables immersive 3D world generation. Existing approaches often rely on explicit geometric alignment between the perspective and the equirectangular projection (ERP) space. Yet, this requires known camera metadata, obscuring the application to in-the-wild data where such calibration is typically absent or noisy. We propose 360Anything, a geometry-free framework built upon pre-trained diffusion transformers. By treating the perspective input and the panorama target simply as token sequences, 360Anything learns the perspective-to-equirectangular mapping in a purely data-driven way, eliminating the need for camera information. Our approach achieves state-of-the-art performance on both image and video perspective-to-360° generation, outperforming prior works that use ground-truth camera information. We also trace the root cause of the seam artifacts at ERP boundaries to zero-padding in the VAE encoder, and introduce Circular Latent Encoding to facilitate seamless generation. Finally, we show competitive results in zero-shot camera FoV and orientation estimation benchmarks, demonstrating 360Anything's deep geometric understanding and broader utility in computer vision tasks. Additional results are available at https://360anything.github.io/."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T18:45:59Z",
        "published_parsed": [
            2026,
            1,
            22,
            18,
            45,
            59,
            3,
            22,
            0
        ],
        "arxiv_comment": "Project page: https://360anything.github.io/",
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Ziyi Wu"
            },
            {
                "name": "Daniel Watson"
            },
            {
                "name": "Andrea Tagliasacchi"
            },
            {
                "name": "David J. Fleet"
            },
            {
                "name": "Marcus A. Brubaker"
            },
            {
                "name": "Saurabh Saxena"
            }
        ],
        "author_detail": {
            "name": "Saurabh Saxena"
        },
        "author": "Saurabh Saxena",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "360Anything：无几何形状地将图像和视频提升至 360°",
        "abstract_cn": "将透视图像和视频提升至 360° 全景，从而生成身临其境的 3D 世界。现有方法通常依赖于透视和等距柱状投影 (ERP) 空间之间的显式几何对齐。然而，这需要已知的相机元数据，从而模糊了对野外数据的应用，而这种校准通常不存在或有噪音。我们提出了 360Anything，这是一个基于预先训练的扩散变压器构建的无几何框架。通过将透视输入和全景目标简单地视为标记序列，360Anything 以纯粹数据驱动的方式学习透视到等距矩形的映射，从而无需相机信息。我们的方法在图像和视频 360° 透视生成方面均实现了最先进的性能，优于使用地面实况相机信息的先前作品。我们还将 ERP 边界处接缝伪影的根本原因追溯到 VAE 编码器中的零填充，并引入循环潜在编码以促进无缝生成。最后，我们在零镜头相机 FoV 和方向估计基准中展示了具有竞争力的结果，展示了 360Anything 深刻的几何理解和在计算机视觉任务中更广泛的实用性。其他结果可在 https://360anything.github.io/ 获取。"
    },
    {
        "id": "http://arxiv.org/abs/2601.16208v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.16208v1",
        "title": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders"
        },
        "updated": "2026-01-22T18:58:16Z",
        "updated_parsed": [
            2026,
            1,
            22,
            18,
            58,
            16,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.16208v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.16208v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Representation Autoencoders (RAEs) have shown distinct advantages in diffusion modeling on ImageNet by training in high-dimensional semantic latent spaces. In this work, we investigate whether this framework can scale to large-scale, freeform text-to-image (T2I) generation. We first scale RAE decoders on the frozen representation encoder (SigLIP-2) beyond ImageNet by training on web, synthetic, and text-rendering data, finding that while scale improves general fidelity, targeted data composition is essential for specific domains like text. We then rigorously stress-test the RAE design choices originally proposed for ImageNet. Our analysis reveals that scaling simplifies the framework: while dimension-dependent noise scheduling remains critical, architectural complexities such as wide diffusion heads and noise-augmented decoding offer negligible benefits at scale Building on this simplified framework, we conduct a controlled comparison of RAE against the state-of-the-art FLUX VAE across diffusion transformer scales from 0.5B to 9.8B parameters. RAEs consistently outperform VAEs during pretraining across all model scales. Further, during finetuning on high-quality datasets, VAE-based models catastrophically overfit after 64 epochs, while RAE models remain stable through 256 epochs and achieve consistently better performance. Across all experiments, RAE-based diffusion models demonstrate faster convergence and better generation quality, establishing RAEs as a simpler and stronger foundation than VAEs for large-scale T2I generation. Additionally, because both visual understanding and generation can operate in a shared representation space, the multimodal model can directly reason over generated latents, opening new possibilities for unified models.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Representation Autoencoders (RAEs) have shown distinct advantages in diffusion modeling on ImageNet by training in high-dimensional semantic latent spaces. In this work, we investigate whether this framework can scale to large-scale, freeform text-to-image (T2I) generation. We first scale RAE decoders on the frozen representation encoder (SigLIP-2) beyond ImageNet by training on web, synthetic, and text-rendering data, finding that while scale improves general fidelity, targeted data composition is essential for specific domains like text. We then rigorously stress-test the RAE design choices originally proposed for ImageNet. Our analysis reveals that scaling simplifies the framework: while dimension-dependent noise scheduling remains critical, architectural complexities such as wide diffusion heads and noise-augmented decoding offer negligible benefits at scale Building on this simplified framework, we conduct a controlled comparison of RAE against the state-of-the-art FLUX VAE across diffusion transformer scales from 0.5B to 9.8B parameters. RAEs consistently outperform VAEs during pretraining across all model scales. Further, during finetuning on high-quality datasets, VAE-based models catastrophically overfit after 64 epochs, while RAE models remain stable through 256 epochs and achieve consistently better performance. Across all experiments, RAE-based diffusion models demonstrate faster convergence and better generation quality, establishing RAEs as a simpler and stronger foundation than VAEs for large-scale T2I generation. Additionally, because both visual understanding and generation can operate in a shared representation space, the multimodal model can directly reason over generated latents, opening new possibilities for unified models."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T18:58:16Z",
        "published_parsed": [
            2026,
            1,
            22,
            18,
            58,
            16,
            3,
            22,
            0
        ],
        "arxiv_comment": "website: https://rae-dit.github.io/scale-rae/",
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Shengbang Tong"
            },
            {
                "name": "Boyang Zheng"
            },
            {
                "name": "Ziteng Wang"
            },
            {
                "name": "Bingda Tang"
            },
            {
                "name": "Nanye Ma"
            },
            {
                "name": "Ellis Brown"
            },
            {
                "name": "Jihan Yang"
            },
            {
                "name": "Rob Fergus"
            },
            {
                "name": "Yann LeCun"
            },
            {
                "name": "Saining Xie"
            }
        ],
        "author_detail": {
            "name": "Saining Xie"
        },
        "author": "Saining Xie",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "使用表示自动编码器缩放文本到图像扩散变压器",
        "abstract_cn": "通过在高维语义潜在空间中进行训练，表示自动编码器 (RAE) 在 ImageNet 上的扩散建模中显示出明显的优势。在这项工作中，我们研究了该框架是否可以扩展到大规模、自由格式的文本到图像（T2I）生成。我们首先通过对网络、合成和文本渲染数据进行训练，将冻结表示编码器 (SigLIP-2) 上的 RAE 解码器扩展到 ImageNet 之外，发现虽然规模提高了总体保真度，但有针对性的数据组合对于文本等特定领域至关重要。然后，我们对最初为 ImageNet 提出的 RAE 设计选择进行严格的压力测试。我们的分析表明，扩展简化了框架：虽然与维度相关的噪声调度仍然至关重要，但诸如宽扩散头和噪声增强解码之类的架构复杂性在规模上提供的优势可以忽略不计。在这个简化的框架上构建，我们对扩散变压器从 0.5B 到 9.8B 参数范围内的 RAE 与最先进的 FLUX VAE 进行了受控比较。在所有模型规模的预训练过程中，RAE 的表现始终优于 VAE。此外，在对高质量数据集进行微调期间，基于 VAE 的模型在 64 个 epoch 后出现灾难性的过拟合，而 RAE 模型在 256 个 epoch 中保持稳定，并始终获得更好的性能。在所有实验中，基于 RAE 的扩散模型表现出更快的收敛速度和更好的生成质量，使 RAE 成为比 VAE 更简单、更强大的基础，可用于大规模 T2I 生成。此外，由于视觉理解和生成都可以在共享表示空间中运行，因此多模态模型可以直接对生成的潜在变量进行推理，为统一模型开辟了新的可能性。"
    },
    {
        "id": "http://arxiv.org/abs/2601.16214v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.16214v1",
        "title": "CamPilot: Improving Camera Control in Video Diffusion Model with Efficient Camera Reward Feedback",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "CamPilot: Improving Camera Control in Video Diffusion Model with Efficient Camera Reward Feedback"
        },
        "updated": "2026-01-22T18:59:56Z",
        "updated_parsed": [
            2026,
            1,
            22,
            18,
            59,
            56,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.16214v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.16214v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Recent advances in camera-controlled video diffusion models have significantly improved video-camera alignment. However, the camera controllability still remains limited. In this work, we build upon Reward Feedback Learning and aim to further improve camera controllability. However, directly borrowing existing ReFL approaches faces several challenges. First, current reward models lack the capacity to assess video-camera alignment. Second, decoding latent into RGB videos for reward computation introduces substantial computational overhead. Third, 3D geometric information is typically neglected during video decoding. To address these limitations, we introduce an efficient camera-aware 3D decoder that decodes video latent into 3D representations for reward quantization. Specifically, video latent along with the camera pose are decoded into 3D Gaussians. In this process, the camera pose not only acts as input, but also serves as a projection parameter. Misalignment between the video latent and camera pose will cause geometric distortions in the 3D structure, resulting in blurry renderings. Based on this property, we explicitly optimize pixel-level consistency between the rendered novel views and ground-truth ones as reward. To accommodate the stochastic nature, we further introduce a visibility term that selectively supervises only deterministic regions derived via geometric warping. Extensive experiments conducted on RealEstate10K and WorldScore benchmarks demonstrate the effectiveness of our proposed method. Project page: \\href{https://a-bigbao.github.io/CamPilot/}{CamPilot Page}.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Recent advances in camera-controlled video diffusion models have significantly improved video-camera alignment. However, the camera controllability still remains limited. In this work, we build upon Reward Feedback Learning and aim to further improve camera controllability. However, directly borrowing existing ReFL approaches faces several challenges. First, current reward models lack the capacity to assess video-camera alignment. Second, decoding latent into RGB videos for reward computation introduces substantial computational overhead. Third, 3D geometric information is typically neglected during video decoding. To address these limitations, we introduce an efficient camera-aware 3D decoder that decodes video latent into 3D representations for reward quantization. Specifically, video latent along with the camera pose are decoded into 3D Gaussians. In this process, the camera pose not only acts as input, but also serves as a projection parameter. Misalignment between the video latent and camera pose will cause geometric distortions in the 3D structure, resulting in blurry renderings. Based on this property, we explicitly optimize pixel-level consistency between the rendered novel views and ground-truth ones as reward. To accommodate the stochastic nature, we further introduce a visibility term that selectively supervises only deterministic regions derived via geometric warping. Extensive experiments conducted on RealEstate10K and WorldScore benchmarks demonstrate the effectiveness of our proposed method. Project page: \\href{https://a-bigbao.github.io/CamPilot/}{CamPilot Page}."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T18:59:56Z",
        "published_parsed": [
            2026,
            1,
            22,
            18,
            59,
            56,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Wenhang Ge"
            },
            {
                "name": "Guibao Shen"
            },
            {
                "name": "Jiawei Feng"
            },
            {
                "name": "Luozhou Wang"
            },
            {
                "name": "Hao Lu"
            },
            {
                "name": "Xingye Tian"
            },
            {
                "name": "Xin Tao"
            },
            {
                "name": "Ying-Cong Chen"
            }
        ],
        "author_detail": {
            "name": "Ying-Cong Chen"
        },
        "author": "Ying-Cong Chen",
        "journal": "arXiv: AI & Vision (Optics)",
        "title_cn": "CamPilot：通过高效的相机奖励反馈改进视频扩散模型中的相机控制",
        "abstract_cn": "摄像机控制的视频扩散模型的最新进展显着改善了摄像机对准。然而，相机的可控性仍然有限。在这项工作中，我们以奖励反馈学习为基础，旨在进一步提高相机的可控性。然而，直接借用现有的 ReFL 方法面临着一些挑战。首先，当前的奖励模型缺乏评估摄像机对齐的能力。其次，将潜在视频解码为 RGB 视频以进行奖励计算会带来大量的计算开销。第三，3D 几何信息在视频解码过程中通常被忽略。为了解决这些限制，我们引入了一种高效的相机感知 3D 解码器，可将视频潜在解码为 3D 表示以进行奖励量化。具体来说，视频潜伏与相机姿势一起被解码为 3D 高斯。在这个过程中，相机位姿不仅作为输入，还作为投影参数。视频潜伏和相机姿势之间的不对准将导致 3D 结构中的几何扭曲，从而导致渲染模糊。基于这个属性，我们明确优化了渲染的新颖视图和真实视图之间的像素级一致性作为奖励。为了适应随机性，我们进一步引入了一个可见性项，它有选择地仅监督通过几何扭曲导出的确定性区域。在 RealEstate10K 和 WorldScore 基准上进行的大量实验证明了我们提出的方法的有效性。项目页面：\\href{https://a-bigbao.github.io/CamPilot/}{CamPilot 页面}。"
    },
    {
        "id": "http://arxiv.org/abs/2601.15897v1",
        "guidislink": true,
        "link": "https://arxiv.org/abs/2601.15897v1",
        "title": "ThermoSplat: Cross-Modal 3D Gaussian Splatting with Feature Modulation and Geometry Decoupling",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "ThermoSplat: Cross-Modal 3D Gaussian Splatting with Feature Modulation and Geometry Decoupling"
        },
        "updated": "2026-01-22T12:24:26Z",
        "updated_parsed": [
            2026,
            1,
            22,
            12,
            24,
            26,
            3,
            22,
            0
        ],
        "links": [
            {
                "href": "https://arxiv.org/abs/2601.15897v1",
                "rel": "alternate",
                "type": "text/html"
            },
            {
                "href": "https://arxiv.org/pdf/2601.15897v1",
                "rel": "related",
                "type": "application/pdf",
                "title": "pdf"
            }
        ],
        "summary": "Multi-modal scene reconstruction integrating RGB and thermal infrared data is essential for robust environmental perception across diverse lighting and weather conditions. However, extending 3D Gaussian Splatting (3DGS) to multi-spectral scenarios remains challenging. Current approaches often struggle to fully leverage the complementary information of multi-modal data, typically relying on mechanisms that either tend to neglect cross-modal correlations or leverage shared representations that fail to adaptively handle the complex structural correlations and physical discrepancies between spectrums. To address these limitations, we propose ThermoSplat, a novel framework that enables deep spectral-aware reconstruction through active feature modulation and adaptive geometry decoupling. First, we introduce a Cross-Modal FiLM Modulation mechanism that dynamically conditions shared latent features on thermal structural priors, effectively guiding visible texture synthesis with reliable cross-modal geometric cues. Second, to accommodate modality-specific geometric inconsistencies, we propose a Modality-Adaptive Geometric Decoupling scheme that learns independent opacity offsets and executes an independent rasterization pass for the thermal branch. Additionally, a hybrid rendering pipeline is employed to integrate explicit Spherical Harmonics with implicit neural decoding, ensuring both semantic consistency and high-frequency detail preservation. Extensive experiments on the RGBT-Scenes dataset demonstrate that ThermoSplat achieves state-of-the-art rendering quality across both visible and thermal spectrums.",
        "summary_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Multi-modal scene reconstruction integrating RGB and thermal infrared data is essential for robust environmental perception across diverse lighting and weather conditions. However, extending 3D Gaussian Splatting (3DGS) to multi-spectral scenarios remains challenging. Current approaches often struggle to fully leverage the complementary information of multi-modal data, typically relying on mechanisms that either tend to neglect cross-modal correlations or leverage shared representations that fail to adaptively handle the complex structural correlations and physical discrepancies between spectrums. To address these limitations, we propose ThermoSplat, a novel framework that enables deep spectral-aware reconstruction through active feature modulation and adaptive geometry decoupling. First, we introduce a Cross-Modal FiLM Modulation mechanism that dynamically conditions shared latent features on thermal structural priors, effectively guiding visible texture synthesis with reliable cross-modal geometric cues. Second, to accommodate modality-specific geometric inconsistencies, we propose a Modality-Adaptive Geometric Decoupling scheme that learns independent opacity offsets and executes an independent rasterization pass for the thermal branch. Additionally, a hybrid rendering pipeline is employed to integrate explicit Spherical Harmonics with implicit neural decoding, ensuring both semantic consistency and high-frequency detail preservation. Extensive experiments on the RGBT-Scenes dataset demonstrate that ThermoSplat achieves state-of-the-art rendering quality across both visible and thermal spectrums."
        },
        "tags": [
            {
                "term": "cs.CV",
                "scheme": "http://arxiv.org/schemas/atom",
                "label": null
            }
        ],
        "published": "2026-01-22T12:24:26Z",
        "published_parsed": [
            2026,
            1,
            22,
            12,
            24,
            26,
            3,
            22,
            0
        ],
        "arxiv_primary_category": {
            "term": "cs.CV"
        },
        "authors": [
            {
                "name": "Zhaoqi Su"
            },
            {
                "name": "Shihai Chen"
            },
            {
                "name": "Xinyan Lin"
            },
            {
                "name": "Liqin Huang"
            },
            {
                "name": "Zhipeng Su"
            },
            {
                "name": "Xiaoqiang Lu"
            }
        ],
        "author_detail": {
            "name": "Xiaoqiang Lu"
        },
        "author": "Xiaoqiang Lu",
        "journal": "arXiv: Nerf",
        "title_cn": "ThermoSplat：具有特征调制和几何解耦的跨模态 3D 高斯喷射",
        "abstract_cn": "集成 RGB 和热红外数据的多模态场景重建对于在不同照明和天气条件下实现稳健的环境感知至关重要。然而，将 3D 高斯散射 (3DGS) 扩展到多光谱场景仍然具有挑战性。当前的方法通常难以充分利用多模态数据的互补信息，通常依赖于往往忽略跨模态相关性或利用无法自适应处理频谱之间复杂的结构相关性和物理差异的共享表示的机制。为了解决这些限制，我们提出了 ThermoSplat，这是一种新颖的框架，可以通过主动特征调制和自适应几何解耦来实现深度光谱感知重建。首先，我们引入了一种跨模态 FiLM 调制机制，该机制可动态调节热结构先验的共享潜在特征，从而通过可靠的跨模态几何线索有效地指导可见纹理合成。其次，为了适应特定于模态的几何不一致，我们提出了一种模态自适应几何解耦方案，该方案可以学习独立的不透明度偏移并为热分支执行独立的光栅化通道。此外，还采用混合渲染管道将显式球谐函数与隐式神经解码相集成，确保语义一致性和高频细节保留。对 RGBT-Scenes 数据集的大量实验表明，ThermoSplat 在可见光和热光谱方面均实现了最先进的渲染质量。"
    },
    {
        "id": "https://www.nature.com/articles/s41566-025-01828-5",
        "title": "Multiplying matrices in a single pass with light",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Multiplying matrices in a single pass with light"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41566-025-01828-5"
            }
        ],
        "link": "https://www.nature.com/articles/s41566-025-01828-5",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Nature Photonics, Published online: 06 January 2026; <a href=\"https://www.nature.com/articles/s41566-025-01828-5\">doi:10.1038/s41566-025-01828-5</a></p>Optical computing has been limited to vector–matrix multiplications, with matrix–matrix operations requiring wavelength- or time-division multiplexing, reducing energy efficiency and speed. Now, researchers have demonstrated a free-space optical approach that overcomes these limitations, enabling parallel matrix–matrix and tensor–matrix multiplications in a single optical operation."
            }
        ],
        "summary": "Optical computing has been limited to vector–matrix multiplications, with matrix–matrix operations requiring wavelength- or time-division multiplexing, reducing energy efficiency and speed. Now, researchers have demonstrated a free-space optical approach that overcomes these limitations, enabling parallel matrix–matrix and tensor–matrix multiplications in a single optical operation.",
        "authors": [
            {
                "name": "Carlos A. Ríos Ocampo"
            },
            {
                "name": "Nathan Youngblood"
            }
        ],
        "author": "Nathan Youngblood",
        "author_detail": {
            "name": "Carlos A. Ríos Ocampo"
        },
        "dc_identifier": "doi:10.1038/s41566-025-01828-5",
        "dc_source": "Nature Photonics, Published online: 2026-01-06; | doi:10.1038/s41566-025-01828-5",
        "updated": "2026-01-06",
        "updated_parsed": [
            2026,
            1,
            6,
            0,
            0,
            0,
            1,
            6,
            0
        ],
        "prism_publicationname": "Nature Photonics",
        "prism_doi": "10.1038/s41566-025-01828-5",
        "prism_url": "https://www.nature.com/articles/s41566-025-01828-5",
        "journal": "Nature Photonics",
        "title_cn": "用光单次将矩阵相乘",
        "abstract_cn": "光学计算仅限于矢量矩阵乘法，矩阵运算需要波长或时分复用，从而降低了能源效率和速度。现在，研究人员展示了一种克服这些限制的自由空间光学方法，能够在单个光学操作中实现并行矩阵-矩阵和张量-矩阵乘法。"
    },
    {
        "id": "https://www.nature.com/articles/s41566-025-01812-z",
        "title": "In-pixel colour correction with organic self-adaptive transistors",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "In-pixel colour correction with organic self-adaptive transistors"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41566-025-01812-z"
            }
        ],
        "link": "https://www.nature.com/articles/s41566-025-01812-z",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Nature Photonics, Published online: 07 January 2026; <a href=\"https://www.nature.com/articles/s41566-025-01812-z\">doi:10.1038/s41566-025-01812-z</a></p>A colour correction array featuring red-, green- and blue-sensitive organic transistors integrated within a single pixel enables self-adaptive intensity and colour correction."
            }
        ],
        "summary": "A colour correction array featuring red-, green- and blue-sensitive organic transistors integrated within a single pixel enables self-adaptive intensity and colour correction.",
        "authors": [
            {
                "name": "Zihan He"
            },
            {
                "name": "Wei Wang"
            },
            {
                "name": "Zepang Zhan"
            },
            {
                "name": "Lingxuan Jia"
            },
            {
                "name": "Yutao Ge"
            },
            {
                "name": "Zitong Zhan"
            },
            {
                "name": "Peiyao Xue"
            },
            {
                "name": "Weijie Wang"
            },
            {
                "name": "Lanyi Xiang"
            },
            {
                "name": "Yingqiao Ma"
            },
            {
                "name": "Yawen Li"
            },
            {
                "name": "Zhiyi Li"
            },
            {
                "name": "Xiaojuan Dai"
            },
            {
                "name": "Dekai Ye"
            },
            {
                "name": "Liyao Liu"
            },
            {
                "name": "Fengjiao Zhang"
            },
            {
                "name": "Ye Zou"
            },
            {
                "name": "Yuze Lin"
            },
            {
                "name": "Xiaowei Zhan"
            },
            {
                "name": "Daoben Zhu"
            },
            {
                "name": "Chong-an Di"
            }
        ],
        "author": "Chong-an Di",
        "author_detail": {
            "name": "Zihan He"
        },
        "dc_identifier": "doi:10.1038/s41566-025-01812-z",
        "dc_source": "Nature Photonics, Published online: 2026-01-07; | doi:10.1038/s41566-025-01812-z",
        "updated": "2026-01-07",
        "updated_parsed": [
            2026,
            1,
            7,
            0,
            0,
            0,
            2,
            7,
            0
        ],
        "prism_publicationname": "Nature Photonics",
        "prism_doi": "10.1038/s41566-025-01812-z",
        "prism_url": "https://www.nature.com/articles/s41566-025-01812-z",
        "journal": "Nature Photonics",
        "title_cn": "使用有机自适应晶体管进行像素内色彩校正",
        "abstract_cn": "色彩校正阵列在单个像素内集成了红色、绿色和蓝色敏感有机晶体管，可实现自适应强度和色彩校正。"
    },
    {
        "id": "https://www.nature.com/articles/s41566-025-01810-1",
        "title": "Stable deep-blue organic light-emitting diodes based on sensitized fluorescence",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Stable deep-blue organic light-emitting diodes based on sensitized fluorescence"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41566-025-01810-1"
            }
        ],
        "link": "https://www.nature.com/articles/s41566-025-01810-1",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Nature Photonics, Published online: 08 January 2026; <a href=\"https://www.nature.com/articles/s41566-025-01810-1\">doi:10.1038/s41566-025-01810-1</a></p>This Review discusses recent advances in sensitized fluorescence emitters for deep-blue organic light-emitting diodes, reviewing progress in molecular design and device performance as well as key remaining challenges."
            }
        ],
        "summary": "This Review discusses recent advances in sensitized fluorescence emitters for deep-blue organic light-emitting diodes, reviewing progress in molecular design and device performance as well as key remaining challenges.",
        "authors": [
            {
                "name": "Dongdong Zhang"
            },
            {
                "name": "Hengyi Dai"
            },
            {
                "name": "Hai Zhang"
            },
            {
                "name": "Lian Duan"
            }
        ],
        "author": "Lian Duan",
        "author_detail": {
            "name": "Dongdong Zhang"
        },
        "dc_identifier": "doi:10.1038/s41566-025-01810-1",
        "dc_source": "Nature Photonics, Published online: 2026-01-08; | doi:10.1038/s41566-025-01810-1",
        "updated": "2026-01-08",
        "updated_parsed": [
            2026,
            1,
            8,
            0,
            0,
            0,
            3,
            8,
            0
        ],
        "prism_publicationname": "Nature Photonics",
        "prism_doi": "10.1038/s41566-025-01810-1",
        "prism_url": "https://www.nature.com/articles/s41566-025-01810-1",
        "journal": "Nature Photonics",
        "title_cn": "基于敏化荧光的稳定深蓝色有机发光二极管",
        "abstract_cn": "本综述讨论了深蓝色有机发光二极管敏化荧光发射器的最新进展，回顾了分子设计和器件性能方面的进展以及仍然存在的关键挑战。"
    },
    {
        "id": "https://www.nature.com/articles/s41566-025-01823-w",
        "title": "Encoding and manipulating ultrafast coherent valleytronic information with lightwaves",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Encoding and manipulating ultrafast coherent valleytronic information with lightwaves"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41566-025-01823-w"
            }
        ],
        "link": "https://www.nature.com/articles/s41566-025-01823-w",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Nature Photonics, Published online: 09 January 2026; <a href=\"https://www.nature.com/articles/s41566-025-01823-w\">doi:10.1038/s41566-025-01823-w</a></p>A method to coherently manipulate excitons and perform all-optical logic operations using the valley degree of freedom in monolayer WS2 is discussed."
            }
        ],
        "summary": "A method to coherently manipulate excitons and perform all-optical logic operations using the valley degree of freedom in monolayer WS2 is discussed.",
        "authors": [
            {
                "name": "Francesco Gucci"
            },
            {
                "name": "Eduardo B. Molinero"
            },
            {
                "name": "Mattia Russo"
            },
            {
                "name": "Pablo San-Jose"
            },
            {
                "name": "Franco V. A. Camargo"
            },
            {
                "name": "Margherita Maiuri"
            },
            {
                "name": "Misha Ivanov"
            },
            {
                "name": "Álvaro Jiménez-Galán"
            },
            {
                "name": "Rui E. F. Silva"
            },
            {
                "name": "Stefano Dal Conte"
            },
            {
                "name": "Giulio Cerullo"
            }
        ],
        "author": "Giulio Cerullo",
        "author_detail": {
            "name": "Francesco Gucci"
        },
        "dc_identifier": "doi:10.1038/s41566-025-01823-w",
        "dc_source": "Nature Photonics, Published online: 2026-01-09; | doi:10.1038/s41566-025-01823-w",
        "updated": "2026-01-09",
        "updated_parsed": [
            2026,
            1,
            9,
            0,
            0,
            0,
            4,
            9,
            0
        ],
        "prism_publicationname": "Nature Photonics",
        "prism_doi": "10.1038/s41566-025-01823-w",
        "prism_url": "https://www.nature.com/articles/s41566-025-01823-w",
        "journal": "Nature Photonics",
        "title_cn": "用光波编码和操纵超快相干谷电子信息",
        "abstract_cn": "讨论了一种利用单层 WS2 谷自由度来相干操纵激子并执行全光逻辑运算的方法。"
    },
    {
        "id": "https://www.nature.com/articles/s41566-025-01825-8",
        "title": "On-chip topological leaky-wave antenna for full-space terahertz wireless connectivity",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "On-chip topological leaky-wave antenna for full-space terahertz wireless connectivity"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41566-025-01825-8"
            }
        ],
        "link": "https://www.nature.com/articles/s41566-025-01825-8",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Nature Photonics, Published online: 12 January 2026; <a href=\"https://www.nature.com/articles/s41566-025-01825-8\">doi:10.1038/s41566-025-01825-8</a></p>On-chip terahertz topological leaky-wave antennas based on valley photonic crystals achieve beam scanning over 75% of the three-dimensional solid angle. The time-reversal-symmetric topological leaky-wave antenna further enables the simultaneous demonstration of real-time high-definition television streaming and 24 Gbps directional wireless data transmission in opposite directions."
            }
        ],
        "summary": "On-chip terahertz topological leaky-wave antennas based on valley photonic crystals achieve beam scanning over 75% of the three-dimensional solid angle. The time-reversal-symmetric topological leaky-wave antenna further enables the simultaneous demonstration of real-time high-definition television streaming and 24 Gbps directional wireless data transmission in opposite directions.",
        "authors": [
            {
                "name": "Wenhao Wang"
            },
            {
                "name": "Yi Ji Tan"
            },
            {
                "name": "Pascal Szriftgiser"
            },
            {
                "name": "Guillaume Ducournau"
            },
            {
                "name": "Ranjan Singh"
            }
        ],
        "author": "Ranjan Singh",
        "author_detail": {
            "name": "Wenhao Wang"
        },
        "dc_identifier": "doi:10.1038/s41566-025-01825-8",
        "dc_source": "Nature Photonics, Published online: 2026-01-12; | doi:10.1038/s41566-025-01825-8",
        "updated": "2026-01-12",
        "updated_parsed": [
            2026,
            1,
            12,
            0,
            0,
            0,
            0,
            12,
            0
        ],
        "prism_publicationname": "Nature Photonics",
        "prism_doi": "10.1038/s41566-025-01825-8",
        "prism_url": "https://www.nature.com/articles/s41566-025-01825-8",
        "journal": "Nature Photonics",
        "title_cn": "用于全空间太赫兹无线连接的片上拓扑漏波天线",
        "abstract_cn": "基于谷光子晶体的片上太赫兹拓扑漏波天线实现了超过75%的三维立体角的波束扫描。时间反转对称拓扑漏波天线进一步实现了实时高清电视流和相反方向的24Gbps定向无线数据传输的同时演示。"
    },
    {
        "id": "https://www.nature.com/articles/s41566-025-01832-9",
        "title": "A high-speed heterogeneous lithium tantalate silicon photonics platform",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "A high-speed heterogeneous lithium tantalate silicon photonics platform"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41566-025-01832-9"
            }
        ],
        "link": "https://www.nature.com/articles/s41566-025-01832-9",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Nature Photonics, Published online: 13 January 2026; <a href=\"https://www.nature.com/articles/s41566-025-01832-9\">doi:10.1038/s41566-025-01832-9</a></p>Lithium tantalate is heterogeneously integrated with silicon photonic integrated circuits via a micro-transfer printing process in a manner fully compatible with existing workflows. A Mach–Zehnder modulator with an insertion loss of 2.9 dB and 70 GHz operation is demonstrated."
            }
        ],
        "summary": "Lithium tantalate is heterogeneously integrated with silicon photonic integrated circuits via a micro-transfer printing process in a manner fully compatible with existing workflows. A Mach–Zehnder modulator with an insertion loss of 2.9 dB and 70 GHz operation is demonstrated.",
        "authors": [
            {
                "name": "Margot Niels"
            },
            {
                "name": "Tom Vanackere"
            },
            {
                "name": "Ewoud Vissers"
            },
            {
                "name": "Tingting Zhai"
            },
            {
                "name": "Patrick Nenezic"
            },
            {
                "name": "Jakob Declercq"
            },
            {
                "name": "Cédric Bruynsteen"
            },
            {
                "name": "Shengpu Niu"
            },
            {
                "name": "Arno Moerman"
            },
            {
                "name": "Olivier Caytan"
            },
            {
                "name": "Nishant Singh"
            },
            {
                "name": "Sam Lemey"
            },
            {
                "name": "Xin Yin"
            },
            {
                "name": "Sofie Janssen"
            },
            {
                "name": "Peter Verheyen"
            },
            {
                "name": "Neha Singh"
            },
            {
                "name": "Dieter Bode"
            },
            {
                "name": "Martin Davi"
            },
            {
                "name": "Filippo Ferraro"
            },
            {
                "name": "Philippe Absil"
            },
            {
                "name": "Sadhishkumar Balakrishnan"
            },
            {
                "name": "Joris Van Campenhout"
            },
            {
                "name": "Günther Roelkens"
            },
            {
                "name": "Bart Kuyken"
            },
            {
                "name": "Maximilien Billet"
            }
        ],
        "author": "Maximilien Billet",
        "author_detail": {
            "name": "Margot Niels"
        },
        "dc_identifier": "doi:10.1038/s41566-025-01832-9",
        "dc_source": "Nature Photonics, Published online: 2026-01-13; | doi:10.1038/s41566-025-01832-9",
        "updated": "2026-01-13",
        "updated_parsed": [
            2026,
            1,
            13,
            0,
            0,
            0,
            1,
            13,
            0
        ],
        "prism_publicationname": "Nature Photonics",
        "prism_doi": "10.1038/s41566-025-01832-9",
        "prism_url": "https://www.nature.com/articles/s41566-025-01832-9",
        "journal": "Nature Photonics",
        "title_cn": "高速异构钽酸锂硅光子平台",
        "abstract_cn": "钽酸锂通过微转移印刷工艺与硅光子集成电路异构集成，与现有工作流程完全兼容。演示了插入损耗为 2.9dB、工作频率为 70GHz 的 Mach-Zehnder 调制器。"
    },
    {
        "id": "https://www.nature.com/articles/s41566-025-01827-6",
        "title": "Photostable donor–acceptor interface for minimizing energy loss in inverted perovskite solar cells",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Photostable donor–acceptor interface for minimizing energy loss in inverted perovskite solar cells"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41566-025-01827-6"
            }
        ],
        "link": "https://www.nature.com/articles/s41566-025-01827-6",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Nature Photonics, Published online: 14 January 2026; <a href=\"https://www.nature.com/articles/s41566-025-01827-6\">doi:10.1038/s41566-025-01827-6</a></p>A new self-assembled monolayer at the buried interface of inverted perovskite solar cells improves photostability and favours energy transfer, resulting in devices with a certified power conversion efficiency of 27.19% and 1,500-h stability under the ISOS-L-2 protocol."
            }
        ],
        "summary": "A new self-assembled monolayer at the buried interface of inverted perovskite solar cells improves photostability and favours energy transfer, resulting in devices with a certified power conversion efficiency of 27.19% and 1,500-h stability under the ISOS-L-2 protocol.",
        "authors": [
            {
                "name": "Congcong Tian"
            },
            {
                "name": "Anxin Sun"
            },
            {
                "name": "Jinling Chen"
            },
            {
                "name": "Rongshan Zhuang"
            },
            {
                "name": "Chen Chen"
            },
            {
                "name": "Jiawei Zheng"
            },
            {
                "name": "Shuo Liu"
            },
            {
                "name": "Jiajun Du"
            },
            {
                "name": "Qianwen Chen"
            },
            {
                "name": "Lei Cai"
            },
            {
                "name": "Shulin Han"
            },
            {
                "name": "Feng Tian"
            },
            {
                "name": "Chun-Chao Chen"
            }
        ],
        "author": "Chun-Chao Chen",
        "author_detail": {
            "name": "Congcong Tian"
        },
        "dc_identifier": "doi:10.1038/s41566-025-01827-6",
        "dc_source": "Nature Photonics, Published online: 2026-01-14; | doi:10.1038/s41566-025-01827-6",
        "updated": "2026-01-14",
        "updated_parsed": [
            2026,
            1,
            14,
            0,
            0,
            0,
            2,
            14,
            0
        ],
        "prism_publicationname": "Nature Photonics",
        "prism_doi": "10.1038/s41566-025-01827-6",
        "prism_url": "https://www.nature.com/articles/s41566-025-01827-6",
        "journal": "Nature Photonics",
        "title_cn": "光稳定的供体-受体界面可最大限度地减少倒置钙钛矿太阳能电池的能量损失",
        "abstract_cn": "倒置钙钛矿太阳能电池埋入界面处的新型自组装单层可提高光稳定性并有利于能量转移，从而使设备在 ISOS-L-2 协议下具有 27.19% 的认证功率转换效率和 1,500 小时的稳定性。"
    },
    {
        "id": "https://www.nature.com/articles/s41566-025-01817-8",
        "title": "Axially chiral molecular contacts with low isomerization barriers for perovskite solar cells",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Axially chiral molecular contacts with low isomerization barriers for perovskite solar cells"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41566-025-01817-8"
            }
        ],
        "link": "https://www.nature.com/articles/s41566-025-01817-8",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Nature Photonics, Published online: 19 January 2026; <a href=\"https://www.nature.com/articles/s41566-025-01817-8\">doi:10.1038/s41566-025-01817-8</a></p>A non-coplanar axially chiral molecular contact favours the crystalline growth of perovskite film and improves interfacial stability in perovskite solar cells. Small-area devices yield a certified power conversion efficiency of 26.44% and maintain 98% of it after 2,000 hours of operation."
            }
        ],
        "summary": "A non-coplanar axially chiral molecular contact favours the crystalline growth of perovskite film and improves interfacial stability in perovskite solar cells. Small-area devices yield a certified power conversion efficiency of 26.44% and maintain 98% of it after 2,000 hours of operation.",
        "authors": [
            {
                "name": "Wenhan Yang"
            },
            {
                "name": "Xin Guan"
            },
            {
                "name": "Qingbin Cai"
            },
            {
                "name": "Yuexin Lin"
            },
            {
                "name": "Zuhong Zhang"
            },
            {
                "name": "Jinbo Zhao"
            },
            {
                "name": "Jia Guo"
            },
            {
                "name": "Annan Zhu"
            },
            {
                "name": "Fenqi Du"
            },
            {
                "name": "Wenjing Zhu"
            },
            {
                "name": "Jin Liu"
            },
            {
                "name": "Sen Jiang"
            },
            {
                "name": "Nan Zhang"
            },
            {
                "name": "Xiaolong Liu"
            },
            {
                "name": "Lei Zhang"
            },
            {
                "name": "Youshen Wu"
            },
            {
                "name": "Shengchun Yang"
            },
            {
                "name": "Meng Li"
            },
            {
                "name": "Chao Liang"
            }
        ],
        "author": "Chao Liang",
        "author_detail": {
            "name": "Wenhan Yang"
        },
        "dc_identifier": "doi:10.1038/s41566-025-01817-8",
        "dc_source": "Nature Photonics, Published online: 2026-01-19; | doi:10.1038/s41566-025-01817-8",
        "updated": "2026-01-19",
        "updated_parsed": [
            2026,
            1,
            19,
            0,
            0,
            0,
            0,
            19,
            0
        ],
        "prism_publicationname": "Nature Photonics",
        "prism_doi": "10.1038/s41566-025-01817-8",
        "prism_url": "https://www.nature.com/articles/s41566-025-01817-8",
        "journal": "Nature Photonics",
        "title_cn": "用于钙钛矿太阳能电池的具有低异构化势垒的轴向手性分子接触",
        "abstract_cn": "非共面轴向手性分子接触有利于钙钛矿薄膜的晶体生长，并提高钙钛矿太阳能电池的界面稳定性。小面积设备经认证的功率转换效率为 26.44%，并在运行 2,000 小时后仍保持 98%。"
    },
    {
        "id": "https://doi.org/10.1364/ol.578637",
        "title": "Mid infrared micro-optics elements based on flexible chalcogenide polymer",
        "link": "https://doi.org/10.1364/ol.578637",
        "published": "2026-01-22",
        "author": "Feng Liu, Zixuan Huang, Jiao Li, Liming Li, Sheng Liu, Peng Li, Xiaowei Lei, Jiwei Zhang, Biqiang Jiang, Xuetao Gan, Jianlin Zhao",
        "summary": "Abstract not available.",
        "journal": "Optics Letters",
        "title_cn": "基于柔性硫属化物聚合物的中红外微光学元件",
        "abstract_cn": "（摘要暂缺，等待官方补全）"
    },
    {
        "id": "https://www.nature.com/articles/s41377-025-02132-1",
        "title": "III-Nitrides empower miniaturized spectral imager in ultraviolet",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "III-Nitrides empower miniaturized spectral imager in ultraviolet"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41377-025-02132-1"
            }
        ],
        "link": "https://www.nature.com/articles/s41377-025-02132-1",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Light: Science &amp; Applications, Published online: 23 January 2026; <a href=\"https://www.nature.com/articles/s41377-025-02132-1\">doi:10.1038/s41377-025-02132-1</a></p>A miniaturized on-chip spectral imager based on III-nitride cascaded photodiodes achieves 0.62 nm accuracy and sub-10 ns response, extending spectral imaging into the ultraviolet regime."
            }
        ],
        "summary": "A miniaturized on-chip spectral imager based on III-nitride cascaded photodiodes achieves 0.62 nm accuracy and sub-10 ns response, extending spectral imaging into the ultraviolet regime.",
        "authors": [
            {
                "name": "Yuji Zhao"
            },
            {
                "name": "Tao Li"
            },
            {
                "name": "Boon Ooi"
            }
        ],
        "author": "Boon Ooi",
        "author_detail": {
            "name": "Yuji Zhao"
        },
        "dc_identifier": "doi:10.1038/s41377-025-02132-1",
        "dc_source": "Light: Science & Applications, Published online: 2026-01-23; | doi:10.1038/s41377-025-02132-1",
        "updated": "2026-01-23",
        "updated_parsed": [
            2026,
            1,
            23,
            0,
            0,
            0,
            4,
            23,
            0
        ],
        "prism_publicationname": "Light: Science & Applications",
        "prism_doi": "10.1038/s41377-025-02132-1",
        "prism_url": "https://www.nature.com/articles/s41377-025-02132-1",
        "journal": "Light: Science & Applications",
        "title_cn": "III-氮化物赋​​予微型紫外光谱成像仪",
        "abstract_cn": "基于 III 族氮化物级联光电二极管的小型化片上光谱成像仪可实现 0.62 nm 精度和亚 10 ns 响应，将光谱成像扩展到紫外区域。"
    },
    {
        "id": "https://doi.org/10.1364/ol.587522",
        "title": "Temporal logic and encoding function based on anisotropic photonic time crystals",
        "link": "https://doi.org/10.1364/ol.587522",
        "published": "2026-01-22",
        "author": "Shuo Xu, HaiFeng Zhang",
        "summary": "Abstract not available.",
        "journal": "Optics Letters",
        "title_cn": "基于各向异性光子时间晶体的时间逻辑和编码功能",
        "abstract_cn": "（摘要暂缺，等待官方补全）"
    },
    {
        "id": "https://doi.org/10.1364/oe.582700",
        "title": "Intelligent Wavefront Correction via Self-supervised Predictive Zernike Phase Inversion Network",
        "link": "https://doi.org/10.1364/oe.582700",
        "published": "2026-01-22",
        "author": "Xinjie Zhang, Haoyu Zhang, Chaoxu Chen, Ziwei Li, Chao Shen, Junwen Zhang, Nan Chi, Jianyang Shi",
        "summary": "Abstract not available.",
        "journal": "Optics Express",
        "title_cn": "通过自监督预测泽尼克反相网络进行智能波前校正",
        "abstract_cn": "（摘要暂缺，等待官方补全）"
    },
    {
        "id": "https://doi.org/10.1364/oe.579304",
        "title": "Photonic decision making using optical frequency difference detection in mutually-coupled semiconductor lasers",
        "link": "https://doi.org/10.1364/oe.579304",
        "published": "2026-01-22",
        "author": "Hidetoshi Taira, Takatomo Mihana, Shun Kotoku, Andre Rohm, Kazutaka Kanno, Atsushi Uchida, Ryoichi Horisaki",
        "summary": "Abstract not available.",
        "journal": "Optics Express",
        "title_cn": "在互耦合半导体激光器中使用光频差检测进行光子决策",
        "abstract_cn": "（摘要暂缺，等待官方补全）"
    },
    {
        "id": "https://doi.org/10.1364/ol.586972",
        "title": "Optical cross-purity",
        "link": "https://doi.org/10.1364/ol.586972",
        "published": "2026-01-22",
        "author": "Ayman Abouraddy, Bahaa Saleh",
        "summary": "Abstract not available.",
        "journal": "Optics Letters",
        "title_cn": "光学交叉纯度",
        "abstract_cn": "（摘要暂缺，等待官方补全）"
    },
    {
        "id": "https://doi.org/10.1364/ol.579897",
        "title": "How sensitive is the reduced scattering coefficient to changes in specific micro-scale biophysical properties of tissue scatterers?",
        "link": "https://doi.org/10.1364/ol.579897",
        "published": "2026-01-22",
        "author": "Robert Wilson, Colleen Flanagan, Mary-Ann Mycek",
        "summary": "Abstract not available.",
        "journal": "Optics Letters",
        "title_cn": "降低的散射系数对组织散射体特定微观生物物理特性的变化有多敏感？",
        "abstract_cn": "（摘要暂缺，等待官方补全）"
    },
    {
        "id": "https://doi.org/10.1364/ol.586614",
        "title": "Multimode interface between optical free-space- and waveguide modes",
        "link": "https://doi.org/10.1364/ol.586614",
        "published": "2026-01-22",
        "author": "Teresia Stranden, Oussama Korichi, Matias Eriksson, Matteo Cherchi, George Thomas, Robert Fickler",
        "summary": "Abstract not available.",
        "journal": "Optics Letters",
        "title_cn": "光学自由空间模式和波导模式之间的多模接口",
        "abstract_cn": "（摘要暂缺，等待官方补全）"
    },
    {
        "id": "https://doi.org/10.1364/ol.586063",
        "title": "Low-loss Plasmonic Waveguide with High Optical Confinement on the Thin-Film Lithium Niobate-on-Insulator (LNOI) Platform",
        "link": "https://doi.org/10.1364/ol.586063",
        "published": "2026-01-22",
        "author": "Shuqi Xiao, Gaolei Hu, Jiapeng Luan, Yue Qin, Zhenzhou Cheng, Zunyue Zhang, Yi Wang, Hon Tsang",
        "summary": "Abstract not available.",
        "journal": "Optics Letters",
        "title_cn": "薄膜绝缘体上铌酸锂 (LNOI) 平台上具有高光学限制的低损耗等离子体波导",
        "abstract_cn": "（摘要暂缺，等待官方补全）"
    },
    {
        "id": "https://doi.org/10.1364/ol.586393",
        "title": "NPRO laser feedback interferometer with improved sensitivity",
        "link": "https://doi.org/10.1364/ol.586393",
        "published": "2026-01-22",
        "author": "Wenxun li, Chunzhao Ma, Weitong Fan, Xuezhen Gong, Danqing Liu, Jie Xu, changlei guo",
        "summary": "Abstract not available.",
        "journal": "Optics Letters",
        "title_cn": "NPRO 激光反馈干涉仪，灵敏度更高",
        "abstract_cn": "（摘要暂缺，等待官方补全）"
    },
    {
        "id": "https://doi.org/10.1364/prj.587213",
        "title": "High-Performance Tellurium Films with Engineered Ordered Texture: Synergistic Enhancement of Carrier Mobility and Stability",
        "link": "https://doi.org/10.1364/prj.587213",
        "published": "2026-01-22",
        "author": "Lijian Li, Yun Wei, Peng Guo, Wanyu Ma, Yifu Zhang, Yinglin Wang, Peng Wan, Hui Li, Caixia Kan, Daning Shi, Mingming Jiang",
        "summary": "Abstract not available.",
        "journal": "Photonics Research",
        "title_cn": "具有工程有序织构的高性能碲薄膜：载流子迁移率和稳定性的协同增强",
        "abstract_cn": "（摘要暂缺，等待官方补全）"
    },
    {
        "id": "https://www.nature.com/articles/s41377-025-02127-y",
        "title": "A near-infrared Sn-Pb perovskite imager with monolithic integration",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "A near-infrared Sn-Pb perovskite imager with monolithic integration"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41377-025-02127-y"
            }
        ],
        "link": "https://www.nature.com/articles/s41377-025-02127-y",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Light: Science &amp; Applications, Published online: 20 January 2026; <a href=\"https://www.nature.com/articles/s41377-025-02127-y\">doi:10.1038/s41377-025-02127-y</a></p>Monolithic Sn-Pb perovskite NIR imager with Sn(SCN)2 passivation achieves low dark current, high detectivity and material recognition for advanced sensing and imaging."
            }
        ],
        "summary": "Monolithic Sn-Pb perovskite NIR imager with Sn(SCN)2 passivation achieves low dark current, high detectivity and material recognition for advanced sensing and imaging.",
        "authors": [
            {
                "name": "Ciyu Ge"
            },
            {
                "name": "Chengjie Deng"
            },
            {
                "name": "Jiaxing Zhu"
            },
            {
                "name": "Yongcheng Zhu"
            },
            {
                "name": "Qi Xu"
            },
            {
                "name": "Borui Jiang"
            },
            {
                "name": "Long Chen"
            },
            {
                "name": "Yuxuan Liu"
            },
            {
                "name": "Boxiang Song"
            },
            {
                "name": "Ping Fu"
            },
            {
                "name": "Chao Chen"
            },
            {
                "name": "Liang Gao"
            },
            {
                "name": "Jiang Tang"
            }
        ],
        "author": "Jiang Tang",
        "author_detail": {
            "name": "Ciyu Ge"
        },
        "dc_identifier": "doi:10.1038/s41377-025-02127-y",
        "dc_source": "Light: Science & Applications, Published online: 2026-01-20; | doi:10.1038/s41377-025-02127-y",
        "updated": "2026-01-20",
        "updated_parsed": [
            2026,
            1,
            20,
            0,
            0,
            0,
            1,
            20,
            0
        ],
        "prism_publicationname": "Light: Science & Applications",
        "prism_doi": "10.1038/s41377-025-02127-y",
        "prism_url": "https://www.nature.com/articles/s41377-025-02127-y",
        "journal": "Light: Science & Applications",
        "title_cn": "具有单片集成功能的近红外锡铅钙钛矿成像仪",
        "abstract_cn": "采用 Sn(SCN)2 钝化的单片 Sn-Pb 钙钛矿近红外成像仪可实现低暗电流、高探测率和材料识别，从而实现先进的传感和成像。"
    },
    {
        "id": "https://www.nature.com/articles/s41377-025-02182-5",
        "title": "High-efficiency femtosecond laser fabrication of graphene-hybrid planar micro-supercapacitors with micro/nanostructured electrodes",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "High-efficiency femtosecond laser fabrication of graphene-hybrid planar micro-supercapacitors with micro/nanostructured electrodes"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41377-025-02182-5"
            }
        ],
        "link": "https://www.nature.com/articles/s41377-025-02182-5",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Light: Science &amp; Applications, Published online: 21 January 2026; <a href=\"https://www.nature.com/articles/s41377-025-02182-5\">doi:10.1038/s41377-025-02182-5</a></p>Universal femtosecond laser and spatial light modulation enable rapid fabrication of graphene-hybrid micro-supercapacitors on silicon. Simultaneous formation of ordered subwavelength electrode micro/nanostructures boosts processing efficiency and device performance."
            }
        ],
        "summary": "Universal femtosecond laser and spatial light modulation enable rapid fabrication of graphene-hybrid micro-supercapacitors on silicon. Simultaneous formation of ordered subwavelength electrode micro/nanostructures boosts processing efficiency and device performance.",
        "authors": [
            {
                "name": "Yuyuan Zhang"
            },
            {
                "name": "Tingting Zou"
            },
            {
                "name": "Haobo Jiang"
            },
            {
                "name": "Xiuyan Fu"
            },
            {
                "name": "Wei Xin"
            },
            {
                "name": "Yiyang Meng"
            },
            {
                "name": "Xilin Li"
            },
            {
                "name": "Jun-Ming Cao"
            },
            {
                "name": "Lin Yang"
            },
            {
                "name": "Yuanzheng Li"
            },
            {
                "name": "Weizhen Liu"
            },
            {
                "name": "Dongdong Han"
            },
            {
                "name": "Xing-Long Wu"
            },
            {
                "name": "Jianjun Yang"
            },
            {
                "name": "Haiyang Xu"
            },
            {
                "name": "Yichun Liu"
            }
        ],
        "author": "Yichun Liu",
        "author_detail": {
            "name": "Yuyuan Zhang"
        },
        "dc_identifier": "doi:10.1038/s41377-025-02182-5",
        "dc_source": "Light: Science & Applications, Published online: 2026-01-21; | doi:10.1038/s41377-025-02182-5",
        "updated": "2026-01-21",
        "updated_parsed": [
            2026,
            1,
            21,
            0,
            0,
            0,
            2,
            21,
            0
        ],
        "prism_publicationname": "Light: Science & Applications",
        "prism_doi": "10.1038/s41377-025-02182-5",
        "prism_url": "https://www.nature.com/articles/s41377-025-02182-5",
        "journal": "Light: Science & Applications",
        "title_cn": "具有微/纳米结构电极的石墨烯混合平面微型超级电容器的高效飞秒激光制造",
        "abstract_cn": "通用飞秒激光和空间光调制能够在硅上快速制造石墨烯混合微型超级电容器。同时形成有序亚波长电极微/纳米结构可提高加工效率和器件性能。"
    },
    {
        "id": "https://www.nature.com/articles/s41377-025-02172-7",
        "title": "TRIXS: a multilayer grating solution towards highly efficient resonant inelastic tender X-ray scattering",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "TRIXS: a multilayer grating solution towards highly efficient resonant inelastic tender X-ray scattering"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41377-025-02172-7"
            }
        ],
        "link": "https://www.nature.com/articles/s41377-025-02172-7",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Light: Science &amp; Applications, Published online: 21 January 2026; <a href=\"https://www.nature.com/articles/s41377-025-02172-7\">doi:10.1038/s41377-025-02172-7</a></p>Multilayer-grating-based spectrometer with high photon flux and moderate energy resolution for tender X-ray"
            }
        ],
        "summary": "Multilayer-grating-based spectrometer with high photon flux and moderate energy resolution for tender X-ray",
        "authors": [
            {
                "name": "Ke-Jin Zhou"
            },
            {
                "name": "Qiushi Huang"
            },
            {
                "name": "Mirian Garcia-Fernandez"
            },
            {
                "name": "Yeqi Zhuang"
            },
            {
                "name": "Stefano Agrestini"
            },
            {
                "name": "Shengyou Wen"
            },
            {
                "name": "Thomas Rice"
            },
            {
                "name": "Sahil Tippireddy"
            },
            {
                "name": "Jaewon Choi"
            },
            {
                "name": "Andrew Walters"
            },
            {
                "name": "Igor V. Kozhevnikov"
            },
            {
                "name": "Zhe Zhang"
            },
            {
                "name": "Runze Qi"
            },
            {
                "name": "Zhong Zhang"
            },
            {
                "name": "Hongchang Wang"
            },
            {
                "name": "Zhanshan Wang"
            }
        ],
        "author": "Zhanshan Wang",
        "author_detail": {
            "name": "Ke-Jin Zhou"
        },
        "dc_identifier": "doi:10.1038/s41377-025-02172-7",
        "dc_source": "Light: Science & Applications, Published online: 2026-01-21; | doi:10.1038/s41377-025-02172-7",
        "updated": "2026-01-21",
        "updated_parsed": [
            2026,
            1,
            21,
            0,
            0,
            0,
            2,
            21,
            0
        ],
        "prism_publicationname": "Light: Science & Applications",
        "prism_doi": "10.1038/s41377-025-02172-7",
        "prism_url": "https://www.nature.com/articles/s41377-025-02172-7",
        "journal": "Light: Science & Applications",
        "title_cn": "TRIXS：一种多层光栅解决方案，可实现高效共振非弹性 X 射线散射",
        "abstract_cn": "基于多层光栅的光谱仪，具有高光子通量和中等能量分辨率，适用于柔和的 X 射线"
    },
    {
        "id": "https://www.nature.com/articles/s41377-026-02190-z",
        "title": "Detection and imaging of chemicals and hidden explosives using terahertz time-domain spectroscopy and deep learning",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Detection and imaging of chemicals and hidden explosives using terahertz time-domain spectroscopy and deep learning"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41377-026-02190-z"
            }
        ],
        "link": "https://www.nature.com/articles/s41377-026-02190-z",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Light: Science &amp; Applications, Published online: 22 January 2026; <a href=\"https://www.nature.com/articles/s41377-026-02190-z\">doi:10.1038/s41377-026-02190-z</a></p>Detection and imaging of chemicals and hidden explosives using terahertz time-domain spectroscopy and deep learning"
            }
        ],
        "summary": "Detecting concealed chemicals and explosives remains a critical challenge in global security. Terahertz time-domain spectroscopy (THz-TDS) offers a promising non-invasive and stand-off detection technique owing to its ability to penetrate optically opaque materials without causing ionization damage. While many chemicals exhibit distinct spectral features in the terahertz range, conventional terahertz-based detection methods often struggle in real-world environments, where variations in sample geometry, thickness, and packaging can lead to inconsistent spectral responses. In this study, we present a chemical imaging system that integrates THz-TDS with deep learning to enable accurate pixel-level identification and classification of different explosives. Operating in reflection mode and enhanced with plasmonic nanoantenna arrays, our THz-TDS system achieves a peak dynamic range of 96 dB and a detection bandwidth of 4.5 THz, supporting practical, stand-off operation. By analyzing individual time-domain pulses with deep neural networks, the system exhibits strong resilience to environmental variations and sample inconsistencies. Blind testing across eight chemicals—including pharmaceutical excipients and explosive compounds—resulted in an average classification accuracy of 99.42% at the pixel level. Notably, the system maintained an average accuracy of 88.83% when detecting explosives concealed under opaque paper coverings, demonstrating its robust generalization capability. These results highlight the potential of combining advanced terahertz spectroscopy with neural networks for highly sensitive and specific chemical and explosive detection in diverse and operationally relevant scenarios.",
        "authors": [
            {
                "name": "Xinghe Jiang"
            },
            {
                "name": "Yuhang Li"
            },
            {
                "name": "Yuzhu Li"
            },
            {
                "name": "Che-Yung Shen"
            },
            {
                "name": "Aydogan Ozcan"
            },
            {
                "name": "Mona Jarrahi"
            }
        ],
        "author": "Mona Jarrahi",
        "author_detail": {
            "name": "Xinghe Jiang"
        },
        "dc_identifier": "doi:10.1038/s41377-026-02190-z",
        "dc_source": "Light: Science & Applications, Published online: 2026-01-22; | doi:10.1038/s41377-026-02190-z",
        "updated": "2026-01-22",
        "updated_parsed": [
            2026,
            1,
            22,
            0,
            0,
            0,
            3,
            22,
            0
        ],
        "prism_publicationname": "Light: Science & Applications",
        "prism_doi": "10.1038/s41377-026-02190-z",
        "prism_url": "https://www.nature.com/articles/s41377-026-02190-z",
        "journal": "Light: Science & Applications",
        "title_cn": "使用太赫兹时域光谱和深度学习对化学品和隐藏爆炸物进行检测和成像",
        "abstract_cn": "检测隐藏的化学品和爆炸物仍然是全球安全的一项严峻挑战。太赫兹时域光谱（THz-TDS）提供了一种有前途的非侵入性和远距离检测技术，因为它能够穿透光学不透明材料而不造成电离损伤。虽然许多化学品在太赫兹范围内表现出独特的光谱特征，但传统的基于太赫兹的检测方法通常在现实环境中举步维艰，其中样品几何形状、厚度和包装的变化可能导致光谱响应不一致。在这项研究中，我们提出了一种化学成像系统，它将 THz-TDS 与深度学习相结合，能够对不同爆炸物进行精确的像素级识别和分类。我们的 THz-TDS 系统在反射模式下运行，并通过等离子体纳米天线阵列进行增强，可实现 96dB 的峰值动态范围和 4.5THz 的检测带宽，支持实际的隔离操作。通过使用深度神经网络分析单个时域脉冲，该系统对环境变化和样本不一致表现出强大的适应能力。对八种化学品（包括药用辅料和爆炸性化合物）进行盲测，像素级平均分类准确度达到 99.42%。值得注意的是，该系统在检测隐藏在不透明纸质覆盖物下的爆炸物时，平均准确率保持在 88.83%，展示了其强大的泛化能力。这些结果凸显了将先进的太赫兹光谱与神经网络相结合的潜力，可在多种和操作相关的场景中进行高灵敏度和特定的化学和爆炸物检测。"
    },
    {
        "id": "https://www.nature.com/articles/s41377-025-02169-2",
        "title": "Dispersion engineering by rotational symmetry breaking in an optical microcavity",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Dispersion engineering by rotational symmetry breaking in an optical microcavity"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41377-025-02169-2"
            }
        ],
        "link": "https://www.nature.com/articles/s41377-025-02169-2",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Light: Science &amp; Applications, Published online: 22 January 2026; <a href=\"https://www.nature.com/articles/s41377-025-02169-2\">doi:10.1038/s41377-025-02169-2</a></p>Dispersion engineering by rotational symmetry breaking in an optical microcavity"
            }
        ],
        "summary": "Dispersion engineering is pivotal for nonlinear optics, yet it often faces challenges posed by material and structural limitations. Here, we establish rotational symmetry breaking as the guiding principle for dispersion engineering in optical microcavities. Through boundary deformation, multi-branch global dispersion emerges in island modes, and local dispersion is controlled via resonance-assisted tunneling between quasi-whispering gallery modes. Enabled by the global dispersion, the optical parametric oscillation is predicted in blue-violet light spectrum with high efficiency (&gt;55%) and large frequency separation (&gt;180 THz). Using the local dispersion engineering, the doubly-resonant enhancement of second-harmonic generation is regulated by the resonance-assisted tunneling.",
        "authors": [
            {
                "name": "Jian-Zheng Ren"
            },
            {
                "name": "Li-Jie Li"
            },
            {
                "name": "Rui-Qi Zhang"
            },
            {
                "name": "Zhi-Yan Wang"
            },
            {
                "name": "Qi-Tao Cao"
            },
            {
                "name": "Yun-Feng Xiao"
            }
        ],
        "author": "Yun-Feng Xiao",
        "author_detail": {
            "name": "Jian-Zheng Ren"
        },
        "dc_identifier": "doi:10.1038/s41377-025-02169-2",
        "dc_source": "Light: Science & Applications, Published online: 2026-01-22; | doi:10.1038/s41377-025-02169-2",
        "updated": "2026-01-22",
        "updated_parsed": [
            2026,
            1,
            22,
            0,
            0,
            0,
            3,
            22,
            0
        ],
        "prism_publicationname": "Light: Science & Applications",
        "prism_doi": "10.1038/s41377-025-02169-2",
        "prism_url": "https://www.nature.com/articles/s41377-025-02169-2",
        "journal": "Light: Science & Applications",
        "title_cn": "光学微腔中旋转对称破缺的色散工程",
        "abstract_cn": "色散工程对于非线性光学至关重要，但它经常面临材料和结构限制带来的挑战。在这里，我们将旋转对称破缺确立为光学微腔色散工程的指导原则。通过边界变形，在岛模式中出现多分支全局色散，并且通过准回音壁模式之间的共振辅助隧道控制局部色散。通过全局色散，可以预测蓝紫光光谱中的光学参量振荡具有高效率（> 55％）和大频率间隔（> 180 THz）。利用局部色散工程，通过谐振辅助隧道调节二次谐波产生的双谐振增强。"
    },
    {
        "id": "https://www.nature.com/articles/s41377-025-02057-9",
        "title": "Soft X-ray imaging with coherence tomography in the water window spectral range using high-harmonic generation",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Soft X-ray imaging with coherence tomography in the water window spectral range using high-harmonic generation"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41377-025-02057-9"
            }
        ],
        "link": "https://www.nature.com/articles/s41377-025-02057-9",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Light: Science &amp; Applications, Published online: 22 January 2026; <a href=\"https://www.nature.com/articles/s41377-025-02057-9\">doi:10.1038/s41377-025-02057-9</a></p>Water window imaging with high-harmonic generation is achieved using soft X-ray coherence tomography (SXCT), revealing the cross-sectional structure of buried nanolayers with 12 nm axial resolution."
            }
        ],
        "summary": "Water window imaging with high-harmonic generation is achieved using soft X-ray coherence tomography (SXCT), revealing the cross-sectional structure of buried nanolayers with 12 nm axial resolution.",
        "authors": [
            {
                "name": "Julius Reinhard"
            },
            {
                "name": "Felix Wiesner"
            },
            {
                "name": "Martin Hennecke"
            },
            {
                "name": "Themistoklis Sidiropoulos"
            },
            {
                "name": "Sophia Kaleta"
            },
            {
                "name": "Julian Späthe"
            },
            {
                "name": "Johann Jakob Abel"
            },
            {
                "name": "Martin Wünsche"
            },
            {
                "name": "Gabriele Schmidl"
            },
            {
                "name": "Jonathan Plentz"
            },
            {
                "name": "Uwe Hübner"
            },
            {
                "name": "Katharina Freiberg"
            },
            {
                "name": "Jonathan Apell"
            },
            {
                "name": "Stephanie Lippmann"
            },
            {
                "name": "Matthias Schnürer"
            },
            {
                "name": "Stefan Eisebitt"
            },
            {
                "name": "Gerhard G. Paulus"
            },
            {
                "name": "Silvio Fuchs"
            }
        ],
        "author": "Silvio Fuchs",
        "author_detail": {
            "name": "Julius Reinhard"
        },
        "dc_identifier": "doi:10.1038/s41377-025-02057-9",
        "dc_source": "Light: Science & Applications, Published online: 2026-01-22; | doi:10.1038/s41377-025-02057-9",
        "updated": "2026-01-22",
        "updated_parsed": [
            2026,
            1,
            22,
            0,
            0,
            0,
            3,
            22,
            0
        ],
        "prism_publicationname": "Light: Science & Applications",
        "prism_doi": "10.1038/s41377-025-02057-9",
        "prism_url": "https://www.nature.com/articles/s41377-025-02057-9",
        "journal": "Light: Science & Applications",
        "title_cn": "使用高次谐波发生在水窗光谱范围内进行相干断层扫描的软 X 射线成像",
        "abstract_cn": "使用软 X 射线相干断层扫描 (SXCT) 实现高次谐波产生的水窗成像，以 12 nm 轴向分辨率揭示埋入纳米层的横截面结构。"
    },
    {
        "id": "https://www.nature.com/articles/s41377-025-02109-0",
        "title": "Experimental demonstration of spatiotemporal analog computation in ultrafast optics",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Experimental demonstration of spatiotemporal analog computation in ultrafast optics"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41377-025-02109-0"
            }
        ],
        "link": "https://www.nature.com/articles/s41377-025-02109-0",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Light: Science &amp; Applications, Published online: 22 January 2026; <a href=\"https://www.nature.com/articles/s41377-025-02109-0\">doi:10.1038/s41377-025-02109-0</a></p>Experimental demonstration of spatiotemporal analog computation in ultrafast optics"
            }
        ],
        "summary": "It is intractable to perform information processing and computation on single ultrafast optical pulses, within picoseconds or even femtoseconds. Here, we experimentally demonstrate an optical spatiotemporal differentiator, a mirror-symmetry-breaking dielectric metagrating, which performs analog computations of both spatial and temporal differentiations on single ultrafast optical wavepackets. The spatiotemporal differentiator is designed with a transfer function with linear dependence on spatial wavevector and temporal frequency and fabricated by using a double-exposure E-beam lithography process. We achieve the first-order spatiotemporal differentiation with experimental resolutions of approximately 14 μm (in space) and 260 fs (in time). Furthermore, we report a parabolic relationship between the transverse velocity of a front-tilted photonic wavepacket and the normalized intensity of its first-order spatiotemporal-differentiation wavepacket. This relationship allows direct measurement of the transverse velocity using only the normalized intensity, fundamentally simplifying velocity detection. These capabilities of optical spatiotemporal computation endow emerging space-time optics with fundamental computation blocks.",
        "authors": [
            {
                "name": "Junyi Huang"
            },
            {
                "name": "Dong Zhao"
            },
            {
                "name": "Jixuan Shi"
            },
            {
                "name": "Hongliang Zhang"
            },
            {
                "name": "Hengyi Wang"
            },
            {
                "name": "Fang-Wen Sun"
            },
            {
                "name": "Qiwen Zhan"
            },
            {
                "name": "Shiyao Zhu"
            },
            {
                "name": "Kun Huang"
            },
            {
                "name": "Zhichao Ruan"
            }
        ],
        "author": "Zhichao Ruan",
        "author_detail": {
            "name": "Junyi Huang"
        },
        "dc_identifier": "doi:10.1038/s41377-025-02109-0",
        "dc_source": "Light: Science & Applications, Published online: 2026-01-22; | doi:10.1038/s41377-025-02109-0",
        "updated": "2026-01-22",
        "updated_parsed": [
            2026,
            1,
            22,
            0,
            0,
            0,
            3,
            22,
            0
        ],
        "prism_publicationname": "Light: Science & Applications",
        "prism_doi": "10.1038/s41377-025-02109-0",
        "prism_url": "https://www.nature.com/articles/s41377-025-02109-0",
        "journal": "Light: Science & Applications",
        "title_cn": "超快光学时空模拟计算的实验演示",
        "abstract_cn": "在皮秒甚至飞秒内对单个超快光脉冲进行信息处理和计算是很困难的。在这里，我们通过实验演示了一种光学时空微分器，一种打破镜像对称的介电元光栅，它可以对单个超快光波包的空间和时间微分进行模拟计算。时空微分器的设计具有与空间波矢量和时间频率线性相关的传递函数，并通过使用双曝光电子束光刻工艺制造。我们以大约 14 μm（空间）和 260fs（时间）的实验分辨率实现了一阶时空微分。此外，我们报告了前倾光子波包的横向速度与其一阶时空微分波包的归一化强度之间的抛物线关系。这种关系允许仅使用归一化强度直接测量横向速度，从根本上简化了速度检测。光学时空计算的这些能力赋予新兴的时空光学基本的计算模块。"
    },
    {
        "id": "https://www.nature.com/articles/s41377-025-02102-7",
        "title": "Generation of vectorial generalized vortex array with metasurfaces",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Generation of vectorial generalized vortex array with metasurfaces"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.nature.com/articles/s41377-025-02102-7"
            }
        ],
        "link": "https://www.nature.com/articles/s41377-025-02102-7",
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<p>Light: Science &amp; Applications, Published online: 22 January 2026; <a href=\"https://www.nature.com/articles/s41377-025-02102-7\">doi:10.1038/s41377-025-02102-7</a></p>Generation of vectorial generalized vortex array with metasurfaces"
            }
        ],
        "summary": "The ability to create complex three-dimensional structures of light is extremely challenging. Now, a technique combining Dammann optimization with metasurfaces has been developed, enabling control over all parameters, including polarization, phase, angular momentum, and spatial modes. The generation of three-dimensional generalized vortex beams can open new horizons for their applications in photonics.",
        "authors": [
            {
                "name": "Qingsong Yao"
            },
            {
                "name": "Zile Li"
            },
            {
                "name": "Guoxing Zheng"
            }
        ],
        "author": "Guoxing Zheng",
        "author_detail": {
            "name": "Qingsong Yao"
        },
        "dc_identifier": "doi:10.1038/s41377-025-02102-7",
        "dc_source": "Light: Science & Applications, Published online: 2026-01-22; | doi:10.1038/s41377-025-02102-7",
        "updated": "2026-01-22",
        "updated_parsed": [
            2026,
            1,
            22,
            0,
            0,
            0,
            3,
            22,
            0
        ],
        "prism_publicationname": "Light: Science & Applications",
        "prism_doi": "10.1038/s41377-025-02102-7",
        "prism_url": "https://www.nature.com/articles/s41377-025-02102-7",
        "journal": "Light: Science & Applications",
        "title_cn": "具有超表面的矢量广义涡阵列的生成",
        "abstract_cn": "创建复杂的三维光结构的能力极具挑战性。现在，一种将达曼优化与超表面相结合的技术已经开发出来，可以控制所有参数，包括偏振、相位、角动量和空间模式。三维广义涡旋光束的产生可以为其在光子学中的应用开辟新的视野。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3572727",
        "title": "RGMLN:Residual Graph Model Learning Network for Bioluminescence Tomography",
        "link": "https://doi.org/10.1109/tci.2025.3572727",
        "published": "2025",
        "author": "De Wei, Yizhe Zhao, Shuangchen Li, Heng Zhang, Beilei Wang, Xiaowei He, Jingjing Yu, Huangjian Yi, Xuelei He, Hongbo Guo",
        "summary": "For bioluminescence tomography reconstruction, regularization algorithms and deep learning frameworks have been widely studied and achieved impressive results. However, the parameter selection of the regularization algorithm and the poor interpretability of deep learning methods have become the key factors that affect the reconstruction results and hinder its applicability. To mitigate the effects of this problem, in this paper, we proposed a novel residual graph model learning network (RGMLN) for bioluminescence tomography reconstruction by combining the advantages of regularization method and deep learning. RGMLN is based on the inference process of the thresholding iterative shrinkage algorithm. The difference is that the penalty term of the regularization method was replaced by a learnable nonlinear mapping between the residual and source distributions to ensure the interpretability of network. Meanwhile, considering the non-Euclidean property of the finite element mesh, a graph convolution operation based on Laplacian graph theory was conducted to aggregate features of mesh nodes using the topological information of the tetrahedral mesh. Lastly, based on residual learning and auto-encoder strategies, gradient descent and prox mapping modules were designed to structure the model-driven RGMLN method to take advantage of both the interpretability of iterative techniques and the flexibility of learning methods. Both numerical and in vivo experiments confirmed that the proposed network has excellent positioning accuracy and can be applied to different meshes and wavelengths.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "RGMLN：生物发光断层扫描残差图模型学习网络",
        "abstract_cn": "对于生物发光断层扫描重建，正则化算法和深度学习框架已被广泛研究并取得了令人印象深刻的成果。然而，正则化算法的参数选择和深度学习方法的可解释性差成为影响重建结果并阻碍其适用性的关键因素。为了减轻这个问题的影响，本文结合正则化方法和深度学习的优点，提出了一种用于生物发光断层扫描重建的新型残差图模型学习网络（RGMLN）。 RGMLN基于阈值迭代收缩算法的推理过程。不同之处在于，正则化方法的惩罚项被替换为残差和源分布之间的可学习非线性映射，以确保网络的可解释性。同时，考虑到有限元网格的非欧性质，利用四面体网格的拓扑信息，进行基于拉普拉斯图论的图卷积运算，聚合网格节点的特征。最后，基于残差学习和自动编码策略，设计了梯度下降和prox映射模块来构建模型驱动的RGMLN方法，以利用迭代技术的可解释性和学习方法的灵活性。数值和体内实验均证实，所提出的网络具有出色的定位精度，并且可以应用于不同的网格和波长。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3577334",
        "title": "Robust Correspondence Imaging Against Random Disturbances With Single-Pixel Detection",
        "link": "https://doi.org/10.1109/tci.2025.3577334",
        "published": "2025",
        "author": "Zhihan Xu, Yin Xiao, Wen Chen",
        "summary": "Random disturbance has become a great challenge for correspondence imaging (CI) due to dynamic and nonlinear scaling factors. In this paper, we propose a robust CI against random disturbances for high-quality object reconstruction. To remove the effect of dynamic scaling factors induced by random disturbance, a wavelet and total variation (WATV) algorithm is developed to estimate a series of varying thresholds. Then, light intensities collected by a single-pixel detector are processed by using the series of estimated varying thresholds. To realize high-quality object reconstruction, the binarized light intensities and a series of random patterns are fed into a plug-and-play priors (PnP) algorithm with an iteration framework and a general denoiser, called as CI-PnP. Theoretical descriptions are given in detail to reveal the formation mechanism in CI under random disturbance. Optical measurements are conducted to verify robustness of the proposed CI against random disturbances. It is demonstrated that the proposed method can remove the effect of dynamic scaling factors induced by random disturbance, and can realize high-quality object reconstruction. The proposed method provides a promising solution to achieving ultra-high robustness against random disturbances in CI, and is promising in various applications.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "通过单像素检测对抗随机干扰的鲁棒对应成像",
        "abstract_cn": "由于动态和非线性缩放因子，随机扰动已成为对应成像（CI）的巨大挑战。在本文中，我们提出了一种针对随机干扰的鲁棒 CI，以实现高质量的对象重建。为了消除随机扰动引起的动态缩放因子的影响，开发了小波和全变分（WATV）算法来估计一系列变化的阈值。然后，通过使用一系列估计的变化阈值来处理单像素检测器收集的光强度。为了实现高质量的对象重建，二值化光强度和一系列随机模式被输入具有迭代框架和通用降噪器的即插即用先验（PnP）算法中，称为 CI-PnP。详细的理论描述揭示了随机扰动下CI的形成机制。进行光学测量是为了验证所提出的 CI 对随机干扰的鲁棒性。结果表明，该方法可以消除随机扰动引起的动态缩放因子的影响，实现高质量的目标重建。该方法为实现 CI 中随机扰动的超高鲁棒性提供了一种有前途的解决方案，并且在各种应用中都有前景。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3577338",
        "title": "$L^{2}$FMamba: Lightweight Light Field Image Super-Resolution With State Space Model",
        "link": "https://doi.org/10.1109/tci.2025.3577338",
        "published": "2025",
        "author": "Zeqiang Wei, Kai Jin, Zeyi Hou, Kuan Song, Xiuzhuang Zhou",
        "summary": "Transformers bring significantly improved performance to the light field image super-resolution task due to their long-range dependency modeling capability. However, the inherently high computational complexity of their core self-attention mechanism has increasingly hindered their advancement in this task. To address this issue, we first introduce the LF-VSSM block, a novel module inspired by progressive feature extraction, to efficiently capture critical long-range spatial-angular dependencies in light field images. LF-VSSM successively extracts spatial features within sub-aperture images, spatial-angular features between sub-aperture images, and spatial-angular features between light field image pixels. On this basis, we propose a lightweight network, $L^{2}$FMamba (Lightweight Light Field Mamba), which integrates the LF-VSSM block to leverage light field features for super-resolution tasks while overcoming the computational challenges of Transformer-based approaches. Extensive experiments on multiple light field datasets demonstrate that our method reduces the number of parameters and complexity while achieving superior super-resolution performance with faster inference speed.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "$L^{2}$FMamba：具有状态空间模型的轻量级光场图像超分辨率",
        "abstract_cn": "由于其远程依赖建模能力，Transformers 为光场图像超分辨率任务带来了显着提高的性能。然而，其核心自注意力机制固有的高计算复杂性越来越阻碍了他们在这项任务中的进步。为了解决这个问题，我们首先引入 LF-VSSM 模块，这是一种受渐进式特征提取启发的新颖模块，可以有效捕获光场图像中关键的远程空间角度依赖性。 LF-VSSM依次提取子孔径图像内的空间特征、子孔径图像之间的空间角度特征以及光场图像像素之间的空间角度特征。在此基础上，我们提出了一种轻量级网络$L^{2}$FMamba（Lightweight Light Field Mamba），它集成了LF-VSSM模块，利用光场特征进行超分辨率任务，同时克服基于Transformer的方法的计算挑战。对多个光场数据集的大量实验表明，我们的方法减少了参数数量和复杂性，同时以更快的推理速度实现了卓越的超分辨率性能。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3577340",
        "title": "Iterative Collaboration Network Guided by Reconstruction Prior for Medical Image Super-Resolution",
        "link": "https://doi.org/10.1109/tci.2025.3577340",
        "published": "2025",
        "author": "Xiaoyan Kui, Zexin Ji, Beiji Zou, Yang Li, Yulan Dai, Liming Chen, Pierre Vera, Su Ruan",
        "summary": "High-resolution medical images can provide more detailed information for better diagnosis. Conventional medical image super-resolution relies on a single task which first performs the extraction of the features and then upscaling based on the features. The features extracted may not be complete for super-resolution. Recent multi-task learning, including reconstruction and super-resolution, is a good solution to obtain additional relevant information. The interaction between the two tasks is often insufficient, which still leads to incomplete and less relevant deep features. To address above limitations, we propose an iterative collaboration network (ICONet) to improve communications between tasks by progressively incorporating reconstruction prior to the super-resolution learning procedure in an iterative collaboration way. It consists of a reconstruction branch, a super-resolution branch, and a SR-Rec fusion module. The reconstruction branch generates the artifact-free image as prior, which is followed by a super-resolution branch for prior knowledge-guided super-resolution. Unlike the widely-used convolutional neural networks for extracting local features and Transformers with quadratic computational complexity for modeling long-range dependencies, we develop a new residual spatial-channel feature learning (RSCFL) module of two branches to efficiently establish feature relationships in spatial and channel dimensions. Moreover, the designed SR-Rec fusion module fuses the reconstruction prior and super-resolution features with each other in an adaptive manner. Our ICONet is built with multi-stage models to iteratively upscale the low-resolution images using steps of ${2 \\times }$ and simultaneously interact between two branches in multi-stage supervisions. Quantitative and qualitative experimental results on the benchmarking dataset show that our ICONet outperforms most state-of-the-art approaches.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "重建先验引导的医学图像超分辨率迭代协作网络",
        "abstract_cn": "高分辨率医学图像可以提供更详细的信息以进行更好的诊断。传统的医学图像超分辨率依赖于单个任务，该任务首先执行特征提取，然后基于特征进行放大。对于超分辨率而言，提取的特征可能不完整。最近的多任务学习，包括重建和超分辨率，是获取额外相关信息的一个很好的解决方案。两个任务之间的交互往往不够充分，这仍然导致深层特征不完整且相关性较差。为了解决上述限制，我们提出了一种迭代协作网络（ICONet），通过以迭代协作方式在超分辨率学习过程之前逐步合并重建来改善任务之间的通信。它由重建分支、超分辨率分支和SR-Rec融合模块组成。重建分支按照先前的方式生成无伪影图像，随后是用于先验知识引导的超分辨率的超分辨率分支。与广泛使用的用于提取局部特征的卷积神经网络和用于建模远程依赖性的具有二次计算复杂度的 Transformer 不同，我们开发了一种新的两个分支的残差空间通道特征学习（RSCFL）模块，以有效地建立空间和通道维度的特征关系。此外，设计的SR-Rec融合模块以自适应方式将重建先验特征和超分辨率特征相互融合。我们的 ICONet 采用多阶段模型构建，可使用 ${2 \\times }$ 的步骤迭代升级低分辨率图像，并在多阶段监督中同时在两个分支之间进行交互。基准数据集的定量和定性实验结果表明，我们的 ICONet 优于大多数最先进的方法。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3572250",
        "title": "A Physics-Inspired Deep Learning Framework With Polar Coordinate Attention for Ptychographic Imaging",
        "link": "https://doi.org/10.1109/tci.2025.3572250",
        "published": "2025",
        "author": "Han Yue, Jun Cheng, Yu-Xuan Ren, Chien-Chun Chen, Grant A. van Riessen, Philip Heng Wai Leong, Steve Feng Shu",
        "summary": "Ptychographic imaging confronts inherent challenges in applying deep learning for phase retrieval from diffraction patterns. Conventional neural architectures, both convolutional neural networks and Transformer-based methods, are optimized for natural images with Euclidean spatial neighborhood-based inductive biases that exhibit geometric mismatch with the concentric coherent patterns characteristic of diffraction data in reciprocal space. In this paper, we present PPN, a physics-inspired deep learning network with Polar Coordinate Attention (PoCA) for ptychographic imaging, that aligns neural inductive biases with diffraction physics through a dual-branch architecture separating local feature extraction from non-local coherence modeling. It consists of a PoCA mechanism that replaces Euclidean spatial priors with physically consistent radial-angular correlations. PPN outperforms existing end-to-end models, with spectral and spatial analysis confirming its greater preservation of high-frequency details. Notably, PPN maintains robust performance compared to iterative methods even at low overlap ratios — well-suited for high-throughput imaging in real-world acquisition scenarios for samples with consistent structural characteristics.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "一种受物理启发的深度学习框架，具有极坐标注意力，用于叠印成像",
        "abstract_cn": "叠层成像在应用深度学习从衍射图案中进行相位检索时面临着固有的挑战。传统的神经架构，无论是卷积神经网络还是基于 Transformer 的方法，都针对具有基于欧几里德空间邻域的归纳偏差的自然图像进行了优化，这些偏差与倒易空间中衍射数据的同心相干图案特征表现出几何不匹配。在本文中，我们提出了 PPN，这是一种受物理启发的深度学习网络，具有用于叠层成像的极坐标注意（PoCA），它通过将局部特征提取与非局部相干建模分开的双分支架构，将神经归纳偏差与衍射物理结合起来。它由 PoCA 机制组成，用物理上一致的径向角相关性取代欧几里得空间先验。 PPN 优于现有的端到端模型，频谱和空间分析证实其更好地保留了高频细节。值得注意的是，与迭代方法相比，即使在低重叠率下，PPN 也能保持稳健的性能——非常适合在现实世界采集场景中对具有一致结构特征的样品进行高通量成像。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3577405",
        "title": "Laser Ultrasonic Imaging Via the Time Domain Linear Sampling Method",
        "link": "https://doi.org/10.1109/tci.2025.3577405",
        "published": "2025",
        "author": "Jian Song, Fatemeh Pourahmadian, Todd W. Murray, Venkatalakshmi V. Narumanchi",
        "summary": "This study investigates the imaging ability of the time-domain linear sampling method (TLSM) when applied to laser ultrasonic (LU) tomography of subsurface defects from limited-aperture measurements. In this vein, the TLSM indicator and its spectral counterpart known as the multifrequency LSM are formulated within the context of LU testing. The affiliated imaging functionals are then computed using synthetic and experimental data germane to LU inspection of aluminum alloy specimens with manufactured defects. Hyperparameters of inversion are computationally analyzed. We demonstrate using synthetic data that the TLSM indicator has the unique ability to recover weak (or hard-to-reach) scatterers and has the potential to generate higher quality images compared to LSM. Provided high-SNR measurements, this advantage may be preserved in reconstructions from LU test data.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "通过时域线性采样方法进行激光超声成像",
        "abstract_cn": "本研究研究了时域线性采样方法 (TLSM) 在应用于有限孔径测量的亚表面缺陷激光超声 (LU) 断层扫描时的成像能力。在这种情况下，TLSM 指标及其频谱对应物（称为多频 LSM）是在 LU 测试的背景下制定的。然后使用与具有制造缺陷的铝合金样本的 LU 检查密切相关的合成和实验数据来计算附属的成像泛函。对反演的超参数进行了计算分析。我们使用合成数据证明，TLSM 指示器具有恢复弱（或难以到达）散射体的独特能力，并且与 LSM 相比，有可能生成更高质量的图像。如果提供高 SNR 测量，则可以在 LU 测试数据的重建中保留此优势。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3578762",
        "title": "Energy-Coded Spectral CT Imaging Method Based on Projection Mix Separation",
        "link": "https://doi.org/10.1109/tci.2025.3578762",
        "published": "2025",
        "author": "Xiaojie Zhao, Yihong Li, Yan Han, Ping Chen, Jiaotong Wei",
        "summary": "Spectral CT can be used to perform material decomposition from polychromatic attenuation data, generate virtual monochromatic or virtual narrow-energy-width images in which beam hardening artifacts are suppressed, and provide detailed energy attenuation coefficients for material characterization. We propose an energy-coded spectral CT imaging method that is based on projection mix separation, which enables simultaneous energy decoding and image reconstruction. An X-ray energy-coded forward model is then constructed. Leveraging the Poisson statistical properties of the measurement data, we formulate a constrained optimization problem for both the energy-coded coefficient matrix and the material decomposition coefficient matrix, which is solved using a block coordinate descent algorithm. Simulations and experimental results demonstrate that the decoded energy spectrum distribution and virtual narrow-energy-width CT images are accurate and effective. The proposed method suppresses beam hardening artifacts and enhances the material identification capabilities of traditional CT.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "基于投影混合分离的能量编码能谱CT成像方法",
        "abstract_cn": "能谱 CT 可用于根据多色衰减数据进行材料分解，生成虚拟单色或虚拟窄能量宽度图像，其中束硬化伪影得到抑制，并为材料表征提供详细的能量衰减系数。我们提出了一种基于投影混合分离的能量编码能谱 CT 成像方法，可同时进行能量解码和图像重建。然后构建 X 射线能量编码正向模型。利用测量数据的泊松统计特性，我们为能量编码系数矩阵和材料分解系数矩阵制定了约束优化问题，并使用块坐标下降算法求解。仿真和实验结果表明，解码的能谱分布和虚拟窄能宽CT图像准确有效。该方法抑制了射束硬化伪影，增强了传统 CT 的材料识别能力。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3581105",
        "title": "G2L-Stereo: Global to Local Two-Stage Real-Time Stereo Matching Network",
        "link": "https://doi.org/10.1109/tci.2025.3581105",
        "published": "2025",
        "author": "Jie Tang, Gaofeng Peng, Jialu Liu, Bo Yu",
        "summary": "Developing fast and accurate stereo matching algorithms is crucial for real-world embedded vision applications. Depth information plays a significant role in scene understanding, and depth calculated through stereo matching is generally considered to be more precise and reliable than that obtained from monocular depth estimation. However, speed-oriented stereo matching methods often suffer from poor feature representation due to sparse sampling and detail loss caused by unreasonable disparity allocation during upsampling. To address these issues, we propose G2L-Stereo, a two-stage real-time stereo matching network that combines global disparity range prediction and local disparity range prediction. In the global disparity range prediction stage, we introduce feature-guided connections for cost aggregation, enhancing the expressive power of sparse features by aligning the feature space across different scales of cost volumes. We also incorporate confidence estimation into the upsampling algorithm to reduce the propagation of inaccurate disparities during upsampling, yielding more precise disparity maps. In the local disparity range prediction stage, we develop a disparity refinement module guided by neighborhood similarity. This module aggregates similar neighboring costs to estimate disparity residuals and refine disparities, restoring lost details in the low-resolution disparity map and further enhancing disparity accuracy. Extensive experiments on the SceneFlow and KITTI datasets validate the effectiveness of our model, showing that G2L-Stereo achieves fast inference while maintaining accuracy comparable to state-of-the-art methods.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "G2L-Stereo：全局到局部两级实时立体匹配网络",
        "abstract_cn": "开发快速、准确的立体匹配算法对于现实世界的嵌入式视觉应用至关重要。深度信息在场景理解中起着重要作用，通过立体匹配计算的深度通常被认为比单目深度估计获得的深度更精确、更可靠。然而，面向速度的立体匹配方法往往由于稀疏采样和上采样过程中不合理的视差分配导致的细节损失而导致特征表示较差。为了解决这些问题，我们提出了 G2L-Stereo，这是一种结合了全局视差范围预测和局部视差范围预测的两阶段实时立体匹配网络。在全局视差范围预测阶段，我们引入了用于成本聚合的特征引导连接，通过跨不同尺度的成本量对齐特征空间来增强稀疏特征的表达能力。我们还将置信度估计纳入上采样算法中，以减少上采样期间不准确视差的传播，从而产生更精确的视差图。在局部视差范围预测阶段，我们开发了一个以邻域相似性为指导的视差细化模块。该模块聚合相似的邻近成本来估计视差残差并细化视差，恢复低分辨率视差图中丢失的细节并进一步提高视差精度。在 SceneFlow 和 KITTI 数据集上进行的大量实验验证了我们模型的有效性，表明 G2L-Stereo 实现了快速推理，同时保持了与最先进方法相当的准确性。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3583465",
        "title": "Vignetting Correction Through Color-Intensity Map Entropy Optimization",
        "link": "https://doi.org/10.1109/tci.2025.3583465",
        "published": "2025",
        "author": "Zhuang He, Hai-Miao Hu, Likun Gao, Haoxin Hu, Xinhui Xue, Zhenglin Tang, Difeng Zhu, Haowen Zheng, Chongze Wang",
        "summary": "Vignetting correction is an essential process of image signal processing. It is an important part for obtaining high-quality images, but the research in this field has not been fully emphasized. The mainstream methods are based on calibration which processes are complex. And many methods get low accuracy and poor robustness in practical. In this paper, we analyzed the optical principle of vignetting and its influence on the image. Then, we proposed an algorithm based on color-intensity map entropy optimization to correct image vignetting. Moreover, because of the lack of dataset of vignetting, we proposed a method for constructing vignetting image dataset through capturing the real scenes. Compared with the dataset generated through simulation, our dataset is more authentic and reliable. Many experiments have been carried out on this dataset, and the results proved that the proposed algorithm achieved the best performance.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "通过颜色强度图熵优化进行渐晕校正",
        "abstract_cn": "暗角校正是图像信号处理的一个重要过程。它是获得高质量图像的重要组成部分，但该领域的研究尚未得到充分重视。主流方法都是基于标定，过程比较复杂。但许多方法在实际应用中精度较低、鲁棒性较差。本文分析了渐晕的光学原理及其对图像的影响。然后，我们提出了一种基于颜色强度图熵优化的算法来校正图像渐晕。此外，由于缺乏渐晕数据集，我们提出了一种通过捕获真实场景来构建渐晕图像数据集的方法。与通过模拟生成的数据集相比，我们的数据集更加真实可靠。在此数据集上进行了大量实验，结果证明所提出的算法取得了最佳性能。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3587407",
        "title": "Test-Time Adaptation Improves Inverse Problem Solving With Patch-Based Diffusion Models",
        "link": "https://doi.org/10.1109/tci.2025.3587407",
        "published": "2025",
        "author": "Jason Hu, Bowen Song, Jeffrey A. Fessler, Liyue Shen",
        "summary": "Diffusion models have achieved excellent success in solving inverse problems due to their ability to learn strong image priors, but existing approaches require a large training dataset of images that should come from the same distribution as the test dataset. In practice, the size of the available training dataset can range from nonexistent to very large. In some cases, conventional diffusion model training from limited data can lead to poor reconstruction results due to poorly learned priors. One potential improvement is to start with a diffusion model trained from available training data having a possibly mismatched distribution, and then refine the network at reconstruction time to account for the distribution mismatch. In this work, we investigate the effect of this network refining process on diffusion models trained from varying degrees of out-of-distribution data. Specifically, we use a self-supervised loss to adapt the learned diffusion network to the testing data while helping the network output maintain consistency with the measurements. We show that, both theoretically and experimentally, test-time adaptation of a patch-based diffusion prior leads to higher quality reconstructions than test-time refinement of traditional whole-image diffusion models. Extensive experiments show that across a wide range of inverse problems, test-time adaptation significantly improves image reconstruction quality when there are significant domain shifts between training and testing distributions. Interestingly, even for the in-distribution case, test-time adaptation also significantly improves reconstruction quality.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "测试时间适应改进了基于补丁的扩散模型的逆问题求解",
        "abstract_cn": "扩散模型由于能够学习强大的图像先验，在解决逆问题方面取得了巨大的成功，但现有方法需要大量的图像训练数据集，这些图像应来自与测试数据集相同的分布。在实践中，可用训练数据集的大小范围可以从不存在到非常大。在某些情况下，由于先验知识学习不佳，利用有限数据进行的传统扩散模型训练可能会导致重建结果不佳。一种潜在的改进是从具有可能不匹配分布的可用训练数据训练的扩散模型开始，然后在重建时细化网络以解决分布不匹配的问题。在这项工作中，我们研究了这种网络细化过程对根据不同程度的分布外数据训练的扩散模型的影响。具体来说，我们使用自监督损失来使学习的扩散网络适应测试数据，同时帮助网络输出保持与测量的一致性。我们在理论上和实验上都表明，与传统全图像扩散模型的测试时细化相比，基于块的扩散先验的测试时适应可以带来更高质量的重建。大量实验表明，在各种反问题中，当训练和测试分布之间存在显着的域变化时，测试时间自适应可显着提高图像重建质量。有趣的是，即使对于分布内的情况，测试时间适应也显着提高了重建质量。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3587458",
        "title": "Robust Preprocessing of Impulsive Motion Artifacts Using Low-Rank Matrix Recovery for Electrical Impedance Tomography",
        "link": "https://doi.org/10.1109/tci.2025.3587458",
        "published": "2025",
        "author": "Xiao-Peng Li, Zhang-Lei Shi, Meng Dai, Hing Cheung So, Inéz Frerichs, Zhanqi Zhao, Lin Yang",
        "summary": "Electrical impedance tomography (EIT) is a valuable bedside tool in critical care medicine and pneumology. However, artifacts associated with body and electrode movements, especially impulsive motion artifacts, hinder its routine use in clinical scenarios. Most of the existing algorithms for EIT data preprocessing or imaging cannot effectively address this issue. In this paper, we propose a novel method, namely, robust preprocessing for EIT (RP4EIT), to preprocess EIT boundary voltages using the concept of low-rank matrix recovery. It aims to resist impulsive motion artifacts and further to enhance the imaging quality. To attain good performance on both the normal measurements and contaminated data, we design a two-stage denoising algorithm using robust statistical analysis and low-rank recovery. Specifically, EIT boundary voltages are first formulated as a matrix, where the rows and columns correspond to the channels and frames, respectively. Then, the entries corrupted by impulsive noise of the matrix are identified and considered as missing elements. Subsequently, RP4EIT exploits the low-rank property to restore the missing components. In doing so, the impulsive motion artifacts are eliminated from EIT measurements. Furthermore, the convergence guarantee of RP4EIT is established. Experimental results on phantom and patient data demonstrate that RP4EIT is able to remove the impulsive motion artifacts from boundary voltages and the recovered data yield high-quality EIT images.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "使用电阻抗断层扫描的低阶矩阵恢复对脉冲运动伪影进行鲁棒预处理",
        "abstract_cn": "电阻抗断层扫描 (EIT) 是重症监护医学和呼吸病学中有价值的床边工具。然而，与身体和电极运动相关的伪影，特别是脉冲运动伪影，阻碍了其在临床场景中的常规使用。现有的EIT数据预处理或成像算法大多无法有效解决这一问题。在本文中，我们提出了一种新方法，即 EIT 鲁棒预处理（RP4EIT），使用低秩矩阵恢复的概念来预处理 EIT 边界电压。它的目的是抵抗脉冲运动伪影并进一步提高成像质量。为了在正常测量和污染数据上获得良好的性能，我们使用稳健的统计分析和低秩恢复设计了两阶段去噪算法。具体来说，EIT边界电压首先被表示为矩阵，其中行和列分别对应于通道和帧。然后，被矩阵的脉冲噪声破坏的条目被识别并被视为丢失元素。随后，RP4EIT 利用低秩属性来恢复丢失的组件。这样做可以从 EIT 测量中消除脉冲运动伪影。进一步建立了RP4EIT的收敛保证。体模和患者数据的实验结果表明，RP4EIT 能够消除边界电压中的脉冲运动伪影，并且恢复的数据可产生高质量的 EIT 图像。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3587408",
        "title": "DAMMER: Direct Adaptive Multi-Resolution MEsh Reconstruction From X-Ray Measurements",
        "link": "https://doi.org/10.1109/tci.2025.3587408",
        "published": "2025",
        "author": "Jannes Merckx, Arnold J. den Dekker, Jan Sijbers, Jan De Beenhouwer",
        "summary": "X-ray computed tomography (XCT) reconstructs a scanned object using measured projection data, with the object typically represented on a voxel grid during the reconstruction process. However, since material interfaces typically do not align with voxel boundaries, a voxel representation inherently suffers from partial volume effects. This paper presents DAMMER: a method that reconstructs a multi-resolution triangle mesh to represent the attenuation values of a piecewise homogeneous object, often encountered in industrial CT, based on X-ray projection data of this object. DAMMER progressively reconstructs this mesh to match the object. For this, different homogeneous segments are created based on an agglomerative hierarchical clustering procedure, which targets a compact object description by optimizing a weighted sum of projection difference and number of edges between different segments. These segments are progressively optimized to match the homogeneous materials in the object. Simulation and real data experiments show that DAMMER generates significantly more accurate reconstructions compared to pixel grid reconstruction methods, outperforming conventional voxel-based methods in capturing the true geometry of complex material boundaries.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "DAMMER：根据 X 射线测量直接自适应多分辨率网格重建",
        "abstract_cn": "X 射线计算机断层扫描 (XCT) 使用测量的投影数据重建扫描对象，在重建过程中该对象通常表示在体素网格上。然而，由于材料界面通常不与体素边界对齐，体素表示本质上会受到部分体积效应的影响。本文提出了 DAMMER：一种基于分段均匀物体的 X 射线投影数据重建多分辨率三角形网格来表示工业 CT 中经常遇到的衰减值的方法。 DAMMER 逐渐重建该网格以匹配对象。为此，基于凝聚层次聚类过程创建不同的同质片段，该过程通过优化不同片段之间的投影差和边缘数量的加权和来实现紧凑的对象描述。这些部分逐渐优化以匹配物体中的均质材料。仿真和真实数据实验表明，与像素网格重建方法相比，DAMMER 生成的重建明显更加准确，在捕获复杂材料边界的真实几何形状方面优于传统的基于体素的方法。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3587603",
        "title": "Hybrid Spatial and Frequency Network for Light Field Image Restoration",
        "link": "https://doi.org/10.1109/tci.2025.3587603",
        "published": "2025",
        "author": "Vinh Van Duong, Thuc Nguyen Huu, Jonghoon Yim, Byeungwoo Jeon",
        "summary": "This paper proposes a novel hybrid light field (LF) restoration method based on a deep convolutional neural network (CNN) designed to capture the characteristics of LF images in both pixel and frequency domains. Restoring high-quality LF images from degraded versions is a complex task due to the high dimensionality of LF data. To address this, we leverage the geometric priors of LF images to design efficient restoration network components capable of effectively handling the 4D LF structure across both pixel and frequency domains. In the frequency restoration stage, where image artifacts often exhibit distinct frequency characteristics, we propose a 4D-DCT separated transform using 2D-DCT in spatial and angular pixel correlations. By decomposing transformed LF data into various frequency components, our frequency restoration network progressively recovers detailed information from each subband frequency component, enhancing performance in complex scenes and noisy images. For pixel restoration, we introduce the geometry-aware attention (GAM) mechanisms into spatial, angular, and epipolar dimensions of the 4D LF structure, helping to capture better global information in each LF embedding feature. Extensive experiments across diverse LF restoration tasks, including LF denoising, LF spatial super-resolution, and LF low-light enhancement, validate the effectiveness of our method compared to state-of-the-art approaches in both objective and subjective quality assessments.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "用于光场图像恢复的混合空间和频率网络",
        "abstract_cn": "本文提出了一种基于深度卷积神经网络（CNN）的新型混合光场（LF）恢复方法，旨在捕获 LF 图像在像素域和频域的特征。由于 LF 数据的高维性，从降级版本恢复高质量 LF 图像是一项复杂的任务。为了解决这个问题，我们利用 LF 图像的几何先验来设计高效的恢复网络组件，能够有效处理跨像素和频域的 4D LF 结构。在频率恢复阶段，图像伪影通常表现出明显的频率特征，我们提出了在空间和角度像素相关性中使用 2D-DCT 的 4D-DCT 分离变换。通过将变换后的低频数据分解为各种频率分量，我们的频率恢复网络逐步从每个子带频率分量中恢复详细信息，从而增强复杂场景和噪声图像中的性能。对于像素恢复，我们将几何感知注意（GAM）机制引入到 4D LF 结构的空间、角度和对极维度中，有助于在每个 LF 嵌入特征中捕获更好的全局信息。跨各种 LF 恢复任务（包括 LF 去噪、LF 空间超分辨率和 LF 低光增强）的广泛实验验证了我们的方法与客观和主观质量评估中最先进的方法相比的有效性。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3587469",
        "title": "Laser Protection via Jointly Learned Defocus and Image Reconstruction",
        "link": "https://doi.org/10.1109/tci.2025.3587469",
        "published": "2025",
        "author": "Johannes Meyer, Michael Henrichsen, Christian Eisele, Bastian Schwarz, Jürgen Limbach, Gunnar Ritt, Stefanie Dengler, Lukas Dippon, Christian Kludt",
        "summary": "We propose a method to harden sensors against laser radiation by defocusing the employed optics on purpose, and to reconstruct the sought focused images of the scene via image reconstruction. The introduced defocus widens the laser spot incident on the sensor and greatly reduces its damage potential. We employ a coded aperture and optimize its pattern jointly with the free parameters of the image reconstruction pipeline. For the image reconstruction, we combine a state-of-the-art alternating direction method of multipliers (ADMM)-based physically informed deconvolution stage with a U-Net-like neural network to remove remaining reconstruction artifacts. To evaluate the performance of our proposed approach, we conducted reconstruction experiments on simulated data, including ablation experiments and on real data and performed sensor destruction tests with and without sensor protection. Destructive experiments with increasing laser power suggest that our approach has the potential to increase the tolerable radiation threshold by about three orders of magnitudes.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "通过联合学习散焦和图像重建实现激光保护",
        "abstract_cn": "我们提出了一种方法，通过故意散焦所使用的光学器件来强化传感器以抵抗激光辐射，并通过图像重建来重建场景的所寻求的聚焦图像。引入的散焦扩大了入射到传感器上的激光光斑，并大大降低了其损坏的可能性。我们采用编码孔径并与图像重建管道的自由参数联合优化其图案。对于图像重建，我们将最先进的基于乘法器交替方向方法 (ADMM) 的物理通知反卷积阶段与类似 U-Net 的神经网络相结合，以消除剩余的重建伪影。为了评估我们提出的方法的性能，我们对模拟数据进行了重建实验，包括烧蚀实验和真实数据，并在有和没有传感器保护的情况下进行了传感器破坏测试。增加激光功率的破坏性实验表明，我们的方法有可能将可容忍辐射阈值提高约三个数量级。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3588025",
        "title": "Pattern Research on Sparse Camera Array for Super-Resolution Imaging",
        "link": "https://doi.org/10.1109/tci.2025.3588025",
        "published": "2025",
        "author": "Tianren Li, Yu Zhang, Tengda Huang, Naishu Jia, Fulin Liu, Yufu Qu, Zhenzhong Wei",
        "summary": "This study addresses the quantitative pattern design of sparse camera arrays in multi-frame super-resolution (SR) imaging systems. We propose the Weighted Ratio of Repeated Spectra (WRRS) metric to predict the super-resolution performance of sparse camera arrays. The WRRS consists of the weight determined by the energy distribution of the imaging scene, and the ratio of repeated spectra intensity determined by array patterns. Our method achieves the optimization of sparse camera array pattern under certain scene without building an actual imaging system. The real image experiment shows that the WRRS is correlated with the median of the SR image quality distribution. Subsequently, a six-camera sparse camera array is designed for aircraft scene with varying object distance. Compared with current qualitatively and quantitatively designed patterns, the proposed sparse camera array pattern that specifically designed for aircraft achieves better average PSNR in the aircraft scene.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "超分辨率成像稀疏相机阵列模式研究",
        "abstract_cn": "本研究解决了多帧超分辨率（SR）成像系统中稀疏相机阵列的定量模式设计。我们提出重复光谱加权比（WRRS）指标来预测稀疏相机阵列的超分辨率性能。 WRRS由成像场景的能量分布确定的权重和阵列图案确定的重复光谱强度的比率组成。我们的方法实现了特定场景下稀疏相机阵列模式的优化，而无需构建实际的成像系统。真实图像实验表明，WRRS与SR图像质量分布的中值相关。随后，针对不同物距的飞机场景设计了六相机稀疏相机阵列。与当前定性和定量设计的图案相比，所提出的专为飞机设计的稀疏相机阵列图案在飞机场景中实现了更好的平均PSNR。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3587449",
        "title": "Compressive Radio-Interferometric Sensing With Random Beamforming as Rank-One Signal Covariance Projections",
        "link": "https://doi.org/10.1109/tci.2025.3587449",
        "published": "2025",
        "author": "Olivier Leblanc, Yves Wiaux, Laurent Jacques",
        "summary": "Radio-interferometry (RI) observes the sky at unprecedented angular resolutions, enabling the study of several far-away galactic objects such as galaxies and black holes. In RI, an array of antennas probes cosmic signals coming from the observed region of the sky. The covariance matrix of the vector gathering all these antenna measurements offers, by leveraging the Van Cittert-Zernike theorem, an incomplete and noisy Fourier sensing of the image of interest. The number of noisy Fourier measurements—or <italic>visibilities</italic>—scales as <inline-formula><tex-math notation=\"LaTeX\">$\\mathcal O(Q^{2}B)$</tex-math></inline-formula> for <inline-formula><tex-math notation=\"LaTeX\">$Q$</tex-math></inline-formula> antennas and <inline-formula><tex-math notation=\"LaTeX\">$B$</tex-math></inline-formula> short-time integration (STI) intervals. We address the challenges posed by this vast volume of data, which is anticipated to increase significantly with the advent of large antenna arrays, by proposing a compressive sensing technique applied directly at the level of the antenna measurements. First, this paper shows that <italic>beamforming</italic>—a common technique of dephasing antenna signals—usually used to focus some region of the sky, is equivalent to sensing a rank-one projection (ROP) of the signal covariance matrix. We build upon our recent work (Leblanc et al., 2024) to propose a compressive sensing scheme relying on random beamforming, trading the <inline-formula><tex-math notation=\"LaTeX\">$Q^{2}$</tex-math></inline-formula>-dependence of the data size for a smaller number <inline-formula><tex-math notation=\"LaTeX\">$P$</tex-math></inline-formula> of ROPs. We provide image recovery guarantees for sparse image reconstruction. Secondly, the data size is made independent of <inline-formula><tex-math notation=\"LaTeX\">$B$</tex-math></inline-formula> by applying <inline-formula><tex-math notation=\"LaTeX\">$M$</tex-math></inline-formula> random modulations of the ROP vectors obtained for the STI. The resulting sample complexities, theoretically derived in a simpler case without modulations and numerically obtained in phase transition diagrams, are shown to scale as <inline-formula><tex-math notation=\"LaTeX\">$\\mathcal O(K)$</tex-math></inline-formula> where <inline-formula><tex-math notation=\"LaTeX\">$K$</tex-math></inline-formula> is the image sparsity. This illustrates the potential of the approach.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "使用随机波束形成作为一阶信号协方差投影的压缩无线电干涉传感",
        "abstract_cn": "射电干涉测量 (RI) 以前所未有的角分辨率观察天空，从而能够研究几个遥远的星系天体，例如星系和黑洞。在 RI 中，天线阵列探测来自天空观测区域的宇宙信号。通过利用 Van Cittert-Zernike 定理，收集所有这些天线测量结果的向量的协方差矩阵提供了感兴趣图像的不完整且有噪声的傅立叶传感。对于 <inline-formula><tex-math notation=\"LaTeX\">$Q$</tex-math></inline-formula> 天线，噪声傅里叶测量的数量（或<italic>可见度</italic>）缩放为 <inline-formula><tex-math notation=\"LaTeX\">$\\mathcal O(Q^{2}B)$</tex-math></inline-formula> <inline-formula><tex-math notation=\"LaTeX\">$B$</tex-math></inline-formula> 短时积分 (STI) 间隔。我们通过提出直接应用于天线测量级别的压缩传感技术来解决海量数据带来的挑战，预计随着大型天线阵列的出现，数据量将显着增加。首先，本文表明，波束成形（一种常见的天线信号相移技术）通常用于聚焦天空的某些区域，相当于感测信号协方差矩阵的一阶投影 (ROP)。我们在最近的工作（Leblanc et al., 2024）的基础上，提出了一种依赖于随机波束成形的压缩传感方案，将 <inline-formula><tex-math notation=\"LaTeX\">$Q^{2}$</tex-math></inline-formula> 与数据大小的相关性交换为较小的数字 <inline-formula><tex-math ROP 的 notation=\"LaTeX\">$P$</tex-math></inline-formula>。我们为稀疏图像重建提供图像恢复保证。其次，通过对为 STI 获得的 ROP 向量应用 <inline-formula><tex-math notation=\"LaTeX\">$M$</tex-math></inline-formula> 随机调制，使数据大小独立于 <inline-formula><tex-math notation=\"LaTeX\">$B$</tex-math></inline-formula>。由此产生的样本复杂度，理论上是在没有调制的更简单情况下导出的，并在相变图中以数值方式获得的，显示为 <inline-formula><tex-math notation=\"LaTeX\">$\\mathcal O(K)$</tex-math></inline-formula> ，其中 <inline-formula><tex-math notation=\"LaTeX\">$K$</tex-math></inline-formula> 是图像稀疏度。这说明了该方法的潜力。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3592319",
        "title": "MAFDE-Net: Multipath Attention-Fusion-Based Dual-Encoder Network for Undersampled MRI Segmentation",
        "link": "https://doi.org/10.1109/tci.2025.3592319",
        "published": "2025",
        "author": "Zhenyu Huang, Jizhong Duan, Yunshuang Xie, Yu Liu",
        "summary": "Magnetic Resonance Imaging (MRI) plays a crucial role in medical diagnosis, but previous studies have mainly relied on fully-sampled magnitude images for segmentation. However, prolonged k-space acquisition may cause discomfort and motion artifacts in patients, and undersampling techniques are commonly used to address these issues. Conventional methods often adopt a strategy of first reconstructing and then segmenting, but this approach neglects the influence of reconstruction on the downstream segmentation task. In view of this, integrating undersampled MRI reconstruction with segmentation and improving undersampled segmentation performance via joint training has emerged as a promising strategy. Therefore, we propose a novel network, MAFDE-Net, that integrates reconstruction and segmentation into a unified framework. The network enhances undersampled MRI segmentation performance through a joint learning mechanism. The proposed framework integrates the R2N branch containing four Res2Net modules, the CNN-Transformer (CT) branch, and the Multipath Attention-Fusion (MAF) module synergistically combining features from both branches. In addition, we include an Inverted Residual (IR) module in the decoder stage to effectively integrate features extracted during the encoding stage. The Dynamic Upsampling (DU) module is introduced to enhance the final upsampling quality. Simulation experiments show that the undersampled segmentation performance of MAFDE-Net on three datasets significantly outperforms the joint model (RecSeg) and seven baseline models (considering reconstruction and segmentation as serial tasks). Additionally, the joint learning mechanism adopted by MAFDE-Net is not limited to undersampling scenarios; it also outperforms single-task models in fully-sampled MRI segmentation tasks, expanding its application scenarios and potential impact.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "MAFDE-Net：基于多路径注意力融合的双编码器网络，用于欠采样 MRI 分割",
        "abstract_cn": "磁共振成像（MRI）在医学诊断中发挥着至关重要的作用，但之前的研究主要依靠全采样震级图像进行分割。然而，长时间的 k 空间采集可能会导致患者不适和运动伪影，欠采样技术通常用于解决这些问题。传统方法往往采用先重建再分割的策略，但这种方法忽略了重建对下游分割任务的影响。鉴于此，将欠采样 MRI 重建与分割相结合，并通过联合训练提高欠采样分割性能已成为一种有前景的策略。因此，我们提出了一种新颖的网络 MAFDE-Net，它将重建和分割集成到一个统一的框架中。该网络通过联合学习机制增强欠采样 MRI 分割性能。所提出的框架集成了包含四个 Res2Net 模块的 R2N 分支、CNN-Transformer (CT) 分支和多路径注意力融合 (MAF) 模块，协同组合两个分支的特征。此外，我们在解码器阶段包含一个反向残差（IR）模块，以有效地集成在编码阶段提取的特征。引入动态上采样（DU）模块来提高最终上采样质量。仿真实验表明，MAFDE-Net 在三个数据集上的欠采样分割性能显着优于联合模型（RecSeg）和七个基线模型（将重建和分割视为串行任务）。此外，MAFDE-Net采用的联合学习机制不仅限于欠采样场景；它在全采样 MRI 分割任务中也优于单任务模型，扩展了其应用场景和潜在影响。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3592335",
        "title": "Learned Discrepancy Reconstruction and Benchmark Dataset for Magnetic Particle Imaging",
        "link": "https://doi.org/10.1109/tci.2025.3592335",
        "published": "2025",
        "author": "Meira Iske, Hannes Albers, Tobias Knopp, Tobias Kluth",
        "summary": "Magnetic Particle Imaging (MPI) is an emerging imaging modality based on the magnetic response of superparamagnetic iron oxide nanoparticles to achieve high-resolution and real-time imaging without harmful radiation. One key challenge in the MPI image reconstruction task arises from its underlying noise model, which does not fulfill the implicit Gaussian assumptions that are made when applying traditional reconstruction approaches. To address this challenge, we introduce the Learned Discrepancy Approach, a novel learning-based reconstruction method for inverse problems that includes a learned discrepancy function. It enhances traditional techniques by incorporating an invertible neural network to explicitly model problem-specific noise distributions. This approach does not rely on implicit Gaussian noise assumptions, making it especially suited to handle the sophisticated noise model in MPI and also applicable to other inverse problems. To further advance MPI reconstruction techniques, we introduce the MPI-MNIST dataset — a large collection of simulated MPI measurements derived from the MNIST dataset of handwritten digits. The dataset includes noise-perturbed measurements generated from state-of-the-art model-based system matrices and measurements of a preclinical MPI scanner device. This provides a realistic and flexible environment for algorithm testing. Validated against the MPI-MNIST dataset, our method demonstrates significant improvements in reconstruction quality in terms of structural similarity, achieving up to 7.9% higher SSIM as well as 2.2 dB higher PSNR compared to classical reconstruction techniques across varying noise levels, underscoring its robustness in high-noise scenarios.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "磁粒子成像的学习差异重建和基准数据集",
        "abstract_cn": "磁粒子成像（MPI）是一种新兴的成像方式，基于超顺磁性氧化铁纳米颗粒的磁响应，可实现高分辨率和实时成像，而无需有害辐射。 MPI 图像重建任务的一个关键挑战来自于其底层噪声模型，该模型不满足应用传统重建方法时所做的隐式高斯假设。为了应对这一挑战，我们引入了学习差异方法，这是一种新颖的基于学习的逆问题重建方法，其中包括学习差异函数。它通过结合可逆神经网络来显式建模特定问题的噪声分布，从而增强了传统技术。该方法不依赖于隐式高斯噪声假设，使其特别适合处理 MPI 中的复杂噪声模型，也适用于其他反问题。为了进一步推进 MPI 重建技术，我们引入了 MPI-MNIST 数据集——源自手写数字 MNIST 数据集的大量模拟 MPI 测量值集合。该数据集包括从最先进的基于模型的系统矩阵生成的受噪声扰动的测量结果以及临床前 MPI 扫描仪设备的测量结果。这为算法测试提供了现实且灵活的环境。通过 MPI-MNIST 数据集的验证，我们的方法在结构相似性方面展示了重建质量的显着改进，与不同噪声水平的经典重建技术相比，SSIM 提高了 7.9%，PSNR 提高了 2.2 dB，强调了其在高噪声场景中的鲁棒性。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3594013",
        "title": "Single-Frame MIMO Radar Velocity Vector Estimation via Multi-Bounce Scattering",
        "link": "https://doi.org/10.1109/tci.2025.3594013",
        "published": "2025",
        "author": "Nishant Mehrotra, Divyanshu Pandey, Upamanyu Madhow, Yasamin Mostofi, Ashutosh Sabharwal",
        "summary": "Radars are widely adopted for autonomous navigation and vehicular networking due to their robustness to weather conditions as compared to visible light cameras and lidars. However, radars currently struggle with differentiating static vs tangentially moving objects within a single radar frame since both yield the same Doppler along line-of-sight paths to the radar. Prior solutions deploy multiple radar or visible light camera modules to form a multi-“look” synthetic aperture for estimating the single-frame velocity vectors, to estimate tangential and radial velocity components of moving objects leading to higher system costs. In this paper, we propose to exploit multi-bounce scattering from secondary static objects in the environment, e.g., building pillars, walls, etc., to form an effective multi-“look” synthetic aperture for single-frame velocity vector estimation with a single multiple-input, multiple-output (MIMO) radar, thus reducing the overall system cost and removing the need for multi-module synchronization. We present a comprehensive theoretical and experiment evaluation of our scheme, demonstrating a $4.5 \\times$ reduction in the error for estimating moving objects’ velocity vectors over comparable single-radar baselines.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "通过多次弹跳散射进行单帧 MIMO 雷达速度矢量估计",
        "abstract_cn": "与可见光摄像机和激光雷达相比，雷达因其对天气条件的鲁棒性而被广泛应用于自主导航和车辆网络。然而，雷达目前很难区分单个雷达框架内的静态物体和切向移动物体，因为两者沿着到达雷达的视线路径产生相同的多普勒。现有的解决方案部署多个雷达或可见光相机模块来形成多“视”合成孔径来估计单帧速度矢量，以估计移动物体的切向和径向速度分量，从而导致更高的系统成本。在本文中，我们建议利用环境中二次静态物体（例如建筑物柱子、墙壁等）的多次反射散射，形成有效的多“外观”合成孔径，用于单个多输入多输出（MIMO）雷达的单帧速度矢量估计，从而降低总体系统成本并消除多模块同步的需要。我们对我们的方案进行了全面的理论和实验评估，证明与可比较的单雷达基线相比，估计移动物体速度矢量的误差减少了 4.5 倍。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3593881",
        "title": "A Novel Bound for Fourier Ring Correlation in Resolution Analysis",
        "link": "https://doi.org/10.1109/tci.2025.3593881",
        "published": "2025",
        "author": "Eduardo X. Miqueles, Yuri R. Tonin, Russell D. Luke",
        "summary": "This work proposes a novel data-driven approach for computing the resolution number of a given image using the well-established Fourier Ring/Shell Correlation (<sc>frc</sc>/<sc>fsc</sc>) technique. The proposed method eliminates the need for the user to select a threshold criterion in a heuristic way, a requirement in current methodologies. To achieve this, the approach leverages linear algebra—specifically, Niculescu’s result—and concepts from information theory, demonstrating that the resolution number is directly linked to the Fisher information derived from each ring or shell in the Fourier domain. As a result, the methodology is entirely data-driven, requiring no prior information about the image under analysis. The mathematical framework’s consistency is validated through numerical experiments and tests with real data from x-ray coherent microscopy, tomography, cryo-EM and confocal microscopy, showing that the newly computed resolution numbers align with conventional metrics derived from the classical <inline-formula><tex-math notation=\"LaTeX\">$1/2$</tex-math></inline-formula>-bit and <inline-formula><tex-math notation=\"LaTeX\">$3\\sigma$</tex-math></inline-formula> thresholds. Furthermore, we highlight that the local resolution of images can vary significantly from the single resolution value typically provided by <sc>frc</sc>/<sc>fsc</sc>. This observation suggests that resolution maps may provide a more reliable framework for assessing resolution in microscopy.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "分辨率分析中傅里叶环相关性的新界限",
        "abstract_cn": "这项工作提出了一种新颖的数据驱动方法，使用成熟的傅里叶环/壳相关（<sc>frc</sc>/<sc>fsc</sc>）技术来计算给定图像的分辨率数。所提出的方法消除了用户以启发式方式选择阈值标准的需要，这是当前方法中的要求。为了实现这一目标，该方法利用了线性代数（特别是尼古列斯库的结果）和信息论中的概念，证明分辨率数与从傅里叶域中的每个环或壳导出的费舍尔信息直接相关。因此，该方法完全是数据驱动的，不需要有关所分析图像的先验信息。通过数值实验和 X 射线相干显微镜、断层扫描、冷冻电镜和共焦显微镜的真实数据测试，数学框架的一致性得到了验证，表明新计算的分辨率数字与源自经典 <inline-formula><tex-math notation=\"LaTeX\">$1/2$</tex-math></inline-formula>-bit 和 <inline-formula><tex-math 的传统指标一致notation=\"LaTeX\">$3\\sigma$</tex-math></inline-formula> 阈值。此外，我们强调图像的局部分辨率可能与通常由 <sc>frc</sc>/<sc>fsc</sc> 提供的单个分辨率值有很大差异。这一观察结果表明，分辨率图可能为评估显微镜分辨率提供更可靠的框架。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3594988",
        "title": "Gaussian Is All You Need: A Unified Framework for Solving Inverse Problems via Diffusion Posterior Sampling",
        "link": "https://doi.org/10.1109/tci.2025.3594988",
        "published": "2025",
        "author": "Nebiyou Yismaw, Ulugbek S. Kamilov, M. Salman Asif",
        "summary": "Diffusion models can generate a variety of high-quality images by modeling complex data distributions. Trained diffusion models can also be very effective image priors for solving inverse problems. Most of the existing diffusion-based methods integrate data consistency steps by approximating the likelihood function within the diffusion reverse sampling process. In this paper, we show that the existing approximations are either insufficient or computationally inefficient. To address these issues, we propose a unified likelihood approximation method that incorporates a covariance correction term to enhance the performance and avoid propagating gradients through the diffusion model. The correction term, when integrated into the reverse diffusion sampling process, achieves better convergence towards the true data posterior for selected distributions and improves performance on real-world natural image datasets. Furthermore, we present an efficient way to factorize and invert the covariance matrix of the likelihood function for several inverse problems. Our comprehensive experiments demonstrate the effectiveness of our method over several existing approaches.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "高斯就是您所需要的：通过扩散后验采样解决反问题的统一框架",
        "abstract_cn": "扩散模型可以通过对复杂的数据分布进行建模来生成各种高质量的图像。经过训练的扩散模型也可以是解决逆问题的非常有效的图像先验。大多数现有的基于扩散的方法通过近似扩散反向采样过程中的似然函数来集成数据一致性步骤。在本文中，我们表明现有的近似方法要么不够充分，要么计算效率低下。为了解决这些问题，我们提出了一种统一的似然近似方法，该方法结合了协方差校正项来增强性能并避免通过扩散模型传播梯度。当校正项集成到反向扩散采样过程中时，可以更好地收敛到所选分布的真实数据后验，并提高现实世界自然图像数据集的性能。此外，我们提出了一种有效的方法来分解和反转几个反问题的似然函数的协方差矩阵。我们的综合实验证明了我们的方法相对于几种现有方法的有效性。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3594983",
        "title": "LoFi: Neural Local Fields for Scalable Image Reconstruction",
        "link": "https://doi.org/10.1109/tci.2025.3594983",
        "published": "2025",
        "author": "AmirEhsan Khorashadizadeh, Tobïas I. Liaudat, Tianlin Liu, Jason D. McEwen, Ivan Dokmanić",
        "summary": "We introduce LoFi (Local Field)—a coordinate-based framework for image reconstruction which combines advantages of convolutional neural networks (CNNs) and neural fields or implicit neural representations (INRs). Unlike conventional deep neural networks, LoFi reconstructs an image one coordinate at a time, by processing only adaptive local information from the input which is relevant for the target coordinate. Similar to INRs, LoFi can efficiently recover images at any continuous coordinate, enabling image reconstruction at multiple resolutions. LoFi achieves excellent generalization to out-of-distribution data with memory usage almost independent of image resolution, while performing as well or better than standard deep learning models like CNNs and vision transformers (ViTs). Remarkably, training on $1024 \\times 1024$ images requires less than 200MB of memory—much less than standard CNNs and ViTs. Our experiments show that Locality enables training on extremely small datasets with ten or fewer samples without overfitting and without explicit regularization or early stopping.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "LoFi：用于可扩展图像重建的神经局部场",
        "abstract_cn": "我们介绍 LoFi（局部场）——一种基于坐标的图像重建框架，它结合了卷积神经网络（CNN）和神经场或隐式神经表示（INR）的优点。与传统的深度神经网络不同，LoFi 通过仅处理来自与目标坐标相关的输入的自适应局部信息，每次重建一个坐标的图像。与INR类似，LoFi可以有效地恢复任意连续坐标下的图像，从而实现多种分辨率下的图像重建。 LoFi 对分布外数据实现了出色的泛化，内存使用几乎与图像分辨率无关，同时其性能与 CNN 和视觉变换器 (ViT) 等标准深度学习模型一样好甚至更好。值得注意的是，训练 1024 美元× 1024 美元的图像需要不到 200MB 的内存，比标准 CNN 和 ViT 少得多。我们的实验表明，Locality 能够在具有十个或更少样本的极小数据集上进行训练，而不会过度拟合，也无需显式正则化或提前停止。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3594073",
        "title": "HDN: Hybrid Deep-Learning and Non-Line-of-Sight Reconstruction Framework for Transcranial Photoacoustic Imaging of Human Brain",
        "link": "https://doi.org/10.1109/tci.2025.3594073",
        "published": "2025",
        "author": "Pengcheng Wan, Fan Zhang, Yuting Shen, Hulin Zhao, Xiran Cai, Xiaohua Feng, Fei Gao",
        "summary": "Photoacoustic imaging combines the high contrast of optical imaging with the deep penetration depth of ultrasonic imaging, showing great potential in cerebrovascular disease detection. However, the ultrasonic wave suffers strong attenuation and multi-scattering when it passes through the skull tissue, resulting in the distortion of the collected photoacoustic signal. In this paper, inspired by the principles of deep learning and non-line-of-sight imaging, we propose an image reconstruction framework named HDN (Hybrid Deep-learning and Non-line-of-sight), which consists of the signal extraction part and difference utilization part. The signal extraction part is used to correct the distorted signal and reconstruct an initial image. The difference utilization part is used to make further use of the signal difference between the distorted signal and corrected signal, reconstructing the residual image between the initial image and the target image. The test results on a photoacoustic digital brain simulation dataset show that compared with the traditional method (delay-and-sum) and deep-learning-based method (UNet), the HDN achieved superior performance in both signal correction and image reconstruction. Specifically for the structural similarity index, the HDN reached 0.661 in imaging results, compared to 0.157 for the delay-and-sum method and 0.305 for the deep-learning-based method.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "HDN：人脑经颅光声成像的混合深度学习和非视距重建框架",
        "abstract_cn": "光声成像结合了光学成像的高对比度和超声成像的深穿透深度，在脑血管疾病检测方面显示出巨大的潜力。然而超声波在穿过颅骨组织时会受到强烈的衰减和多重散射，导致采集到的光声信号失真。在本文中，受深度学习和非视距成像原理的启发，我们提出了一种名为HDN（混合深度学习和非视距成像）的图像重建框架，该框架由信号提取部分和差异利用部分组成。信号提取部分用于校正失真信号并重建初始图像。差异利用部分用于进一步利用失真信号与校正信号之间的信号差异，重建初始图像与目标图像之间的残差图像。在光声数字大脑模拟数据集上的测试结果表明，与传统方法（延迟求和）和基于深度学习的方法（UNet）相比，HDN在信号校正和图像重建方面均取得了优越的性能。具体到结构相似性指数，HDN 的成像结果达到 0.661，而延迟求和方法为 0.157，基于深度学习的方法为 0.305。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3597462",
        "title": "Non-Line-of-Sight mmW SAR Imaging With Equivariant Adaptive Threshold Learning",
        "link": "https://doi.org/10.1109/tci.2025.3597462",
        "published": "2025",
        "author": "Xiang Cai, Shunjun Wei, Mou Wang, Hao Zhang, Kun Chen, Xinyuan Liu, Jun Shi, Guolong Cui",
        "summary": "High-precision 2-D/3-D Synthetic Aperture Radar (SAR) image reconstruction from the indirect scattered echoes of hidden targets represents a core technical challenge in millimeter-wave (mmW) Non-Line-of-Sight (NLOS) environmental perception. Deep learning approaches have demonstrated exceptional performance in SAR imaging. However, existing methods are predominantly designed for Line-of-Sight (LOS) scenarios, where clean LOS simulation signals can be acquired for training purposes, a condition often difficult or impossible to meet in NLOS imaging due to complex multipath environments and noise. To tackle this issue within specific NLOS configurations, particularly those involving strong specular reflections from discrete, isolated hidden objects, we propose an Equivariant Imaging (EI) framework tailored for mmW SAR. The EI framework is a fully self-supervised learning approach that leverages the group invariance present in signal distributions, enabling robust image reconstruction from partial NLOS measurements contaminated with noise and multipath artifacts. In our method, the reconstruction function is based on a deep unfolding network with Total Variation (TV) constraints, mapping the NLOS scattered echoes to the target image. Moreover, we introduce an Adaptive Peak Convolution Network (APConv) into the reconstruction process to dynamically adjust thresholds, replacing traditional fixed-threshold methods. This enhances imaging flexibility and quality under these defined NLOS conditions. Finally, we validate the proposed method using various NLOS echo data collected through an experimental mmW system. Numerical and visual results both demonstrate the effectiveness of our approach for NLOS mmW SAR imaging tasks. The proposed EI framework thus offers a promising approach for advancing NLOS mmW SAR perception capabilities, particularly for environments and target configurations aligning with those investigated and supported by our current experiments.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "具有等变自适应阈值学习的非视距毫米波 SAR 成像",
        "abstract_cn": "根据隐藏目标的间接散射回波进行高精度 2-D/3-D 合成孔径雷达 (SAR) 图像重建是毫米波 (mmW) 非视距 (NLOS) 环境感知的核心技术挑战。深度学习方法在 SAR 成像中表现出了卓越的性能。然而，现有方法主要是针对视距（LOS）场景设计的，可以获取干净的视距模拟信号用于训练目的，但由于复杂的多径环境和噪声，在非视距成像中通常很难或不可能满足这一条件。为了在特定的非视距配置中解决这个问题，特别是那些涉及离散、孤立的隐藏物体的强镜面反射的配置，我们提出了一种专为毫米波 SAR 定制的等变成像 (EI) 框架。 EI 框架是一种完全自我监督的学习方法，它利用信号分布中存在的群体不变性，从而能够根据受噪声和多径伪影污染的部分 NLOS 测量进行稳健的图像重建。在我们的方法中，重建函数基于具有总变分 (TV) 约束的深度展开网络，将 NLOS 散射回波映射到目标图像。此外，我们在重建过程中引入自适应峰值卷积网络（APConv）来动态调整阈值，取代传统的固定阈值方法。这增强了在这些定义的非视距条件下的成像灵活性和质量。最后，我们使用通过实验毫米波系统收集的各种非视距回波数据来验证所提出的方法。数值和视觉结果都证明了我们的方法对于非视距毫米波 SAR 成像任务的有效性。因此，所提出的 EI 框架为提高非视距毫米波 SAR 感知能力提供了一种有前景的方法，特别是对于与我们当前实验所研究和支持的环境和目标配置相一致的环境和目标配置。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3597429",
        "title": "Anomaly Distinguishability in an Asteroid Analogue Using Quasi-Monostatic Experimental Radar Measurements",
        "link": "https://doi.org/10.1109/tci.2025.3597429",
        "published": "2025",
        "author": "Yusuf Oluwatoki Yusuf, Astrid Dufaure, Liisa-Ida Sorsa, Christelle Eyraud, Jean-Michel Geffrin, Alain Hérique, Sampsa Pursiainen",
        "summary": "This study conducts a quantitative distinguishability analysis using quasi-monostatic experimental radar data to find a topographic and backpropagated tomographic reconstruction for an analogue of asteroid Itokawa (25143). In particular, we consider a combination of travel-time and wavefield backpropagation tomography using the time-frequency representation (TFR) and principal component analysis (PCA) approaches as filtering techniques. Furthermore, we hypothesise that the travel time of the main peaks in the signal can be projected as a topographic imaging of the analogue asteroid while also presenting a tomographic reconstruction based on the main peaks in the signal. We compare the performance of several different filtering approaches covering several noise levels and two hypothetical interior structures: homogeneous and detailed. Our results suggest that wavefield information is vital for obtaining an appropriate reconstruction quality regardless of the noise level and that different filters affect the distinguishability under different assumptions of the noise. The results also suggest that the main peaks of the measured signal can be used to topographically distinguish the signatures in the measurements, hence the interior structure of the different analogue asteroids. Similarly, a tomographic reconstruction with the main peaks of the measured signal can be used to distinguish the interior structure of the different analogue asteroids.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "使用准单站实验雷达测量的小行星类似物的异常可区分性",
        "abstract_cn": "本研究使用准单基地实验雷达数据进行定量可区分性分析，以找到类似小行星 Itokawa (25143) 的地形和反向传播断层扫描重建。特别是，我们考虑使用时频表示（TFR）和主成分分析（PCA）方法作为滤波技术，结合走时和波场反向传播断层扫描。此外，我们假设信号中主峰的传播时间可以投影为模拟小行星的地形成像，同时还可以根据信号中的主峰进行断层扫描重建。我们比较了几种不同过滤方法的性能，涵盖多种噪声水平和两种假设的内部结构：均匀和详细。我们的结果表明，无论噪声水平如何，波场信息对于获得适当的重建质量至关重要，并且不同的滤波器会影响不同噪声假设下的可区分性。结果还表明，测量信号的主峰可用于在地形上区分测量中的特征，从而区分不同模拟小行星的内部结构。类似地，可以使用测量信号的主峰进行断层扫描重建来区分不同模拟小行星的内部结构。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3597449",
        "title": "A Helical Reconstruction Network for Multi-Source Static CT",
        "link": "https://doi.org/10.1109/tci.2025.3597449",
        "published": "2025",
        "author": "Chunliang Ma, Kaiwen Tan, Yunxiang Li, Shouhua Luo",
        "summary": "Nanovision static CT is an innovative CT scanning technique that features the arrangement of the X-ray source array and detector array on two parallel planes with a consistent offset. This configuration significantly enhances temporal resolution compared to conventional CT, providing particular advantages for dynamic organ imaging and low-dose imaging applications. However, it also introduces cone angle and sparse angle artifacts during helical scanning. To address this, this paper proposes a novel theoretical analysis framework to systematically analyze the artifact generation mechanism of the traditional FDK algorithm in this scenario. Through numerical solutions and data superposition, we are able to attribute the causes of artifacts for the first time to two types of data incompleteness issues arising from the lack of cone angle data and insufficient sparse angular sampling. Building on these insights, we propose an innovative dual-module collaborative reconstruction network. First, we introduce the Helical Bi-directional xFDK algorithm (HbixFDK), which employs a limited-angle weighted compensation strategy to mitigate data incompleteness in the cone angle region. Next, we develop the attention-based Helical FISTA network (HFISTA-Net), which utilizes the output from HbixFDK as the initial reconstruction to effectively suppress sparse sampling artifacts. Extensive experiments conducted on the TCIA dataset and clinical static CT scans demonstrate that our proposed method significantly reduces both cone angle and sparse angle artifacts in static CT helical scanning. The approach achieves rapid and high-precision helical reconstruction, showcasing superior accuracy and computational efficiency.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "多源静态CT螺旋重建网络",
        "abstract_cn": "Nanovision 静态 CT 是一种创新的 CT 扫描技术，其特点是 X 射线源阵列和探测器阵列以一致的偏移排列在两个平行平面上。与传统 CT 相比，这种配置显着提高了时间分辨率，为动态器官成像和低剂量成像应用提供了独特的优势。然而，它在螺旋扫描期间也会引入锥角和稀疏角伪影。针对这一问题，本文提出了一种新颖的理论分析框架，系统地分析了传统FDK算法在此场景下的伪影生成机制。通过数值求解和数据叠加，我们首次将伪影的原因归因于锥角数据缺失和稀疏角度采样不足引起的两类数据不完整性问题。基于这些见解，我们提出了一种创新的双模块协作重建网络。首先，我们介绍螺旋双向 xFDK 算法（HbixFDK），该算法采用有限角度加权补偿策略来减轻锥角区域的数据不完整性。接下来，我们开发了基于注意力的螺旋 FISTA 网络（HFISTA-Net），它利用 HbixFDK 的输出作为初始重建来有效抑制稀疏采样伪影。对 TCIA 数据集和临床静态 CT 扫描进行的大量实验表明，我们提出的方法显着减少了静态 CT 螺旋扫描中的锥角和稀疏角伪影。该方法实现了快速、高精度的螺旋重建，展示了卓越的精度和计算效率。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3598455",
        "title": "Double-Branched and Multi-Magnetic Directions Feature Fusion Network (DB&amp;MDF2-Net) for the Accurate Reconstruction of Magnetic Particle Imaging",
        "link": "https://doi.org/10.1109/tci.2025.3598455",
        "published": "2025",
        "author": "Jintao Li, Lizhi Zhang, Shuangchen Li, Huanlong Gao, Shuaishuai He, Yizhe Zhao, Xiaowei He, Yuqing Hou, Hongbo Guo",
        "summary": "Objective: Magnetic particle imaging (MPI) is a novel non-destructive medical imaging method that visualizes the spatial distribution of superparamagnetic iron oxide nanoparticles. However, due to the non-uniformity of the selection and drive field, the unsatisfactory of the receive coil and the different components of the magnetization signal (induced electromotive force) detected by the orthogonal coil, processing the voltage signals measured by the receiving coils in different directions without discrimination will affect the reconstruction quality. Methods: This study introduces the Double-Branched and Multi-Magnetic Directions Feature Fusion Network (DB&MDF2-Net) to address these challenges. The dual-branch(DB) strategy processes X and Y-directional magnetic field components independently, reducing information confusion. Each branch has a dual-sampling feature(DSF) layer that captures multi-scale spatial information and preserves spatial structure, enhancing the extraction of particle distribution and edge details. Additionally, a multi-head self-attention transformer(MSA-T) layer efficiently integrates features from different modules, allowing the network to learn complex inter-feature relationships. Results: The effectiveness of the DB strategy, DSF and MSA-T layers in our proposed method were validated through ablation experiments. Simulate and phantom experiments further demonstrate significant improvements in detail capture and anti-noise capability of DB&MDF2-Net without any hardware modifications, enabling more precise restoration of real particle distribution characteristics. Conclusion: These findings suggest that DB&MDF2-Net can significantly improve the imaging accuracy of MPI. Significance: This research is expected to enhance the practicality of MPI in biomedical applications and contribute to the future development of MPI technology.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "用于磁粒子成像精确重建的双分支多磁方向特征融合网络（DB&amp;MDF2-Net）",
        "abstract_cn": "目的：磁粒子成像（MPI）是一种新型的无损医学成像方法，可可视化超顺磁性氧化铁纳米粒子的空间分布。然而，由于选择场和驱动场的不均匀性、接收线圈的不理想以及正交线圈检测到的磁化信号（感应电动势）的不同分量，对不同方向的接收线圈测量到的电压信号不加区分地处理会影响重建质量。方法：本研究引入了双分支多磁方向特征融合网络（DB&MDF2-Net）来应对这些挑战。双分支（DB）策略独立处理X和Y方向磁场分量，减少信息混乱。每个分支都有一个双采样特征（DSF）层，可以捕获多尺度空间信息并保留空间结构，增强粒子分布和边缘细节的提取。此外，多头自注意力变压器（MSA-T）层有效地集成了来自不同模块的特征，使网络能够学习复杂的特征间关系。结果：我们提出的方法中 DB 策略、DSF 和 MSA-T 层的有效性通过消融实验得到了验证。模拟和仿真实验进一步证明了DB&MDF2-Net在无需任何硬件修改的情况下，在细节捕获和抗噪声能力方面的显着提升，能够更精确地恢复真实的颗粒分布特征。结论：这些结果表明DB&MDF2-Net可以显着提高MPI的成像精度。意义：本研究有望增强MPI在生物医学应用中的实用性，为MPI技术的未来发展做出贡献。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3598421",
        "title": "Robust Cardiac Cine MRI Reconstruction With Spatiotemporal Diffusion Model",
        "link": "https://doi.org/10.1109/tci.2025.3598421",
        "published": "2025",
        "author": "Zi Wang, Jiahao Huang, Mingkai Huang, Chengyan Wang, Guang Yang, Xiaobo Qu",
        "summary": "Accelerated dynamic magnetic resonance imaging (MRI) is highly expected in clinical applications. However, its reconstruction remains challenging due to the inherently high dimensionality and spatiotemporal complexity. While diffusion models have demonstrated robust performance in spatial imaging, their application to spatiotemporal data has been underexplored. To address this gap, we propose a novel spatiotemporal diffusion model (STDM) specifically designed for robust dynamic MRI reconstruction. Our approach decomposes the complex 3D diffusion process into manageable sub-problems by focusing on 2D spatiotemporal images, thereby reducing dimensionality and enhancing computational efficiency. Each 2D image is treated independently, allowing for a parallel reverse diffusion process guided by data consistency to ensure measurement alignment. To further improve the image quality, we introduce a dual-directional diffusion framework (dSTDM), which simultaneously performs reverse diffusion along two orthogonal directions, effectively capturing the full 3D data distribution. Comprehensive experiments on cardiac cine MRI datasets demonstrate that our approach achieves state-of-the-art performance in highly accelerated reconstruction. Additionally, it exhibits preliminary robustness across various undersampling scenarios and unseen datasets, including patient data, non-Cartesian radial sampling, and different anatomies.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "利用时空扩散模型进行稳健的心脏电影 MRI 重建",
        "abstract_cn": "加速动态磁共振成像（MRI）在临床应用中备受期待。然而，由于其固有的高维度和时空复杂性，其重建仍然具有挑战性。虽然扩散模型在空间成像中表现出了强大的性能，但其在时空数据中的应用尚未得到充分探索。为了解决这一差距，我们提出了一种新型时空扩散模型（STDM），专门为稳健的动态 MRI 重建而设计。我们的方法通过关注 2D 时空图像，将复杂的 3D 扩散过程分解为可管理的子问题，从而降低维度并提高计算效率。每个 2D 图像均独立处理，允许在数据一致性的指导下进行并行反向扩散过程，以确保测量对齐。为了进一步提高图像质量，我们引入了双向扩散框架（dSTDM），它同时沿两个正交方向执行反向扩散，有效捕获完整的3D数据分布。对心脏电影 MRI 数据集的综合实验表明，我们的方法在高度加速重建中实现了最先进的性能。此外，它在各种欠采样场景和未见过的数据集（包括患者数据、非笛卡尔径向采样和不同的解剖结构）中表现出初步的稳健性。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3599774",
        "title": "Multi-Video Super-Resolution: Spatiotemporal Fusion for Sparse Camera Array",
        "link": "https://doi.org/10.1109/tci.2025.3599774",
        "published": "2025",
        "author": "Xudong Liu, Tianren Li, Yu Zhang, Yufu Qu, Zhenzhong Wei",
        "summary": "A sparse camera array captures multiple images of a scene within the same spatial plane, enabling super-resolution reconstruction. However, existing methods often fail to fully exploit time as an additional dimension for enhanced information acquisition. Even when temporal and spatial observations are collected simultaneously, their individual contributions are often conflated. Analysis of the system’s imaging model reveals that the spatiotemporal camera system, integrating a camera array with video sequences, holds greater potential for degradation recovery. Based on these insights, we propose a novel multi-video super-resolution network for spatiotemporal information fusion. Guided by explicit physical dimensional orientation, the network effectively integrates spatial information and propagates it along the temporal dimension. By utilizing diverse and informative spatiotemporal sampling, our method more readily addresses challenges arising from ill-posed mapping matrices during reconstruction. Experimental results on both synthetic and real-world datasets show that the components of our network, with information fully propagated and spatiotemporally fused, work synergistically to enhance super-resolution performance, providing substantial improvements over state-of-the-art methods. We believe our study can inspire innovations for future super-resolution tasks by optimizing information acquisition and utilization.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "多视频超分辨率：稀疏相机阵列的时空融合",
        "abstract_cn": "稀疏相机阵列捕获同一空间平面内场景的多个图像，从而实现超分辨率重建。然而，现有方法通常无法充分利用时间作为增强信息获取的附加维度。即使同时收集时间和空间观测数据，它们各自的贡献也经常被混为一谈。对系统成像模型的分析表明，时空相机系统将相机阵列与视频序列集成在一起，具有更大的退化恢复潜力。基于这些见解，我们提出了一种用于时空信息融合的新型多视频超分辨率网络。在明确的物理维度定向的指导下，网络有效地整合空间信息并沿时间维度传播。通过利用多样化和信息丰富的时空采样，我们的方法更容易解决重建过程中不适定映射矩阵带来的挑战。合成数据集和真实世界数据集的实验结果表明，我们的网络组件通过信息完全传播和时空融合，协同工作以增强超分辨率性能，与最先进的方法相比提供了实质性改进。我们相信我们的研究可以通过优化信息获取和利用来激发未来超分辨率任务的创新。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3598440",
        "title": "Towards Multi-Source Illumination Color Constancy Through Physics-Based Rendering and Spectral Power Distribution Embedding",
        "link": "https://doi.org/10.1109/tci.2025.3598440",
        "published": "2025",
        "author": "Xinhui Xue, Hai-Miao Hu, Zhuang He, Haowen Zheng",
        "summary": "Color constancy seeks to keep the perceived color of objects consistent under varying illumination conditions. However, existing methods often rely on restrictive prior assumptions or suffer from limited generalization capability, posing significant challenges in complex scenes with multiple light sources. In this paper, we propose a neural network-enhanced, physics-based approach to multi-illuminant color constancy that leverages spectral imaging—highly sensitive to illumination variation. First, we analyze the physical image-formation process under mixed lighting and introduce a master–subordinate illumination model, extending conventional correlated-color-temperature re-illumination techniques. Our neural network framework explicitly models the correlation between narrow-band spectral reflectance and the spectral power distribution (SPD) of the illumination, enabling accurate recovery of the scene light’s full SPD. Using this model, we fuse RGB images with the estimated illumination spectra to predict illuminant chromaticity precisely, then correct image colors to a standard reference light. Extensive experiments on synthetic multi–color-temperature datasets and real-world spectral datasets demonstrate that our neural network-based method achieves state-of-the-art accuracy in spectral estimation and color-constancy correction.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "通过基于物理的渲染和光谱功率分布嵌入实现多源照明颜色恒定性",
        "abstract_cn": "颜色恒常性旨在使物体的感知颜色在不同的照明条件下保持一致。然而，现有的方法通常依赖于限制性的先验假设或泛化能力有限，这在具有多个光源的复杂场景中提出了重大挑战。在本文中，我们提出了一种神经网络增强的、基于物理的方法来实现多光源颜色恒定性，该方法利用对照明变化高度敏感的光谱成像。首先，我们分析了混合照明下的物理图像形成过程，并引入了主从照明模型，扩展了传统的相关色温再照明技术。我们的神经网络框架明确地模拟了窄带光谱反射率与照明的光谱功率分布 (SPD) 之间的相关性，从而能够准确恢复场景光的完整 SPD。使用该模型，我们将 RGB 图像与估计的照明光谱融合，以精确预测光源色度，然后将图像颜色校正为标准参考光。对合成多色温数据集和真实世界光谱数据集的大量实验表明，我们基于神经网络的方法在光谱估计和颜色恒常性校正方面实现了最先进的精度。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3602315",
        "title": "Single-View Fluorescence Molecular Tomography Based on Hyperspectral NIR-II Imaging",
        "link": "https://doi.org/10.1109/tci.2025.3602315",
        "published": "2025",
        "author": "Yunfei Li, Qian Liu, Fuhong Cai",
        "summary": "Biological tissue optics has garnered significant attention in biomedical research for its non-destructive, high-sensitivity nature. However, the scattering and absorption properties of biological tissues fundamentally limit the penetration depth of optical imaging. Fluorescence molecular tomography (FMT) offers a solution balancing imaging depth and resolution, yet tissue scattering and absorption continue to challenge depth-resolved reconstruction accuracy. This study develops a sensitive near-infrared II (NIR-II) hyperspectral imaging system to investigate the relationship between fluorescence penetration depth and tissue absorption/scattering coefficients. By leveraging the strong water absorption peak around 1450 nm, we strategically divide the reconstruction object into layers within the FMT model, significantly improving the ill-posed inverse problem. We then utilize hyperspectral data to select wavelengths with progressively decreasing absorption coefficients relative to the 1450 nm peak. This enables layer-by-layer 3D reconstruction of deep biological tissues, overcoming the limitations of conventional FMT. Our method demonstrates single-perspective FMT reconstruction capable of resolving heterogeneous targets at 10 mm depth with a 0.74 Dice coefficient in depth discrimination. This spectraldimension-enhanced FMT method enables accurate 3D reconstruction from single-view measurements. By exploiting the depth-dependent light-tissue interactions at selected NIR-II wavelengths, our approach achieves imaging quality comparable to multi-angle systems while simplifying the experimental setup. Both simulation and phantom experiments demonstrate precise target localization and shape recovery, suggesting promising potential for small animal imaging applications where system complexity and acquisition speed are critical.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "基于高光谱 NIR-II 成像的单视荧光分子断层扫描",
        "abstract_cn": "生物组织光学因其非破坏性、高灵敏度的性质而在生物医学研究中引起了极大的关注。然而，生物组织的散射和吸收特性从根本上限制了光学成像的穿透深度。荧光分子断层扫描 (FMT) 提供了一种平衡成像深度和分辨率的解决方案，但组织散射和吸收继续挑战深度分辨重建精度。本研究开发了一种灵敏的近红外 II (NIR-II) 高光谱成像系统，以研究荧光穿透深度与组织吸收/散射系数之间的关系。通过利用 1450 nm 附近的强吸水峰，我们在 FMT 模型中策略性地将重建对象划分为多个层，显着改善了不适定逆问题。然后，我们利用高光谱数据来选择相对于 1450 nm 峰值吸收系数逐渐降低的波长。这使得深层生物组织的逐层3D重建成为可能，克服了传统FMT的局限性。我们的方法展示了单视角 FMT 重建能够解析 10 毫米深度的异质目标，深度辨别系数为 0.74 Dice。这种光谱维度增强的 FMT 方法可以通过单视图测量进行精确的 3D 重建。通过利用选定的 NIR-II 波长下的深度相关光组织相互作用，我们的方法实现了与多角度系统相当的成像质量，同时简化了实验设置。模拟和模型实验都证明了精确的目标定位和形状恢复，这表明系统复杂性和采集速度至关重要的小动物成像应用具有广阔的前景。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3603741",
        "title": "Fourier Analysis of Interference Scanning Optical Probe Microscopy",
        "link": "https://doi.org/10.1109/tci.2025.3603741",
        "published": "2025",
        "author": "Emmanuel Soubies, Wolfgang Bacsa",
        "summary": "As opposed to popular far-field and near-field optical microscopy techniques, Interference Scanning Optical probe Microscopy (ISOM) operates in the intermediate-field region, where the probing distance is typically of the order of the wavelength of incident light. Specifically, ISOM enables the imaging of nanostructures through numerical inverse scattering of standing waves generated by the interference between the incident (or reflected) and scattered waves. In this work, we shed new light on this microscopy modality through an in-depth Fourier analysis. Our analysis reveals insights on the required acquisition sampling step as well as on the resolution limit of the system. Moreover, we propose two novel methods to address the associated inverse scattering problem, leveraging the intrinsic structure of the image formation model to reduce computational complexity and sensitivity to errors in model parameters. Finally, we illustrate our theoretical findings with numerical experiments.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "干涉扫描光学探针显微镜的傅里叶分析",
        "abstract_cn": "与流行的远场和近场光学显微镜技术相反，干涉扫描光学探针显微镜 (ISOM) 在中场区域工作，其中探测距离通常为入射光波长的数量级。具体来说，ISOM 通过驻波的数值逆散射来成像纳米结构，该驻波是由入射波（或反射波）和散射波之间的干涉产生的。在这项工作中，我们通过深入的傅里叶分析对这种显微镜模式有了新的认识。我们的分析揭示了对所需采集采样步骤以及系统分辨率限制的见解。此外，我们提出了两种新颖的方法来解决相关的逆散射问题，利用图像形成模型的内在结构来降低计算复杂性和对模型参数错误的敏感性。最后，我们用数值实验来说明我们的理论发现。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3603689",
        "title": "Closed-Form Approximation of the Total Variation Proximal Operator",
        "link": "https://doi.org/10.1109/tci.2025.3603689",
        "published": "2025",
        "author": "Edward P. Chandler, Shirin Shoushtari, Brendt Wohlberg, Ulugbek S. Kamilov",
        "summary": "Total variation (TV) is a widely used function for regularizing imaging inverse problems that is particularly appropriate for images whose underlying structure is piecewise constant. TV regularized optimization problems are typically solved using proximal methods, but the way in which they are applied is constrained by the absence of a closed-form expression for the proximal operator of the TV function. A closed-form approximation of the TV proximal operator has previously been proposed, but its accuracy was not theoretically explored in detail. We address this gap by making several new theoretical contributions, proving that the approximation leads to a proximal operator of some convex function, it is equivalent to a gradient descent step on a smoothed version of TV, and that its error can be fully characterized and controlled with its scaling parameter. We experimentally validate our theoretical results on image denoising and sparse-view computed tomography (CT) image reconstruction.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "全变分近端算子的闭式逼近",
        "abstract_cn": "全变分 (TV) 是一种广泛使用的函数，用于正则化成像反问题，特别适合基础结构分段常数的图像。 TV 正则化优化问题通常使用近端方法来解决，但它们的应用方式受到 TV 函数近端算子缺乏封闭式表达式的限制。之前已经提出了 TV 近端算子的闭式近似，但其准确性并未在理论上进行详细探讨。我们通过做出几个新的理论贡献来解决这个差距，证明近似导致了一些凸函数的近端算子，它相当于平滑版本的 TV 上的梯度下降步骤，并且它的误差可以通过其缩放参数来完全表征和控制。我们通过实验验证了图像去噪和稀疏视图计算机断层扫描（CT）图像重建的理论结果。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3607150",
        "title": "Multi-Frequency Neural Born Iterative Method for Solving 2-D Inverse Scattering Problems",
        "link": "https://doi.org/10.1109/tci.2025.3607150",
        "published": "2025",
        "author": "Daoqi Liu, Tao Shan, Maokun Li, Fan Yang, Shenheng Xu",
        "summary": "In this work, we propose a deep learning-based imaging method for addressing the multi-frequency electromagnetic (EM) inverse scattering problem (ISP). By combining deep learning technology with EM computation, we have successfully developed a multi-frequency neural Born iterative method (NeuralBIM), guided by the principles of the single-frequency NeuralBIM. This method integrates multitask learning techniques with NeuralBIM’s efficient iterative inversion process to construct a robust multi-frequency Born iterative inversion model. During training, the model employs a multitask learning approach guided by homoscedastic uncertainty to adaptively allocate the weights of each frequency’s data. Additionally, an unsupervised learning method, constrained by the physics of the ISP, is used to train the multi-frequency NeuralBIM model, eliminating the need for contrast and total field data. The effectiveness of the multi-frequency NeuralBIM is validated through synthetic and experimental data, demonstrating improvements in accuracy and computational efficiency for solving the ISP. Moreover, this method exhibits good generalization capabilities and noise resistance.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "解决二维逆散射问题的多频神经出生迭代法",
        "abstract_cn": "在这项工作中，我们提出了一种基于深度学习的成像方法来解决多频电磁（EM）逆散射问题（ISP）。通过将深度学习技术与EM计算相结合，我们在单频NeuralBIM原理的指导下，成功开发了多频神经Born迭代方法（NeuralBIM）。该方法将多任务学习技术与NeuralBIM的高效迭代反演过程相结合，构建鲁棒的多频Born迭代反演模型。在训练过程中，该模型采用由同方差不确定性引导的多任务学习方法来自适应分配每个频率数据的权重。此外，受 ISP 物理约束的无监督学习方法用于训练多频 NeuralBIM 模型，无需对比和总现场数据。多频 NeuralBIM 的有效性通过合成和实验数据得到验证，证明了解决 ISP 的准确性和计算效率的提高。此外，该方法表现出良好的泛化能力和抗噪声能力。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3608970",
        "title": "Masked Autoencoder-Based Knowledge Transfer for Spectral Reconstruction From RGB Images",
        "link": "https://doi.org/10.1109/tci.2025.3608970",
        "published": "2025",
        "author": "Lin Feng, Xinying Wang, Zhixiong Huang, Yining Wang, Jiawen Zhu, Paolo Gamba",
        "summary": "Mainstream spectral reconstruction methods typically meticulously design complex and computationally intensive architectures in convolutional neural networks (CNNs) or Transformers to model the mapping from RGB to hyperspectral image (HSI). However, the bottleneck in achieving accurate spectral reconstruction may not lie in model complexity. Direct end-to-end learning on limited training samples struggles to encapsulate discriminative and generalizable feature representations, leading to overfitting and consequently suboptimal reconstruction fidelity. To address these challenges, we propose a new Masked Autoencoder-based Knowledge Transfer network for Spectral Reconstruction from RGB images (MAE-KTSR). MAE-KTSR decouples the feature representation process into a two-stage paradigm, facilitating a holistic comprehension of diverse objects and scenes, thereby enhancing the generalizability of spectral reconstruction. In the first stage, we introduce Spatial-Spectral Masked Autoencoders (S$^{2}$-MAE) to extract discriminative spectral features through masked modeling under constrained spectral conditions. S$^{2}$-MAE reconstructs spectral images from partially masked inputs, learning a generalizable feature representation that provides useful prior knowledge for RGB-to-HSI reconstruction. In the second stage, a lightweight convolutional reconstruction network is deployed to further extract and aggregate local spectral-spatial features. Specifically, an Inter-Stage Feature Fusion module (ISFF) is introduced to effectively exploit the global MAE-based spectral priors learned in the first stage. Experimental results on three spectral reconstruction benchmarks (NTIRE2020-Clean, CAVE, and Harvard) and one real-world hyperspecral dataset (Pavia University) demonstrate the effectiveness of MAE-KTSR. Additionally, MAE-KTSR is experimentally validated to facilitate downstream real-world applications, such as HSI classification.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "基于掩码自动编码器的知识传输，用于 RGB 图像的光谱重建",
        "abstract_cn": "主流光谱重建方法通常在卷积神经网络 (CNN) 或 Transformer 中精心设计复杂且计算密集型的架构，以对从 RGB 到高光谱图像 (HSI) 的映射进行建模。然而，实现精确谱重建的瓶颈可能并不在于模型复杂性。对有限训练样本的直接端到端学习很难封装有区别的和可概括的特征表示，导致过度拟合，从而导致重建保真度不佳。为了应对这些挑战，我们提出了一种新的基于掩码自动编码器的知识传输网络，用于 RGB 图像的光谱重建（MAE-KTSR）。 MAE-KTSR 将特征表示过程解耦为两阶段范式，促进对不同对象和场景的整体理解，从而增强光谱重建的通用性。在第一阶段，我们引入空间光谱掩模自动编码器（S$^{2}$-MAE），通过在约束光谱条件下的掩模建模来提取判别性光谱特征。 S$^{2}$-MAE 从部分屏蔽的输入中重建光谱图像，学习可概括的特征表示，为 RGB 到 HSI 重建提供有用的先验知识。在第二阶段，部署轻量级卷积重建网络来进一步提取和聚合局部光谱空间特征。具体来说，引入了阶段间特征融合模块（ISFF），以有效利用第一阶段学习到的基于全局 MAE 的谱先验。三个光谱重建基准（NTIRE2020-Clean、CAVE 和Harvard）和一个真实世界高光谱数据集（帕维亚大学）的实验结果证明了 MAE-KTSR 的有效性。此外，MAE-KTSR 经过实验验证，可促进下游实际应用，例如 HSI 分类。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3608969",
        "title": "Robust Frequency Domain Full-Waveform Inversion via HV-Geometry",
        "link": "https://doi.org/10.1109/tci.2025.3608969",
        "published": "2025",
        "author": "Zhijun Zeng, Matej Neumann, Yunan Yang",
        "summary": "Conventional frequency-domain full-waveform inversion (FWI) is typically implemented with an <inline-formula><tex-math notation=\"LaTeX\">$L^{2}$</tex-math></inline-formula> misfit function, which suffers from challenges such as cycle skipping and sensitivity to noise. While the Wasserstein metric has proven effective in addressing these issues in time-domain FWI, its applicability in frequency-domain FWI is limited due to the complex-valued nature of the data and reduced transport-like dependency on wave speed. To mitigate these challenges, we introduce the HV metric (<inline-formula><tex-math notation=\"LaTeX\">$d_{\\text{HV}}$</tex-math></inline-formula>), inspired by optimal transport theory, which compares signals based on horizontal and vertical changes without requiring the normalization of data. We implement <inline-formula><tex-math notation=\"LaTeX\">$d_{\\text{HV}}$</tex-math></inline-formula> as the misfit function in frequency-domain FWI and evaluate its performance on synthetic and real-world datasets from seismic imaging and ultrasound computed tomography (USCT). Numerical experiments demonstrate that <inline-formula><tex-math notation=\"LaTeX\">$d_{\\text{HV}}$</tex-math></inline-formula> outperforms the <inline-formula><tex-math notation=\"LaTeX\">$L^{2}$</tex-math></inline-formula> and Wasserstein metrics in scenarios with limited prior model information and high noise while robustly improving inversion results on clinical USCT data.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "通过 HV 几何进行鲁棒频域全波形反演",
        "abstract_cn": "传统的频域全波形反演（FWI）通常使用 <inline-formula><tex-math notation=\"LaTeX\">$L^{2}$</tex-math></inline-formula> 失配函数来实现，该函数面临周期跳跃和对噪声敏感等挑战。虽然 Wasserstein 度量已被证明可以有效解决时域 FWI 中的这些问题，但由于数据的复值性质以及对波速的类似传输依赖性的降低，其在频域 FWI 中的适用性受到限制。为了缓解这些挑战，我们引入了 HV 指标（<inline-formula><tex-math notation=\"LaTeX\">$d_{\\text{HV}}$</tex-math></inline-formula>），其灵感来自最佳传输理论，它根据水平和垂直变化比较信号，而不需要数据标准化。我们将 <inline-formula><tex-math notation=\"LaTeX\">$d_{\\text{HV}}$</tex-math></inline-formula> 实现为频域 FWI 中的失配函数，并评估其在来自地震成像和超声计算机断层扫描 (USCT) 的合成和真实数据集上的性能。数值实验表明，在先验模型信息有限、噪声较高的场景下，<inline-formula><tex-math notation=\"LaTeX\">$d_{\\text{HV}}$</tex-math></inline-formula> 优于 <inline-formula><tex-math notation=\"LaTeX\">$L^{2}$</tex-math></inline-formula> 和 Wasserstein 度量，同时稳健地改善了反演结果临床 USCT 数据。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3609974",
        "title": "An Efficient Algorithm for Spatial-Spectral Partial Volume Compartment Mapping With Applications to Multicomponent Diffusion and Relaxation MRI",
        "link": "https://doi.org/10.1109/tci.2025.3609974",
        "published": "2025",
        "author": "Yunsong Liu, Debdut Mandal, Congyu Liao, Kawin Setsompop, Justin P. Haldar",
        "summary": "We introduce a new algorithm to solve a regularized spatial-spectral image estimation problem. Our approach is based on the linearized alternating directions method of multipliers (LADMM), which is a variation of the popular ADMM algorithm. Although LADMM has existed for some time, it has not been very widely used in the computational imaging literature. This is in part because there are many possible ways of mapping LADMM to a specific optimization problem, and it is nontrivial to find a computationally efficient implementation out of the many competing alternatives. We believe that our proposed implementation represents the first application of LADMM to the type of optimization problem considered in this work (involving a linear-mixture forward model, spatial regularization, and nonnegativity constraints). We evaluate our algorithm in a variety of multiparametric MRI partial volume mapping scenarios (diffusion-relaxation, relaxation-relaxation, relaxometry, and fingerprinting), where we consistently observe substantial ($\\sim 3 \\,\\times$−50 ×) speed improvements. We expect this to reduce barriers to using spatially-regularized partial volume compartment mapping methods. Further, the considerable improvements we observed also suggest the potential value of considering LADMM for a broader set of computational imaging problems.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "一种有效的空间光谱部分体积室映射算法及其在多分量扩散和弛豫 MRI 中的应用",
        "abstract_cn": "我们引入一种新算法来解决正则化空间光谱图像估计问题。我们的方法基于线性化交替方向乘法器 (LADMM)，它是流行的 ADMM 算法的变体。尽管 LADMM 已经存在了一段时间，但它在计算成像文献中的应用还不是很广泛。部分原因是有许多可能的方法将 LADMM 映射到特定的优化问题，并且从许多竞争的替代方案中找到计算高效的实现并非易事。我们相信，我们提出的实现代表了 LADMM 在本工作中考虑的优化问题类型的首次应用（涉及线性混合前向模型、空间正则化和非负性约束）。我们在各种多参数 MRI 部分容积映射场景（扩散-松弛、松弛-松弛、松弛测量和指纹识别）中评估我们的算法，我们始终观察到显着的 ($\\sim 3 \\,\\times$−50 ×) 速度改进。我们希望这能够减少使用空间规则化部分体积室映射方法的障碍。此外，我们观察到的显着改进也表明考虑 LADMM 对于更广泛的计算成像问题具有潜在价值。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3609957",
        "title": "Ptychography Using Blind Multi-Mode PMACE",
        "link": "https://doi.org/10.1109/tci.2025.3609957",
        "published": "2025",
        "author": "Qiuchen Zhai, Gregery T. Buzzard, Kevin M. Mertes, Brendt Wohlberg, Charles A. Bouman",
        "summary": "Ptychography is an imaging technique that enables nanometer-scale reconstruction of complex transmittance images by scanning objects with overlapping X-ray illumination patterns. However, the illumination function is typically unknown and only partially coherent, which presents challenges for reconstruction. In this paper, we introduce Blind Multi-Mode Projected Multi-Agent Consensus Equilibrium (BM-PMACE) for blind ptychographic reconstruction. BM-PMACE jointly estimates both the complex transmittance image and the multi-modal probe functions associated with a partially coherent probe source. Importantly, BM-PMACE maintains a location-specific probe state that captures spatially varying probe aberrations. Our method also incorporates a dynamic strategy for integrating additional probe modes. Our experiments on synthetic and measured data demonstrate that BM-PMACE outperforms existing approaches in reconstruction quality and convergence rate.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "使用盲多模式 PMACE 进行叠层成像",
        "abstract_cn": "叠层照相术是一种成像技术，通过扫描具有重叠 X 射线照明图案的物体，能够实现复杂透射率图像的纳米级重建。然而，照明函数通常是未知的并且仅部分相干，这给重建带来了挑战。在本文中，我们介绍了用于盲叠图重建的盲多模式投影多智能体共识均衡（BM-PMACE）。 BM-PMACE 联合估计复杂的透射率图像和与部分相干探测源相关的多模态探测函数。重要的是，BM-PMACE 保持特定位置的探针状态，捕获空间变化的探针像差。我们的方法还结合了集成附加探测模式的动态策略。我们对合成和测量数据的实验表明，BM-PMACE 在重建质量和收敛速度方面优于现有方法。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3611590",
        "title": "Generalized Ray Tracing With Basis Functions for Tomographic Projections",
        "link": "https://doi.org/10.1109/tci.2025.3611590",
        "published": "2025",
        "author": "Youssef Haouchat, Sepand Kashani, Philippe Thévenaz, Michael Unser",
        "summary": "This work aims at the precise and efficient computation of the x-ray projection of an image represented by a linear combination of general shifted basis functions that typically overlap. We achieve this with a suitable adaptation of ray tracing, which is one of the most efficient methods to compute line integrals. In our work, the cases in which the image is expressed as a spline are of particular relevance. The proposed implementation is applicable to any projection geometry as it computes the forward and backward operators over a collection of arbitrary lines. We validate our work with experiments in the context of inverse problems for image reconstruction to maximize the image quality for a given resolution of the reconstruction grid.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "具有断层投影基本函数的广义射线追踪",
        "abstract_cn": "这项工作的目的是精确有效地计算由通常重叠的一般移位基函数的线性组合表示的图像的 X 射线投影。我们通过适当调整光线追踪来实现这一目标，这是计算线积分的最有效方法之一。在我们的工作中，图像表示为样条线的情况特别相关。所提出的实现适用于任何投影几何，因为它计算任意线集合上的前向和后向运算符。我们在图像重建逆问题的背景下通过实验验证了我们的工作，以最大限度地提高重建网格给定分辨率的图像质量。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3612849",
        "title": "Distilling Knowledge for Designing Computational Imaging Systems",
        "link": "https://doi.org/10.1109/tci.2025.3612849",
        "published": "2025",
        "author": "Leon Suarez-Rodriguez, Roman Jacome, Henry Arguello",
        "summary": "Designing the physical encoder is crucial for accurate image reconstruction in computational imaging (CI) systems. Currently, these systems are designed using an end-to-end (E2E) optimization approach, where the encoder is represented as a neural network layer and is jointly optimized with the computational decoder. However, the performance of E2E optimization is significantly reduced by the physical constraints imposed on the encoder, such as binarization, light throughput, and the compression ratio. Additionally, since the E2E learns the parameters of the encoder by backpropagating the reconstruction error, it does not promote optimal intermediate outputs and suffers from gradient vanishing. To address these limitations, we reinterpret the concept of knowledge distillation (KD)—traditionally used to train smaller neural networks by transferring knowledge from a larger pretrained model—for designing a physically constrained CI system by transferring the knowledge of a pretrained, less-constrained CI system. Our approach involves three steps: First, given the original CI system (student), a teacher system is created by relaxing the constraints on the student’s encoder. Second, the teacher is optimized to solve a less-constrained version of the student’s problem. Third, the teacher guides the training of the highly constrained student through two proposed knowledge transfer functions, targeting both the encoder and the decoder feature space. The proposed method can be employed to any imaging modality since the relaxation scheme and the loss functions can be adapted according to the physical acquisition and the employed decoder. This approach was validated on three representative CI modalities: magnetic resonance, single-pixel, and compressive spectral imaging. Simulations show that a teacher system with an encoder that has a structure similar to that of the student encoder provides effective guidance. Our approach achieves significantly improved reconstruction performance and encoder design, outperforming both E2E optimization and traditional non-data-driven encoder designs.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "提炼知识以设计计算成像系统",
        "abstract_cn": "设计物理编码器对于计算成像 (CI) 系统中的精确图像重建至关重要。目前，这些系统是使用端到端（E2E）优化方法设计的，其中编码器表示为神经网络层，并与计算解码器联合优化。然而，编码器受到的物理约束（例如二值化、光吞吐量和压缩比）会显着降低端到端优化的性能。此外，由于 E2E 通过反向传播重建误差来学习编码器的参数，因此它不会促进最佳的中间输出，并且会出现梯度消失的问题。为了解决这些限制，我们重新解释了知识蒸馏（KD）的概念——传统上用于通过从较大的预训练模型转移知识来训练较小的神经网络——通过转移预训练的、约束较少的 CI 系统的知识来设计物理受限的 CI 系统。我们的方法包括三个步骤：首先，给定原始 CI 系统（学生），通过放宽对学生编码器的约束来创建教师系统。其次，教师被优化以解决学生问题的较少约束版本。第三，教师通过两个针对编码器和解码器特征空间提出的知识转移函数来指导高度受限的学生的训练。所提出的方法可以应用于任何成像模态，因为松弛方案和损失函数可以根据物理采集和所使用的解码器进行调整。该方法在三种代表性 CI 模式上得到了验证：磁共振、单像素和压缩光谱成像。仿真表明，具有与学生编码器结构相似的编码器的教师系统可以提供有效的指导。我们的方法显着提高了重建性能和编码器设计，优于端到端优化和传统的非数据驱动编码器设计。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3613961",
        "title": "Generating Synthetic 4DCT From 4DCBCT for Lung Tumor Adaptive Photon and Proton Therapy Using a Unet Attention-Guided CycleGAN With Structure-Consistency Loss",
        "link": "https://doi.org/10.1109/tci.2025.3613961",
        "published": "2025",
        "author": "Xiangyu Zhang, Xinyu Song, Jing Li, Lian Duan, Guangyu Wang, Weige Wei, Yongchang Wu, Sen Bai, Guangjun Li",
        "summary": "This study aims to develop a deep learning-based synthetic 4DCT (s4DCT) generation method from 4DCBCT to enhance the accuracy of dose calculation and respiratory motion management in adaptive radiotherapy for lung tumors. A Unet-based attention mechanism integrated with CycleGAN, incorporating structure-consistency loss called UGGAN-GC, was developed to generate s4DCT images and was compared with several commonly used models. 4DCT and 4DCBCT images of 17 lung tumor patients were included and randomly divided into training set, validation set and test set. Elastix was used to deformably register 4DCT to 4DCBCT to generate the ground truth for training and evaluation of image-quality and dose calculation. Quantitative and qualitative methods were used to assess the quality of regions of interest (ROIs) and images of s4DCT. 4DCT was deformably registered to 4DCBCT and s4DCT using Elastix to evaluate the Dice similarity coefficient (DSC) of ROIs and gross tumor volume (GTV) motion. The average intensity projections (AIP) of the ground truth were used to design photon and proton therapy plans. Dose distributions were compared between s4DCT-AIP and ground truth-AIP using gamma analysis and dose-volume histograms. The experimental results showed that UGGAN-GC eliminated streak artifacts, generated the clearest anatomical structures, and achieved the best HU correction for soft tissues. The MAEs of 4DCBCT, Unet, Pix2pix, Cut, Fastcut, CycleGAN, UGGAN, and UGGAN-GC were 117.65, 71.87, 64.73, 62.92, 62.14, 63.01, 59.97, and 59.66 HU, respectively. The gamma passing rate (GPR) (2%/2 mm) of photon plans exceeded 99.8% for all models. The ranking of proton plan GPR (2%/2 mm) was: UGGAN-GC (97.7%), CycleGAN (95.4%), UGGAN (95.2%), Fastcut (93.1%), Pix2pix (90.8%), Unet (89.9%), and Cut (87.7%). The s4DCT generated by UGGAN-GC demonstrated excellent image quality, characterized by high HU accuracy, structural similarity, and edge detail fidelity, and had the potential to achieve accurate dose calculation and respiratory motion management for online photon and proton therapy plans.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "使用具有结构一致性损失的 Unet 注意力引导循环 GAN 从 4DCBCT 生成用于肺肿瘤自适应光子和质子治疗的合成 4DCT",
        "abstract_cn": "本研究旨在开发一种基于4DCBCT的基于深度学习的合成4DCT（s4DCT）生成方法，以提高肺部肿瘤适应性放疗中剂量计算和呼吸运动管理的准确性。开发了一种与 CycleGAN 集成的基于 Unet 的注意力机制，并结合了称为 UGGAN-GC 的结构一致性损失，用于生成 s4DCT 图像，并与几种常用模型进行了比较。纳入17例肺部肿瘤患者的4DCT和4DCBCT图像，并随机分为训练集、验证集和测试集。 Elastix 用于将 4DCT 变形配准到 4DCBCT，以生成用于训练和评估图像质量和剂量计算的基本事实。使用定量和定性方法来评估感兴趣区域 (ROI) 和 s4DCT 图像的质量。使用 Elastix 将 4DCT 变形配准到 4DCBCT 和 s4DCT，以评估 ROI 的 Dice 相似系数 (DSC) 和总肿瘤体积 (GTV) 运动。真实情况的平均强度投影 (AIP) 用于设计光子和质子治疗计划。使用伽马分析和剂量体积直方图比较 s4DCT-AIP 和 groundtruth-AIP 之间的剂量分布。实验结果表明，UGGAN-GC消除了条纹伪影，生成了最清晰的解剖结构，并对软组织实现了最佳的HU校正。 4DCBCT、Unet、Pix2pix、Cut、Fastcut、CycleGAN、UGGAN 和 UGGAN-GC 的 MAE 分别为 117.65、71.87、64.73、62.92、62.14、63.01、59.97 和 59.66 HU。所有模型的光子计划伽马通过率（GPR）（2%/2 mm）均超过 99.8%。质子计划GPR（2%/2 mm）的排名为：UGGAN-GC（97.7%）、CycleGAN（95.4%）、UGGAN（95.2%）、Fastcut（93.1%）、Pix2pix（90.8%）、Unet（89.9%）和Cut（87.7%）。 UGGAN-GC生成的s4DCT表现出优异的图像质量，具有高HU精度、结构相似性和边缘细节保真度，并且有潜力为在线光子和质子治疗计划实现精确的剂量计算和呼吸运动管理。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3614497",
        "title": "Modeling Real-World MPI System Matrices From Sparse Observations",
        "link": "https://doi.org/10.1109/tci.2025.3614497",
        "published": "2025",
        "author": "Feiyang Liao, Ming Li, Weixuan Feng, Yajie Xu, Tongtong Zhang, Zhongyi Wu, Hui Hui, Jian Zheng, Jie Tian",
        "summary": "Magnetic Particle Imaging (MPI) offers unique advantages, including high sensitivity, real-time imaging, and absence of ionizing radiation. However, the prevailing system matrix (SM)-based reconstruction in MPI faces critical limitations: time-consuming calibration, noise vulnerability, and reliance on high-resolution training data. To overcome these challenges, we propose an imaging physics driven neural field framework for efficient SM calibration and robust reconstruction. Key innovations include: (1) First-order derivative constraints to suppress spiky noise, (2) An M-order separable representation to enforce smoothness and reduce fluctuation artifacts, and (3) Chebyshev polynomial integration to enhance encoding efficiency and embed imaging physics priors. The method adapts to variable resolution requirements, reduces dependency on high-resolution data, and demonstrates robustness to noise across diverse SNR conditions. Experiments on the OpenMPI dataset show remarkable performance, achieving 1.55% nRMSE at 25% sparsity and minimal 0.21% degradation at 6.25% sparsity. Furthermore, upsampling sparse internal MPI system via the proposed method successfully reconstructs phantom geometries with high fidelity. These results validate the method’s potential to advance MPI toward broader research applications.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "根据稀疏观测对现实世界的 MPI 系统矩阵进行建模",
        "abstract_cn": "磁粒子成像 (MPI) 具有独特的优势，包括高灵敏度、实时成像和无电离辐射。然而，MPI 中流行的基于系统矩阵 (SM) 的重建面临着严重的局限性：校准耗时、噪声脆弱性以及对高分辨率训练数据的依赖。为了克服这些挑战，我们提出了一种成像物理驱动的神经场框架，用于高效的 SM 校准和稳健的重建。主要创新包括：（1）抑制尖峰噪声的一阶导数约束，（2）增强平滑度并减少波动伪影的 M 阶可分离表示，以及（3）切比雪夫多项式积分以提高编码效率并嵌入成像物理先验。该方法适应可变的分辨率要求，减少对高分辨率数据的依赖，并在不同的 SNR 条件下展示对噪声的鲁棒性。 OpenMPI 数据集上的实验显示出卓越的性能，在 25% 稀疏度下实现了 1.55% nRMSE，在 6.25% 稀疏度下实现了 0.21% 的最低降级。此外，通过所提出的方法对稀疏内部 MPI 系统进行上采样，成功地以高保真度重建了幻影几何形状。这些结果验证了该方法有可能推动 MPI 走向更广泛的研究应用。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3615397",
        "title": "Semi-Analytical Super-Resolution X-Space Reconstruction for Magnetic Particle Imaging Scanner via Adaptive Kernel Optimization",
        "link": "https://doi.org/10.1109/tci.2025.3615397",
        "published": "2025",
        "author": "Yanjun Liu, Lei Li, Guanghui Li, Siao Lei, Deshang Duan, Yang Jing, Peng Yang, Xin Feng, Yu An, Hui Hui, Jie Tian",
        "summary": "Magnetic Particle Imaging (MPI) is an emerging biomedical imaging technique. The x-space method, one of the mainstream reconstruction methods in MPI, offers high efficiency and real-time capabilities but is limited by theoretical spatial resolution constraints and typically necessitates high gradient magnetic fields. This study introduces a semi-analytical reconstruction (Semi-AR) method for x-space MPI scanner, incorporating a kernel optimization step to achieve a spatial resolution better than the theoretical limit. By modeling the x-space MPI system with focus-field sequences as a linear shift invariant system, the point spread function (PSF) is decomposed into basis functions and variants across different spatial frequencies. These functions are weighted to reconstruct a high-resolution PSF, with optimal weights adaptively determined via quadratic programming. A mouse-sized MPI scanner with 3D focus-field sequences was developed to evaluate the method. Simulation and experimental results showcase Semi-AR’s superior spatial resolution and robustness compared to existing x-space techniques, particularly in detecting low-brightness targets near highlighted non-target organs. Both phantom and in vivo experiments robustly validate Semi-AR’s effectiveness, providing new insights into MPI scanner development, and advancing preclinical and potential clinical MPI applications.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "通过自适应核优化的磁粒子成像扫描仪半解析超分辨率 X 空间重建",
        "abstract_cn": "磁粒子成像（MPI）是一种新兴的生物医学成像技术。 x空间方法是MPI中主流的重建方法之一，具有高效率和实时性，但受到理论空间分辨率的限制，通常需要高梯度磁场。本研究介绍了一种用于 x 空间 MPI 扫描仪的半解析重建 (Semi-AR) 方法，该方法结合了内核优化步骤，以实现优于理论极限的空间分辨率。通过将具有聚焦场序列的 x 空间 MPI 系统建模为线性平移不变系统，点扩散函数 (PSF) 被分解为跨不同空间频率的基函数和变体。这些函数被加权以重建高分辨率PSF，并通过二次规划自适应地确定最佳权重。开发了具有 3D 聚焦场序列的鼠标大小的 MPI 扫描仪来评估该方法。仿真和实验结果表明，与现有的 x 空间技术相比，Semi-AR 具有卓越的空间分辨率和鲁棒性，特别是在检测突出显示的非目标器官附近的低亮度目标方面。体模和体内实验都有力地验证了 Semi-AR 的有效性，为 MPI 扫描仪开发提供了新的见解，并推进了临床前和潜在的临床 MPI 应用。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3617235",
        "title": "The Marginal Importance of Known Distortions and Alignment in CASSI Systems",
        "link": "https://doi.org/10.1109/tci.2025.3617235",
        "published": "2025",
        "author": "Léo Paillet, Antoine Rouxel, Hervé Carfantan, Simon Lacroix, Antoine Monmayrant",
        "summary": "Coded Aperture Snapshot Spectral Imagers (CASSI) are designed to acquire 2D coded acquisitions of hyperspectral scenes (HSS). Associated with reconstruction algorithms, they allow to analyze the HSS using a small amount of data. Various configurations of such imagers exist, with different distortions. In this article we show that reconstruction quality is relatively insensitive to these distortions, if known and correctly modeled. To this end, we introduce a differentiable ray-tracing-based model that incorporates aberrations and distortions to render coded hyperspectral acquisitions using CASSI. Such simulated acquisitions are used to train state-of-the-art hyperspectral cube reconstruction algorithms. We also adapted these algorithms through the use of a ray-tracing-based mapping function which accounts for aberrations and distortions. We evaluated four comparable CASSI systems with varying degree of optical aberrations and misalignments, using five state-of-the-art hyperspectral cube reconstruction algorithms. Our analyses show that if known and properly modeled, the effects of geometric distortions of the system and misalignment of the dispersive elements have a marginal impact on the overall reconstruction quality. Therefore, relaxing traditional constraints on measurement conformity and fidelity to the scene enables the development of novel imaging instruments, guided by performance metrics applied to the design or the processing of acquisitions. By providing a complete framework for design, simulation and evaluation, this work contributes to the optimization and exploration of new CASSI systems and more generally to the computational imaging community.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "CASSI 系统中已知畸变和对准的边际重要性",
        "abstract_cn": "编码孔径快照光谱成像仪 (CASSI) 旨在获取高光谱场景 (HSS) 的 2D 编码数据。与重建算法相关，它们允许使用少量数据来分析 HSS。这种成像器存在多种配置，具有不同的畸变。在本文中，我们表明，如果已知并正确建模，重建质量对这些失真相对不敏感。为此，我们引入了一种基于可微分光线追踪的模型，该模型结合了像差和畸变，以使用 CASSI 渲染编码高光谱采集。此类模拟采集用于训练最先进的高光谱立方体重建算法。我们还通过使用基于光线追踪的映射函数来调整这些算法，该函数考虑了像差和扭曲。我们使用五种最先进的高光谱立方体重建算法评估了四个具有不同程度的光学像差和错位的可比 CASSI 系统。我们的分析表明，如果已知并正确建模，系统几何畸变和色散元件未对准的影响对整体重建质量具有边际影响。因此，放松对测量一致性和场景保真度的传统限制可以在应用于设计或采集处理的性能指标的指导下开发新型成像仪器。通过提供完整的设计、模拟和评估框架，这项工作有助于新 CASSI 系统的优化和探索，更广泛地有助于计算成像社区。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3617237",
        "title": "MISD: Model-Informed Stable Diffusion Model for Limited Noisy Data CT Reconstruction",
        "link": "https://doi.org/10.1109/tci.2025.3617237",
        "published": "2025",
        "author": "Qi Wang, Yufang Cai, Haijun Yu, Fenlin Liu, Weiwen Wu",
        "summary": "Limited data computed tomography (LDCT) plays a critical role in accelerating the scanning process and reducing radiation exposure for patients. However, LDCT reconstruction is inherently an ill-posed inverse problem, often resulting in pronounced edge artifacts and the loss of fine structural details. In recent years, score-based generative models (SGMs) have shown great promise in LDCT reconstruction by alleviating the ill-posedness and enabling high-fidelity image recovery in the case of noise-free condition. However, in practical CT systems, measurement data is often contaminated by noise. The coexistence of noise and limited data presents significant challenges for SGM-based image reconstruction methods. To address this challenge, this study proposes a Model-Informed Stable Diffusion (MISD) model which integrates a sampling process with a generative prior in the image-space module and a physics prior in the projection-space module. The projection-space module incorporates physical information to establish a noise suppression mechanism, effectively reducing the impact of noise. At the same time, the image-space module uses a generative model to progressively reconstruct clear structures and features from an initial state characterized by pure noise. Together, these two modules form a cohesive mathematical framework, utilizing iterative optimization to gradually minimize the effects of noise and artifacts. Experimental results show that the MISD method consistently achieves higher quantitative metrics and recovers finer structural details than other state-of-the-art reconstruction techniques, both on simulated and real datasets.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "MISD：用于有限噪声数据 CT 重建的模型知情稳定扩散模型",
        "abstract_cn": "有限数据计算机断层扫描 (LDCT) 在加速扫描过程和减少患者辐射暴露方面发挥着关键作用。然而，LDCT 重建本质上是一个不适定的逆问题，通常会导致明显的边缘伪影和精细结构细节的丢失。近年来，基于分数的生成模型（SGM）通过减轻不适定性并在无噪声条件下实现高保真图像恢复，在 LDCT 重建中显示出了巨大的前景。然而，在实际的CT系统中，测量数据常常受到噪声的污染。噪声和有限数据的共存对基于 SGM 的图像重建方法提出了重大挑战。为了应对这一挑战，本研究提出了一种基于模型的稳定扩散（MISD）模型，该模型将采样过程与图像空间模块中的生成先验和投影空间模块中的物理先验集成在一起。投影空间模块结合物理信息建立噪声抑制机制，有效降低噪声的影响。同时，图像空间模块使用生成模型从以纯噪声为特征的初始状态逐步重建清晰的结构和特征。这两个模块共同形成了一个紧密结合的数学框架，利用迭代优化来逐渐最小化噪声和伪影的影响。实验结果表明，与其他最先进的重建技术相比，MISD 方法在模拟数据集和真实数据集上始终能够实现更高的定量指标并恢复更精细的结构细节。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3617255",
        "title": "DROLL: Dual-Domain Reconstruction Network With a High-Fidelity Domain-Transform Operator Based on Learned Low-Rank Prior for Sparse-View CT Reconstruction",
        "link": "https://doi.org/10.1109/tci.2025.3617255",
        "published": "2025",
        "author": "Haowen Zhang, Pengcheng Zhang, Yikun Zhang, Yang Chen, Yi Liu, Zhiguo Gui",
        "summary": "Sparse-view CT reconstruction represents a prototypical ill-posed inverse problem. The implementation of deep learning solutions has proven to be highly successful in this field. The dual-domain reconstruction network achieves a favorable trade-off between reconstruction performance and computational cost by leveraging the powerful mapping capability of deep learning and the domain-transform relying on analytical reconstruction algorithms. However, further research is required to enhance the domain-transform in this field. Inspired by the successful utilization of low-rank prior in various medical imaging tasks, we proposed an end-to-end one-shot dual-domain network for sparse-view CT reconstruction. The domain-transform was designed as a high-fidelity multi-channel parallel back-projection in proposed network. In this way, feature maps between channels in the image domain imply strong low-rank priors. We implemented the singular value thresholding algorithm as a network layer, learning parameters and thresholds in a data-driven manner, fully leveraging the low-rank prior across channels to greatly reduce information loss and distortion during domain-transform. Moreover, we constructed a projection completion network based on dual attention mechanism that synthesizes missing view projections by effectively utilizing potential local correlation among projection domains during fan-beam scanning. In the image domain, a refine subnetwork based on Vision Transformer utilizes mix-scale features to implement two-dimensional filtering belonging to the back-projection filter algorithm. Extensive experiments on two clinically relevant datasets have demonstrated that the proposed network achieves competing performance on both quantitative metrics and visual quality.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "DROLL：具有基于学习低秩先验的高保真域变换算子的双域重建网络，用于稀疏视图 CT 重建",
        "abstract_cn": "稀疏视图 CT 重建代表了一个典型的不适定逆问题。事实证明，深度学习解决方案的实施在该领域取得了巨大成功。双域重建网络利用深度学习强大的映射能力和依赖解析重建算法的域变换，在重建性能和计算成本之间实现了良好的权衡。然而，需要进一步的研究来增强该领域的领域转换。受到各种医学成像任务中低秩先验的成功利用的启发，我们提出了一种用于稀疏视图 CT 重建的端到端单次双域网络。在所提出的网络中，域变换被设计为高保真多通道并行反投影。通过这种方式，图像域中通道之间的特征映射意味着强大的低秩先验。我们将奇异值阈值算法实现为网络层，以数据驱动的方式学习参数和阈值，充分利用跨通道的低秩先验，大大减少域转换过程中的信息丢失和失真。此外，我们构建了一个基于双重注意机制的投影完成网络，通过在扇束扫描过程中有效利用投影域之间潜在的局部相关性来合成缺失的视图投影。在图像领域，基于Vision Transformer的细化子网络利用混合尺度特征来实现属于反投影滤波算法的二维滤波。对两个临床相关数据集的广泛实验表明，所提出的网络在定量指标和视觉质量方面都实现了竞争性能。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3619811",
        "title": "High-Quality Diffractive Lens Infrared Computational Imaging via Severe Degradation Estimation Framework",
        "link": "https://doi.org/10.1109/tci.2025.3619811",
        "published": "2025",
        "author": "Pengzhou Ji, Xiong Dun, Yujie Xing, Xuquan Wang, Jian Zhang, Hongmei Li, Kan Zhao, Hongfei Jiao, Zhanshan Wang, Xinbin Cheng",
        "summary": "Diffractive lens (DLs) computational imaging promises lightweight infrared imaging. However, it is still challenging to accurately obtain the degradation of DLs computational imaging systems to achieve high-quality imaging. Degradation estimation methods based on image-to-image are the most feasible way, but existing methods face the problem of low accuracy for severe degradation estimation. In this paper, we proposed a severe degradation estimation framework based on KernelNet, and realized the improvement of the accuracy of severe degenerate estimation by more than 1.13 dB. Furthermore, DyUnet, an image restoration network, was proposed, which is based on dynamic convolution. The results of the mid-wave diffractive lens infrared computational imaging system indicated that our method achieved high-quality imaging results comparable to the conventional one, while the number of optical elements was reduced from 7 to 2, and the weight was reduced by 50$\\%$.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "通过严重退化估计框架进行高质量衍射镜头红外计算成像",
        "abstract_cn": "衍射透镜 (DL) 计算成像有望实现轻量级红外成像。然而，准确获得DL计算成像系统的退化以实现高质量成像仍然具有挑战性。基于图像到图像的退化估计方法是最可行的方法，但现有方法面临严重退化估计精度低的问题。本文提出了一种基于KernelNet的严重退化估计框架，实现了严重退化估计的精度提高了1.13 dB以上。此外，还提出了基于动态卷积的图像恢复网络DyUnet。中波衍射透镜红外计算成像系统的结果表明，我们的方法取得了与传统方法相当的高质量成像结果，同时光学元件数量从7个减少到2个，重量减轻了50$\\%$。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3619821",
        "title": "Prior Image Constrained Total Variation-Stokes for Cerebral Perfusion CT Imaging",
        "link": "https://doi.org/10.1109/tci.2025.3619821",
        "published": "2025",
        "author": "Shanzhou Niu, Shuo Li, Tinghua Wang, Weiwen Wu, You Zhang, Jing Wang, Jianhua Ma",
        "summary": "Cerebral perfusion computed tomography (CPCT) can non-invasively and rapidly assess blood flow circulation in the brain, making it widely adopted in clinical settings. However, the dynamic scanning protocol associated with CPCT entails substantial ionizing radiation exposure, leading to elevated radiation risks. Lowering the tube current can efficiently reduce radiation dose, but leads to significant image quality deterioration for standard filtered back-projection (FBP) algorithm due to increased quantum noise in measured projection data. In this study, we present an iterative image reconstruction method to improve the low-dose CPCT image quality, which uses the prior image constrained total variation-stokes (PICTVS) based on the penalized weighted least squares (PWLS) criterion. This method leverages information from the prior image to enhance the image quality of low-dose CPCT. Specifically, PICTVS utilizes high-quality geometric structural information from the prior image and fuses it into low-dose CPCT image reconstruction while preserving the main features of the target image. An effective alternating minimization method was developed to solve the objective function associated with the PWLS-PICTVS reconstruction. The novelty of the PWLS-PICTVS algorithm is listed as follows: (1) The PICTVS regularization incorporates the structural information of prior image into the target image where the gradients of both images align; (2) In image areas where the gradients differ, the PICTVS regularization employs total variation (TV) instead; and (3) The PICTVS regularization facilitates the integration of shared edge structure information from a high-quality prior image into the low-dose image while avoiding introducing mismatched anatomy information. Qualitative and quantitative analyses were conducted to assess the efficacy of the PWLS-PICTVS image reconstruction algorithm using a digital brain perfusion phantom and simulated low-dose clinical patient data. The experimental results show that the PWLS-PICTVS algorithm significantly improves noise suppression, streak artifact reduction, and edge preservation when compared with the other reconstruction methods. Importantly, the CPCT images reconstructed using the PWLS-PICTVS method yield more accurate hemodynamic parameter maps, enhancing their potential for clinical diagnosis.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "脑灌注 CT 成像的先验图像约束总变异斯托克斯",
        "abstract_cn": "脑灌注计算机断层扫描（CPCT）可以无创、快速评估大脑中的血流循环，使其在临床环境中得到广泛采用。然而，与 CPCT 相关的动态扫描方案需要大量的电离辐射暴露，导致辐射风险升高。降低管电流可以有效减少辐射剂量，但由于测量的投影数据中的量子噪声增加，导致标准滤波反投影（FBP）算法的图像质量显着下降。在本研究中，我们提出了一种迭代图像重建方法来提高低剂量 CPCT 图像质量，该方法使用基于惩罚加权最小二乘 (PWLS) 准则的先验图像约束总变分斯托克斯 (PICTVS)。该方法利用先前图像的信息来增强低剂量 CPCT 的图像质量。具体来说，PICTVS利用先前图像中的高质量几何结构信息，并将其融合到低剂量CPCT图像重建中，同时保留目标图像的主要特征。开发了一种有效的交替最小化方法来求解与 PWLS-PICTVS 重建相关的目标函数。 PWLS-PICTVS算法的新颖之处在于：(1)PICTVS正则化将先验图像的结构信息合并到目标图像中，并且两幅图像的梯度对齐。 (2) 在梯度不同的图像区域，PICTVS正则化采用全变分(TV)； (3) PICTVS正则化有利于将来自高质量先验图像的共享边缘结构信息集成到低剂量图像中，同时避免引入不匹配的解剖信息。进行定性和定量分析，以评估使用数字脑灌注模型和模拟低剂量临床患者数据的 PWLS-PICTVS 图像重建算法的有效性。实验结果表明，与其他重建方法相比，PWLS-PICTVS 算法显着改善了噪声抑制、条纹伪影减少和边缘保留。重要的是，使用 PWLS-PICTVS 方法重建的 CPCT 图像可产生更准确的血流动力学参数图，增强其临床诊断的潜力。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3623006",
        "title": "Joint High-Order Motion Compensation and Imaging Algorithm for Ultrahigh-Resolution Spaceborne ISAR",
        "link": "https://doi.org/10.1109/tci.2025.3623006",
        "published": "2025",
        "author": "Yichen Zhou, Yong Wang",
        "summary": "The acquisition of high-resolution images of space orbiting satellites by spaceborne ISAR has significant importance for enhancing space situation awareness. However, challenges persist with the increase of resolution. Two main issues arise: (1) The assumption of a stable imaging projection plane is invalid under the current imaging regime. (2) The high-order spatial-variant range cell migration and phase errors caused by complex relative motion is introduced. Therefore, it is important to optimize the existing ISAR imaging geometry models and imaging algorithms. In this paper, integration of high-order motion compensation and high-resolution imaging algorithm is proposed. Firstly, the spaceborne ISAR geometric imaging model is established, and the rationality of the model and the unique properties application to image space satellites target are investigated. Subsequently, by effectively utilizing the properties, a high-order range migration elimination method based on image partition is proposed, along with the image partition parameters estimation method. For the remaining phase error, a high-resolution imaging algorithm is introduced to eliminate error, which can overcome the influence of cross terms and strong scattering points. Finally, compared with the existing algorithms, simulation results validate the effectiveness and superiority of the proposed algorithm under different SNR.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "超高分辨率星载ISAR联合高阶运动补偿与成像算法",
        "abstract_cn": "星载ISAR获取空间轨道卫星高分辨率图像对于增强空间态势感知具有重要意义。然而，随着分辨率的提高，挑战仍然存在。出现两个主要问题：（1）稳定成像投影平面的假设在当前成像机制下是无效的。 (2)引入了复杂相对运动引起的高阶空间变异距离单元迁移和相位误差。因此，优化现有ISAR成像几何模型和成像算法具有重要意义。本文提出了高阶运动补偿与高分辨率成像相结合的算法。首先建立了星载ISAR几何成像模型，研究了该模型的合理性以及在图像空间卫星目标中的独特性能应用。随后，有效利用这些特性，提出了一种基于图像分割的高阶范围偏移消除方法以及图像分割参数估计方法。对于剩余的相位误差，引入高分辨率成像算法消除误差，可以克服交叉项和强散射点的影响。最后，与现有算法进行比较，仿真结果验证了所提算法在不同信噪比下的有效性和优越性。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3622992",
        "title": "A Message-Passing Perspective on Ptychographic Phase Retrieval",
        "link": "https://doi.org/10.1109/tci.2025.3622992",
        "published": "2025",
        "author": "Hajime Ueda, Shun Katakami, Masato Okada",
        "summary": "We introduce a probabilistic approach to ptychographic reconstruction in computational imaging. Ptychography is an imaging method where the complex amplitude of an object is estimated from a sequence of diffraction measurements. We formulate this reconstruction as a Bayesian inverse problem and derive an inference algorithm, termed “Ptycho-EP,” based on belief propagation and Vector Approximate Message Passing from information theory. Prior knowledge about the unknown object can be integrated into the probabilistic model, and the Bayesian framework inherently enables the uncertainty quantification of the reconstruction. Numerical experiments demonstrate that, when the probe’s illumination function is known, our algorithm accurately retrieves the object image at a sampling ratio approaching the information theoretic limit. In scenarios where the illumination function is unknown, both the object and the probe can be jointly reconstructed via an Expectation-Maximization algorithm. We evaluate the performance of our algorithm against conventional methods, highlighting its superior convergence speed.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "叠字相位检索的消息传递视角",
        "abstract_cn": "我们引入了计算成像中叠层重建的概率方法。叠层照相术是一种成像方法，通过一系列衍射测量来估计物体的复振幅。我们将这种重建表述为贝叶斯逆问题，并基于信息论中的置信传播和向量近似消息传递推导了一种称为“Ptycho-EP”的推理算法。关于未知对象的先验知识可以集成到概率模型中，并且贝叶斯框架本质上能够实现重建的不确定性量化。数值实验表明，当探头的照明函数已知时，我们的算法能够以接近信息论极限的采样率准确地检索物体图像。在照明函数未知的情况下，可以通过期望最大化算法联合重建物体和探针。我们相对于传统方法评估了我们的算法的性能，强调了其卓越的收敛速度。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3623041",
        "title": "High-Fidelity Holographic Reconstruction via Physics-Aware Heterogeneous Self-Supervised Learning",
        "link": "https://doi.org/10.1109/tci.2025.3623041",
        "published": "2025",
        "author": "Sida Gao, Ziyang Li, Zhengyu Wu, Qi Li, Pengcheng Jia, Yutong Li, Shutian Liu, Zhengjun Liu",
        "summary": "Single-shot digital holography has demonstrated great potential for capturing the complex amplitude of optical fields in lensless imaging systems. Nevertheless, accurately reconstructing intricate interference patterns remains challenging due to high-frequency texture distortion and limited generalization across diverse real-world conditions. To address these issues, we propose a physics-embedded network that explicitly incorporates angular spectrum propagation and spatial-domain amplitude constraints into a deep learning framework, ensuring both physical consistency and strong representational capacity. Building on this foundation, we devised HoloSSL, a physics-aware heterogeneous self-supervised learning framework for robust single-frame holographic reconstruction. The framework consists of two complementary stages: (1) physics-aware self-supervised pretraining using Hermite-Gaussian synthesized holograms to learn a prior-consistent mapping, and (2) unsupervised domain adaptation using real captured intensity-only holograms, where intensity fidelity and propagation consistency jointly guide label-free fine-tuning. To enhance texture representation, we design a swin-hourglass block that integrates cross-scale self-attention with frequency-aware modeling. Extensive simulations and real-world experiments demonstrate that HoloSSL outperforms state-of-the-art methods in terms of reconstruction fidelity, structural consistency, and robustness to noise, providing a new paradigm for adaptive, interpretable, and high-fidelity holographic imaging.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "通过物理感知异构自监督学习进行高保真全息重建",
        "abstract_cn": "单次数字全息术在捕捉无透镜成像系统中复杂的光场振幅方面表现出了巨大的潜力。然而，由于高频纹理失真和不同现实条件下的泛化能力有限，准确重建复杂的干涉图案仍然具有挑战性。为了解决这些问题，我们提出了一种物理嵌入式网络，该网络明确地将角谱传播和空间域振幅约束合并到深度学习框架中，确保物理一致性和强大的表示能力。在此基础上，我们设计了 HoloSSL，一种物理感知的异构自监督学习框架，用于稳健的单帧全息重建。该框架由两个互补阶段组成：（1）使用 Hermite-Gaussian 合成全息图进行物理感知的自监督预训练，以学习先验一致的映射；（2）使用真实捕获的仅强度全息图进行无监督域适应，其中强度保真度和传播一致性共同指导无标签微调。为了增强纹理表示，我们设计了一个 swin-hourglass 模块，它将跨尺度自注意力与频率感知建模相结合。大量的模拟和真实实验表明，HoloSSL 在重建保真度、结构一致性和噪声鲁棒性方面优于最先进的方法，为自适应、可解释和高保真全息成像提供了新的范例。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3623000",
        "title": "Graph Attention-Driven Bayesian Deep Unrolling for Dual-Peak Single-Photon Lidar Imaging",
        "link": "https://doi.org/10.1109/tci.2025.3623000",
        "published": "2025",
        "author": "Kyungmin Choi, JaKeoung Koo, Stephen McLaughlin, Abderrahim Halimi",
        "summary": "Single-photon Lidar imaging offers a significant advantage in 3D imaging due to its high resolution and long-range capabilities, however it is challenging to apply in noisy environments with multiple targets per pixel. To tackle these challenges, several methods have been proposed. Statistical methods demonstrate interpretability on the inferred parameters, but they are often limited in their ability to handle complex scenes. Deep learning-based methods have shown superior performance in terms of accuracy and robustness, but they lack interpretability or they are limited to a single-peak per pixel. In this paper, we propose a deep unrolling algorithm for dual-peak single-photon Lidar imaging. We introduce a hierarchical Bayesian model for multiple targets and propose a neural network that unrolls the underlying statistical method. To support multiple targets, we adopt a dual depth maps representation and exploit geometric deep learning to extract features from the point cloud. The proposed method takes advantages of statistical methods and learning-based methods in terms of accuracy and quantifying uncertainty. The experimental results on synthetic and real data demonstrate the competitive performance when compared to existing methods, while also providing uncertainty information.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "用于双峰单光子激光雷达成像的图注意力驱动贝叶斯深度展开",
        "abstract_cn": "单光子激光雷达成像由于其高分辨率和远距离功能而在 3D 成像中具有显着优势，但在每个像素有多个目标的嘈杂环境中应用具有挑战性。为了应对这些挑战，已经提出了几种方法。统计方法证明了推断参数的可解释性，但它们处理复杂场景的能力通常受到限制。基于深度学习的方法在准确性和鲁棒性方面表现出了卓越的性能，但它们缺乏可解释性，或者仅限于每个像素的单峰。在本文中，我们提出了一种用于双峰单光子激光雷达成像的深度展开算法。我们引入了针对多个目标的分层贝叶斯模型，并提出了一种展开底层统计方法的神经网络。为了支持多个目标，我们采用双深度图表示并利用几何深度学习从点云中提取特征。该方法在准确性和量化不确定性方面利用了统计方法和基于学习的方法的优点。合成数据和真实数据的实验结果证明了与现有方法相比的竞争性能，同时还提供了不确定性信息。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3622928",
        "title": "Limitations of Data-Driven Spectral Reconstruction: An Optics-Aware Analysis",
        "link": "https://doi.org/10.1109/tci.2025.3622928",
        "published": "2025",
        "author": "Qiang Fu, Matheus Souza, Eunsue Choi, Suhyun Shin, Seung-Hwan Baek, Wolfgang Heidrich",
        "summary": "Hyperspectral imaging empowers machine vision systems with the distinct capability of identifying materials through recording their spectral signatures. Recent efforts in data-driven spectral reconstruction aim at extracting spectral information from RGB images captured by cost-effective RGB cameras, instead of dedicated hardware. Published work reports exceedingly high numerical scores for this reconstruction task, yet real-world performance lags substantially behind. In this paper we systematically analyze the performance of such methods with three groups of dedicated experiments. First, we evaluate the practical overfitting limitations with respect to current datasets by training the networks with less data, validating the trained models with unseen yet slightly modified data, and cross-dataset validation. Second, we reveal fundamental limitations in the ability of RGB to spectral methods to deal with metameric or near-metameric conditions, which have so far gone largely unnoticed due to the insufficiencies of existing datasets. We achieve this by validating the trained models with metamer data generated by metameric black theory and re-training the networks with various forms of metamers. This methodology can also be used for data augmentation as a partial mitigation of the dataset issues, although the RGB to spectral inverse problem remains fundamentally ill-posed. Finally, we analyze the potential for modifying the problem setting to achieve better performance by exploiting some form of optical encoding provided by either incidental optical aberrations or some form of deliberate optical design. Our experiments show that such approaches do indeed provide improved results under certain circumstances, however their overall performance is limited by the same dataset issues as in the plain RGB to spectral scenario. We therefore conclude that future progress on snapshot spectral imaging will heavily depend on the generation of improved datasets which can then be used to design effective optical encoding strategies.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "数据驱动的光谱重建的局限性：光学感知分析",
        "abstract_cn": "高光谱成像使机器视觉系统具有通过记录材料的光谱特征来识别材料的独特能力。最近在数据驱动的光谱重建方面的努力旨在从经济高效的 RGB 相机捕获的 RGB 图像中提取光谱信息，而不是专用硬件。已发表的工作报告了这项重建任务的极高数值分数，但现实世界的表现却严重落后。在本文中，我们通过三组专门实验系统地分析了此类方法的性能。首先，我们通过使用较少的数据训练网络、使用未见过但稍作修改的数据验证训练后的模型以及跨数据集验证来评估当前数据集的实际过度拟合限制。其次，我们揭示了 RGB 到光谱方法处理同色异谱或近同色异谱条件的能力的基本限制，由于现有数据集的不足，到目前为止，这些限制在很大程度上未被注意到。我们通过使用同色异谱黑理论生成的同色异谱数据验证训练模型并使用各种形式的同色异谱重新训练网络来实现这一目标。尽管 RGB 到光谱逆问题从根本上来说仍然是不适定的，但该方法也可用于数据增强，作为数据集问题的部分缓解。最后，我们分析了通过利用偶然光学像差或某种形式的故意光学设计提供的某种形式的光学编码来修改问题设置以实现更好性能的潜力。我们的实验表明，此类方法确实在某些情况下提供了改进的结果，但它们的整体性能受到与普通 RGB 到光谱场景中相同的数据集问题的限制。因此，我们得出的结论是，快照光谱成像的未来进展将在很大程度上取决于改进数据集的生成，这些数据集随后可用于设计有效的光学编码策略。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3622903",
        "title": "Using Randomized Nyström Preconditioners to Accelerate Variational Image Reconstruction",
        "link": "https://doi.org/10.1109/tci.2025.3622903",
        "published": "2025",
        "author": "Tao Hong, Zhaoyi Xu, Jason Hu, Jeffrey A. Fessler",
        "summary": "Model-based iterative reconstruction plays a key role in solving inverse problems. However, the associated minimization problems are generally large-scale, nonsmooth, and sometimes even nonconvex, which present challenges in designing efficient iterative solvers. Preconditioning methods can significantly accelerate the convergence of iterative methods. In some applications, computing preconditioners on-the-fly is beneficial. Moreover, forward models in image reconstruction are typically represented as operators, and the corresponding explicit matrices are often unavailable, which brings additional challenges in designing preconditioners. Therefore, for practical use, computing and applying preconditioners should be computationally inexpensive. This paper adapts the randomized Nyström approximation to compute effective preconditioners that accelerate image reconstruction without requiring an explicit matrix for the forward model. We leverage modern GPU computational platforms to compute the preconditioner on-the-fly. Moreover, we propose efficient approaches for applying the preconditioners to problems with classical nonsmooth regularizers, i.e., wavelet, total variation, and Hessian Schatten-norm. Our numerical results on image deblurring, super-resolution with impulsive noise, and 2D computed tomography reconstruction illustrate the efficiency and effectiveness of the proposed preconditioner.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "使用随机 Nyström 预处理器加速变分图像重建",
        "abstract_cn": "基于模型的迭代重建在解决反问题中起着关键作用。然而，相关的最小化问题通常是大规模的、非平滑的，有时甚至是非凸的，这给设计高效的迭代求解器带来了挑战。预处理方法可以显着加速迭代方法的收敛。在某些应用中，即时计算预处理器是有益的。此外，图像重建中的前向模型通常表示为算子，而相应的显式矩阵通常不可用，这给设计预处理器带来了额外的挑战。因此，对于实际应用，计算和应用预处理器应该是计算成本低廉的。本文采用随机 Nyström 近似来计算有效的预处理器，从而加速图像重建，而不需要前向模型的显式矩阵。我们利用现代 GPU 计算平台来实时计算预处理器。此外，我们提出了将预处理器应用于经典非光滑正则化问题的有效方法，即小波、全变分和 Hessian Schatten 范数。我们在图像去模糊、脉冲噪声超分辨率和二维计算机断层扫描重建方面的数值结果说明了所提出的预处理器的效率和有效性。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3625052",
        "title": "Convergent Complex Quasi-Newton Proximal Methods for Gradient-Driven Denoisers in Compressed Sensing MRI Reconstruction",
        "link": "https://doi.org/10.1109/tci.2025.3625052",
        "published": "2025",
        "author": "Tao Hong, Zhaoyi Xu, Se Young Chun, Luis Hernandez-Garcia, Jeffrey A. Fessler",
        "summary": "In compressed sensing (CS) MRI, model-based methods are pivotal to achieving accurate reconstruction. One of the main challenges in model-based methods is finding an effective prior to describe the statistical distribution of the target image. Plug-and-Play (PnP) and REgularization by Denoising (RED) are two general frameworks that use denoisers as the prior. While PnP/RED methods with convolutional neural network (CNN) based denoisers outperform classical hand-crafted priors in CS MRI, their convergence theory relies on assumptions that do not hold for practical CNN models. The recently developed gradient-driven denoisers offer a framework that bridges the gap between practical performance and theoretical guarantees. However, the numerical solvers for the associated minimization problem remain slow for CS MRI reconstruction. This paper proposes a complex quasi-Newton proximal method that achieves faster convergence than existing approaches. To address the complex domain in CS MRI, we propose a modified Hessian estimation method that guarantees Hermitian positive definiteness. Furthermore, we provide a rigorous convergence analysis of the proposed method for nonconvex settings. Numerical experiments on both Cartesian and non-Cartesian sampling trajectories demonstrate the effectiveness and efficiency of our approach.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "压缩感知 MRI 重建中梯度驱动降噪器的收敛复拟牛顿近端方法",
        "abstract_cn": "在压缩感知 (CS) MRI 中，基于模型的方法对于实现精确重建至关重要。基于模型的方法的主要挑战之一是找到有效的先验来描述目标图像的统计分布。即插即用（PnP）和去噪REgularization（RED）是两个使用降噪器作为先验的通用框架。虽然使用基于卷积神经网络 (CNN) 的降噪器的 PnP/RED 方法在 CS MRI 中优于经典的手工先验方法，但它们的收敛理论依赖于不适用于实际 CNN 模型的假设。最近开发的梯度驱动降噪器提供了一个框架，弥补了实际性能和理论保证之间的差距。然而，对于 CS MRI 重建，相关最小化问题的数值求解器仍然很慢。本文提出了一种复杂的拟牛顿近端方法，该方法比现有方法具有更快的收敛速度。为了解决 CS MRI 中的复杂域问题，我们提出了一种改进的 Hessian 估计方法，保证 Hermitian 正定性。此外，我们针对非凸设置对所提出的方法进行了严格的收敛分析。笛卡尔和非笛卡尔采样轨迹的数值实验证明了我们方法的有效性和效率。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3625049",
        "title": "MR-EIT: Multi-Resolution Reconstruction for Electrical Impedance Tomography via Data-Driven and Unsupervised Dual-Mode Neural Networks",
        "link": "https://doi.org/10.1109/tci.2025.3625049",
        "published": "2026",
        "author": "Fangming Shi, Jinzhen Liu, Xiangqian Meng, Yapeng Zhou, Hui Xiong",
        "summary": "Neural-network-based approaches have shown promising performance in the field of electrical impedance tomography (EIT), but their effectiveness in multi-resolution reconstruction tasks within this domain still requires further validation. We introduce MR-EIT, a dual-mode (data-driven and unsupervised) multi-resolution method for EIT reconstruction. MR-EIT integrates an ordered feature extraction module and an unordered coordinate feature expression module. The former learns the mapping from voltage to two-dimensional conductivity features through pre-training, while the latter realizes multi-resolution reconstruction independent of the order and size of the input sequence by utilizing symmetric functions and local feature extraction mechanisms. In the data-driven mode, MR-EIT reconstructs high-resolution images from low-resolution data of finite element meshes through two stages of pre-training and joint training and demonstrates excellent performance in simulation experiments. In the unsupervised learning mode, MR-EIT does not require pre-training data and performs iterative optimization solely based on measured voltages to rapidly achieve image reconstruction from low to high resolution. It shows robustness to noise and efficient super-resolution reconstruction capabilities in both simulation and real water tank experiments. Experimental results indicate that MR-EIT outperforms the comparison methods in terms of Structural Similarity (SSIM) and Relative Image Error (RIE), especially in the unsupervised learning mode, where it can significantly reduce the number of iterations and improve image reconstruction quality.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "MR-EIT：通过数据驱动和无监督双模神经网络进行电阻抗断层扫描的多分辨率重建",
        "abstract_cn": "基于神经网络的方法在电阻抗断层扫描 (EIT) 领域表现出了良好的性能，但其在该领域的多分辨率重建任务中的有效性仍需要进一步验证。我们介绍 MR-EIT，一种用于 EIT 重建的双模式（数据驱动和无监督）多分辨率方法。 MR-EIT集成了有序特征提取模块和无序坐标特征表达模块。前者通过预训练学习电压到二维电导率特征的映射，而后者利用对称函数和局部特征提取机制实现与输入序列的阶数和大小无关的多分辨率重建。在数据驱动模式下，MR-EIT通过预训练和联合训练两个阶段，从有限元网格的低分辨率数据重建高分辨率图像，并在仿真实验中表现出优异的性能。在无监督学习模式下，MR-EIT不需要预训练数据，仅根据测量电压进行迭代优化，快速实现从低分辨率到高分辨率的图像重建。它在模拟和真实水箱实验中都表现出了对噪声的鲁棒性和高效的超分辨率重建能力。实验结果表明，MR-EIT在结构相似度（SSIM）和相对图像误差（RIE）方面优于比较方法，特别是在无监督学习模式下，可以显着减少迭代次数并提高图像重建质量。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3625054",
        "title": "Fast ISAR Imaging Algorithm for Azimuth Gapped Data Based on Structured Toeplitz Matrix",
        "link": "https://doi.org/10.1109/tci.2025.3625054",
        "published": "2025",
        "author": "Yu Gong, Yicheng Jiang, Zitao Liu, Yun Zhang",
        "summary": "With the advancement of modern radar systems, there are increasingly stringent requirements for reconstructing Inverse Synthetic Aperture Radar (ISAR) images from gap missing sampling (GMS) data. Compressed sensing (CS), while being a conventional approach for sparse reconstruction, suffers from inherent discrete dictionary mismatch issues that degrade reconstruction accuracy. Matrix completion (MC) methods, leveraging the low-rank properties of matrices, prevent the grid mismatch problem by directly recovering missing data. Although existing Hankel transformation methods can address GMS reconstruction, their computational efficiency remains quite slow. To address the fast ISAR imaging problem with azimuth GMS, we propose a fast imaging algorithm based on structured Toeplitz matrix. Our approach leverages the inherent low-rank properties of data by employing a structured Toeplitz formulation, thereby exploiting the enhanced low-rank property from the data structure. Numerical simulations reveal that the Toeplitz transformation achieves superior accuracy relative to the Hankel transformation. For achieving high-efficiency and high-precision image reconstruction, we further develop a reconstruction algorithm based on the fast Alternating Direction Method of Multipliers (ADMM). In contrast to the SLR+S algorithm using Hankel transformation, our proposed algorithm significantly reduces computational time while maintaining reconstruction accuracy. Finally, the experimental results further validate the effectiveness of the proposed algorithm, providing substantial support for its engineering applications.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "基于结构化Toeplitz矩阵的方位间隙数据快速ISAR成像算法",
        "abstract_cn": "随着现代雷达系统的进步，对从间隙缺失采样（GMS）数据重建逆合成孔径雷达（ISAR）图像的要求越来越严格。压缩感知（CS）虽然是稀疏重建的传统方法，但存在固有的离散字典不匹配问题，从而降低了重建精度。矩阵补全（MC）方法利用矩阵的低秩特性，通过直接恢复丢失的数据来防止网格不匹配问题。尽管现有的 Hankel 变换方法可以解决 GMS 重建问题，但其计算效率仍然相当缓慢。为了解决方位GMS的快速ISAR成像问题，我们提出了一种基于结构化Toeplitz矩阵的快速成像算法。我们的方法通过采用结构化的 Toeplitz 公式来利用数据固有的低秩属性，从而利用数据结构中增强的低秩属性。数值模拟表明，托普利茨变换相对于汉克尔变换具有更高的精度。为了实现高效、高精度的图像重建，我们进一步开发了一种基于快速交替方向乘子法（ADMM）的重建算法。与使用 Hankel 变换的 SLR+S 算法相比，我们提出的算法在保持重建精度的同时显着减少了计算时间。最后，实验结果进一步验证了所提算法的有效性，为其工程应用提供了实质性支持。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3626239",
        "title": "TAG-Splat: Two-Stage Anisotropic Gaussian Splatting for CL Reconstruction",
        "link": "https://doi.org/10.1109/tci.2025.3626239",
        "published": "2025",
        "author": "Dongrui Dai, Xiang Zou, Wuliang Shi, Yuxiang Xing",
        "summary": "Computed Laminography (CL) has significant advantages in 3D imaging of plate-like objects. However, interlayer aliasing artifacts due to incomplete data acquisition limit its application. In this work, we propose a Two-stage Anisotropic Gaussian Splatting for CL reconstruction (TAG-Splat). Specifically, the scanned object is modeled as a series of 3D Gaussian kernels with learnable parameters. In the first stage, we employ FDK to obtain an analytical result of preliminary estimation by that we fit a Gaussian kernel representation (GKR) in a supervised manner. In the second stage, we analogize the cone-beam X-ray scanner to a pinhole camera model, and apply the differentiable rasterization technique from 3D Gaussian Splatting (3DGS) to generate rendered projections of the GKR at arbitrary angles. To accommodate various CL imaging geometries, we incorporate a virtual detector plane and establish a mapping relationship to the real projection data to satisfy camera conditions. Additionally, we design a novel anisotropic Gaussian regularization tailored to the characteristics of CL, which effectively suppresses aliasing artifacts and restores axial resolution. The Gaussian parameters are iteratively optimized according to data fidelity, and volumetric reconstruction is obtained through voxelization of the Gaussians in the end. Both simulations and real experiments on rotational CL demonstrate that the proposed TAG-Splat achieves superior reconstruction performance than traditional analytical and iterative methods.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "TAG-Splat：用于 CL 重建的两阶段各向异性高斯泼溅",
        "abstract_cn": "计算机断层扫描 (CL) 在板状物体的 3D 成像方面具有显着优势。然而，由于数据采集不完整而导致的层间混叠伪影限制了其应用。在这项工作中，我们提出了用于 CL 重建的两阶段各向异性高斯分布 (TAG-Splat)。具体来说，扫描对象被建模为一系列具有可学习参数的 3D 高斯核。在第一阶段，我们使用FDK通过以监督方式拟合高斯核表示（GKR）来获得初步估计的分析结果。在第二阶段，我们将锥束 X 射线扫描仪类比为针孔相机模型，并应用 3D 高斯溅射 (3DGS) 的可微分光栅化技术来生成 GKR 在任意​​角度的渲染投影。为了适应各种 CL 成像几何形状，我们结合了虚拟探测器平面并建立了与真实投影数据的映射关系以满足相机条件。此外，我们针对 CL 的特点设计了一种新颖的各向异性高斯正则化，可以有效抑制混叠伪影并恢复轴向分辨率。根据数据保真度对高斯参数进行迭代优化，最终通过高斯体素化获得体重建。旋转 CL 的模拟和实际实验都表明，所提出的 TAG-Splat 比传统的分析和迭代方法具有更优越的重建性能。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3626235",
        "title": "A Novel ISAR Imaging Scaling Approach for Maneuvering Targets Based on Monopulse Radar",
        "link": "https://doi.org/10.1109/tci.2025.3626235",
        "published": "2025",
        "author": "Yufeng Liu, Yong Wang, Mei Liu",
        "summary": "Inverse Synthetic Aperture Radar (ISAR) imaging faces challenges in cross-range scaling for maneuvering targets due to nonuniform rotation, which complicates the estimation of rotational parameters. Though the traditional methods are theoretically effective, they are constrained by high computational complexity, thereby limiting real-time applications. Meanwhile, the monopulse technique, which is derived from monopulse radar and known for high angular measurement accuracy, has been integrated with ISAR to enhance imaging performance. However, traditional methods directly apply the monopulse technique after ISAR imaging, prone to inducing angle glint phenomena, which degrade the accuracy of scatterer projection. This paper innovatively integrates the monopulse technique into the ISAR imaging process and proposes a novel cross-range scaling method for maneuvering targets. By establishing a relationship between the monopulse angle and the ISAR equivalent rotation angle, the method decouples the estimation of Equivalent Rotation Velocity (ERV) and Equivalent Rotation Acceleration (ERA). Amplitude information is used to derive ERV, while phase information is utilized to obtain ERA, which significantly reduces computational complexity. The proposed algorithm offers high estimation accuracy and is well-suited for real-time, high-precision applications. Simulation results validate the effectiveness of the method and demonstrate its potential to enhance ISAR cross-range scaling for maneuvering targets.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "基于单脉冲雷达的机动目标 ISAR 成像缩放新方法",
        "abstract_cn": "由于旋转不均匀，逆合成孔径雷达（ISAR）成像面临机动目标跨距离缩放的挑战，这使得旋转参数的估计变得复杂。尽管传统方法在理论上是有效的，但它们受到高计算复杂度的限制，从而限制了实时应用。同时，源自单脉冲雷达、以高角度测量精度着称的单脉冲技术已与ISAR集成，以增强成像性能。然而，传统方法在ISAR成像后直接应用单脉冲技术，容易产生角度闪烁现象，从而降低散射体投影的精度。本文创新地将单脉冲技术集成到ISAR成像过程中，提出了一种新颖的机动目标跨距离缩放方法。该方法通过建立单脉冲角与ISAR等效旋转角之间的关系，解耦等效旋转速度（ERV）和等效旋转加速度（ERA）的估计。利用幅度信息推导ERV，利用相位信息获得ERA，大大降低了计算复杂度。该算法具有较高的估计精度，非常适合实时、高精度的应用。仿真结果验证了该方法的有效性，并展示了其增强机动目标 ISAR 跨距离缩放的潜力。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3627065",
        "title": "Autofocused Ptychographic Imaging Based on Mid-Frequency Discrete Cosine Transform",
        "link": "https://doi.org/10.1109/tci.2025.3627065",
        "published": "2025",
        "author": "Bailin Zhuang, Li Liu, Jinxiang Du, Lei Zhong, Haoyang Liang, Ming Gong, Qihang Zhang, Honggang Gu, Shiyuan Liu",
        "summary": "The axial misalignment, one of the most critical systematic errors in ptychographic imaging system, may cause inconsistencies between inversion reconstruction and physical experiment, leading to reconstruction artifacts. Here, we propose a precise and robust autofocused ptychographic imaging algorithm based on mid-frequency discrete cosine transform operator to assess image sharpness cross virtual planes within the depth of field. This algorithm demonstrates unprecedented sensitivity to the defocus blur, enabling it to escape from local minima and suppress convergence oscillations without the need for complex cross-domain computations. Both simulations and experiments for amplitude and biological specimens indicate that the proposed approach stably converges within an uncertainty on the order of depth of field, effectively eliminating reconstruction artifacts, and delivers a several-fold to orders of magnitude improvement in convergence speed, calibration accuracy and uncertainty compared to conventional total variation model based autofocused ptychographic imaging algorithms. Furthermore, its simple-to-implement architecture ensures excellent compatibility with diverse ptychographic reconstruction frameworks, significantly expanding its applicability to a wide range of coherent diffraction imaging techniques, such as multi-plane phase retrieval, in-line holography, and coherent tomography.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "基于中频离散余弦变换的自动聚焦叠层成像",
        "abstract_cn": "轴向失准是叠层成像系统中最关键的系统误差之一，可能会导致反演重建与物理实验之间的不一致，从而导致重建伪影。在这里，我们提出了一种基于中频离散余弦变换算子的精确且鲁棒的自动聚焦叠层成像算法，以评估景深内跨虚拟平面的图像清晰度。该算法对散焦模糊表现出前所未有的敏感性，使其能够摆脱局部极小值并抑制收敛振荡，而无需复杂的跨域计算。振幅和生物样本的仿真和实验表明，该方法在景深量级的不确定性范围内稳定收敛，有效消除了重建伪影，与传统的基于全变分模型的自动聚焦叠层成像算法相比，在收敛速度、校准精度和不确定性方面提供了数倍数量级的提高。此外，其易于实现的架构确保了与不同叠层重建框架的良好兼容性，显着扩展了其对各种相干衍射成像技术的适用性，例如多平面相位检索、在线全息术和相干断层扫描。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3627134",
        "title": "TIF-Net: Self-Supervised Net via Tuy's Inversion Formula for Limited Angle Reconstruction",
        "link": "https://doi.org/10.1109/tci.2025.3627134",
        "published": "2025",
        "author": "Guojun Zhu, Xinyun Zhong, Wenhui Huang, Guotao Quan, Yan Xi, Shipeng Xie, Yikun Zhang, Xu Ji, Yang Chen",
        "summary": "In medical or industrial measurements, limited angle reconstruction is a kind of ill-posed problem in computed tomography (CT). The CT images reconstructed from conventional analytical algorithms demonstrates structural distortions and artifacts. Recently, deep learning-based methods are utilized to resolve the limited angle reconstruction problem. However, most of the methods are supervised and require full scan CT images for training purposes. The training labels are often unavailable under real-world scenarios. In this work, we proposed a self-supervised limited-angle reconstruction method for CT that entirely eliminates the reliance on external supervision signals. It requires only limited-angle data acquired via a limited-angle acquisition protocol, enabling computationally efficient and rapid reconstruction. The method utilized the reconstruction results from Tuy's inversion method as training labels. To bridge the distribution gap between the regions that satisfy and fail to satisfy Tuy's data sufficiency condition, a dedicated data synthesis process was designed. The method was validated using both numerical simulations and real experimental data. Results demonstrated that the proposed method can effectively suppress the limited angle artifacts without the need of any full scan CT labels. The performance of the proposed method approaches that of the supervised methods, based on visual inspections. The proposed method is also computationally efficient, enabling real-time limited angle CT reconstruction.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "TIF-Net：通过 Tuy 反演公式进行有限角度重建的自监督网络",
        "abstract_cn": "在医学或工业测量中，有限角度重建是计算机断层扫描（CT）中的一种不适定问题。根据传统分析算法重建的 CT 图像显示出结构扭曲和伪影。最近，基于深度学习的方法被用来解决有限角度重建问题。然而，大多数方法都是有监督的，并且需要全扫描 CT 图像用于训练目的。在现实场景中，训练标签通常不可用。在这项工作中，我们提出了一种自监督的 CT 有限角度重建方法，完全消除了对外部监督信号的依赖。它仅需要通过有限角度采集协议采集的有限角度数据，从而实现计算高效且快速的重建。该方法利用 Tuy 反演方法的重建结果作为训练标签。为了弥合满足和不满足 Tuy 数据充足条件的区域之间的分布差距，设计了专用的数据合成流程。使用数值模拟和真实实验数据对该方法进行了验证。结果表明，该方法无需任何全扫描 CT 标签即可有效抑制有限角度伪影。基于目视检查，所提出的方法的性能接近监督方法的性能。所提出的方法计算效率也很高，能够实现实时有限角度 CT 重建。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3608958",
        "title": "HEDU-Net: Improving Spectral Snapshot Compressive Imaging With Explicable Degradation Compensation",
        "link": "https://doi.org/10.1109/tci.2025.3608958",
        "published": "2026",
        "author": "Jingxuan Geng, Jiamin Wu, Yonggang Li, Chunhua Yang",
        "summary": "With the widespread adoption of utilizing coded aperture snapshot spectral imaging (CASSI) to acquire hyperspectral images (HSIs), reconstruction algorithms become increasingly important as one of the most critical parts of CASSI. By formulating the iterative optimization problem as a multi-stage end-to-end neural network, the deep unfolding framework has made gratifying progress in improving the reconstruction reliability and fidelity. Nevertheless, there still exist three knotty issues limiting the performance of current reconstruction algorithms: 1) predetermined sensing matrix ignoring the gap between real and ideal degradation procedure. 2) ill-structured feature extraction and fusion network making it difficult to effectively recover the spatial texture and ensure spectral consistency. 3) inadequate stage interaction module, which hinders the transmission of useful information. To address these issues, in this paper, we propose a hyperspectral explicable degradation-compensatory unfolding neural network (HEDU-Net), which attempts to dynamically compensate for the differences between ideal and real degradation procedures using a residual network under the deep unfolding strategy. Moreover, a spatial-spectral interaction transformer is designed via plugging the Swin transformer under the framework of the MixS2 transformer to independently excavate spatial or spectral features and fuse them thoroughly. Finally, to mitigate the information loss between adjacent stages, stage interaction is also enhanced by proposing a specific feature aggregation module based on the multi-scale attention mechanism. Experiments on both simulation and practical datasets show the state-of-the-art (SOTA) performance and wide application prospects of our method .",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "HEDU-Net：通过可解释的退化补偿改进光谱快照压缩成像",
        "abstract_cn": "随着利用编码孔径快照光谱成像（CASSI）获取高光谱图像（HSI）的广泛采用，重建算法作为CASSI最关键的部分之一变得越来越重要。通过将迭代优化问题表述为多阶段端到端神经网络，深度展开框架在提高重建可靠性和保真度方面取得了可喜的进展。尽管如此，仍然存在限制当前重建算法性能的三个棘手问题：1）预定的感知矩阵忽略了真实和理想退化过程之间的差距。 2）结构不良的特征提取和融合网络，难以有效恢复空间纹理并保证光谱一致性。 3）舞台交互模块不足，阻碍了有用信息的传递。为了解决这些问题，在本文中，我们提出了一种高光谱可解释退化补偿展开神经网络（HEDU-Net），它试图在深度展开策略下使用残差网络动态补偿理想和实际退化过程之间的差异。此外，通过将Swin变压器插入MixS2变压器的框架下，设计了空间-光谱交互变压器，以独立挖掘空间或光谱特征并将其彻底融合。最后，为了减轻相邻阶段之间的信息丢失，还通过提出基于多尺度注意力机制的特定特征聚合模块来增强阶段交互。模拟和实际数据集上的实验表明了我们的方法的最先进的（SOTA）性能和广泛的应用前景。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3629320",
        "title": "Wavefront Estimation From a Single Measurement: Uniqueness and Algorithms",
        "link": "https://doi.org/10.1109/tci.2025.3629320",
        "published": "2025",
        "author": "Nicholas Chimitt, Ali Almuallem, Qi Guo, Stanley H. Chan",
        "summary": "Wavefront estimation is an essential component of adaptive optics where the goal is to recover the underlying phase from its Fourier magnitude. While this may sound identical to classical phase retrieval, wavefront estimation faces more strict requirements regarding uniqueness as adaptive optics systems need a unique phase to compensate for the distorted wavefront. Existing real-time wavefront estimation methodologies are dominated by sensing via specialized optical hardware due to their high speed, but they often have a low spatial resolution. A computational method that can perform both fast and accurate wavefront estimation with a single measurement can improve resolution and bring new applications such as real-time passive wavefront estimation, opening the door to a new generation of medical and defense applications. In this paper, we tackle the wavefront estimation problem by observing that the non-uniqueness is related to the geometry of the pupil shape. By analyzing the source of ambiguities and breaking the symmetry, we present a joint optics-algorithm approach by co-designing the shape of the pupil and the reconstruction neural network. Using our proposed lightweight neural network, we demonstrate wavefront estimation of a phase of size $128\\times 128$ at 5,200 frames per second on a CPU computer, achieving an average Strehl ratio up to 0.98 in the noiseless case. We additionally test our method on real measurements using a spatial light modulator.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "单次测量的波前估计：独特性和算法",
        "abstract_cn": "波前估计是自适应光学的重要组成部分，其目标是从傅里叶幅度恢复基础相位。虽然这听起来与经典相位检索相同，但波前估计面临着关于唯一性的更严格要求，因为自适应光学系统需要独特的相位来补偿扭曲的波前。现有的实时波前估计方法由于速度快而主要通过专门的光学硬件进行传感，但它们通常具有较低的空间分辨率。一种可以通过单次测量进行快速而准确的波前估计的计算方法可以提高分辨率并带来实时被动波前估计等新应用，为新一代医疗和国防应用打开了大门。在本文中，我们通过观察非唯一性与瞳孔形状的几何形状相关来解决波前估计问题。通过分析模糊性的来源和打破对称性，我们通过共同设计瞳孔的形状和重建神经网络，提出了一种联合光学算法方法。使用我们提出的轻量级神经网络，我们在 CPU 计算机上以每秒 5,200 帧的速度演示了大小为 128×128$ 的相位的波前估计，在无噪声情况下实现了高达 0.98 的平均斯特列比。我们还使用空间光调制器在实际测量中测试了我们的方法。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3629414",
        "title": "Accelerated Microwave Tomographic Imaging With a PDE-Constrained Optimization Method",
        "link": "https://doi.org/10.1109/tci.2025.3629414",
        "published": "2025",
        "author": "Stephen H. Kim, Lara Pinar, Andreas H. Hielscher",
        "summary": "We introduce a computationally efficient image reconstruction method that accelerates microwave tomographic imaging while maintaining the accuracy of traditional methods. The new method makes use of a PDE-constrained formulation that allows simultaneous updating both the forward solution (the scattered field) and the inverse solution (dielectric properties) at each optimization iteration. We implement the method within a framework of a reduced Hessian, inexact Newton approach combined with discrete cosine transform (DCT) based image compression and line-search-free updates, which mitigates the ill-posed nature of the problem while improving computational speed. The node-centered finite volume (FV) method is employed as a forward model of the frequency-domain scattered field in the transverse magnetic (TM) mode due to its energy-conservative properties and geometric flexibility. We assess the performance of this new approach using numerical simulations and experimental data. Our results demonstrate that the reduced Hessian DCT-based PDE-constrained approach accelerates the image reconstruction process with a speedup factor from 11 to 28 compared to the unconstrained quasi-Newton method, while maintaining computational stability and robustness to noise and initial guess variation.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "采用偏微分方程约束优化方法的加速微波断层成像",
        "abstract_cn": "我们引入了一种计算高效的图像重建方法，可以加速微波断层扫描成像，同时保持传统方法的准确性。新方法利用偏微分方程约束公式，允许在每次优化迭代时同时更新正解（散射场）和逆解（介电特性）。我们在简化的 Hessian、不精确牛顿方法与基于离散余弦变换 (DCT) 的图像压缩和免线搜索更新相结合的框架内实现该方法，这减轻了问题的不适定性质，同时提高了计算速度。节点中心有限体积（FV）方法因其能量守恒特性和几何灵活性而被用作横磁（TM）模式下频域散射场的正演模型。我们使用数值模拟和实验数据评估这种新方法的性能。我们的结果表明，与无约束拟牛顿法相比，基于简化 Hessian DCT 的 PDE 约束方法可加速图像重建过程，加速因子为 11 至 28，同时保持计算稳定性以及对噪声和初始猜测变化的鲁棒性。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3636746",
        "title": "Fast Correction for Geometric Distortion in PFA Wavefront Curvature Compensation",
        "link": "https://doi.org/10.1109/tci.2025.3636746",
        "published": "2026",
        "author": "Yining Zhang, Jixia Fan, Yanqi Liu, Xinhua Mao",
        "summary": "In large-scene synthetic aperture radar (SAR) imaging, the selection of appropriate algorithms is crucial as it directly impacts processing efficiency and image fidelity. The Polar Format Algorithm (PFA) is widely used for its high-speed image formation capabilities. However, its reliance on the planar wavefront approximation inevitably introduces phase errors. A primary challenge arising from linear components of these errors is geometric distortion, which manifests as space-variant shift from actual positions. Traditional inverse warping correction method based on two-dimensional(2-D) interpolation suffers from high computational costs. To address this limitation, this paper proposes a separable 2-D interpolation framework that decouples the correction process into two one-dimensional (1-D) interpolations along azimuth and range axes. Through inverse solutions of geometric distortion functions, it is demonstrated that applying this framework to geometric distortion correction can effectively reduce the complexity while preserving image precision. Simulations and real-data comparisons validate that the proposed fast geometric distortion correction method significantly improve correction speed thus boosting overall computational efficiency.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "PFA 波前曲率补偿中几何畸变的快速校正",
        "abstract_cn": "在大场景合成孔径雷达（SAR）成像中，选择合适的算法至关重要，因为它直接影响处理效率和图像保真度。极坐标格式算法（PFA）因其高速图像形成能力而被广泛应用。然而，它对平面波前近似的依赖不可避免地引入了相位误差。这些误差的线性分量产生的主要挑战是几何畸变，表现为与实际位置的空间变化偏移。传统的基于二维（2-D）插值的逆扭曲校正方法存在计算成本较高的问题。为了解决这一限制，本文提出了一种可分离的二维插值框架，将校正过程解耦为沿方位轴和距离轴的两个一维（1-D）插值。通过几何畸变函数的逆解，证明将该框架应用于几何畸变校正可以有效降低复杂度，同时保持图像精度。仿真和实际数据比较验证了所提出的快速几何畸变校正方法显着提高了校正速度，从而提高了整体计算效率。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3636744",
        "title": "Rotational Motion Compensation and Sparse ISAR Imaging of Maneuvering Targets via Deep Unrolling Network",
        "link": "https://doi.org/10.1109/tci.2025.3636744",
        "published": "2026",
        "author": "Yue Wang, Xueru Bai, Feng Zhou",
        "summary": "Accurate rotational motion compensation is critical for achieving well-focused inverse synthetic aperture radar (ISAR) imaging of maneuvering targets. However, low signal-to-noise ratio (SNR) and incomplete echoes often lead to significant performance degradation in conventional methods. Furthermore, these methods rely heavily on manual parameter tuning, which limits their adaptability to varying SNR and data missing rate in practical applications. In this article, a novel deep unrolling network for ISAR imaging of maneuvering targets is proposed. Firstly, an iterative method, termed RMC-PDHG, is proposed for rotational motion compensation and well-focused ISAR imaging based on Primal-Dual Hybrid Gradient (PDHG), enabling accurate imaging of maneuvering targets under low SNR and incomplete echo conditions. On this basis, a rotational motion compensation and imaging network, i.e., RMC-PDHG-Net, is developed by unrolling the RMC-PDHG. This network incorporates a hypernetwork to dynamically generate optimal internal parameters such as the regularization coefficient and step size based on intermediate image features, thereby gaining robustness to varying SNR and data missing rate. Additionally, a two-stage training strategy combining unsupervised and supervised learning is proposed to improve rotation parameter estimation accuracy and image reconstruction quality. Experimental results on simulated and measured data have demonstrated the effectiveness and robustness of the proposed network.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "通过深度展开网络对机动目标进行旋转运动补偿和稀疏 ISAR 成像",
        "abstract_cn": "精确的旋转运动补偿对于实现机动目标的聚焦良好的逆合成孔径雷达 (ISAR) 成像至关重要。然而，低信噪比 (SNR) 和不完整的回波通常会导致传统方法的性能显着下降。此外，这些方法严重依赖手动参数调整，这限制了它们对实际应用中变化的信噪比和数据丢失率的适应性。在本文中，提出了一种用于机动目标 ISAR 成像的新型深度展开网络。首先，提出了一种称为RMC-PDHG的迭代方法，用于基于原始对偶混合梯度（PDHG）的旋转运动补偿和聚焦良好的ISAR成像，能够在低信噪比和不完整回波条件下对机动目标进行精确成像。在此基础上，通过展开RMC-PDHG开发了旋转运动补偿和成像网络，即RMC-PDHG-Net。该网络结合了超网络，可以根据中间图像特征动态生成最佳内部参数，例如正则化系数和步长，从而获得对变化的信噪比和数据丢失率的鲁棒性。此外，提出了一种结合无监督和监督学习的两阶段训练策略，以提高旋转参数估计精度和图像重建质量。模拟和测量数据的实验结果证明了所提出网络的有效性和鲁棒性。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3636743",
        "title": "Convergence-Guaranteed Spectral CT Reconstruction via Internal and External Prior Mining",
        "link": "https://doi.org/10.1109/tci.2025.3636743",
        "published": "2026",
        "author": "Chunyan Liu, Dianlin Hu, Jiangjun Peng, Hong Wang, Qianyu Shu, Jianjun Wang",
        "summary": "Spectral computed tomography (CT) is an imaging technology that utilizes the absorption characteristics of different X-ray energies to obtain the X-ray attenuation characteristics of objects in different energy ranges. However, the limited number of photons detected by spectral CT under a specific X-ray spectrum leads to obvious projection data noise. Making full use of the various properties of the original data is an effective way to recover a clean image from a small amount of noisy projection data. This paper proposes a spectral CT reconstruction method based on representative coefficient image denoising under a low-rank decomposition framework. This method integrates model-driven internal low-rank and nonlocal priors, and data-driven external deep priors, aiming to fully exploit the inherent spectral correlation, nonlocal self-similarity and deep spatial features in spectral CT images. Specifically, we use low-rank decomposition to characterize the global low-rankness of spectral CT images under a plug-and-play framework, and jointly utilize nonlocal low-rankness and smoothness as well as deep image priors to denoise representative coefficient images. Therefore, the proposed method faithfully represents the real underlying information of images by cleverly combining internal and external, nonlocal and local priors. Meanwhile, we design an effective proximal alternating minimization (PAM) algorithm to solve the proposed reconstruction model and establish the theoretical guarantee of the proposed algorithm. Experimental results show that compared with existing popular algorithms, the proposed method can significantly reduce running time while improving spectral CT images quality.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "通过内部和外部先验挖掘保证收敛的光谱 CT 重建",
        "abstract_cn": "能谱计算机断层扫描（CT）是利用不同X射线能量的吸收特性来获取物体在不同能量范围内的X射线衰减特性的成像技术。然而，特定X射线谱下能谱CT检测到的光子数量有限，导致投影数据噪声明显。充分利用原始数据的各种属性是从少量噪声投影数据中恢复出干净图像的有效方法。本文提出了一种低秩分解框架下基于代表系数图像去噪的能谱CT重建方法。该方法集成了模型驱动的内部低秩和非局部先验以及数据驱动的外部深层先验，旨在充分利用能谱CT图像中固有的谱相关性、非局部自相似性和深层空间特征。具体来说，我们在即插即用框架下使用低秩分解来表征能谱CT图像的全局低秩性，并联合利用非局部低秩性和平滑性以及深度图像先验来对代表系数图像进行去噪。因此，该方法通过巧妙地结合内部和外部、非局部和局部先验，忠实地表示了图像的真实底层信息。同时，我们设计了一种有效的近端交替最小化（PAM）算法来求解所提出的重建模型，并为所提出的算法建立了理论保证。实验结果表明，与现有流行算法相比，该方法可以显着减少运行时间，同时提高能谱CT图像质量。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3636749",
        "title": "Multi-Slice Knowledge-Driven System Matrix Calibration in Magnetic Particle Imaging",
        "link": "https://doi.org/10.1109/tci.2025.3636749",
        "published": "2026",
        "author": "Pengyue Guo, Zechen Wei, Yu Zeng, Bingye Wang, Yidong Liao, Jiawei Hu, Lingwen Hou, Kai Liu, Ning He, Qibin Wang, Lei Li, Hui Hui, Yihan Wang, Shouping Zhu, Jie Tian",
        "summary": "Magnetic particle imaging (MPI) is a novel tomographic imaging technique with high sensitivity and high temporal resolution. Reconstruction methods based on the system matrix (SM) enable accurate estimation of the concentration distribution of magnetic nanoparticles. However, SM calibration measurement is highly time-consuming, and the SM needs to be recalibrated whenever the scan parameters, particle types, or even the particle environment change. Although previous studies have proposed methods to accelerate SM calibration, these approaches do not fully exploit the similarity between the two-dimensional (2D) SMs of adjacent slices. In this study, we propose a multi-slice knowledge-driven SM calibration method, MKD-SM, which leverages knowledge obtained from multiple adjacent x-y slices to improve SM calibration accuracy at high downsampling ratios. Specifically, based on the significant similarity of the 2D SMs from adjacent x-y slices, MKD-SM employs a cross-misaligned sampling method to obtain the low-resolution (LR) SM within the field of view (FOV), ensuring that the 2D LR SMs obtained from adjacent slices exhibit complementarity. Additionally, we use a federated affinity fusion method to aggregate the complementary knowledge across multiple adjacent slices and utilize an architecture based on a cascade of CNNs and transformers for high-resolution (HR) SM recovery. Experimental results on the public OpenMPI dataset demonstrate that MKD-SM outperforms existing calibration methods, achieving higher SM calibration accuracy, particularly at high downsampling ratios. Ablation studies confirm the effectiveness of leveraging knowledge from adjacent slices. Furthermore, the proposed method has been successfully applied to an in-house field-free line (FFL) MPI scanner, enabling HR image reconstruction with LR SM measurements.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "磁粒子成像中的多切片知识驱动系统矩阵校准",
        "abstract_cn": "磁粒子成像（MPI）是一种具有高灵敏度和高时间分辨率的新型断层成像技术。基于系统矩阵（SM）的重建方法能够准确估计磁性纳米粒子的浓度分布。然而，SM校准测量非常耗时，每当扫描参数、粒子类型甚至粒子环境发生变化时，都需要重新校准SM。尽管之前的研究提出了加速 SM 校准的方法，但这些方法并没有充分利用相邻切片的二维 (2D) SM 之间的相似性。在本研究中，我们提出了一种多切片知识驱动的 SM 校准方法 MKD-SM，该方法利用从多个相邻 x-y 切片获得的知识来提高高下采样率下的 SM 校准精度。具体来说，基于相邻x-y切片的2D SM的显着相似性，MKD-SM采用交叉错位采样方法来获得视场（FOV）内的低分辨率（LR）SM，确保从相邻切片获得的2D LR SM表现出互补性。此外，我们使用联合亲和融合方法来聚合多个相邻切片之间的互补知识，并利用基于 CNN 和转换器级联的架构来实现高分辨率 (HR) SM 恢复。公共 OpenMPI 数据集上的实验结果表明，MKD-SM 优于现有的校准方法，实现了更高的 SM 校准精度，特别是在高下采样率下。消融研究证实了利用相邻切片知识的有效性。此外，所提出的方法已成功应用于内部无场线 (FFL) MPI 扫描仪，从而能够通过 LR SM 测量进行 HR 图像重建。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3636750",
        "title": "SFTNet: Strip Fourier Transform Network for Motion Deblurring",
        "link": "https://doi.org/10.1109/tci.2025.3636750",
        "published": "2026",
        "author": "Jun Li, Maohua Wang, Li Xu, Yifan Wu, Yin Gao",
        "summary": "Deep learning has significantly advanced motion deblurring. However, most existing methods do not fully exploit the synergy between spatial and frequency domains, and conventional channel attention mechanisms are suboptimal for frequency-domain feature representation, thereby limiting further progress. To address these limitations, we propose integrating spatial deformation and frequency analysis through a Strip Fourier Transform Module (SFTM). SFTM exploits blur characteristics to enhance motion feature extraction. Additionally, we introduce an Instance Frequency-Domain Channel Attention (IFCA) module, which exploits both low- and high-frequency components to extract salient features. The resulting Strip Fourier Transform Network (SFTNet), combining frequency- and spatial-domain techniques, outperforms existing methods by improving deblurring performance while reducing computational complexity. Extensive experiments on benchmark datasets demonstrate that our method consistently achieves superior results in complex scenarios compared to state-of-the-art approaches.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "SFTNet：用于运动去模糊的带状傅里叶变换网络",
        "abstract_cn": "深度学习显着改进了运动去模糊。然而，大多数现有方法没有充分利用空间域和频域之间的协同作用，并且传统的通道注意机制对于频域特征表示来说不是最优的，从而限制了进一步的进展。为了解决这些限制，我们建议通过带状傅立叶变换模块（SFTM）集成空间变形和频率分析。 SFTM 利用模糊特征来增强运动特征提取。此外，我们还引入了实例频域通道注意（IFCA）模块，该模块利用低频和高频分量来提取显着特征。由此产生的带状傅立叶变换网络 (SFTNet) 结合了频域和空间域技术，通过提高去模糊性能同时降低计算复杂性，优于现有方法。对基准数据集的大量实验表明，与最先进的方法相比，我们的方法在复杂场景中始终能取得优异的结果。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3636751",
        "title": "Learning Generalized Mapping Functions via Deep-Unrolling for PET Image Reconstruction",
        "link": "https://doi.org/10.1109/tci.2025.3636751",
        "published": "2025",
        "author": "Hitesh D. Khunti, Bhaskar D. Rao",
        "summary": "This paper presents a unified framework that synergically combines model-based iterative algorithms with deep learning-based approaches for tomographic image reconstruction. In particular, the proposed method integrates the interpretability and adaptability of model-based techniques with the expressive power of deep learning,enabling sophisticated non-linear and data-driven priors that enhance reconstruction quality. This synergy yields a framework that is interpretable, robust, generalizable, and produces higher-quality images, effectively addressing key limitations of model-based and learning-based approaches in isolation. First, we show there exists a simple approach to generalize and accelerate Expectation Maximization algorithms which can adaptively speedup convergence based on individual voxel values. We then introduce a key re-parametrization that enables viewing multiple reconstruction algorithms as special cases of a general mapping function between iterations. Building on these insights, we propose a novel model-based deep neural network architecture that effectively is a generalized deep unrolling of a family of algorithms. The proposed method learns to reconstruct high-quality images by systematically performing the required trade-off across the represented algorithms, or it can learn a specific algorithm through training without compromising its robustness and generalization. Furthermore, to address the scarcity of PET imaging data the proposed method can be trained both in supervised and self-supervised regime. Our approach demonstrates superior adaptation with limited training data across varying noise levels, scan duration and out-of-distribution data. Experimental results show significant improvements in image quality compared to both existing iterative methods and deep learning approaches, while maintaining computational efficiency and theoretical interpretability. Code is publicly available online.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "通过深度展开学习广义映射函数以进行 PET 图像重建",
        "abstract_cn": "本文提出了一个统一的框架，它将基于模型的迭代算法与基于深度学习的断层图像重建方法协同结合。特别是，所提出的方法将基于模型的技术的可解释性和适应性与深度学习的表达能力相结合，实现复杂的非线性和数据驱动的先验，从而提高重建质量。这种协同作用产生了一个可解释、稳健、可推广的框架，并生成更高质量的图像，有效地解决了基于模型和基于学习的方法的关键局限性。首先，我们证明存在一种简单的方法来概括和加速期望最大化算法，该算法可以根据单个体素值自适应地加速收敛。然后，我们引入了一个关键的重新参数化，可以将多个重建算法视为迭代之间一般映射函数的特殊情况。基于这些见解，我们提出了一种新颖的基于模型的深度神经网络架构，它实际上是一系列算法的广义深度展开。所提出的方法通过在所表示的算法之间系统地执行所需的权衡来学习重建高质量图像，或者它可以通过训练来学习特定的算法，而不会影响其鲁棒性和泛化性。此外，为了解决 PET 成像数据的稀缺问题，所提出的方法可以在监督和自我监督的情况下进行训练。我们的方法展示了对不同噪声水平、扫描持续时间和分布外数据的有限训练数据的卓越适应能力。实验结果表明，与现有迭代方法和深度学习方法相比，图像质量显着提高，同时保持计算效率和理论可解释性。代码可在线公开获取。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3636757",
        "title": "Low-Rank Decomposition and Polarization-Driven Transmittance Synergy for Underwater Descattering With Cross-Domain Generalization",
        "link": "https://doi.org/10.1109/tci.2025.3636757",
        "published": "2025",
        "author": "Weifeng Kong, Guanying Huo, Chao Peng, Yong Su, Zhen Cheng",
        "summary": "To address the challenge of image degradation caused by light scattering in turbid underwater environments, this study proposes an underwater descattering framework integrating polarization physics with low-rank decomposition. First, a dynamic attenuation-regularized low-rank decomposition model is established, enabling adaptive parameter adjustment to separate background scattered light from target signals. Then, a nonlinear correlation equation for polarization-driven transmittance based on Beer-Lambert Law is developed, combining isotropic intensity attenuation transmittance through adaptive weighting mechanism to establish the composite transmittance, more in line with the underwater optical and physical characteristics Finally, a dual-constraint optimization architecture is designed to effectively suppress descattering noise. Experimental results demonstrate that our method achieves better imaging results and significant improvements in key metrics. This research establishes an innovative “underwater imaging-cross-domain migration” paradigm for scattering environment imaging, showing promising applications in marine exploration and intelligent navigation.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "具有跨域泛化的水下去散射的低阶分解和偏振驱动透射率协同作用",
        "abstract_cn": "为了解决浑浊水下环境中光散射引起的图像退化的挑战，本研究提出了一种将偏振物理与低阶分解相结合的水下去散射框架。首先，建立动态衰减正则化低秩分解模型，实现自适应参数调整以将背景散射光与目标信号分离。然后，建立基于比尔-朗伯定律的偏振驱动透射率非线性相关方程，通过自适应加权机制结合各向同性强度衰减透射率，建立更符合水下光学和物理特性的复合透射率。最后，设计双约束优化架构，有效抑制去散射噪声。实验结果表明，我们的方法取得了更好的成像结果，并在关键指标上取得了显着改进。该研究建立了一种创新的“水下成像-跨域偏移”散射环境成像范式，在海洋勘探和智能导航中展示了良好的应用前景。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3640864",
        "title": "Moving Targets Imaging by SVD of a Space-Velocity MIMO Radar Data Driven Matrix",
        "link": "https://doi.org/10.1109/tci.2025.3640864",
        "published": "2026",
        "author": "Liliana Borcea, Josselin Garnier",
        "summary": "We introduce a method for Multiple Input Multiple Output (MIMO) radar imaging of moving targets in a strongly reflecting, complex stationary scenery (clutter). The radar system has fixed nearby antennas that play the dual role of sources and receivers. It gathers data either by emitting probing pulses from one antenna at a time, or by sending from all the antennas non-coherent, possibly orthogonal, waveforms. We show how to obtain from the measurements an imaging function that depends on search position and velocity and is approximately separable in these variables, for a single moving target. For multiple moving targets in clutter, the imaging function is a sum of separable functions. By sampling this imaging function on a position-velocity grid we obtain an imaging matrix whose Singular Value Decomposition (SVD) allows the separation of the clutter and the targets moving at different velocities. The decomposition also leads directly to estimates of the locations and motion of the targets. The imaging method is designed to work in strong clutter, with unknown and possibly heterogeneous statistics. It does not require prior estimation of the covariance matrix of the clutter response or of its rank. We give an analysis of the imaging method and illustrate how it works with numerical simulations.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "空速 MIMO 雷达数据驱动矩阵的 SVD 移动目标成像",
        "abstract_cn": "我们介绍了一种在强反射、复杂的静止场景（杂波）中对移动目标进行多输入多输出 (MIMO) 雷达成像的方法。雷达系统附近有固定的天线，起到信号源和接收器的双重作用。它通过一次从一根天线发射探测脉冲，或者通过从所有天线发送非相干（可能是正交）波形来收集数据。我们展示了如何从测量中获得成像函数，该函数取决于搜索位置和速度，并且对于单个移动目标，这些函数在这些变量中近似可分离。对于杂波中的多个运动目标，成像函数是可分离函数的和。通过在位置速度网格上对该成像函数进行采样，我们获得了一个成像矩阵，其奇异值分解（SVD）可以分离杂波和以不同速度移动的目标。分解还直接导致对目标位置和运动的估计。该成像方法设计用于在强杂波、未知且可能异构的统计数据中工作。它不需要事先估计杂波响应的协方差矩阵或其秩。我们对成像方法进行了分析，并说明了它如何与数值模拟一起工作。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3640427",
        "title": "Multilevel Plug-and-Play Image Restoration",
        "link": "https://doi.org/10.1109/tci.2025.3640427",
        "published": "2025",
        "author": "Nils Laurent, Julián Tachella, Elisa Riccietti, Nelly Pustelnik",
        "summary": "Plug-and-play (PnP) image reconstruction methods leverage pretrained deep neural network denoisers as image priors to solve general inverse problems, and can obtain a competitive performance without having to train a network on a specific problem. Despite their flexibility, PnP methods often require several iterations to converge and their performance can be highly sensitive to the choice of the initialization and of the hyperparameters. In this paper, we propose a new multilevel PnP framework to accelerate the convergence of PnP methods in the context of large-scale images. The proposed scheme, following a coarse-to-fine strategy, is initialized at the coarsest scale and the resolution of the starting point is progressively improved to reach the fine level with the highest resolution. The scheme then combines classical PnP iterations with cheaper iterations, involv ing representations of the images at coarser scales. As a result of the combination of these two ingredients, the multilevel PnP scheme accelerates the convergence and improves the robustness to the choice of initialization and hyperparameters. In a series of experiments, including image inpainting, demosaicing, and deblurring, we show that the proposed multilevel PnP method outperforms other PnP methods in both speed and reconstruction performance.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "多级即插即用图像修复",
        "abstract_cn": "即插即用（PnP）图像重建方法利用预训练的深度神经网络降噪器作为图像先验来解决一般逆问题，并且无需在特定问题上训练网络即可获得有竞争力的性能。尽管 PnP 方法具有灵活性，但它们通常需要多次迭代才能收敛，并且它们的性能对初始化和超参数的选择高度敏感。在本文中，我们提出了一种新的多级 PnP 框架，以加速大规模图像背景下 PnP 方法的收敛。所提出的方案遵循从粗到细的策略，在最粗的尺度上进行初始化，并逐步提高起始点的分辨率以达到最高分辨率的精细水平。然后，该方案将经典的 PnP 迭代与更便宜的迭代相结合，涉及更粗尺度的图像表示。由于这两个因素的结合，多级 PnP 方案加速了收敛并提高了初始化和超参数选择的鲁棒性。在一系列实验中，包括图像修复、去马赛克和去模糊，我们表明所提出的多级 PnP 方法在速度和重建性能方面都优于其他 PnP 方法。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3641031",
        "title": "Distribution-Adaptive Hierarchical Quantization Enhanced Binary Networks for Spectral Compressive Imaging",
        "link": "https://doi.org/10.1109/tci.2025.3641031",
        "published": "2026",
        "author": "Mengying Jin, Liang Xiao, Zhihui Wei",
        "summary": "Hyperspectral image processing faces significant challenges in storage and computation. Snapshot Compressive Imaging (SCI) effectively encodes three-dimensional data into two-dimensional measurements, facilitating efficient data acquisition. However, reconstructing high-quality data from these compressed measurements remains a formidable task. Binary Neural Networks (BNNs) have gained attention for their ability to reduce storage requirements and computational costs. Yet, they often struggle with accuracy loss, fixed quantization limits, and lack of domain knowledge utilization. To overcome these limitations, distribution-adaptive hierarchical quantization-enhanced binary networks are proposed to achieve efficient SCI reconstruction. First, an adaptive distribution strategy and a binary weight evaluation branch are proposed to improve representation accuracy. Second, a hierarchical quantization scheme is presented to enhance multiscale feature extraction while maintaining efficiency. Third, domain-specific priors and a novel sparsity constraint are incorporated to capture fine details and improve training stability. The experimental results demonstrate the superiority of our approach, achieving an increase of 1.98 dB in PSNR and an improvement of 0.055 in SSIM compared to state-of-the-art BNNs.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "用于光谱压缩成像的分布自适应分层量化增强二元网络",
        "abstract_cn": "高光谱图像处理在存储和计算方面面临重大挑战。快照压缩成像 (SCI) 有效地将三维数据编码为二维测量，促进高效的数据采集。然而，从这些压缩测量中重建高质量数据仍然是一项艰巨的任务。二元神经网络 (BNN) 因其降低存储需求和计算成本的能力而受到关注。然而，他们经常面临精度损失、固定量化限制和缺乏领域知识利用等问题。为了克服这些限制，提出了分布自适应分层量化增强二元网络来实现高效的 SCI 重建。首先，提出了自适应分布策略和二进制权重评估分支来提高表示精度。其次，提出了一种分层量化方案来增强多尺度特征提取，同时保持效率。第三，结合特定领域的先验和新颖的稀疏约束来捕获精细细节并提高训练稳定性。实验结果证明了我们的方法的优越性，与最先进的 BNN 相比，PSNR 提高了 1.98 dB，SSIM 提高了 0.055。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3641749",
        "title": "List of Reviewers",
        "link": "https://doi.org/10.1109/tci.2025.3641749",
        "published": "2025",
        "author": "Unknown",
        "summary": "Abstract not available.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "审稿人名单",
        "abstract_cn": "（摘要暂缺，等待官方补全）"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3642761",
        "title": "M\n                    <sup>3</sup>\n                    Depth: Wavelet-Enhanced Depth Estimation on Mars via Mutual Boosting of Dual-Modal Data",
        "link": "https://doi.org/10.1109/tci.2025.3642761",
        "published": "2026",
        "author": "Junjie Li, Jiawei Wang, Miyu Li, Yu Liu, Yumei Wang, Haitao Xu",
        "summary": "Depth estimation plays a great potential role in obstacle avoidance and navigation for further Mars exploration missions. Compared to traditional stereo matching, learning-based stereo depth estimation provides a data-driven approach to infer dense and precise depth maps from stereo image pairs. However, these methods always suffer performance degradation in environments with sparse textures and lacking geometric constraints, such as the unstructured terrain of Mars. To address these challenges, we propose M3Depth, a depth estimation model tailored for Mars rovers. Considering the sparse and smooth texture of Martian terrain, which is primarily composed of low-frequency features, our model incorporates a convolutional kernel based on wavelet transform that effectively captures low-frequency response and expands the receptive field. Additionally, we introduce a consistency loss that explicitly models the complementary relationship between depth map and surface normal map, utilizing the surface normal as a geometric constraint to enhance the accuracy of depth estimation. Besides, a pixel-wise refinement module with mutual boosting mechanism is designed to iteratively refine both depth and surface normal predictions. Experimental results on synthetic Mars datasets with depth annotations show that M3Depth achieves a 16% improvement in depth estimation accuracy compared to other state-of-the-art methods in depth estimation. Furthermore, the model demonstrates strong applicability in real-world Martian scenarios, offering a promising solution for future Mars exploration missions.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "M <sup>3</sup> 深度：通过双模态数据相互增强的小波增强火星深度估计",
        "abstract_cn": "深度估计在进一步火星探测任务的避障和导航中发挥着巨大的潜在作用。与传统的立体匹配相比，基于学习的立体深度估计提供了一种数据驱动的方法来从立体图像对推断密集且精确的深度图。然而，这些方法在纹理稀疏且缺乏几何约束的环境中总是会出现性能下降，例如火星的非结构化地形。为了应对这些挑战，我们提出了 M3Depth，这是一种为火星探测器量身定制的深度估计模型。考虑到火星地形的稀疏和光滑纹理主要由低频特征组成，我们的模型结合了基于小波变换的卷积核，可以有效捕获低频响应并扩大感受野。此外，我们引入了一致性损失，它明确地模拟了深度图和表面法线图之间的互补关系，利用表面法线作为几何约束来提高深度估计的准确性。此外，还设计了具有相互增强机制的像素级细化模块，以迭代地细化深度和表面法线预测。在具有深度注释的合成火星数据集上的实验结果表明，与其他最先进的深度估计方法相比，M3Depth 的深度估计精度提高了 16%。此外，该模型在现实火星场景中表现出强大的适用性，为未来的火星探索任务提供了一个有前景的解决方案。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3642236",
        "title": "Self-Supervised Learning-Based Reconstruction of High-Resolution 4D Light Fields",
        "link": "https://doi.org/10.1109/tci.2025.3642236",
        "published": "2026",
        "author": "Jianxin Lei, Dongze Wu, Chengcai Xu, Hongcheng Gu, Guangquan Zhou, Junhui Hou, Ping Zhou",
        "summary": "Hand-held light field (LF) cameras often exhibit low spatial resolution due to the inherent trade-off between spatial and angular dimensions. Existing supervised learning-based LF spatial super-resolution (SR) methods, which rely on pre-defined image degradation models, struggle to overcome the domain gap between the training phase—where LFs with natural resolution are used as ground truth—and the inference phase, which aims to reconstruct higher-resolution LFs, especially when applied to real-world data. To address this challenge, this paper introduces a novel self-supervised learning-based method for LF spatial SR, which can produce higher spatial resolution LF images than originally captured ones without pre-defined image degradation models. The self-supervised method incorporates a hybrid LF imaging prototype, a real-world hybrid LF dataset, and a self-supervised LF spatial SR framework. The prototype makes reference image pairs between low-resolution central-view sub-aperture images and high-resolution (HR) images. The self-supervised framework consists of a well-designed LF spatial SR network with hybrid input, a central-view synthesis network with an HR-aware loss that enables side-view sub-aperture images to learn high-frequency information from the only HR central view reference image, and a backward degradation network with an epipolar-plane image gradient loss to preserve LF parallax structures. Extensive experiments on both simulated and real-world datasets demonstrate the significant superiority of our approach over state-of-the-art ones in reconstructing higher spatial resolution LF images without pre-defined degradation.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "基于自监督学习的高分辨率 4D 光场重建",
        "abstract_cn": "由于空间和角度维度之间固有的权衡，手持式光场 (LF) 相机通常表现出较低的空间分辨率。现有的基于监督学习的 LF 空间超分辨率 (SR) 方法依赖于预定义的图像退化模型，难以克服训练阶段（将具有自然分辨率的 LF 用作地面实况）和推理阶段（旨在重建更高分辨率的 LF）之间的域差距，尤其是在应用于现实世界数据时。为了应对这一挑战，本文引入了一种新颖的基于自监督学习的 LF 空间 SR 方法，该方法可以在没有预定义图像退化模型的情况下生成比原始捕获的图像更高的空间分辨率 LF 图像。自监督方法结合了混合 LF 成像原型、现实世界的混合 LF 数据集和自监督 LF 空间 SR 框架。该原型在低分辨率中央视图子孔径图像和高分辨率（HR）图像之间建立参考图像对。自监督框架由精心设计的具有混合输入的 LF 空间 SR 网络、具有 HR 感知损失的中心视图合成网络（使侧视子孔径图像能够从唯一的 HR 中心视图参考图像中学习高频信息）以及具有极面图像梯度损失以保留 LF 视差结构的后向退化网络组成。对模拟和现实世界数据集的大量实验表明，我们的方法在重建更高空间分辨率的低频图像而没有预定义的退化方面比最先进的方法具有显着的优越性。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3643318",
        "title": "Constrained Conditional Denoising Diffusion for Hyperspectral-Multispectral Fusion",
        "link": "https://doi.org/10.1109/tci.2025.3643318",
        "published": "2026",
        "author": "James E. Fowler",
        "summary": "Diffusion models have recently risen to prominence for a variety of inverse-imaging problems. Many such models use what is commonly known as conditional diffusion which effectively samples from the distribution of the desired image conditioned on some known side information, often a degraded or lower-resolution version of the target image. However, an alternative paradigm has recently emerged in the form of constrained diffusion in which explicit constraints between the target image and the side information are iteratively incorporated into the diffusion reconstruction during inference. While prior literature has considered conditional and constrained diffusion to effectively be mutually exclusive, a diffusion algorithm is proposed to combine the two within the widely-used denoising diffusion probabilistic models (DDPM) framework. The resulting approach—constrained conditional denoising diffusion—inputs both the target and side information into the diffusion network during both training and inference similar to conditional diffusion but also applies explicit constraints during inference like constrained diffusion. The proposed approach is evaluated for the task of fusing a hyperspectral image, possessing high spectral resolution, with a multispectral image, having high spatial resolution, to yield an image with high resolution both spatially and spectrally, an inverse-imaging problem called hyperspectral-multispectral fusion. Experimental results demonstrate that, not only can constrained and conditional diffusion operate complementarily and achieve performance superior to either used alone, but also that the proposed constrained conditional denoising diffusion outperforms other state-of-the-art approaches for hyperspectral-multispectral fusion.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "高光谱-多光谱融合的约束条件去噪扩散",
        "abstract_cn": "扩散模型最近在各种逆成像问题中日益受到重视。许多这样的模型使用通常所说的条件扩散，它根据一些已知的辅助信息（通常是目标图像的降级或较低分辨率版本）从所需图像的分布中有效地进行采样。然而，最近出现了一种替代范式，即约束扩散的形式，其中目标图像和辅助信息之间的显式约束在推理过程中迭代地纳入扩散重建中。虽然先前文献认为条件扩散和约束扩散实际上是相互排斥的，但提出了一种扩散算法，将两者结合在广泛使用的去噪扩散概率模型（DDPM）框架内。由此产生的方法——约束条件去噪扩散——在训练和推理过程中将目标信息和辅助信息输入扩散网络，类似于条件扩散，但也在推理过程中应用显式约束，如约束扩散。所提出的方法针对将具有高光谱分辨率的高光谱图像与具有高空间分辨率的多光谱图像融合的任务进行评估，以产生在空间和光谱上都具有高分辨率的图像，这是一种称为高光谱-多光谱融合的逆成像问题。实验结果表明，约束扩散和条件扩散不仅可以互补运行并实现优于单独使用的性能，而且所提出的约束条件去噪扩散优于其他最先进的高光谱-多光谱融合方法。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3643313",
        "title": "DANG: Data Augmentation Based on NIR-II Guided Diffusion Model for Fluorescence Molecular Tomography",
        "link": "https://doi.org/10.1109/tci.2025.3643313",
        "published": "2026",
        "author": "Qiushi Huang, Chunzhao Li, Anqi Xiao, Jie Tian, Zhenhua Hu",
        "summary": "Fluorescence molecular tomography (FMT), particularly within the second near-infrared window (NIR-II, 1000-1700 nm), is a sophisticated imaging technique for numerous medical applications, enabling reconstruction of the threedimensional distribution of internal tumors from surface fluorescence signals. Recent studies have demonstrated the effectiveness of deep learning methods in FMT reconstruction tasks; however, their performance heavily relies on large-scale, diverse labeled datasets. The existing research primarily focuses on datasets with static tumor characteristics, including fixed tumor numbers, locations, and sizes, which show an insufficient pattern diversity, limiting the neural networks' generalization ability for complex real-world scenarios. To address this limitation, we draw inspiration from the similarity between Monte Carlo photon simulation and the sampling process of diffusion model, to propose a diffusion-based data augmentation strategy. Further, we introduce a novel NIR-II-specific guidance mechanism to enhance sample fidelity and diversity by incorporating spectral optical properties. Quantitative analysis validated that high-quality NIR-II fluorescence signal samples are synthesized, where the proposed NIR-II guidance achieved a 56.7% reduction in Fréchet Inception Distance and a 21.5% improvement in Inception Score, covering a broad spectrum of patterns. Since the synthetic samples are unlabeled, they are integrated with the original dataset to train FMT neural networks using semi-supervised learning. By combining patterndiversifying strengths of diffusion models with semi-supervised learning, the proposed strategy maximizes the utility of limited datasets. Both simulative and in vivo experiments confirmed that data augmentation significantly enhances the network's reconstruction performance in precisely localizing tumor sources and reconstructing complex morphologies.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "DANG：基于 NIR-II 引导扩散模型的荧光分子断层扫描数据增强",
        "abstract_cn": "荧光分子断层扫描 (FMT)，特别是在第二近红外窗口（NIR-II，1000-1700 nm）内，是一种适用于众多医学应用的复杂成像技术，能够根据表面荧光信号重建内部肿瘤的三维分布。最近的研究证明了深度学习方法在 FMT 重建任务中的有效性；然而，它们的性能很大程度上依赖于大规模、多样化的标记数据集。现有的研究主要集中在具有静态肿瘤特征的数据集，包括固定的肿瘤数量、位置和大小，其模式多样性不足，限制了神经网络对复杂现实场景的泛化能力。为了解决这个限制，我们从蒙特卡罗光子模拟和扩散模型采样过程的相似性中汲取灵感，提出了一种基于扩散的数据增强策略。此外，我们引入了一种新颖的 NIR-II 特定引导机制，通过结合光谱光学特性来增强样品保真度和多样性。定量分析验证了合成了高质量的 NIR-II 荧光信号样本，其中提出的 NIR-II 指导实现了 Fréchet 起始距离减少 56.7%，起始分数提高 21.5%，涵盖了广泛的模式。由于合成样本未标记，因此它们与原始数据集集成，以使用半监督学习训练 FMT 神经网络。通过将扩散模型的模式多样化优势与半监督学习相结合，所提出的策略最大化了有限数据集的效用。模拟和体内实验均证实，数据增强显着增强了网络在精确定位肿瘤源和重建复杂形态方面的重建性能。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3643726",
        "title": "High Temporal-Lateral Resolution Photoacoustic Microscopy Imaging With Dual Branch Graph Induced Fusion Network",
        "link": "https://doi.org/10.1109/tci.2025.3643726",
        "published": "2026",
        "author": "Zhengyuan Zhang, Xiangjun Yin, Zhuoyi Lin, Wenwen Zhang, Ze Feng, Arunima Sharma, Manojit Pramanik, Chia-Wen Lin, Yuanjin Zheng",
        "summary": "Photoacoustic microscopy (PAM) is a novel implementation of photoacoustic imaging (PAI) for visualizing the 3D bio-structure, which is realized by raster scanning of the tissue. However, temporal resolution, lateral resolution, and penetration depth, as three involved critical imaging parameters, have mutual effect to one the other. The improvement of one parameter results in the degradation of other two parameters, which constrains the overall performance of the PAM system. In this work, we propose to break these limitations by hardware and software co-design. Starting with low lateral resolution, low sampling rate AR-PAM imaging which possesses deep penetration capability, we aim to enhance the lateral resolution and upscale the images, so that high temporal resolution (scanning speed), high lateral resolution, and deep penetration for the PAM system can be achieved. Considering huge information gap between input image and target image, a dedicated dual branch network is proposed, which includes a high resolution branch and a high speed branch to fully extract embedded information from training data. What's more, to effectively fuse the high level semantic information and low level spatial details from these two branches, a novel self-attention and graph induced fusion module is designed. This module significantly eliminates blurring effect to enhance imaging resolution and amplifies the true signal to increase imaging contrast, as proved by comparison algorithms. As a result, the imaging speed is increased 16× times and the imaging lateral resolution is improved 5× times, while the deep penetration merit of AR-PAM modality is still reserved.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "采用双分支图诱导融合网络的高时间横向分辨率光声显微成像",
        "abstract_cn": "光声显微镜 (PAM) 是光声成像 (PAI) 的一种新颖实现方式，用于可视化 3D 生物结构，这是通过组织的光栅扫描实现的。然而，时间分辨率、横向分辨率和穿透深度这三个关键成像参数相互影响。一个参数的提高会导致另外两个参数的下降，从而制约PAM系统的整体性能。在这项工作中，我们建议通过硬件和软件协同设计来打破这些限制。我们从具有深穿透能力的低横向分辨率、低采样率AR-PAM成像入手，提高横向分辨率，提升图像质量，从而实现PAM系统的高时间分辨率（扫描速度）、高横向分辨率和深穿透能力。考虑到输入图像和目标图像之间巨大的信息差距，提出了一种专用的双分支网络，其中包括高分辨率分支和高速分支，以从训练数据中充分提取嵌入信息。此外，为了有效地融合这两个分支的高级语义信息和低级空间细节，设计了一种新颖的自注意力和图诱导融合模块。对比算法证明，该模块可显着消除模糊效应，提高成像分辨率，并放大真实信号，提高成像对比度。成像速度提高了16倍，成像横向分辨率提高了5倍，同时仍然保留了AR-PAM模态的深穿透优点。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3644225",
        "title": "Taking advantage of multiple scattering for Optical Reflection Tomography",
        "link": "https://doi.org/10.1109/tci.2025.3644225",
        "published": "2025",
        "author": "Thomas Wasik, Victor Barolle, Alexandre Aubry, Josselin Garnier",
        "summary": "Optical Diffraction Tomography (ODT) is a powerful non-invasive imaging technique widely used in biological and medical applications. While significant progress has been made in transmission configuration, reflection ODT remains challenging due to the ill-posed nature of the inverse problem. We present a novel optimization algorithm for 3D refractive index (RI) reconstruction in reflection-mode microscopy. Our method takes advantage of the multiply-scattered waves that are reflected by uncontrolled background structures and that illuminate the foreground RI from behind. It tackles the ill-posed nature of the problem using weighted time loss, positivity constraints and Total Variation regularization. We have validated our method with data generated by detailed 2D and 3D simulations, demonstrating its performance under weak scattering conditions and with simplified forward models used in the optimization routine for computational efficiency. In addition, we highlight the need for multi-wavelength analysis and the use of regularization to ensure the reconstruction of the low spatial frequencies of the foreground RI.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "利用多次散射进行光学反射断层扫描",
        "abstract_cn": "光学衍射断层扫描 (ODT) 是一种强大的非侵入性成像技术，广泛应用于生物和医学应用。虽然传输配置方面取得了重大进展，但由于反演问题的不适定性质，反射 ODT 仍然具有挑战性。我们提出了一种用于反射模式显微镜中 3D 折射率 (RI) 重建的新颖优化算法。我们的方法利用了不受控制的背景结构反射的多重散射波，并从后面照亮前景 RI。它使用加权时间损失、正约束和总变分正则化来解决问题的不适定性质。我们使用详细的 2D 和 3D 模拟生成的数据验证了我们的方法，证明了其在弱散射条件下的性能，并在优化例程中使用了简化的前向模型以提高计算效率。此外，我们强调需要多波长分析和使用正则化来确保重建前景 RI 的低空间频率。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3644248",
        "title": "Convergent Primal-Dual Plug-and-Play Image Restoration: A General Algorithm and Applications",
        "link": "https://doi.org/10.1109/tci.2025.3644248",
        "published": "2026",
        "author": "Yodai Suzuki, Ryosuke Isono, Shunsuke Ono",
        "summary": "We propose a general deep plug-and-play (PnP) algorithm with a theoretical convergence guarantee. PnP strategies have demonstrated outstanding performance in various image restoration tasks by exploiting the powerful priors underlying Gaussian denoisers. However, existing PnP methods often lack theoretical convergence guarantees under realistic assumptions due to their ad-hoc nature, resulting in inconsistent behavior. Moreover, even when convergence guarantees are provided, they are typically designed for specific settings or require a considerable computational cost in handling non-quadratic data-fidelity terms and additional constraints, which are key components in many image restoration scenarios. To tackle these challenges, we integrate the PnP paradigm with primal-dual splitting (PDS), an efficient proximal splitting methodology for solving a wide range of convex optimization problems, and develop a general convergent PnP framework. Specifically, we establish theoretical conditions for the convergence of the proposed PnP algorithm under a reasonable assumption. Furthermore, we show that the problem solved by the proposed PnP algorithm is not a standard convex optimization problem but a more general monotone inclusion problem, where we provide a mathematical representation of the solution set. Our approach efficiently handles a broad class of image restoration problems with guaranteed theoretical convergence. Numerical experiments on specific image restoration tasks validate the practicality and effectiveness of our theoretical results.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "收敛原始-对偶即插即用图像恢复：通用算法和应用",
        "abstract_cn": "我们提出了一种具有理论收敛保证的通用深度即插即用（PnP）算法。通过利用高斯降噪器的强大先验，PnP 策略在各种图像恢复任务中表现出了出色的性能。然而，现有的 PnP 方法由于其临时性质，往往缺乏现实假设下的理论收敛保证，从而导致行为不一致。此外，即使提供了收敛保证，它们通常也是针对特定设置而设计的，或者在处理非二次数据保真度项和附加约束时需要相当大的计算成本，而这些是许多图像恢复场景中的关键组成部分。为了应对这些挑战，我们将 PnP 范式与原始对偶分裂（PDS）（一种用于解决各种凸优化问题的有效近端分裂方法）相结合，并开发了一个通用的收敛 PnP 框架。具体来说，我们在合理的假设下建立了所提出的 PnP 算法收敛的理论条件。此外，我们表明所提出的 PnP 算法解决的问题不是标准的凸优化问题，而是更一般的单调包含问题，其中我们提供了解集的数学表示。我们的方法可以有效地处理广泛的图像恢复问题，并保证理论收敛。针对特定图像恢复任务的数值实验验证了我们的理论结果的实用性和有效性。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3643713",
        "title": "IEEE Transactions on Computational Imaging Publication Information",
        "link": "https://doi.org/10.1109/tci.2025.3643713",
        "published": "2026",
        "author": "Unknown",
        "summary": "Abstract not available.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "IEEE 计算成像出版物信息汇刊",
        "abstract_cn": "（摘要暂缺，等待官方补全）"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3646325",
        "title": "Dual-Probe Pulse-Echo Speed-of-Sound Imaging",
        "link": "https://doi.org/10.1109/tci.2025.3646325",
        "published": "2026",
        "author": "Michael Jaeger, Vera H.J. van Hal, Richard Lopata, Hans-Martin Schwab",
        "summary": "Knowledge of the spatial distribution of speed of sound (SoS) will greatly improve the diagnostic power of abdominal ultrasound (US) imaging. It can be used to account for wavefront aberrations and improving the B-mode image quality, but SoS is also an important disease marker as it can reflect disease-related changes in tissue composition. However, the relatively small aperture size compared to the desired image depth in abdominal US imaging inherently limits the axial resolution and the estimation accuracy of determining SoS. Fundamentally, a larger physical aperture would produce images with improved contrast and resolution. In this study, we assess the impact of combining two probes to a larger aperture on the estimation accuracy of SoS. Two ways of dual-probe operation are investigated, monostatic (where only one probe transmits and receives at a time) and bistatic (where both probes receive on each transmit), as well as classical single-probe operation. The quality of SoS maps is compared in digital and physical phantoms mimicking abdominal imaging. The primary result is that axial resolution of bistatic operation clearly outperforms the one of monostatic dual-probe operation, both in simulations (by 74<inline-formula><tex-math notation=\"LaTeX\">$\\%$</tex-math></inline-formula> and 96<inline-formula><tex-math notation=\"LaTeX\">$\\%$</tex-math></inline-formula>) and in the experiment (by 103<inline-formula><tex-math notation=\"LaTeX\">$\\%$</tex-math></inline-formula>), indicating that the larger angle differences provided by trans-aperture data (where one probe receives and the other transmits) is essential for the superior axial resolution. Furthermore, bistatic dual-probe operation produced SoS maps with improved background uniformity and performed best at recovering layer contrast, while the latter was substantially more underestimated in monostatic dual-probe and classical single-probe operation. This study emphasizes the importance of larger effective apertures for future ultrasound device designs.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "双探头脉冲回波声速成像",
        "abstract_cn": "了解声速 (SoS) 的空间分布将极大提高腹部超声 (US) 成像的诊断能力。它可用于解释波前像差并提高 B 模式图像质量，但 SoS 也是一种重要的疾病标志物，因为它可以反映与疾病相关的组织成分变化。然而，与腹部超声成像中所需的图像深度相比，孔径尺寸相对较小，这固有地限制了轴向分辨率和确定 SoS 的估计精度。从根本上说，更大的物理光圈将产生具有更高对比度和分辨率的图像。在本研究中，我们评估了将两个探头组合到更大孔径对 SoS 估计精度的影响。研究了双探头操作的两种方式，单基地（一次只有一个探头发送和接收）和双基地（两个探头在每次发送时接收），以及经典的单探头操作。在模拟腹部成像的数字体模和物理体模中比较 SoS 地图的质量。主要结果是，无论是在模拟中（通过 74<inline-formula><tex-math notation=\"LaTeX\">$\\%$</tex-math></inline-formula> 和 96<inline-formula><tex-math notation=\"LaTeX\">$\\%$</tex-math></inline-formula>）还是在实验中，双站操作的轴向分辨率均明显优于单站双探头操作的轴向分辨率（按 103<inline-formula><tex-math notation=\"LaTeX\">$\\%$</tex-math></inline-formula>），表明跨孔径数据（其中一个探头接收，另一个探头发射）提供的较大角度差异对于卓越的轴向分辨率至关重要。此外，双站双探头操作生成的 SoS 图具有改进的背景均匀性，并且在恢复层对比度方面表现最佳，而后者在单站双探头和经典单探头操作中被大大低估。这项研究强调了更大的有效孔径对于未来超声设备设计的重要性。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3647229",
        "title": "Fast Sinogram-Based System Calibration for Field Free Line Magnetic Particle Imaging",
        "link": "https://doi.org/10.1109/tci.2025.3647229",
        "published": "2026",
        "author": "Serhat Ilbey, Justin Ackers, Heinrich Lehr, Matthias Graeser, Jochen Franke",
        "summary": "In this study, we propose a novel calibration method for magnetic particle imaging (MPI), in which a field-based calibration procedure is employed directly in the sinogram domain for a dynamic 3D field free line (FFL) sinusoidal trajectory. Unlike the conventional voxel-wise calibration in the image-domain, our approach involves performing calibration measurements in sinogram domain with alternating magnetic field offsets. The resulting sinogram-based calibration data are then used to synthesize the 3D system matrix (SM) in the image domain by exploiting the shift invariance property of MPI systems. With the proposed method, frequency mixing terms originating from the simultaneous translation and rotation of the FFL can be acquired without the use of an external calibration device, such as a precise 3D-axis robot. The proposed sinogram-based calibration method for the 3D FFL trajectory with 100 ms duration achieved acquisition of a 57 × 57 × 11 SM in approximately 1 minute with minimal image degradation. In contrast, the conventional system calibration method requires about 1 h for the same spatial resolution.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "基于正弦图的快速无场线磁粒子成像系统校准",
        "abstract_cn": "在这项研究中，我们提出了一种用于磁粒子成像 (MPI) 的新型校准方法，其中直接在正弦图域中采用基于场的校准程序，以获得动态 3D 无场线 (FFL) 正弦轨迹。与图像域中传统的体素校准不同，我们的方法涉及使用交变磁场偏移在正弦图域中执行校准测量。然后，通过利用 MPI 系统的平移不变性，所得基于正弦图的校准数据可用于合成图像域中的 3D 系统矩阵 (SM)。通过所提出的方法，无需使用外部校准设备（例如精确的 3D 轴机器人）即可获取源自 FFL 同时平移和旋转的混频项。所提出的基于正弦图的校准方法用于持续时间为 100 ms 的 3D FFL 轨迹，在大约 1 分钟内实现了 57 × 57 × 11 SM 的采集，并且图像质量下降最小。相比之下，传统的系统标定方法需要大约1小时才能达到相同的空间分辨率。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3648531",
        "title": "Deep Learning-Based Inpainting for Sparse Arrays in Ultrafast Ultrasound Imaging",
        "link": "https://doi.org/10.1109/tci.2025.3648531",
        "published": "2026",
        "author": "Roser Viñals, Jean-Philippe Thiran",
        "summary": "Sparse arrays offer a promising solution for reducing the data volume required to reconstruct ultrasound images, making them well-suited for portable and wireless devices. However, the quality of images beamformed from a limited number of transducer elements is significantly degraded. This study proposes a deep learning-based inpainting technique to estimate complete radio frequency (RF) signals (before beamforming) from downsampled RF signals obtained using a subset of transducer elements. This approach allows for quality enhancement without the need to beamform images, offering flexibility particularly beneficial for applications such as speed-of-sound estimation algorithms. We introduce a model-based loss function that combines the signal and image domains by incorporating a measurement model associated with image reconstruction. We then compare this loss with another that accounts solely for the RF signal domain. Additionally, we train our network exclusively in the RF image domain, mapping images beamformed from downsampled RF signals to those from complete signals. We compare these approaches qualitatively and quantitatively, with all enhancing image quality. The proposed method with the model-based loss achieves superior detail and quality metrics. Although trained on downsampled RF signals simulating sparse arrays in reception, all methods — especially our inpainting approach with the model-based loss — demonstrate strong adaptability to ultrafast acquisitions with reduced transducer elements in both transmission and reception. This highlights their potential for reducing the number of transducer elements in ultrasound probes. Furthermore, the proposed method exhibits superior generalization performance when evaluated on a different probe than the one used to acquire the training dataset.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "超快超声成像中基于深度学习的稀疏阵列修复",
        "abstract_cn": "稀疏阵列为减少重建超声图像所需的数据量提供了一种有前景的解决方案，使其非常适合便携式和无线设备。然而，由有限数量的换能器元件波束形成的图像质量显着下降。本研究提出了一种基于深度学习的修复技术，可根据使用换能器元件子集获得的下采样 RF 信号来估计完整的射频 (RF) 信号（波束成形之前）。这种方法无需波束形成图像即可增强质量，提供的灵活性特别有利于声速估计算法等应用。我们引入了一种基于模型的损失函数，它通过合并与图像重建相关的测量模型来结合信号域和图像域。然后，我们将此损耗与仅考虑射频信号域的另一个损耗进行比较。此外，我们专门在射频图像域中训练我们的网络，将下采样射频信号波束形成的图像映射到完整信号的图像。我们对这些方法进行定性和定量比较，所有方法都提高了图像质量。所提出的基于模型损失的方法实现了卓越的细节和质量指标。尽管在接收中模拟稀疏阵列的下采样射频信号上进行了训练，但所有方法（尤其是我们采用基于模型的损耗的修复方法）都表现出了对超快采集的强大适应性，并且在传输和接收中减少了换能器元件。这凸显了它们减少超声探头中换能器元件数量的潜力。此外，当在与用于获取训练数据集的探针不同的探针上进行评估时，所提出的方法表现出优异的泛化性能。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3649390",
        "title": "ICSD-NeRF: Independent Canonical Spaces for Enhanced Dynamic Scene Modeling in Neural Radiance Fields",
        "link": "https://doi.org/10.1109/tci.2025.3649390",
        "published": "2026",
        "author": "Suwoong Yeom, Hosung Son, Chanhee Kang, Eunho Shin, Joonsoo Kim, Kug-jin Yun, Suk-Ju Kang",
        "summary": "Novel view synthesis for dynamic scenes is a critical challenge in computer vision and computational imaging. Despite significant advancements, generating realistic images from monocularly captured dynamic scenes remains a complex task. Recent methods leveraging neural radiance fields and 3D Gaussian splatting in canonical spaces have made notable progress. However, these approaches often estimate both color and geometric information within a single space, limiting their effectiveness in handling large deformations of dynamic objects or significant color variations. To address these challenges, we propose ICSD-NeRF, which optimizes color and geometry in separate canonical spaces. Additionally, we introduce decision fields to effectively distinguish and optimize static and dynamic objects, enabling dynamic regions to be disentangled from the static background during training. To further enhance the representation of geometric structures in static regions, we employ an MLP to refine geometric features. We validate our approach on widely used dynamic scene novel view synthesis datasets, demonstrating that ICSD-NeRF outperforms existing methods by achieving higher rendering accuracy. Notably, our method achieves higher PSNR scores on benchmark datasets than current state-of-the-art techniques.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "ICSD-NeRF：用于增强神经辐射场动态场景建模的独立规范空间",
        "abstract_cn": "动态场景的新颖视图合成是计算机视觉和计算成像中的关键挑战。尽管取得了重大进步，但从单眼捕捉的动态场景生成逼真的图像仍然是一项复杂的任务。最近在规范空间中利用神经辐射场和 3D 高斯分布的方法取得了显着进展。然而，这些方法通常会估计单个空间内的颜色和几何信息，从而限制了它们处理动态对象大变形或显着颜色变化的有效性。为了应对这些挑战，我们提出了 ICSD-NeRF，它可以在单独的规范空间中优化颜色和几何形状。此外，我们引入决策场来有效区分和优化静态和动态对象，使动态区域在训练过程中与静态背景分离。为了进一步增强静态区域中几何结构的表示，我们采用 MLP 来细化几何特征。我们在广泛使用的动态场景新颖视图合成数据集上验证了我们的方法，证明 ICSD-NeRF 通过实现更高的渲染精度优于现有方法。值得注意的是，我们的方法在基准数据集上获得了比当前最先进的技术更高的 PSNR 分数。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3649389",
        "title": "Conformalized Generative Bayesian Imaging: An Uncertainty Quantification Framework for Computational Imaging",
        "link": "https://doi.org/10.1109/tci.2025.3649389",
        "published": "2026",
        "author": "Canberk Ekmekci, Mujdat Cetin",
        "summary": "Uncertainty quantification plays an important role in achieving trustworthy and reliable learning-based computational imaging. Recent advances in generative modeling and Bayesian neural networks have enabled the development of uncertainty-aware image reconstruction methods. Current generative model-based methods seek to quantify the inherent (aleatoric) uncertainty on the underlying image for given measurements by learning to sample from the posterior distribution of the underlying image. On the other hand, Bayesian neural network-based approaches aim to quantify the model (epistemic) uncertainty on the parameters of a deep neural network-based reconstruction method by approximating the posterior distribution of those parameters. Unfortunately, an ongoing need for an inversion method that can jointly quantify complex aleatoric uncertainty and epistemic uncertainty patterns still persists. In this paper, we present a scalable framework that can quantify both aleatoric and epistemic uncertainties. The proposed framework accepts an existing generative model-based posterior sampling method as an input and introduces an epistemic uncertainty quantification capability through Bayesian neural networks with latent variables and deep ensembling. Furthermore, by leveraging the conformal prediction methodology, the proposed framework can be easily calibrated to ensure rigorous uncertainty quantification. We evaluated the proposed framework on magnetic resonance imaging, computed tomography, and image inpainting problems and showed that the epistemic and aleatoric uncertainty estimates produced by the proposed framework display the characteristic features of true epistemic and aleatoric uncertainties. Furthermore, our results demonstrated that the use of conformal prediction on top of the proposed framework enables marginal coverage guarantees consistent with frequentist principles.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "共形生成贝叶斯成像：计算成像的不确定性量化框架",
        "abstract_cn": "不确定性量化在实现可信且可靠的基于学习的计算成像方面发挥着重要作用。生成建模和贝叶斯神经网络的最新进展使得不确定性感知图像重建方法的发展成为可能。当前基于生成模型的方法试图通过学习从底层图像的后验分布中采样来量化给定测量的底层图像的固有（任意）不确定性。另一方面，基于贝叶斯神经网络的方法旨在通过逼近基于深度神经网络的重建方法的参数的后验分布来量化这些参数的模型（认知）不确定性。不幸的是，仍然需要一种能够联合量化复杂的任意不确定性和认知不确定性模式的反演方法。在本文中，我们提出了一个可扩展的框架，可以量化任意和认知不确定性。所提出的框架接受现有的基于生成模型的后验采样方法作为输入，并通过具有潜在变量和深度集成的贝叶斯神经网络引入认知不确定性量化能力。此外，通过利用共形预测方法，可以轻松校准所提出的框架，以确保严格的不确定性量化。我们评估了所提出的磁共振成像、计算机断层扫描和图像修复问题的框架，并表明所提出的框架产生的认知和任意不确定性估计显示了真正的认知和任意不确定性的特征。此外，我们的结果表明，在所提出的框架之上使用保形预测可以实现与频率主义原则一致的边际覆盖率保证。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2025.3650359",
        "title": "Learning Degradation-Aware Diffusion Prior for Hyperspectral Reconstruction From RGB Image",
        "link": "https://doi.org/10.1109/tci.2025.3650359",
        "published": "2026",
        "author": "Jingxiang Yang, Haifeng Xu, Heyuan Yin, Hongyi Liu, Liang Xiao",
        "summary": "Hyperspectral image (HSI) is applicable in many fields due to the ability in discriminating different materials. Collecting HSI usually requires expensive hardware and long period. Reconstructing HSI from RGB image, also called spectral super-resolution (SSR), is an affordable and feasible way for HSI acquisition. Despite the SSR results achieved by existing deep unfolding networks (DUNs), they still face challenges in: 1) recovering the fine-grained and realistic details; 2) suppressing the spectral distortion. Diffusion model has advantages in generating diverse and realistic contents, while its fidelity is limited due to the inherent randomness. In this study, to reconstruct a faithful and realistic HSI, we integrate the diffusion model in DUN, and propose a degradation-aware unrolling diffusion model for SSR (deDiff-SSR). The generative diffusion prior is jointly leveraged with the spectral degradation and deep prior learning. Specifically, we first pre-train a channel attention enhanced denoising diffusion probabilistic model (DDPM), the spectral correlation is exploited for learning the diffusion prior of HSI. To aware the degradation, by optimizing a diffusion and deep priors regularized HSI SSR model, we propose a degradation-aware diffusion sampling method, the spectral degradation is learned to refine each diffusion sampling step. Via unrolling the degradation-aware diffusion sampling steps, we build the deDiff-SSR network. It contains diffusion and deep proximal operators to represent the diffusion and deep priors, respectively. We implement the diffusion proximal operator with one sampling step of the pre-trained DDPM. Moreover, we design a state-space Transformer as the deep proximal operator, the spectral-spatial long-range relationship of HSI can be efficiently captured. The experiments on several indoor and remote sensing datasets demonstrate the effectiveness of deDiff-SSR.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "学习用于从 RGB 图像进行高光谱重建的退化感知扩散先验",
        "abstract_cn": "高光谱图像（HSI）由于具有区分不同材料的能力而适用于许多领域。采集HSI通常需要昂贵的硬件和较长的周期。从 RGB 图像重建 HSI，也称为光谱超分辨率 (SSR)，是一种经济实惠且可行的 HSI 采集方法。尽管现有的深度展开网络（DUN）取得了 SSR 的成果，但它们仍然面临以下挑战：1）恢复细粒度和真实的细节； 2）抑制光谱畸变。扩散模型在生成多样化且真实的内容方面具有优势，但由于固有的随机性，其保真度受到限制。在本研究中，为了重建忠实且现实的 HSI，我们将扩散模型集成到 DUN 中，并提出了一种用于 SSR 的退化感知展开扩散模型（deDiff-SSR）。生成扩散先验与光谱退化和深度先验学习共同利用。具体来说，我们首先预训练通道注意增强去噪扩散概率模型（DDPM），利用谱相关性来学习 HSI 的扩散先验。为了感知退化，通过优化扩散和深度先验正则化 HSI SSR 模型，我们提出了一种退化感知扩散采样方法，通过学习光谱退化来细化每个扩散采样步骤。通过展开退化感知扩散采样步骤，我们构建了 deDiff-SSR 网络。它包含扩散和深度近端算子，分别表示扩散和深度先验。我们通过预训练 DDPM 的一个采样步骤来实现扩散近端算子。此外，我们设计了一个状态空间 Transformer 作为深度近端算子，可以有效地捕获 HSI 的谱空间长程关系。在多个室内和遥感数据集上的实验证明了 deDiff-SSR 的有效性。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2026.3653304",
        "title": "Neural Networks Meet Light Transport Physics for Passive Non-line-of-sight Imaging Enhancement",
        "link": "https://doi.org/10.1109/tci.2026.3653304",
        "published": "2026",
        "author": "Rui Liang, Zhenjun Xu, Xi Tong, Jiangxin Yang, Xin Li, Yanpeng Cao",
        "summary": "Passive non-line-of-sight (NLOS) imaging has garnered significant interest as a promising technique for cost-effective “corner-turning sensing”. Existing methods, however, face fundamental limitations: data-driven models generally suffer from limited generalization and interpretability, while physics-based approaches typically produce low-fidelity reconstructions. To address these challenges, this paper proposes a hybrid physics-data-driven imaging (HPDI) framework. HPDI employs a dual-path architecture that integrates a physics-informed coarse-to-fine pathway (CTFP) with a data-driven implicit reconstruction pathway (IRP). The former executes a staged progression from physics-informed coarse reconstruction to final refinement, while the latter encodes scene-specific statistical priors in an end-to-end manner. An adaptive fusion network synergistically integrates the physical insights of CTFP and the statistical abstractions of IRP, yielding enhanced reconstruction performance. To enable comprehensive evaluation, we construct multiple datasets covering diverse acquisition conditions (with/without occluder) and representative scenarios (sparse/complex). Experimental results demonstrate that HPDI consistently outperforms state-of-the-art methods in reconstruction fidelity, while exhibiting enhanced generalization under distribution shifts and higher data efficiency. This work represents a significant step toward harnessing the complementary strengths of physics-informed modeling and data-driven learning, thereby advancing the development of high-performance NLOS imaging.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "神经网络与光传输物理学相结合，实现被动非视距成像增强",
        "abstract_cn": "被动非视距 (NLOS) 成像作为一种具有成本效益的“转角传感”的有前途的技术，引起了人们的极大兴趣。然而，现有的方法面临着根本的局限性：数据驱动的模型通常受到有限的泛化和可解释性的影响，而基于物理的方法通常会产生低保真度的重建。为了应对这些挑战，本文提出了一种混合物理数据驱动成像（HPDI）框架。 HPDI 采用双路径架构，集成了物理信息粗略到精细路径 (CTFP) 与数据驱动的隐式重建路径 (IRP)。前者执行从物理信息粗略重建到最终细化的分阶段进展，而后者以端到端的方式对特定于场景的统计先验进行编码。自适应融合网络协同集成 CTFP 的物理见解和 IRP 的统计抽象，从而增强重建性能。为了实现全面评估，我们构建了涵盖不同采集条件（有/无遮挡物）和代表性场景（稀疏/复杂）的多个数据集。实验结果表明，HPDI 在重建保真度方面始终优于最先进的方法，同时在分布变化和更高的数据效率下表现出增强的泛化能力。这项工作代表了利用物理信息建模和数据驱动学习的互补优势迈出了重要一步，从而推动了高性能非视距成像的发展。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2026.3653323",
        "title": "Efficient Hyperspectral Image Reconstruction Using Lightweight Separate Spectral Transformers",
        "link": "https://doi.org/10.1109/tci.2026.3653323",
        "published": "2026",
        "author": "Jianan Li, Wangcai Zhao, Tingfa Xu",
        "summary": "Hyperspectral imaging (HSI) is essential across various disciplines for its capacity to capture rich spectral information. However, efficiently reconstructing hyperspectral images from compressive sensing measurements presents significant challenges. To tackle these, we adopt a divide-and-conquer strategy that capitalizes on the unique spectral and spatial characteristics of hyperspectral images. We introduce the Lightweight Separate Spectral Transformer (LSST), an innovative architecture tailored for efficient hyperspectral image reconstruction. This architecture consists of Separate Spectral Transformer Blocks (SSTB) for modeling spectral relationships and Lightweight Spatial Convolution Blocks (LSCB) for spatial processing. The SSTB employs Grouped Spectral Self-attention and a Spectrum Shuffle operation to effectively manage both local and non-local spectral relationships. Simultaneously, the LSCB utilizes depth-wise separable convolutions and strategic ordering to enhance spatial information processing. Furthermore, we implement the Focal Spectrum Loss, a novel loss weighting mechanism that dynamically adjusts during training to improve reconstruction across spectrally complex bands. Extensive testing demonstrates that our LSST achieves superior performance while requiring fewer FLOPs and parameters, underscoring its efficiency and effectiveness. The source code is available at: https://github.com/wcz1124/LSST.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "使用轻量级分离光谱变压器进行高效高光谱图像重建",
        "abstract_cn": "高光谱成像（HSI）因其捕获丰富光谱信息的能力而在各个学科中至关重要。然而，从压缩传感测量中有效地重建高光谱图像面临着巨大的挑战。为了解决这些问题，我们采用分而治之的策略，利用高光谱图像独特的光谱和空间特征。我们推出了轻量级分离光谱变换器（LSST），这是一种专为高效高光谱图像重建而定制的创新架构。该架构由用于建模光谱关系的独立光谱变换器模块 (SSTB) 和用于空间处理的轻量级空间卷积模块 (LSCB) 组成。 SSTB 采用分组频谱自注意力和频谱洗牌操作来有效管理本地和非本地频谱关系。同时，LSCB 利用深度可分离卷积和策略排序来增强空间信息处理。此外，我们还实现了焦谱损失，这是一种新颖的损失加权机制，可以在训练期间动态调整，以改善光谱复杂波段的重建。广泛的测试表明，我们的 LSST 实现了卓越的性能，同时需要更少的 FLOP 和参数，强调了其效率和有效性。源代码位于：https://github.com/wcz1124/LSST。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2026.3653305",
        "title": "Sub-DM: Subspace Diffusion Model with Orthogonal Decomposition for MRI Reconstruction",
        "link": "https://doi.org/10.1109/tci.2026.3653305",
        "published": "2026",
        "author": "Yu Guan, Qinrong Cai, Wei Li, Qiuyun Fan, Dong Liang, Qiegen Liu",
        "summary": "Diffusion model-based approaches recently achieved remarkable success in MRI reconstruction, but integration into clinical routine remains challenging due to its time-consuming convergence. This phenomenon is particularly notable when directly apply conventional diffusion process to k-space data without considering the inherent properties of k-space sampling, limiting k-space learning efficiency and image reconstruction quality. To tackle these challenges, we introduce subspace diffusion model with orthogonal decomposition, a method (referred to as Sub-DM) that restrict the diffusion process via projections onto subspace as the k-space data distribution evolves toward noise. Particularly, the orthogonal decomposition strategy constructs a low-rank subspace using stacked wavelet tensor. This enables the diffusion process to generate accurate priors with fewer iterations and enhances model generalization by focusing on low-dimensional intrinsic features. Owing to its near-reversible property, the strategy preserves information integrity while facilitating bidirectional refinement of model across different spaces, thereby enriching prior knowledge from diverse dimensions. Comprehensive experiments on different datasets clearly demonstrate that Sub-DM achieves faster convergence speed and exhibits more robust generalization ability.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "Sub-DM：用于 MRI 重建的正交分解子空间扩散模型",
        "abstract_cn": "基于扩散模型的方法最近在 MRI 重建方面取得了显着的成功，但由于其耗时的收敛，融入临床常规仍然具有挑战性。当直接将传统扩散过程应用于k空间数据而不考虑k空间采样的固有属性时，这种现象尤其显着，限制了k空间学习效率和图像重建质量。为了应对这些挑战，我们引入了具有正交分解的子空间扩散模型，这是一种随着 k 空间数据分布向噪声演化而通过投影到子空间来限制扩散过程的方法（称为 Sub-DM）。特别地，正交分解策略使用堆叠小波张量构造低秩子空间。这使得扩散过程能够以更少的迭代生成准确的先验，并通过关注低维内在特征来增强模型泛化能力。由于其近乎可逆的特性，该策略保留了信息完整性，同时促进了跨不同空间的模型的双向细化，从而丰富了不同维度的先验知识。在不同数据集上的综合实验清楚地表明，Sub-DM 实现了更快的收敛速度并表现出更强大的泛化能力。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2026.3653330",
        "title": "Scan-Adaptive MRI Undersampling Using Neighbor-based Optimization (SUNO)",
        "link": "https://doi.org/10.1109/tci.2026.3653330",
        "published": "2026",
        "author": "Siddhant Gautam, Angqi Li, Nicole Seiberlich, Jeffrey A. Fessler, Saiprasad Ravishankar",
        "summary": "Accelerated MRI involves collecting partial $k$-space measurements to reduce acquisition time, patient discomfort, and motion artifacts, and typically uses regular undersampling patterns or human-designed schemes. Recent works have studied population-adaptive sampling patterns learned from a group of patients (or scans). However, such patterns can be sub-optimal for individual scans, as they may fail to capture scan or slice-specific details, and their effectiveness can depend on the size and composition of the population. To overcome this issue, we propose a framework for jointly learning scan-adaptive Cartesian undersampling patterns and a corresponding reconstruction model from a training set. We use an alternating algorithm for learning the sampling patterns and the reconstruction model where we use an iterative coordinate descent (ICD) based offline optimization of scan-adaptive $k$-space sampling patterns for each example in the training set. A nearest neighbor search is then used to select the scan-adaptive sampling pattern at test time from initially acquired low-frequency $k$-space information. We applied the proposed framework (dubbed SUNO) to the fastMRI multi-coil knee and brain datasets, demonstrating improved performance over the currently used undersampling patterns at both $4\\times$ and $8\\times$ acceleration factors in terms of both visual quality and quantitative metrics. The code for the proposed framework is available at https://github.com/sidgautam95/adaptive-sampling-mri-suno. This paper has been accepted for publication in IEEE Transactions on Computational Imaging. The final published version is available at https://doi.org/10.1109/TCI.2026.3653330.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "使用基于邻域的优化 (SUNO) 进行扫描自适应 MRI 欠采样",
        "abstract_cn": "加速 MRI 涉及收集部分 $k$ 空间测量值，以减少采集时间、患者不适和运动伪影，并且通常使用常规欠采样模式或人为设计的方案。最近的工作研究了从一组患者（或扫描）中学习到的人群自适应采样模式。然而，这种模式对于单个扫描来说可能不是最佳的，因为它们可能无法捕获扫描或切片特定的细节，并且它们的有效性可能取决于人群的大小和组成。为了克服这个问题，我们提出了一个框架，用于联合学习扫描自适应笛卡尔欠采样模式以及来自训练集的相应重建模型。我们使用交替算法来学习采样模式和重建模型，其中我们对训练集中的每个示例使用基于迭代坐标下降 (ICD) 的扫描自适应 $k$ 空间采样模式的离线优化。然后使用最近邻搜索在测试时从最初获取的低频 $k$ 空间信息中选择扫描自适应采样模式。我们将所提出的框架（称为 SUNO）应用于 fastMRI 多线圈膝盖和大脑数据集，证明在视觉质量和定量指标方面，在 $4\\times$ 和 $8\\times$ 加速因子下，性能优于当前使用的欠采样模式。所提议框架的代码可在 https://github.com/sidgautam95/adaptive-sampling-mri-suno 获取。该论文已被 IEEE Transactions on Computational Imaging 接受发表。最终发布的版本可在 https://doi.org/10.1109/TCI.2026.3653330 获取。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2026.3653309",
        "title": "Data-Driven Multi-keV Virtual Monoenergetic Images Generation from Single-Energy CT Guided by Image-Domain Material Decomposition",
        "link": "https://doi.org/10.1109/tci.2026.3653309",
        "published": "2026",
        "author": "Wenwen Zhang, Zihan Chai, Yantao Niu, Zhijie Zhang, Linxuan Li, Baohua Sun, Junfang Xian, Wei Zhao",
        "summary": "Virtual monoenergetic images (VMIs), reconstructed from dual-energy CT (DECT) by capturing photon attenuation data at two distinct energy levels, can reduce beam-hardening artifacts and provide more quantitatively accurate attenuation measurements. Data-driven deep learning approaches have demonstrated the feasibility of synthesizing VMIs from conventional single-energy CT (SECT) scans. However, the lack of incorporation of physics-related information in such methods compromises their interpretability and robustness. Here we propose a novel hybrid data-driven framework that synergizes convolutional neural networks with physics-based material decomposition derived from DECT principles. This approach directly yields high-quality VMIs across various keV levels from SECT acquisitions. Through rigorous validation on 130 clinical cases spanning diverse anatomical regions and pathological conditions, our method demonstrates significant improvements over conventional purely data-driven approaches, as evidenced by enhanced anatomical visualization and superior performance on quantitative metrics. By eliminating dependence on DECT hardware while maintaining computational efficiency and incorporating physics-guided constraints, our framework leverages the widespread availability of SECT to provide a cost-effective, high-performance solution for diagnostic imaging in routine clinical practice.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "由图像域材料分解引导的单能 CT 生成数据驱动的多 keV 虚拟单能图像",
        "abstract_cn": "虚拟单能图像 (VMI) 通过在两个不同能量级别捕获光子衰减数据，从双能 CT (DECT) 重建，可以减少光束硬化伪影，并提供更定量准确的衰减测量。数据驱动的深度学习方法已经证明了从传统单能 CT (SECT) 扫描合成 VMI 的可行性。然而，此类方法中缺乏物理相关信息，损害了其可解释性和鲁棒性。在这里，我们提出了一种新颖的混合数据驱动框架，该框架将卷积神经网络与源自 DECT 原理的基于物理的材料分解相结合。这种方法直接从 SECT 采集中产生跨不同 keV 级别的高质量 VMI。通过对跨越不同解剖区域和病理条件的 130 个临床病例的严格验证，我们的方法比传统的纯数据驱动方法有了显着改进，增强的解剖可视化和定量指标的卓越性能证明了这一点。通过消除对 DECT 硬件的依赖，同时保持计算效率并结合物理引导的约束，我们的框架利用 SECT 的广泛可用性，为常规临床实践中的诊断成像提供经济高效、高性能的解决方案。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2026.3654807",
        "title": "DPD-DEMD: Denoising Prior Guided Weakly Supervised Image Domain Dual-Energy Material Decomposition",
        "link": "https://doi.org/10.1109/tci.2026.3654807",
        "published": "2026",
        "author": "Xinyun Zhong, Xu Zhuo, Tianling Lyu, Yikun Zhang, Qianjin Feng, Guotao Quan, Xu Ji, Yang Chen",
        "summary": "Dual-energy material decomposition is widely used in clinical diagnosis, especially for material characterization. However, conventional image-domain methods suffer from noise amplification, thus reducing signal-to-noise ratio and compromising diagnostic accuracy. Although deep learning approaches have shown significant progress, they often require high-quality paired or unpaired labels, limiting their clinical application. To address these issues, this work explores the feasibility of weakly supervised methods and proposes a denoising prior guided weakly supervised learning framework, DPD-DEMD, to achieve high-accuracy image-domain dual-energy material decomposition. DPD-DEMD utilizes pretrained CT denoising models to construct robust priors for our dual energy material decomposition task. Furthermore, we propose an adaptive confidence mask mechanism for pseudo label generation and a multi-prior fusion strategy, thereby substantially improving the stability and reliability of the weakly supervised learning process. In addition, we fully exploit the correlation between dual energy images and further propose global-local regularization loss to improve the material decomposition accuracy. Extensive experiments conducted on both simulated and clinical datasets verify the superior performance and robustness of the proposed method, thereby demonstrating its potential clinical value in material decomposition. Our code is available at <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/zhongxinyun/DPD-DEMD.git</uri>.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "DPD-DEMD：去噪先验引导弱监督图像域双能材料分解",
        "abstract_cn": "双能材料分解广泛应用于临床诊断，特别是材料表征。然而，传统的图像域方法会受到噪声放大的影响，从而降低信噪比并影响诊断准确性。尽管深度学习方法已经取得了显着进展，但它们通常需要高质量的配对或不配对标签，限制了它们的临床应用。为了解决这些问题，本文探讨了弱监督方法的可行性，并提出了一种去噪先验引导的弱监督学习框架DPD-DEMD，以实现高精度图像域双能材料分解。 DPD-DEMD 利用预训练的 CT 去噪模型为我们的双能材料分解任务构建稳健的先验。此外，我们提出了一种用于伪标签生成的自适应置信掩码机制和多先验融合策略，从而大大提高了弱监督学习过程的稳定性和可靠性。此外，我们充分利用双能量图像之间的相关性，进一步提出全局-局部正则化损失来提高材料分解的精度。在模拟和临床数据集上进行的大量实验验证了所提出方法的优越性能和鲁棒性，从而证明了其在材料分解方面的潜在临床价值。我们的代码位于 <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/zhongxinyun/DPD-DEMD.git</uri>。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2026.3655460",
        "title": "Joint Translational Motion Compensation of ISAR Imaging for Uniformly Accelerated Motion Targets Based on MPD-TSLS Under Low SNR",
        "link": "https://doi.org/10.1109/tci.2026.3655460",
        "published": "2026",
        "author": "Tao Liu, Yu Wang, Biao Tian, Shiyou Xu, Zengping Chen",
        "summary": "Effective and accurate translational motion compensation is crucial for inverse synthetic aperture radar (ISAR) imaging. Traditional data-based translational motion compensation methods are inapplicable to uniformly accelerated targets in low signal-to-noise ratio (SNR) scenarios. In this paper, a parametric approach is proposed based on joint modified phase difference and two-step least squares (MPD-TSLS). The method employs a second-order polynomial model for translational motion, whereby the energy of all scatterers is converted to a single range and Doppler cell through MPD operation, respectively. The estimated acceleration and velocity are then obtained by TSLS. To enhance precision, an optimization approach based on LS for refining polynomial parameters is also employed. The proposed method achieves a substantial increase in SNR, ensuring precise compensation accuracy while maintaining high computational efficiency by relying exclusively on fast Fourier transform (FFT) and matrix operations. The experimental results obtained from both simulated and real datasets fully verify that the proposed method exhibits superior performance compared with the other implemented methods.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "低信噪比下基于MPD-TSLS的匀加速运动目标ISAR成像联合平移运动补偿",
        "abstract_cn": "有效且准确的平移运动补偿对于逆合成孔径雷达（ISAR）成像至关重要。传统的基于数据的平移运动补偿方法不适用于低信噪比（SNR）场景下的均匀加速目标。本文提出了一种基于联合修正相位差和两步最小二乘法（MPD-TSLS）的参数化方法。该方法采用二阶多项式模型进行平移运动，通过MPD运算将所有散射体的能量分别转换为单个距离和多普勒单元。然后通过 TSLS 获得估计的加速度和速度。为了提高精度，还采用了基于 LS 的优化方法来细化多项式参数。该方法仅依靠快速傅里叶变换（FFT）和矩阵运算，实现了信噪比的大幅提高，确保了精确的补偿精度，同时保持了高计算效率。从模拟和真实数据集获得的实验结果充分验证了所提出的方法与其他实现的方法相比具有优越的性能。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2026.3655489",
        "title": "A Convergent Generalized Krylov Subspace Method for Compressed Sensing MRI Reconstruction with Gradient-Driven Denoisers",
        "link": "https://doi.org/10.1109/tci.2026.3655489",
        "published": "2026",
        "author": "Tao Hong, Umberto Villa, Jeffrey A. Fessler",
        "summary": "Model-based reconstruction plays a key role in compressed sensing (CS) MRI, as it incorporates effective image regularizers to improve the quality of reconstruction. The Plug-and-Play and Regularization-by-Denoising frameworks leverage advanced denoisers (e.g., convolutional neural network (CNN)-based denoisers) and have demonstrated strong empirical performance. However, their theoretical guarantees remain limited, as practical CNNs often violate key assumptions. In contrast, gradient-driven denoisers achieve competitive performance, and the required assumptions for theoretical analysis are easily satisfied. However, solving the associated optimization problem remains computationally demanding. To address this challenge, we propose a generalized Krylov subspace method (GKSM) to solve the optimization problem efficiently. Moreover, we also establish rigorous convergence guarantees for GKSM in nonconvex settings. Numerical experiments on CS MRI reconstruction with spiral and radial acquisitions validate both the computational efficiency of GKSM and the accuracy of the theoretical predictions. The proposed optimization method is applicable to any linear inverse problem.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "梯度驱动降噪器压缩感知 MRI 重建的收敛广义 Krylov 子空间方法",
        "abstract_cn": "基于模型的重建在压缩感知 (CS) MRI 中发挥着关键作用，因为它结合了有效的图像正则器来提高重建质量。即插即用和降噪正则化框架利用先进的降噪器（例如基于卷积神经网络 (CNN) 的降噪器），并展示了强大的经验性能。然而，它们的理论保证仍然有限，因为实际的 CNN 经常违反关键假设。相比之下，梯度驱动降噪器实现了有竞争力的性能，并且很容易满足理论分析所需的假设。然而，解决相关的优化问题仍然需要大量的计算。为了应对这一挑战，我们提出了一种广义 Krylov 子空间方法（GKSM）来有效地解决优化问题。此外，我们还在非凸设置中为 GKSM 建立了严格的收敛保证。利用螺旋和径向采集进行 CS MRI 重建的数值实验验证了 GKSM 的计算效率和理论预测的准确性。所提出的优化方法适用于任何线性逆问题。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2026.3655494",
        "title": "Deep Lightweight Unrolled Network for High Dynamic Range Modulo Imaging",
        "link": "https://doi.org/10.1109/tci.2026.3655494",
        "published": "2026",
        "author": "Brayan Monroy, Jorge Bacca",
        "summary": "Modulo-Imaging (MI) offers a promising alternative for expanding the dynamic range of images by resetting the signal intensity when it reaches the saturation level. Subsequently, high-dynamic range (HDR) modulo imaging requires a recovery process to obtain the HDR image. MI is a non-convex and ill-posed problem where recent recovery networks suffer in high-noise scenarios. In this work, we formulate the HDR reconstruction task as an optimization problem that incorporates a deep prior and subsequently unrolls it into an optimization-inspired deep neural network. The network employs a lightweight convolutional denoiser for fast inference with minimal computational overhead, effectively recovering intensity values while mitigating noise. Moreover, we introduce the Scaling Equivariance term that facilitates self-supervised fine-tuning, thereby enabling the model to adapt to new modulo images that fall outside the original training distribution. Extensive evaluations demonstrate the superiority of our method compared to state-of-the-art recovery algorithms in terms of performance and quality.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "用于高动态范围模成像的深度轻量级展开网络",
        "abstract_cn": "模成像 (MI) 提供了一种有前途的替代方案，通过在信号强度达到饱和水平时重置信号强度来扩展图像的动态范围。随后，高动态范围（HDR）模成像需要恢复过程以获得HDR图像。 MI 是一个非凸且不适定的问题，最近的恢复网络在高噪声场景中会受到影响。在这项工作中，我们将 HDR 重建任务表述为一个优化问题，该问题结合了深度先验，然后将其展开到受优化启发的深度神经网络中。该网络采用轻量级卷积降噪器以最小的计算开销进行快速推理，有效地恢复强度值，同时减轻噪声。此外，我们引入了缩放等方差项，它有助于自我监督微调，从而使模型能够适应原始训练分布之外的新模图像。广泛的评估表明，与最先进的恢复算法相比，我们的方法在性能和质量方面具有优越性。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2026.3656024",
        "title": "IE-GADCI: An End-to-End Incoherence-Enhanced Generative Adversarial Deep Compressive Imaging",
        "link": "https://doi.org/10.1109/tci.2026.3656024",
        "published": "2026",
        "author": "Kangning Zhang, Yifei Sun, Varun Yelluru, Weijian Yang",
        "summary": "Single-pixel imaging (SPI) within the framework of compressive sensing (CS) is a powerful technique that enables image acquisition at sub-Nyquist sampling rates by leveraging the sparse latent representations of the object scenes. As a cost-effective alternative to focal plane array cameras, SPI has been explored for various imaging applications. We recently introduced a novel block-scanning SPI approach that samples the scene using a single, learnable illumination pattern, which substantially enhanced acquisition speed compared to traditional SPI systems that rely on pattern switching via digital micromirror devices. In this work, we present a new computational framework, termed Incoherence-Enhanced Generative Adversarial Deep Compressive Imaging (IE-GADCI), designed to jointly optimize both the illumination pattern and the image reconstruction algorithm for block-scanning SPI, under the principle of compressive sensing. Our architecture employs a neural network that learns the latent sparse representations of the scene and integrates information from both the image and sparsity domains to achieve high-resolution reconstructions with high computational efficiency. A key innovation of IE-GADCI is its optimization of the incoherence between the illumination pattern and the sparse representation, which substantially improves reconstruction fidelity. We validated the performance of IE-GADCI through numerical simulations on natural and biomedical image datasets. We benchmarked IE-GADCI against state-of-the-art methods used in SPI, and additionally, single image super-resolution (SISR), given the conceptual similarity between block-scanning SPI and SISR. At a subsampling rate of just 1.5625%, IE-GADCI achieves a peak signal-to-noise ratio (PSNR) exceeding that of competing methods by more than 2 dB. These results highlight the potential of IE-GADCI for high-speed, high-fidelity imaging in applications such as consumer electronics and biomedical imaging, including calcium imaging for neuronal activity recording.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "IE-GADCI：端到端不相干增强生成对抗性深度压缩成像",
        "abstract_cn": "压缩感知 (CS) 框架内的单像素成像 (SPI) 是一种强大的技术，可通过利用对象场景的稀疏潜在表示，实现亚奈奎斯特采样率的图像采集。作为焦平面阵列相机的经济高效替代方案，SPI 已被探索用于各种成像应用。我们最近推出了一种新颖的块扫描 SPI 方法，该方法使用单个可学习的照明模式对场景进行采样，与依赖于通过数字微镜设备进行模式切换的传统 SPI 系统相比，该方法大大提高了采集速度。在这项工作中，我们提出了一种新的计算框架，称为不相干增强生成对抗深度压缩成像（IE-GADCI），旨在根据压缩感知原理联合优化块扫描 SPI 的照明模式和图像重建算法。我们的架构采用神经网络来学习场景的潜在稀疏表示，并集成来自图像和稀疏域的信息，以实现具有高计算效率的高分辨率重建。 IE-GADCI 的一个关键创新是它优化了照明模式和稀疏表示之间的不相干性，从而大大提高了重建保真度。我们通过对自然和生物医学图像数据集的数值模拟验证了 IE-GADCI 的性能。考虑到块扫描 SPI 和 SISR 之间概念上的相似性，我们将 IE-GADCI 与 SPI 中使用的最先进方法以及单图像超分辨率 (SISR) 进行了基准测试。 IE-GADCI 的子采样率仅为 1.5625%，其峰值信噪比 (PSNR) 比竞争方法高出 2 dB 以上。这些结果凸显了 IE-GADCI 在消费电子和生物医学成像等应用中进行高速、高保真成像的潜力，包括用于神经元活动记录的钙成像。"
    },
    {
        "id": "https://doi.org/10.1109/tci.2026.3656014",
        "title": "Robust Compressive Sensing Imaging for Quantization Bit Erasure",
        "link": "https://doi.org/10.1109/tci.2026.3656014",
        "published": "2026",
        "author": "Zan Chen, Chuyuan Chen, Bo Wang, Junhao Zhu, Yuanjing Feng, Yongqiang Li, Xingsong Hou, Xueming Qian",
        "summary": "Existing compressive sensing (CS) reconstruction algorithms are primarily designed for deterministic measurements. However, in real-world scenarios, quantization bit erasures during transmission or storage introduce uncertainty into measurements and significantly complicate reconstruction. We extend the CS framework to explicitly handle such bit-level uncertainty, enabling robust image recovery from quantized measurements with missing bits. We begin by enumerating all valid combinations of the erased quantization bits to construct a candidate set of feasible measurement values. This candidate set is then incorporated as a constraint in a newly formulated inverse problem. We propose an iterative plug-and-play algorithm to solve this problem, alternating between two key steps: (1) an image update using a pretrained denoiser, and (2) a measurement update via a soft-min projection strategy accelerated by coordinate descent. Extensive experiments demonstrate the effectiveness of the proposed approach, achieving high-quality reconstructions even under extremely low sampling rates and severe erasure conditions. Our framework offers a scalable and principled solution for bit-erasure-robust CS reconstruction in error-prone and resource-constrained imaging environments. The test code is available at <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/ZanChen1/RCS-QuantBitErasure</uri>.",
        "journal": "IEEE Trans. Comp. Imaging",
        "title_cn": "用于量化位擦除的鲁棒压缩传感成像",
        "abstract_cn": "现有的压缩感知（CS）重建算法主要是为确定性测量而设计的。然而，在现实场景中，传输或存储期间的量化位擦除会给测量带来不确定性，并使重建变得非常复杂。我们扩展了 CS 框架以明确处理这种位级不确定性，从而能够从丢失位的量化测量中恢复稳健的图像。我们首先枚举已擦除量化位的所有有效组合，以构建可行测量值的候选集。然后将该候选集作为约束合并到新制定的逆问题中。我们提出了一种迭代即插即用算法来解决这个问题，在两个关键步骤之间交替：（1）使用预先训练的降噪器进行图像更新，以及（2）通过坐标下降加速的软最小投影策略进行测量更新。大量的实验证明了所提出方法的有效性，即使在极低的采样率和严重的擦除条件下也能实现高质量的重建。我们的框架为容易出错和资源受限的成像环境中的位擦除鲁棒 CS 重建提供了可扩展且原则性的解决方案。测试代码位于 <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/ZanChen1/RCS-QuantBitErasure</uri>。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3641303",
        "title": "Fine-Grained Image Captioning by Ranking Diffusion Transformer",
        "link": "https://doi.org/10.1109/tip.2025.3641303",
        "published": "2025",
        "author": "Jun Wan, Min Gan, Lefei Zhang, Jie Zhou, Jun Liu, Bo Du, C. L. Philip Chen",
        "summary": "The CLIP visual feature-based image captioning models have developed rapidly and achieved remarkable results. However, existing models still struggle to produce descriptive and discriminative captions because they insufficiently exploit fine-grained visual cues and fail to model complex vision–language alignment. To address these limitations, we propose a Ranking Diffusion Transformer (RDT), which integrates a Ranking Visual Encoder (RVE) and a Ranking Loss (RL) for fine-grained image captioning. The RVE introduces a novel ranking attention mechanism that effectively mines diverse and discriminative visual information from CLIP features. Meanwhile, the RL leverages the ranking of generated caption quality as a global semantic supervisory signal, thereby enhancing the diffusion process and strengthening vision–language semantic alignment. We show that by collaborating RVE and RL via the novel RDT—and by gradually adding and removing noise in the diffusion process—more discriminative visual features are learned and precisely aligned with the language features. Experimental results on popular benchmark datasets demonstrate that our proposed RDT surpasses existing state-of-the-art image captioning models in the literature. The code is publicly available at: https://github.com/junwan2014/RDT",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "通过 Ranking Diffusion Transformer 进行细粒度图像描述",
        "abstract_cn": "基于CLIP视觉特征的图像字幕模型发展迅速并取得了显着的成果。然而，现有的模型仍然难以生成描述性和区分性的字幕，因为它们没有充分利用细粒度的视觉线索，并且无法对复杂的视觉语言对齐进行建模。为了解决这些限制，我们提出了一种排名扩散变换器（RDT），它集成了排名视觉编码器（RVE）和排名损失（RL），用于细粒度图像描述。 RVE 引入了一种新颖的排名注意力机制，可以有效地从 CLIP 特征中挖掘多样化和有区别的视觉信息。同时，强化学习利用生成的字幕质量排名作为全局语义监督信号，从而增强扩散过程并加强视觉-语言语义对齐。我们表明，通过新颖的 RDT 来协作 RVE 和 RL，并通过在扩散过程中逐渐添加和消除噪声，可以学习更具辨别力的视觉特征，并与语言特征精确对齐。流行基准数据集上的实验结果表明，我们提出的 RDT 超越了文献中现有的最先进的图像字幕模型。该代码公开于：https://github.com/junwan2014/RDT"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3642612",
        "title": "Incomplete Modalities Restoration via Hierarchical Adaptation for Robust Multimodal Segmentation",
        "link": "https://doi.org/10.1109/tip.2025.3642612",
        "published": "2025",
        "author": "Yujia Sun, Weisheng Dong, Peng Wu, Mingtao Feng, Tao Huang, Xin Li, Guangming Shi",
        "summary": "Multimodal semantic segmentation has significantly advanced the field of semantic segmentation by integrating data from multiple sources. However, this task often encounters missing modality scenarios due to challenges such as sensor failures or data transmission errors, which can result in substantial performance degradation. Existing approaches to addressing missing modalities predominantly involve training separate models tailored to specific missing scenarios, typically requiring considerable computational resources. In this paper, we propose a Hierarchical Adaptation framework to Restore Missing Modalities for Multimodal segmentation (HARM3), which enables frozen pretrained multimodal models to be directly applied to missing-modality semantic segmentation tasks with minimal parameter updates. Central to HARM3 is a text-instructed missing modality prompt module, which learns multimodal semantic knowledge by utilizing available modalities and textual instructions to generate prompts for the missing modalities. By incorporating a small set of trainable parameters, this module effectively facilitates knowledge transfer between high-resource domains and low-resource domains where missing modalities are more prevalent. Besides, to further enhance the model’s robustness and adaptability, we introduce adaptive perturbation training and an affine modality adapter. Extensive experimental results demonstrate the effectiveness and robustness of HARM3 across a variety of missing modality scenarios.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "通过分层适应稳健的多模态分割来恢复不完整模态",
        "abstract_cn": "多模态语义分割通过集成多个来源的数据显着推进了语义分割领域。然而，由于传感器故障或数据传输错误等挑战，该任务经常遇到模态缺失的情况，这可能导致性能大幅下降。解决缺失模式的现有方法主要涉及训练针对特定缺失场景的单独模型，通常需要大量计算资源。在本文中，我们提出了一种用于恢复多模态分割缺失模态的分层适应框架（HARM3），该框架使冻结的预训练多模态模型能够以最少的参数更新直接应用于缺失模态语义分割任务。 HARM3 的核心是文本指示的缺失模态提示模块，它通过利用可用的模态和文本指令来生成缺失模态的提示来学习多模态语义知识。通过合并一小组可训练参数，该模块有效地促进了高资源领域和低资源领域之间的知识转移，而在低资源领域中，缺失模式更为普遍。此外，为了进一步增强模型的鲁棒性和适应性，我们引入了自适应扰动训练和仿射模态适配器。大量实验结果证明了 HARM3 在各种缺失模态场景中的有效性和鲁棒性。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3643154",
        "title": "Hiding Local Manipulations on SAR Images: A Counter-Forensic Attack",
        "link": "https://doi.org/10.1109/tip.2025.3643154",
        "published": "2025",
        "author": "Sara Mandelli, Edoardo Daniele Cannas, Paolo Bestagini, Stefano Tebaldini, Stefano Tubaro",
        "summary": "The vast accessibility of Synthetic Aperture Radar (SAR) images through online portals has propelled the research across various fields. This widespread use and easy availability have unfortunately made SAR data susceptible to malicious alterations, such as local editing applied to the images for inserting or covering the presence of sensitive targets. To contrast malicious manipulations, in the last years the forensic community has begun to dig into the SAR manipulation issue, proposing detectors that effectively localize the tampering traces in amplitude images. Nonetheless, in this paper we demonstrate that an expert practitioner can exploit the complex nature of SAR data to obscure any signs of manipulation within a locally altered amplitude image. We refer to this approach as a counter-forensic attack. To achieve the concealment of manipulation traces, the attacker can simulate a re-acquisition of the manipulated scene by the SAR system that initially generated the pristine image. In doing so, the attacker can obscure any evidence of manipulation, making it appear as if the image was legitimately produced by the system. This attack has unique features that make it both highly generalizable and relatively easy to apply. First, it is a black-box attack, meaning it is not designed to deceive a specific forensic detector. Furthermore, it does not require a training phase and is not based on adversarial operations. We assess the effectiveness of the proposed counter-forensic approach across diverse scenarios, examining various manipulation operations. The obtained results indicate that our devised attack successfully eliminates traces of manipulation, deceiving even the most advanced forensic detectors.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "隐藏 SAR 图像的本地操作：反取证攻击",
        "abstract_cn": "通过在线门户广泛获取合成孔径雷达 (SAR) 图像，推动了各个领域的研究。不幸的是，这种广泛使用和易于获取使得 SAR 数据容易受到恶意更改，例如对图像进行本地编辑以插入或覆盖敏感目标的存在。为了对比恶意操纵，在过去几年中，法医界已经开始深入研究 SAR 操纵问题，提出了能够有效定位幅度图像中的篡改痕迹的探测器。尽管如此，在本文中，我们证明专家从业者可以利用 SAR 数据的复杂性来掩盖局部改变的幅度图像中的任何操纵迹象。我们将这种方法称为反取证攻击。为了实现操纵痕迹的隐藏，攻击者可以模拟最初生成原始图像的SAR系统重新获取操纵场景。通过这样做，攻击者可以掩盖任何操纵的证据，使图像看起来好像是由系统合法生成的。这种攻击具有独特的功能，使其具有高度通用性且相对易于应用。首先，它是一种黑盒攻击，这意味着它并不是为了欺骗特定的法医探测器而设计的。此外，它不需要训练阶段，也不基于对抗性操作。我们评估所提出的反取证方法在不同场景中的有效性，检查各种操纵操作。获得的结果表明，我们设计的攻击成功消除了操纵痕迹，甚至欺骗了最先进的法医探测器。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3642633",
        "title": "FA-Net: A Feature Alignment Network for Video-Based Visible-Infrared Person Re-Identification",
        "link": "https://doi.org/10.1109/tip.2025.3642633",
        "published": "2025",
        "author": "Xi Yang, Wenjiao Dong, Xian Wang, De Cheng, Nannan Wang",
        "summary": "Video-based visible-infrared person re-identification (VVI-ReID) aims to match target pedestrians between visible and infrared videos, which is significantly applied in 24-hour surveillance systems. The key of VVI-ReID is to learn modality invariant and spatio-temporal invariant sequence-level representation to solve the challenges such as modality differences, spatio-temporal misalignment, and domain shift noise. However, existing methods predominantly emphasize on reducing modality discrepancy while relatively neglect temporal misalignment and domain shift noise reduction. To this end, this paper proposes a VVI-ReID framework called Feature Alignment Network (FA-Net) from the perspective of feature alignment, aiming to mitigate temporal misalignment. FA-Net comprises two main alignment modules: Spatial-Temporal Alignment Module (STAM) and Modality Distribution Constraint (MDC). STAM integrates global and local features to ensure individuals’ spatial representation alignment. Additionally, STAM also establishes temporal relationships by exploring inter-frame features to address cross-frame person feature matching. Furthermore, we introduce the Modality Distribution Constraint (MDC), which utilizes a symmetric distribution loss to align the distributions of features from different modalities. Besides, the SAM Guidance Augmentation (SAM-GA) strategy is designed to transform the image space of RGB and IR frames to provide more informative and less noisy frame information. Extensive experimental results demonstrate the effectiveness of the proposed method, surpassing existing state-of-the-art methods. Our code will be available at: https://github.com/code/FANet",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "FA-Net：用于基于视频的可见红外人员重新识别的特征对齐网络",
        "abstract_cn": "基于视频的可见光-红外行人重识别（VVI-ReID）旨在匹配可见光和红外视频之间的目标行人，在24小时监控系统中得到广泛应用。 VVI-ReID的关键是学习模态不变和时空不变的序列级表示，以解决模态差异、时空错位和域移位噪声等挑战。然而，现有的方法主要强调减少模态差异，而相对忽视了时间错位和域移位噪声的减少。为此，本文从特征对齐的角度提出了一种称为特征对齐网络（FA-Net）的VVI-ReID框架，旨在减轻时间错位。 FA-Net 包括两个主要的对齐模块：时空对齐模块（STAM）和模态分布约束（MDC）。 STAM 整合了全局和局部特征，以确保个体的空间表征对齐。此外，STAM 还通过探索帧间特征来建立时间关系，以解决跨帧人物特征匹配问题。此外，我们引入了模态分布约束（MDC），它利用对称分布损失来对齐不同模态的特征分布。此外，SAM 引导增强（SAM-GA）策略旨在转换 RGB 和 IR 帧的图像空间，以提供更多信息和更少噪声的帧信息。大量的实验结果证明了该方法的有效性，超越了现有的最先进的方法。我们的代码将在以下位置提供：https://github.com/code/FANet"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3642557",
        "title": "Rethinking Artifact Mitigation in HDR Reconstruction: From Detection to Optimization",
        "link": "https://doi.org/10.1109/tip.2025.3642557",
        "published": "2025",
        "author": "Xinyue Li, Zhangkai Ni, Hang Wu, Wenhan Yang, Hanli Wang, Lianghua He, Sam Kwong",
        "summary": "Artifact remains a long-standing challenge in High Dynamic Range (HDR) reconstruction. Existing methods focus on model designs for artifact mitigation but ignore explicit detection and suppression strategies. Because artifact lacks clear boundaries, distinct shapes, and semantic consistency, and there is no existing dedicated dataset for HDR artifact, progress in direct artifact detection and recovery is impeded. To bridge the gap, we propose a unified HDR reconstruction framework that integrates artifact detection and model optimization. Firstly, we build the first HDR artifact dataset (HADataset), comprising 1,213 diverse multi-exposure Low Dynamic Range (LDR) image sets and 1,765 HDR image pairs with per-pixel artifact annotations. Secondly, we develop an effective HDR artifact detector (HADetector), a robust artifact detection model capable of accurately localizing HDR reconstruction artifact. HADetector plays two pivotal roles: (1) enhancing existing HDR reconstruction models through fine-tuning, and (2) serving as a non-reference image quality assessment (NR-IQA) metric, the Artifact Score (AS), which aligns closely with human visual perception for reliable quality evaluation. Extensive experiments validate the effectiveness and generalizability of our framework, including the HADataset, HADetector, fine-tuning paradigm, and AS metric. The code and datasets are available at: https://github.com/xinyueliii/hdr-artifact-detect-optimize",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "重新思考 HDR 重建中的伪影缓解：从检测到优化",
        "abstract_cn": "伪影仍然是高动态范围 (HDR) 重建中长期存在的挑战。现有方法侧重于伪影缓解的模型设计，但忽略了显式检测和抑制策略。由于伪影缺乏清晰的边界、独特的形状和语义一致性，并且没有现有的 HDR 伪影专用数据集，因此直接伪影检测和恢复的进展受到阻碍。为了弥补这一差距，我们提出了一个统一的 HDR 重建框架，集成了伪影检测和模型优化。首先，我们构建了第一个 HDR 伪影数据集 (HADataset)，其中包含 1,213 个不同的多重曝光低动态范围 (LDR) 图像集和 1,765 个带有每像素伪影注释的 HDR 图像对。其次，我们开发了一种有效的 HDR 伪影检测器（HADetector），这是一种强大的伪影检测模型，能够准确定位 HDR 重建伪影。 HADetector 发挥着两个关键作用：(1) 通过微调增强现有 HDR 重建模型，(2) 作为非参考图像质量评估 (NR-IQA) 指标，即伪影评分 (AS)，它与人类视觉感知紧密结合，以实现可靠的质量评估。大量实验验证了我们框架的有效性和通用性，包括 HADataset、HADetector、微调范式和 AS 指标。代码和数据集可在以下网址获取：https://github.com/xinyueliii/hdr-artifact-detect-optimize"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3640863",
        "title": "Improving the Stability and Efficiency of Diffusion Models for Content Consistent Super-Resolution",
        "link": "https://doi.org/10.1109/tip.2025.3640863",
        "published": "2025",
        "author": "Lingchen Sun, Rongyuan Wu, Jie Liang, Zhengqiang Zhang, Hongwei Yong, Lei Zhang",
        "summary": "The generative priors of pre-trained latent diffusion models (DMs) have demonstrated great potential to enhance the visual quality of image super-resolution (SR) results. However, the noise sampling process in DMs introduces randomness in the SR outputs, and the generated contents can differ a lot with different noise samples. The multi-step diffusion process can be accelerated by distilling methods, but the generative capacity is difficult to control. To address these issues, we analyze the respective advantages of DMs and generative adversarial networks (GANs) and propose to partition the generative SR process into two stages, where the DM is employed for reconstructing image structures and the GAN is employed for improving fine-grained details. Specifically, we propose a non-uniform timestep sampling strategy in the first stage. A single timestep sampling is first applied to extract the coarse information from the input image, then a few reverse steps are used to reconstruct the main structures. In the second stage, we finetune the decoder of the pre-trained variational auto-encoder by adversarial GAN training for deterministic detail enhancement. Once trained, our proposed method, namely content consistent super-resolution (CCSR), allows flexible use of different diffusion steps in the inference stage without re-training. Extensive experiments show that with 2 or even 1 diffusion step, CCSR can significantly improve the content consistency of SR outputs while keeping high perceptual quality. Codes and models can be found at https://github.com/csslc/CCSR.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "提高内容一致超分辨率扩散模型的稳定性和效率",
        "abstract_cn": "预先训练的潜在扩散模型（DM）的生成先验已证明在增强图像超分辨率（SR）结果的视觉质量方面具有巨大潜力。然而，DM 中的噪声采样过程在 SR 输出中引入了随机性，并且不同噪声样本生成的内容可能有很大差异。多步扩散过程可以通过蒸馏方法加速，但生成能力难以控制。为了解决这些问题，我们分析了 DM 和生成对抗网络（GAN）各自的优势，并建议将生成 SR 过程分为两个阶段，其中 DM 用于重建图像结构，GAN 用于改善细粒度细节。具体来说，我们在第一阶段提出了非均匀时间步采样策略。首先应用单时间步采样从输入图像中提取粗略信息，然后使用一些反向步骤来重建主要结构。在第二阶段，我们通过对抗性 GAN 训练来微调预训练变分自动编码器的解码器，以实现确定性细节增强。经过训练后，我们提出的方法，即内容一致超分辨率（CCSR），允许在推理阶段灵活使用不同的扩散步骤，而无需重新训练。大量实验表明，通过 2 个甚至 1 个扩散步骤，CCSR 可以显着提高 SR 输出的内容一致性，同时保持较高的感知质量。代码和模型可以在 https://github.com/csslc/CCSR 找到。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3642527",
        "title": "Micro-Expression Analysis Based on Self-Adaptive Pseudo-Labeling and Residual Connected Channel Attention Mechanisms",
        "link": "https://doi.org/10.1109/tip.2025.3642527",
        "published": "2026",
        "author": "Jinxiu Zhang, Weidong Min, Jiahao Li, Qing Han",
        "summary": "Micro-expressions can reveal genuine emotions that are not easily concealed, making them invaluable in fields such as psychotherapy and criminal interrogation. However, existing pseudo-labeling-based methods for micro-expression analysis have two major limitations. First, pseudo-labels generated by the sliding window do not account for the actual proportion of micro-expressions in the video, which leads to inaccurate labeling. Second, they predominantly focus on overall features, thereby neglecting subtle features. In this paper, we propose a micro-expression analysis method called Spot-Then-Recognize Method (STRM), which integrates spotting and recognition tasks. To address the first limitation, we propose a Self-Adaptive Pseudo-labeling Method (SAPM) that dynamically assigns pseudo-labels to micro-expression frames according to their actual proportion in the video sequence, thereby improving labeling accuracy. To address second limitation, we design a Multi-Scale Residual Channel Attention Network (MSRCAN) to effectively extract subtle micro-expression features. The MSRCAN comprises three modules: Multi-Scale Shared Network (MSSN), Spotting Network, and Recognition Network. The MSSN initially extracts micro-expression features by performing multi-scale feature extraction with Residual Connected Channel Attention Modules (RCCAM), which are then refined in the spotting and recognition networks. We conducted comprehensive experiments on three short video datasets (CASME II, SMIC-E-HS, SMIC-E-NIR) and two long video datasets (CAS(ME)2, SAMMLV). Experimental results show that our proposed method significantly outperforms existing methods, achieving an overall performance of 58.24%, a 19.62% improvement, and a $1.51\\times $ gain over the baseline in terms of micro-expression analysis.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "基于自适应伪标签和残差连通通道注意力机制的微表情分析",
        "abstract_cn": "微表情可以揭示不易隐藏的真实情感，使其在心理治疗和刑事审讯等领域具有无价的价值。然而，现有的基于伪标记的微表情分析方法有两个主要局限性。首先，滑动窗口生成的伪标签没有考虑到视频中微表情的实际比例，从而导致标注不准确。其次，他们主要关注整体特征，从而忽略了细微特征。在本文中，我们提出了一种称为点然后识别方法（STRM）的微表情分析方法，该方法集成了点和识别任务。为了解决第一个限制，我们提出了一种自适应伪标记方法（SAPM），该方法根据微表情帧在视频序列中的实际比例动态地将伪标签分配给微表情帧，从而提高标记精度。为了解决第二个限制，我们设计了多尺度残留通道注意网络（MSRCAN）来有效提取微妙的微表情特征。 MSRCAN由三个模块组成：多尺度共享网络（MSSN）、发现网络和识别网络。 MSSN 最初通过使用剩余连接通道注意模块 (RCCAM) 执行多尺度特征提取来提取微表情特征，然后在发现和识别网络中对其进行细化。我们对三个短视频数据集（CASME II、SMIC-E-HS、SMIC-E-NIR）和两个长视频数据集（CAS(ME)2、SAMMLV）进行了全面的实验。实验结果表明，我们提出的方法显着优于现有方法，在微表情分析方面，总体性能达到 58.24%，提高了 19.62%，比基线提高了 1.51 美元\\times 美元。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3641310",
        "title": "Privacy-Preserving CNN Inference for Image Super-Resolution Cross Multiple Ciphertexts",
        "link": "https://doi.org/10.1109/tip.2025.3641310",
        "published": "2025",
        "author": "Peijia Zheng, Donger Mo, Yufei Zhou, Xiangyu Gao, Xiaochun Cao, Jiwu Huang",
        "summary": "Online image super-resolution (SR) services have been widely used in applications such as Remini and DeepAI. However, the exposure of plaintext images raises serious privacy concerns. While secure CNN inference techniques are employed to protect images in image classification, they are not applicable to the unique challenges posed by image SR: the output resolution is significantly higher than that of the input image. In this paper, we present a secure CNN inference scheme for image SR by employing a multiple ciphertext encapsulation method. We begin by designing fundamental homomorphic operations, including addition, multiplication, and rotation across ciphertexts. Recognizing that image SR typically involves an upsampling layer—unlike image classification—we propose a fast algorithm for secure upsampling. This technique leverages pre-weight block masking and cross-ciphertext rotation, resulting in a significant speedup compared to direct homomorphic upsampling. We then present an efficient batched homomorphic two-dimensional convolution method across ciphertexts, incorporating kernel rearrangement and merging strategies. We also design a polynomial activation function specifically optimized for image SR, further enhancing performance. Extensive experiments demonstrate that our HE-friendly SR network outperforms existing secure solutions, while the proposed multiple ciphertext encapsulation technique achieves at least a 2x improvement in both computational efficiency and memory usage.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "用于跨多个密文的图像超分辨率的隐私保护 CNN 推理",
        "abstract_cn": "在线图像超分辨率（SR）服务已广泛应用于Remini、DeepAI等应用中。然而，明文图像的暴露引起了严重的隐私问题。虽然安全CNN推理技术用于保护图像分类中的图像，但它们不适用于图像SR带来的独特挑战：输出分辨率明显高于输入图像的分辨率。在本文中，我们通过采用多重密文封装方法，提出了一种用于图像 SR 的安全 CNN 推理方案。我们首先设计基本的同态运算，包括密文间的加法、乘法和旋转。认识到图像 SR 通常涉及上采样层（与图像分类不同），我们提出了一种用于安全上采样的快速算法。该技术利用预权重块掩码和交叉密文旋转，与直接同态上采样相比，显着加速。然后，我们提出了一种跨密文的高效批量同态二维卷积方法，结合了内核重排和合并策略。我们还设计了专门针对图像超分辨率优化的多项式激活函数，进一步增强性能。大量实验表明，我们的 HE 友好 SR 网络优于现有的安全解决方案，而所提出的多重密文封装技术在计算效率和内存使用方面实现了至少 2 倍的改进。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3643138",
        "title": "NiCI-Pruning: Enhancing Diffusion Model Pruning via Noise in Clean Image Guidance",
        "link": "https://doi.org/10.1109/tip.2025.3643138",
        "published": "2025",
        "author": "Junzhu Mao, Zeren Sun, Yazhou Yao, Tianfei Zhou, Liqiang Nie, Xiansheng Hua",
        "summary": "The substantial successes achieved by diffusion probabilistic models have prompted the study of their employment in resource-limited scenarios. Pruning methods have been proven effective in compressing discriminative models relying on the correlation between training losses and model performances. However, diffusion models employ an iterative process for generating high-quality images, leading to a breakdown of such connections. To address this challenge, we propose a simple yet effective method, named NiCI-Pruning (Noise in Clean Image Pruning), for the compression of diffusion models. NiCI-Pruning capitalizes the noise predicted by the model based on clean image inputs, favoring it as a feature for establishing reconstruction losses. Accordingly, Taylor expansion is employed for the proposed reconstruction loss to evaluate the parameter importance effectively. Moreover, we propose an interval sampling strategy that incorporates a timestep-weighted schema, alleviating the risk of misleading information obtained at later timesteps. We provide comprehensive experimental results to affirm the superiority of our proposed approach. Notably, our method achieves a remarkable average reduction of 30.4% in FID score increase across five different datasets compared to the state-of-the-art diffusion pruning method at equivalent pruning rates. Our code and models have been made available at https://github.com/NUST-Machine-Intelligence-Laboratory/NiCI-Pruning",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "NiCI-Pruning：通过清洁图像引导中的噪声增强扩散模型修剪",
        "abstract_cn": "扩散概率模型取得的巨大成功促使人们对其在资源有限的情况下的应用进行研究。事实证明，剪枝方法可以有效地依赖训练损失和模型性能之间的相关性来压缩判别模型。然而，扩散模型采用迭代过程来生成高质量图像，从而导致这种连接的崩溃。为了应对这一挑战，我们提出了一种简单而有效的方法，称为 NiCI-Pruning（干净图像修剪中的噪声），用于压缩扩散模型。 NiCI-Pruning 利用模型基于干净图像输入预测的噪声，有利于将其作为建立重建损失的特征。因此，泰勒展开用于所提出的重建损失，以有效地评估参数重要性。此外，我们提出了一种区间采样策略，该策略结合了时间步长加权模式，减轻了在稍后时间步长获得的误导性信息的风险。我们提供全面的实验结果来证实我们提出的方法的优越性。值得注意的是，与同等剪枝率下最先进的扩散剪枝方法相比，我们的方法在五个不同数据集上的 FID 分数增长平均显着降低了 30.4%。我们的代码和模型已在 https://github.com/NUST-Machine-Intelligence-Laboratory/NiCI-Pruning 上提供"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3642574",
        "title": "UniqueSplat: View-Conditioned 3D Gaussian Splatting for Generalizable 3D Reconstruction",
        "link": "https://doi.org/10.1109/tip.2025.3642574",
        "published": "2025",
        "author": "Haixu Song, Xiaoke Yang, Shengjun Zhang, Jiwen Lu, Yueqi Duan",
        "summary": "In this paper, we propose UniqueSplat, a view-conditioned feed-forward 3D Gaussian Splatting model to reconstruct customized 3D radiance fields for each view query. Existing feed-forward methods such as pixelSplat and MVSplat aim to generate fixed Gaussians across all views of each scene by minimizing the error between rendered views and ground-truth images. However, such fixed Gaussians generally render images from all views and lack the ability to adapt to specific viewpoints, as they do not incorporate target view information when predicting Gaussians. To address this, our UniqueSplat learns the view-conditioned information as a prior and incorporates this knowledge into network parameters, so that Gaussians are dynamically adjusted in accordance with different views. Specifically, we propose a two-branch view-conditioned hyperNetwork to simultaneously learn view-agnostic embeddings and view-specific knowledge, which not only explores the shareable knowledge from various views, but also adapts the model to specific views at test time. Extensive experiments on widely-used datasets including RealEstate10K, ACID and DTU demonstrate the superiority of UniqueSplat over the state-of-the-art methods. Moreover, UniqueSplat encouragingly outperforms existing methods in cross-dataset evaluation, showing its notable generalization ability.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "UniqueSplat：用于通用 3D 重建的视图条件 3D 高斯分布",
        "abstract_cn": "在本文中，我们提出了 UniqueSplat，一种视图条件前馈 3D 高斯 Splatting 模型，用于为每个视图查询重建定制的 3D 辐射场。现有的前馈方法（例如 PixelSplat 和 MVSplat）旨在通过最小化渲染视图与地面实况图像之间的误差，在每个场景的所有视图中生成固定高斯分布。然而，这种固定高斯模型通常会从所有视图渲染图像，并且缺乏适应特定视点的能力，因为它们在预测高斯模型时没有结合目标视图信息。为了解决这个问题，我们的 UniqueSplat 学习视图条件信息作为先验，并将这些知识合并到网络参数中，以便根据不同的视图动态调整高斯。具体来说，我们提出了一个两分支视图条件超网络来同时学习视图不可知的嵌入和视图特定的知识，它不仅探索来自各种视图的可共享知识，而且在测试时使模型适应特定视图。对广泛使用的数据集（包括 RealEstate10K、ACID 和 DTU）进行的大量实验证明了 UniqueSplat 相对于最先进方法的优越性。此外，UniqueSplat 在跨数据集评估方面优于现有方法，显示出其显着的泛化能力。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3642622",
        "title": "BVSR-EvD: Blurry Video Space-Time Super-Resolution With Events via Diffusion Models",
        "link": "https://doi.org/10.1109/tip.2025.3642622",
        "published": "2025",
        "author": "Wenming Weng, Yueyi Zhang, Wenhao Xu, Zeyu Xiao, Zhiwei Xiong",
        "summary": "Video restoration from low-resolution and low-frame-rate blurry sources remains challenging due to insufficient data priors. In this paper, we propose BVSR-EvD, leveraging event cameras and diffusion models to boost blurry video space-time super-resolution. Specifically, we identify three distinct data priors from event-video dual modalities: motion prior from events, content prior from videos, and physical prior from their integration, contributing to temporal stability, content preservation, and detail enhancement respectively. To effectively utilize these data priors, BVSR-EvD creates the Trident Diffusion Model (Trident-DM), which decomposes each denoising step into trident decoupling and adaptive self-composition stages. The former employs single-modal and dual-modal meta-networks to extract the three unique data priors, while the latter dynamically integrates them through learned prior-aware weight maps. BVSR-EvD achieves up to <inline-formula> <tex-math notation=\"LaTeX\">$\\times 8$ </tex-math></inline-formula> spatial super-resolution and <inline-formula> <tex-math notation=\"LaTeX\">$\\times 64$ </tex-math></inline-formula> temporal super-resolution from blurry videos, surpassing existing methods on public video datasets.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "BVSR-EvD：通过扩散模型实现事件的模糊视频时空超分辨率",
        "abstract_cn": "由于数据先验不足，从低分辨率和低帧速率模糊源进行视频恢复仍然具有挑战性。在本文中，我们提出了 BVSR-EvD，利用事件相机和扩散模型来提高模糊视频时空超分辨率。具体来说，我们从事件-视频双模态中识别出三种不同的数据先验：事件的运动先验、视频的内容先验以及它们集成的物理先验，分别有助于时间稳定性、内容保留和细节增强。为了有效利用这些数据先验，BVSR-EvD 创建了 Trident 扩散模型 (Trident-DM)，它将每个去噪步骤分解为 Trident 解耦和自适应自组合阶段。前者采用单模态和双模态元网络来提取三个独特的数据先验，而后者通过学习的先验感知权重图动态地集成它们。 BVSR-EvD 在模糊视频中实现了高达 <inline-formula> <tex-math notation=\"LaTeX\">$\\times 8$ </tex-math></inline-formula> 空间超分辨率和 <inline-formula> <tex-math notation=\"LaTeX\">$\\times 64$ </tex-math></inline-formula> 时间超分辨率，超越了公共视频数据集上的现有方法。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3643146",
        "title": "Hi-Mamba: Hierarchical Mamba for Efficient Image Super-Resolution",
        "link": "https://doi.org/10.1109/tip.2025.3643146",
        "published": "2025",
        "author": "Junbo Qiao, Jincheng Liao, Wei Li, Yulun Zhang, Yong Guo, Jiao Xie, Jie Hu, Shaohui Lin",
        "summary": "Despite Transformers have achieved significant success in low-level vision tasks, they are constrained by computing self-attention with a quadratic complexity and limited-size windows. This limitation results in a lack of global receptive field across the entire image. Recently, State Space Models (SSMs) have gained widespread attention due to their global receptive field and linear complexity with respect to input length. However, integrating SSMs into low-level vision tasks presents two major challenges: 1) Relationship degradation of long-range tokens with a long-range forgetting problem by encoding pixel-by-pixel high-resolution images. 2) Significant redundancy in the existing multi-direction scanning strategy. To this end, we propose Hi-Mamba for image super-resolution (SR) to address these challenges, which unfolds the image with only a single scan. Specifically, the Global Hierarchical Mamba Block (GHMB) enables token interactions across the entire image, providing a global receptive field while leveraging a multi-scale structure to facilitate long-range dependency learning. Additionally, the Direction Alternation Module (DAM) adjusts the scanning patterns of GHMB across different layers to enhance spatial relationship modeling. Extensive experiments demonstrate that our Hi-Mamba achieves 0.2–0.27dB PSNR gains on the Urban100 dataset across different scaling factors compared to the state-of-the-art MambaIRv2 for SR. Moreover, our lightweight Hi-Mamba also outperforms lightweight SRFormer by 0.39dB PSNR for $\\times 2$ SR.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "Hi-Mamba：分层 Mamba 可实现高效图像超分辨率",
        "abstract_cn": "尽管 Transformer 在低级视觉任务中取得了巨大的成功，但它们受到计算自注意力的二次复杂度和有限大小的窗口的限制。这种限制导致整个图像缺乏全局感受野。最近，状态空间模型（SSM）由于其全局感受野和输入长度的线性复杂性而受到广泛关注。然而，将 SSM 集成到低级视觉任务中面临两个主要挑战：1）通过逐像素高分辨率图像编码，导致长程标记与长程遗忘问题的关系退化。 2）现有的多方向扫描策略存在明显的冗余。为此，我们提出了用于图像超分辨率（SR）的 Hi-Mamba 来解决这些挑战，它只需一次扫描即可展开图像。具体来说，全局分层曼巴块（GHMB）支持跨整个图像的令牌交互，提供全局感受野，同时利用多尺度结构促进远程依赖性学习。此外，方向交替模块 (DAM) 调整 GHMB 跨不同层的扫描模式，以增强空间关系建模。大量实验表明，与用于 SR 的最先进的 MambaIRv2 相比，我们的 Hi-Mamba 在不同缩放因子的 Urban100 数据集上实现了 0.2–0.27dB PSNR 增益。此外，我们的轻量级 Hi-Mamba 的性能也比轻量级 SRFormer 高出 0.39dB PSNR，SR 为 $\\times 2$。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3643156",
        "title": "ViV-ReID: Bidirectional Structural-Aware Spatial–Temporal Graph Networks on Large-Scale Video-Based Vessel Re-Identification Dataset",
        "link": "https://doi.org/10.1109/tip.2025.3643156",
        "published": "2025",
        "author": "Mingxin Zhang, Fuxiang Feng, Xing Fang, Lin Zhang, Youmei Zhang, Xiaolei Li, Wei Zhang",
        "summary": "Vessel re-identification (ReID) serves as a foundational task for intelligent maritime transportation systems. To enhance maritime surveillance capabilities, this study investigates video-based vessel ReID, a critical yet underexplored task in intelligent transportation systems. The lack of relevant datasets has limited the progress of Video-based vessel ReID research work. We established ViV-ReID, the first publicly available large-scale video-based vessel ReID dataset, comprising 480 vessel identities captured from 20 cross-port camera views (7,165 tracklets and 1.14 million frames), establishing a benchmark for advancing vessel ReID from image to video processing. Videos offer significantly richer information than single-frame images. The dynamic nature of video often leads to fragmented spatio-temporal features causing disrupted contextual understanding, and to address this problem, we further propose a Bidirectional Structural-Aware Spatial-Temporal Graph Network (Bi-SSTN) that explicitly aligns spatio-temporal features using vessel structural priors. Extensive experiments on the ViV-ReID dataset demonstrate that image-based ReID methods often show suboptimal performance when applied to video data. Meanwhile, it is crucial to validate the effectiveness of spatio-temporal information and establish performance benchmarks for different methods. The Bidirectional Structural-Aware Spatial-Temporal Graph Network (Bi-SSTN) significantly outperforms state-of-the-art methods on ViV-ReID, confirming its efficacy in modeling vessel-specific spatio-temporal patterns. Project web page: https://vsislab.github.io/ViV_ReID/",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "ViV-ReID：基于大规模视频的血管重新识别数据集的双向结构感知时空图​​网络",
        "abstract_cn": "船舶重新识别（ReID）是智能海上运输系统的基础任务。为了增强海上监视能力，本研究研究了基于视频的船舶再识别，这是智能交通系统中一项关键但尚未充分探索的任务。相关数据集的缺乏限制了基于视频的船舶ReID研究工作的进展。我们建立了 ViV-ReID，这是第一个公开的大规模基于视频的船舶 ReID 数据集，包含从 20 个跨港口摄像机视图捕获的 480 个船舶身份（7,165 个轨迹和 114 万帧），为推进船舶 ReID 从图像处理到视频处理建立了基准。视频提供的信息比单帧图像要丰富得多。视频的动态特性通常会导致时空特征碎片化，从而导致上下文理解中断，为了解决这个问题，我们进一步提出了一种双向结构感知时空图​​网络（Bi-SSTN），它使用血管结构先验显式对齐时空特征。 ViV-ReID 数据集上的大量实验表明，基于图像的 ReID 方法在应用于视频数据时通常表现出次优的性能。同时，验证时空信息的有效性并为不同方法建立性能基准至关重要。双向结构感知时空图​​网络 (Bi-SSTN) 显着优于 ViV-ReID 上最先进的方法，证实了其在建模血管特定时空模式方面的功效。项目网页：https://vsislab.github.io/ViV_ReID/"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3644125",
        "title": "Face Forgery Detection With CLIP-Enhanced Multi-Encoder Distillation",
        "link": "https://doi.org/10.1109/tip.2025.3644125",
        "published": "2025",
        "author": "Chunlei Peng, Tianzhe Yan, Decheng Liu, Nannan Wang, Ruimin Hu, Xinbo Gao",
        "summary": "With the development of face forgery technology, fake faces are rampant, threatening the security and authenticity of many fields. Therefore, it is of great significance to study face forgery detection. At present, existing detection methods have deficiencies in the comprehensiveness of feature extraction and model adaptability, and it is difficult to accurately deal with complex and changeable forgery scenarios. However, the rise of multimodal models provides new insights for current forgery detection methods. At present, most methods use relatively simple text prompts to describe the difference between real and fake faces. However, these researchers ignore that the CLIP model itself does not have the relevant knowledge of forgery detection. Therefore, our paper proposes a face forgery detection method based on multi-encoder fusion and cross-modal knowledge distillation. On the one hand, the prior knowledge of the CLIP model and the forgery model is fused. On the other hand, through the alignment distillation, the student model can learn the visual abnormal patterns and semantic features of the forged samples captured by the teacher model. Specifically, our paper extracts the features of face photos by fusing the CLIP text encoder and the CLIP image encoder, and uses the dataset in the field of forgery detection to pretrain and fine-tune the Deepfake-V2-Model to enhance the detection ability, which are regarded as the teacher model. At the same time, the visual and language patterns of the teacher model are aligned with the visual patterns of the pretrained student model, and the aligned representations are refined to the student model. This not only combines the rich representation of the CLIP image encoder and the excellent generalization ability of text embedding, but also enables the original model to effectively acquire relevant knowledge for forgery detection. Experiments show that our method effectively improves the performance on face forgery detection.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "使用 CLIP 增强型多编码器蒸馏进行人脸伪造检测",
        "abstract_cn": "随着人脸伪造技术的发展，假脸泛滥，威胁着许多领域的安全性和真实性。因此，研究人脸伪造检测具有重要意义。目前现有的检测方法在特征提取的全面性和模型适应性方面存在不足，难以准确应对复杂多变的伪造场景。然而，多模态模型的兴起为当前的伪造检测方法提供了新的见解。目前大多数方法都是使用相对简单的文字提示来描述真假人脸的区别。然而，这些研究人员忽略了CLIP模型本身并不具备伪造检测的相关知识。因此，我们的论文提出了一种基于多编码器融合和跨模态知识蒸馏的人脸伪造检测方法。一方面，融合了CLIP模型和伪造模型的先验知识。另一方面，通过对齐蒸馏，学生模型可以学习教师模型捕获的伪造样本的视觉异常模式和语义特征。具体来说，我们的论文通过融合CLIP文本编码器和CLIP图像编码器来提取人脸照片的特征，并使用伪造检测领域的数据集对Deepfake-V2-Model进行预训练和微调以增强检测能力，将其作为教师模型。同时，教师模型的视觉和语言模式与预训练的学生模型的视觉模式对齐，并且对齐的表示被细化到学生模型。这不仅结合了CLIP图像编码器的丰富表示和文本嵌入的出色泛化能力，而且使原始模型能够有效地获取用于伪造检测的相关知识。实验表明，我们的方法有效提高了人脸伪造检测的性能。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3644231",
        "title": "TG-TSGNet: A Text-Guided Arbitrary-Resolution Terrain Scene Generation Network",
        "link": "https://doi.org/10.1109/tip.2025.3644231",
        "published": "2025",
        "author": "Yifan Zhu, Yan Wang, Xinghui Dong",
        "summary": "With the increasing demand for terrain visualization in many fields, such as augmented reality, virtual reality and geographic mapping, traditional terrain scene modeling methods encounter great challenges in processing efficiency, content realism and semantic consistency. To address these challenges, we propose a Text-Guided Arbitrary-Resolution Terrain Scene Generation Network (TG-TSGNet), which contains a ConvMamba-VQGAN, a Text Guidance Sub-network and an Arbitrary-Resolution Image Super-Resolution Module (ARSRM). The ConvMamba-VQGAN is built on top of the Conv-Based Local Representation Block (CLRB) and the Mamba-Based Global Representation Block (MGRB) that we design, to utilize local and global features. Furthermore, the Text Guidance Sub-network comprises a text encoder and a Text-Image Alignment Module (TIAM) for the sake of incorporating textual semantics into image representation. In addition, the ARSRM can be trained together with the ConvMamba-VQGAN, to perform the task of image super-resolution. To fulfill the text-guided terrain scene generation task, we derive a set of textual descriptions for the 36,672 images across the 38 categories of the Natural Terrain Scene Data Set (NTSD). These descriptions can be used to train and test the TG-TSGNet (The data set, model and source code are available at https://github.com/INDTLab/TG-TSGNet). Experimental results show that the TG-TSGNet outperforms, or at least performs comparably to, the baseline methods in image realism and semantic consistency with proper efficiency. We believe that the promising performance should be due to the ability of the TG-TSGNet not only to capture both the local and global characteristics and the semantics of terrain scenes, but also to reduce the computational cost of image generation.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "TG-TSGNet：文本引导的任意分辨率地形场景生成网络",
        "abstract_cn": "随着增强现实、虚拟现实、地理测绘等领域对地形可视化的需求不断增加，传统的地形场景建模方法在处理效率、内容真实性和语义一致性等方面遇到了巨大的挑战。为了应对这些挑战，我们提出了一种文本引导任意分辨率地形场景生成网络（TG-TSGNet），其中包含 ConvMamba-VQGAN、文本引导子网络和任意分辨率图像超分辨率模块（ARSRM）。 ConvMamba-VQGAN 建立在我们设计的基于 Conv 的局部表示块（CLRB）和基于 Mamba 的全局表示块（MGRB）之上，以利用局部和全局特征。此外，文本引导子网络包括文本编码器和文本图像对齐模块（TIAM），以便将文本语义合并到图像表示中。此外，ARSRM可以与ConvMamba-VQGAN一起训练，以执行图像超分辨率的任务。为了完成文本引导的地形场景生成任务，我们为自然地形场景数据集 (NTSD) 38 个类别的 36,672 张图像导出了一组文本描述。这些描述可用于训练和测试 TG-TSGNet（数据集、模型和源代码可在 https://github.com/INDTLab/TG-TSGNet 获取）。实验结果表明，TG-TSGNet 在图像真实性和语义一致性方面优于或至少与基线方法相当，并且具有适当的效率。我们认为，良好的性能应该归功于 TG-TSGNet 不仅能够捕获局部和全局特征以及地形场景的语义，而且还能够降低图像生成的计算成本。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3609135",
        "title": "Meta-TIP: An Unsupervised End-to-End Fusion Network for Multi-Dataset Style-Adaptive Threat Image Projection",
        "link": "https://doi.org/10.1109/tip.2025.3609135",
        "published": "2025",
        "author": "Bowen Ma, Tong Jia, Hao Wang, Dongyue Chen",
        "summary": "Threat Image Projection (TIP) is a convenient and effective means to expand X-ray baggage images, which is essential for training both security personnel and computer-aided screening systems. Existing methods are primarily divided into two categories: X-ray imaging principle-based methods and GAN-based generative methods. The former cast prohibited items acquisition and projection as two individual steps and rarely consider the style consistency between the source prohibited items and target X-ray images from different datasets, making them less flexible and reliable for practical applications. Although GAN-based methods can directly generate visually consistent prohibited items on target images, they suffer from unstable training and lack of interpretability, which significantly impact the quality of the generated items. To overcome these limitations, we present a conceptually simple, flexible and unsupervised end-to-end TIP framework, termed as Meta-TIP, which superimposes the prohibited item distilled from the source image onto the target image in a style-adaptive manner. Specifically, Meta-TIP mainly applies three innovations: 1) reconstruct a pure prohibited item from a cluttered source image with a novel foreground-background contrastive loss; 2) a material-aware style-adaptive projection module learns two modulation parameters pertinently based on the style of similar material objects in the target image to control the appearance of prohibited items; 3) a novel logarithmic form loss is well-designed based on the principle of TIP to optimize synthetic results in an unsupervised manner. We comprehensively verify the authenticity and training effect of the synthetic X-ray images on four public datasets, i.e., SIXray, OPIXray, PIXray, and PIDray dataset, and the results confirm that our framework can flexibly generate very realistic synthetic images without any limitations.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "Meta-TIP：用于多数据集样式自适应威胁图像投影的无监督端到端融合网络",
        "abstract_cn": "威胁图像投影 (TIP) 是一种方便有效的扩展 X 射线行李图像的方法，对于培训安全人员和计算机辅助安检系统至关重要。现有的方法主要分为两类：基于X射线成像原理的方法和基于GAN的生成方法。前者将违禁物品采集和投影作为两个单独的步骤，很少考虑来自不同数据集的源违禁物品和目标 X 射线图像之间的风格一致性，这使得它们在实际应用中不太灵活和可靠。虽然基于 GAN 的方法可以直接在目标图像上生成视觉上一致的违禁物品，但它们的训练不稳定且缺乏可解释性，这显着影响了生成物品的质量。为了克服这些限制，我们提出了一种概念上简单、灵活且无监督的端到端 TIP 框架，称为 Meta-TIP，它以风格自适应的方式将从源图像中提取的违禁项叠加到目标图像上。具体来说，Meta-TIP主要应用了三项创新：1）利用新颖的前景-背景对比损失从杂乱的源图像中重建纯粹的违禁物品； 2）材质感知风格自适应投影模块根据目标图像中相似材质物体的风格有针对性地学习两个调制参数，以控制违禁物品的出现； 3）基于TIP原理精心设计了一种新颖的对数形式损失，以无监督的方式优化合成结果。我们在 SIXray、OPIXray、PIXray 和 PIDray 四个公共数据集上全面验证了合成 X 射线图像的真实性和训练效果，结果证实我们的框架可以灵活地生成非常逼真的合成图像，没有任何限制。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3644785",
        "title": "PoseMoE: Mixture-of-Experts Network for Monocular 3D Human Pose Estimation",
        "link": "https://doi.org/10.1109/tip.2025.3644785",
        "published": "2025",
        "author": "Mengyuan Liu, Jiajie Liu, Jinyan Zhang, Wenhao Li, Junsong Yuan",
        "summary": "The lifting-based methods have dominated monocular 3D human pose estimation by leveraging detected 2D poses as intermediate representations. The 2D component of the final 3D human pose benefits from the detected 2D poses, whereas its depth counterpart must be estimated from scratch. The lifting-based methods encode the detected 2D pose and unknown depth in an entangled feature space, explicitly introducing depth uncertainty to the detected 2D pose, thereby limiting overall estimation accuracy. This work reveals that the depth representation is pivotal for the estimation process. Specifically, when depth is in an initial, completely unknown state, jointly encoding depth features with 2D pose features is detrimental to the estimation process. In contrast, when depth is initially refined to a more dependable state via network-based estimation, encoding it together with 2D pose information is beneficial. To address this limitation, we present a Mixture-of-Experts network for monocular 3D pose estimation named PoseMoE. Our approach introduces: 1) A mixture-of-experts network where specialized expert modules refine the well-detected 2D pose features and learn the depth features. This mixture-of-experts design disentangles the feature encoding process for 2D pose and depth, therefore reducing the explicit influence of uncertain depth features on 2D pose features. 2) A cross-expert knowledge aggregation module is proposed to aggregate cross-expert spatio-temporal contextual information. This step enhances features through bidirectional mapping between 2D pose and depth. Extensive experiments show that our proposed PoseMoE outperforms the conventional lifting-based methods on three widely used datasets: Human3.6M, MPI-INF-3DHP, and 3DPW.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "PoseMoE：用于单目 3D 人体姿势估计的专家混合网络",
        "abstract_cn": "基于提升的方法利用检测到的 2D 姿势作为中间表示，在单目 3D 人体姿势估计中占据主导地位。最终 3D 人体姿势的 2D 组件受益于检测到的 2D 姿势，而其深度对应部分必须从头开始估计。基于提升的方法在纠缠特征空间中对检测到的 2D 姿态和未知深度进行编码，明确地将深度不确定性引入到检测到的 2D 姿态中，从而限制了整体估计精度。这项工作表明深度表示对于估计过程至关重要。具体来说，当深度处于初始、完全未知的状态时，将深度特征与 2D 姿态特征联合编码对估计过程是有害的。相反，当深度最初通过基于网络的估计被细化为更可靠的状态时，将其与 2D 姿态信息一起编码是有益的。为了解决这个限制，我们提出了一种用于单目 3D 姿态估计的专家混合网络，名为 PoseMoE。我们的方法引入了：1）专家混合网络，其中专门的专家模块细化检测良好的 2D 姿态特征并学习深度特征。这种专家混合设计解开了 2D 姿态和深度的特征编码过程，因此减少了不确定深度特征对 2D 姿态特征的显式影响。 2）提出了跨专家知识聚合模块来聚合跨专家时空上下文信息。此步骤通过 2D 位姿和深度之间的双向映射来增强特征。大量实验表明，我们提出的 PoseMoE 在三个广泛使用的数据集上优于传统的基于提升的方法：Human3.6M、MPI-INF-3DHP 和 3DPW。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3644140",
        "title": "Boosting Faithful Multi-Modal LLMs via Complementary Visual Grounding",
        "link": "https://doi.org/10.1109/tip.2025.3644140",
        "published": "2025",
        "author": "Zheren Fu, Zhendong Mao, Lei Zhang, Yongdong Zhang",
        "summary": "Multimodal Large Language Models (MLLMs) exhibit impressive performance across vision-language tasks, but still face the hallucination challenges, where generated texts are factually inconsistent with visual input. Existing mitigation methods focus on surface symptoms of hallucination and heavily rely on post-hoc corrections, extensive data curation, or costly inference schemes. In this work, we identify two key factors of MLLM hallucination: Insufficient Visual Context, where ambiguous visual contexts lead to language speculation, and Progressive Textual Drift, where model attention strays from visual inputs in longer responses. To address these problems, we propose a novel Complementary Visual Grounding (CVG) framework. CVG exploits the intrinsic architecture of MLLMs, without requiring any external tools, models, or additional data. CVG first disentangles visual context into two complementary branches based on query relevance, then maintains steadfast visual grounding during the auto-regressive generation. Finally, it contrasts the output distributions of two branches to produce a faithful response. Extensive experiments on various hallucination and general benchmarks demonstrate that CVG achieves state-of-the-art performances across MLLM architectures and scales.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "通过补充视觉基础提升忠实的多模式法学硕士",
        "abstract_cn": "多模态大语言模型（MLLM）在视觉语言任务中表现出令人印象深刻的性能，但仍然面临幻觉挑战，即生成的文本实际上与视觉输入不一致。现有的缓解方法侧重于幻觉的表面症状，并严重依赖事后纠正、广泛的数据管理或昂贵的推理方案。在这项工作中，我们确定了 MLLM 幻觉的两个关键因素：视觉上下文不足（模糊的视觉上下文导致语言推测）和渐进文本漂移（模型注意力在较长的响应中偏离视觉输入）。为了解决这些问题，我们提出了一种新颖的互补视觉基础（CVG）框架。 CVG 利用 MLLM 的内在架构，无需任何外部工具、模型或额外数据。 CVG 首先根据查询相关性将视觉上下文分解为两个互补的分支，然后在自回归生成过程中保持稳定的视觉基础。最后，它对比两个分支的输出分布以产生忠实的响应。对各种幻觉和一般基准的大量实验表明，CVG 在 MLLM 架构和规模上实现了最先进的性能。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3644787",
        "title": "Bi-Grid Reconstruction for Image Anomaly Detection",
        "link": "https://doi.org/10.1109/tip.2025.3644787",
        "published": "2025",
        "author": "Aimin Feng, Huichuan Huang, Guangyu Wei, Wenlong Sun",
        "summary": "In the domain of image anomaly detection, significant progress has been made in unsupervised and self-supervised methods with datasets containing only normal samples. Although these methods perform well in general industrial anomaly detection scenarios, they often struggle with over- or under-detection when faced with fine-grained anomalies in products. In this paper, we propose GRAD: Bi-Grid Reconstruction for Image Anomaly Detection, which utilizes two continuous grids to detect anomalies from both normal and abnormal perspectives. In this work: 1) Grids serve as feature repositories to assist in the reconstruction task, achieving stronger generalization compared to discrete storage, while also helping to avoid the Identical Shortcut (IS) problem common in general reconstruction methods. 2) An additional grid storing abnormal features is introduced alongside the normal grid storing normal features, which refines the boundaries of normal features, thereby enhancing GRAD’s detection performance for fine-grained defects. 3) The Feature Block Pasting (FBP) module is designed to synthesize a variety of anomalies at the feature level, enabling the rapid deployment of the abnormal grid. Additionally, benefiting from the powerful representation capabilities of grids, GRAD is suitable for a unified task setting, requiring only a single model to be trained for multiple classes. GRAD has been comprehensively tested on classic industrial datasets including MVTecAD, VisA, and the newest GoodsAD dataset, showing significant improvement over current state-of-the-art methods.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "用于图像异常检测的双网格重建",
        "abstract_cn": "在图像异常检测领域，仅包含正常样本的数据集的无监督和自监督方法已经取得了重大进展。尽管这些方法在一般工业异常检测场景中表现良好，但在面对产品中的细粒度异常时，它们常常会遇到检测过度或检测不足的问题。在本文中，我们提出了 GRAD：用于图像异常检测的双网格重建，它利用两个连续网格从正常和异常角度检测异常。在这项工作中：1）网格作为特征存储库来协助重建任务，与离散存储相比实现了更强的泛化性，同时还有助于避免一般重建方法中常见的相同快捷方式（IS）问题。 2）在存储正常特征的正常网格旁边引入了额外的存储异常特征的网格，细化了正常特征的边界，从而增强了GRAD对细粒度缺陷的检测性能。 3）特征块粘贴（FBP）模块旨在在特征层面综合多种异常，实现异常网格的快速部署。此外，受益于网格强大的表示能力，GRAD适合统一的任务设置，只需要单个模型即可针对多个类别进行训练。 GRAD 已在经典工业数据集（包括 MVTecAD、VisA 和最新的 GoodsAD 数据集）上进行了全面测试，显示出相对于当前最先进方法的显着改进。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3644795",
        "title": "Degradation-Aware Prompted Transformer for Unified Medical Image Restoration",
        "link": "https://doi.org/10.1109/tip.2025.3644795",
        "published": "2025",
        "author": "Jinbao Wei, Gang Yang, Zhijie Wang, Shimin Tao, Aiping Liu, Xun Chen",
        "summary": "Medical image restoration (MedIR) aims to recover high-quality images from degraded inputs, yet faces unique challenges from physics-driven degradations and multi-modal task interference. While existing all-in-one methods handle natural image degradations well, they struggle with medical scenarios due to limited degradation perception and suboptimal multi-task optimization. In response, we introduce DaPT, a Degradation-aware Prompted Transformer, which integrates dynamic prompt learning and modular expert mining for unified MedIR. First, DaPT introduces spatially compact prompts with optimal transport regularization, amplifying inter-prompt differences to capture diverse degradation patterns. Second, a mixture of experts dynamically routes inputs to specialized modules via prompt guidance, resolving task conflicts while reducing computational overhead. The synergy of prompt learning and expert mining further enables robust restoration across multi-modal medical data, offering a practical solution for clinical imaging. Extensive experiments across multiple modalities (MRI, CT, PET) and diverse degradations, covering both in-distribution and out-of-distribution scenarios, demonstrate that DaPT consistently outperforms state-of-the-art methods and generalizes reliably to unseen settings, underscoring its robustness, effectiveness, and clinical practicality. The source code will be released at https://github.com/weijinbao1998/DaPT",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "用于统一医学图像恢复的退化感知提示变压器",
        "abstract_cn": "医学图像恢复（MedIR）旨在从退化的输入中恢复高质量图像，但面临着物理驱动的退化和多模态任务干扰的独特挑战。虽然现有的一体化方法可以很好地处理自然图像退化，但由于有限的退化感知和次优的多任务优化，它们在医疗场景中遇到了困难。为此，我们推出了 DaPT，一种退化感知提示转换器，它集成了动态提示学习和模块化专家挖掘，以实现统一的 MedIR。首先，DaPT 引入了具有最佳传输正则化的空间紧凑提示，放大提示间差异以捕获不同的降解模式。其次，专家组合通过及时指导动态地将输入路由到专用模块，解决任务冲突，同时减少计算开销。即时学习和专家挖掘的协同作用进一步实现了多模式医疗数据的稳健恢复，为临床成像提供了实用的解决方案。跨多种模式（MRI、CT、PET）和不同降解的广泛实验，涵盖分布内和分布外场景，表明 DaPT 始终优于最先进的方法，并可靠地推广到未见过的环境，强调了其稳健性、有效性和临床实用性。源码将发布在https://github.com/weijinbao1998/DaPT"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3644172",
        "title": "SGNet: Style-Guided Network With Temporal Compensation for Unpaired Low-Light Colonoscopy Video Enhancement",
        "link": "https://doi.org/10.1109/tip.2025.3644172",
        "published": "2026",
        "author": "Guanghui Yue, Lixin Zhang, Wanqing Liu, Jingfeng Du, Tianwei Zhou, Hanhe Lin, Qiuping Jiang, Wenqi Ren",
        "summary": "A low-light colonoscopy video enhancement method is needed as poor illumination in colonoscopy can hinder accurate disease diagnosis and adversely affect surgical procedures. Existing low-light video enhancement methods usually apply a frame-by-frame enhancement strategy without considering the temporal correlation between them, which often causes a flickering problem. In addition, most methods are designed for endoscopic devices with fixed imaging styles and cannot be easily adapted to different devices. In this paper, we propose a Style-Guided Network (SGNet) for unpaired Low-Light Colonoscopy Video Enhancement (LLCVE). Given that collecting content-consistent paired videos is difficult, SGNet adopts a CycleGAN-based framework to convert low-light videos to normal-light videos, in which a Temporal Compensation (TC) module and a Style Guidance (SG) module are proposed to alleviate the flickering problem and achieve flexible style transfer, respectively. The TC module compensates for a low-light frame by learning the correlated feature of its adjacent frames, thereby improving the temporal smoothness of the enhanced video. The SG module encodes the text of the imaging style and adaptively explores its intrinsic relationships with video features to obtain style representations, which are then used to guide the subsequent enhancement process. Extensive experiments on a curated database show that SGNet achieves promising performance on the LLCVE task, outperforming state-of-the-art methods in both quantitative metrics and visual quality.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "SGNet：具有时间补偿的风格引导网络，用于不成对的低光结肠镜检查视频增强",
        "abstract_cn": "由于结肠镜检查中的照明不良会妨碍准确的疾病诊断并对手术过程产生不利影响，因此需要一种低光结肠镜检查视频增强方法。现有的低光视频增强方法通常采用逐帧增强策略，没有考虑它们之间的时间相关性，这往往会导致闪烁问题。此外，大多数方法是针对具有固定成像风格的内窥镜设备而设计的，并且不能轻易地适应不同的设备。在本文中，我们提出了一种用于不配对低光结肠镜检查视频增强（LLCVE）的风格引导网络（SGNet）。鉴于收集内容一致的配对视频很困难，SGNet 采用基于 CycleGAN 的框架将低光视频转换为正常光视频，其中提出了时间补偿（TC）模块和风格指导（SG）模块，分别缓解闪烁问题并实现灵活的风格转换。 TC模块通过学习相邻帧的相关特征来补偿低光帧，从而提高增强视频的时间平滑度。 SG模块对图像风格的文本进行编码，并自适应地探索其与视频特征的内在关系，以获得风格表示，然后用于指导后续的增强过程。在精选数据库上进行的大量实验表明，SGNet 在 LLCVE 任务上取得了令人鼓舞的性能，在定量指标和视觉质量方面均优于最先进的方法。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3644789",
        "title": "A3-TTA: Adaptive Anchor Alignment Test-Time Adaptation for Image Segmentation",
        "link": "https://doi.org/10.1109/tip.2025.3644789",
        "published": "2025",
        "author": "Jianghao Wu, Xiangde Luo, Yubo Zhou, Lianming Wu, Guotai Wang, Shaoting Zhang",
        "summary": "Test-Time Adaptation (TTA) offers a practical solution for deploying image segmentation models under domain shift without accessing source data or retraining. Among existing TTA strategies, pseudo-label-based methods have shown promising performance. However, they often rely on perturbation-ensemble heuristics (e.g., dropout sampling, test-time augmentation, Gaussian noise), which lack distributional grounding and yield unstable training signals. This can trigger error accumulation and catastrophic forgetting during adaptation. To address this, we propose A3-TTA, a TTA framework that constructs reliable pseudo-labels through anchor-guided supervision. Specifically, we identify well-predicted target domain images using a class compact density metric, under the assumption that confident predictions imply distributional proximity to the source domain. These anchors serve as stable references to guide pseudo-label generation, which is further regularized via semantic consistency and boundary-aware entropy minimization. Additionally, we introduce a self-adaptive exponential moving average strategy to mitigate label noise and stabilize model update during adaptation. Evaluated on both multi-domain medical images (heart structure and prostate segmentation) and natural images, A3-TTA significantly improves average Dice scores by 10.40 to 17.68 percentage points compared to the source model, outperforming several state-of-the-art TTA methods under different segmentation model architectures. A3-TTA also excels in continual TTA, maintaining high performance across sequential target domains with strong anti-forgetting ability. The code will be made publicly available at https://github.com/HiLab-git/A3-TTA",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "A3-TTA：图像分割的自适应锚点对齐测试时间自适应",
        "abstract_cn": "测试时适应 (TTA) 提供了一种实用的解决方案，用于在域转移下部署图像分割模型，而无需访问源数据或重新训练。在现有的 TTA 策略中，基于伪标签的方法表现出了良好的性能。然而，它们通常依赖于扰动集合启发法（例如，丢失采样、测试时间增强、高斯噪声），​​这些方法缺乏分布式基础并产生不稳定的训练信号。这可能会在适应过程中引发错误积累和灾难性遗忘。为了解决这个问题，我们提出了 A3-TTA，这是一种通过锚引导监督构建可靠伪标签的 TTA 框架。具体来说，我们使用类紧凑密度度量来识别预测良好的目标域图像，假设置信的预测意味着与源域的分布接近。这些锚作为稳定的参考来指导伪标签生成，通过语义一致性和边界感知熵最小化进一步规范化。此外，我们引入了自适应指数移动平均策略，以减轻标签噪声并稳定适应过程中的模型更新。在多领域医学图像（心脏结构和前列腺分割）和自然图像上进行评估，与源模型相比，A3-TTA 的平均 Dice 分数显着提高了 10.40 至 17.68 个百分点，在不同分割模型架构下优于几种最先进的 TTA 方法。 A3-TTA在连续TTA方面也表现出色，在连续目标域上保持高性能，具有很强的抗遗忘能力。该代码将在 https://github.com/HiLab-git/A3-TTA 上公开发布"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3644167",
        "title": "Cross-Frequency Attention and Color Contrast Constraint for Remote Sensing Dehazing",
        "link": "https://doi.org/10.1109/tip.2025.3644167",
        "published": "2025",
        "author": "Yuxin Feng, Jufeng Li, Tao Huang, Fangfang Wu, Yakun Ju, Chunxu Li, Weisheng Dong, Alex C. Kot",
        "summary": "Current deep learning-based methods for remote sensing image dehazing have developed rapidly, yet they still commonly struggle to simultaneously preserve fine texture details and restore accurate colors. The fundamental reason lies in the insufficient modeling of high-frequency information that captures structural details, as well as the lack of effective constraints for color restoration. To address the insufficient modeling of global high-frequency information, we first develop an omni-directional high-frequency feature in painting mechanism that leverages the wavelet transform to extract multi-directional high-frequency components. While maintaining the advantage of linear complexity, it models global long-range texture dependencies through cross-frequency perception. Then, to further strengthen local high-frequency representation, we design a high-frequency prompt attention module that dynamically injects wavelet-domain optimized high-frequency features as cross-level guidance signals, significantly enhancing the model’s capability in edge sharpness restoration and texture detail reconstruction. Further, to alleviate the problem of inaccurate color restoration, we propose a color contrast loss function based on the HSV color space, which explicitly models the statistical distribution differences of brightness and saturation in hazy regions, guiding the model to generate dehazed images with consistent colors and natural visual appearance. Finally, extensive experiments on multiple benchmark datasets demonstrate that the proposed method outperforms existing approaches in both texture detail restoration and color consistency. Further results and code are available at: https://github.com/fyxnl/C4RSD",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "遥感去雾的跨频注意力和色彩对比度约束",
        "abstract_cn": "当前基于深度学习的遥感图像去雾方法发展迅速，但它们通常仍然难以同时保留精细的纹理细节和恢复准确的颜色。根本原因在于对捕捉结构细节的高频信息建模不足，以及对色彩还原缺乏有效约束。为了解决全局高频信息建模不足的问题，我们首先在绘画机制中开发了一种全向高频特征，利用小波变换来提取多方向高频分量。在保持线性复杂度优势的同时，它通过跨频感知对全局长程纹理依赖性进行建模。然后，为了进一步加强局部高频表示，我们设计了高频提示注意模块，动态注入小波域优化的高频特征作为跨级引导信号，显着增强模型的边缘锐度恢复和纹理细节重建能力。此外，为了缓解颜色恢复不准确的问题，我们提出了一种基于HSV颜色空间的颜色对比度损失函数，该函数明确地模拟了模糊区域中亮度和饱和度的统计分布差异，指导模型生成具有一致颜色和自然视觉外观的去雾图像。最后，对多个基准数据集的大量实验表明，所提出的方法在纹理细节恢复和颜色一致性方面均优于现有方法。更多结果和代码请访问：https://github.com/fyxnl/C4RSD"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3644793",
        "title": "Bayesian Multifractal Image Segmentation",
        "link": "https://doi.org/10.1109/tip.2025.3644793",
        "published": "2025",
        "author": "Kareth M. León-López, Abderrahim Halimi, Jean-Yves Tourneret, Herwig Wendt",
        "summary": "Multifractal analysis (MFA) provides a framework for the global characterization of image textures by describing the spatial fluctuations of their local regularity based on the multifractal spectrum. Several works have shown the interest of using MFA for the description of homogeneous textures in images. Nevertheless, natural images can be composed of several textures and, in turn, multifractal properties associated with those textures. This paper introduces an unsupervised Bayesian multifractal segmentation method to model and segment multifractal textures by jointly estimating the multifractal parameters and labels on images, at the pixel-level. For this, a computationally and statistically efficient multifractal parameter estimation model for wavelet leaders is firstly developed, defining different multifractality parameters for different regions of an image. Then, a multiscale Potts Markov random field is introduced as a prior to model the inherent spatial and scale correlations (referred to as cross-scale correlations) between the labels of the wavelet leaders. A Gibbs sampling methodology is finally used to draw samples from the posterior distribution of the unknown model parameters. Numerical experiments are conducted on synthetic multifractal images to evaluate the performance of the proposed segmentation approach. The proposed method achieves superior performance compared to traditional unsupervised segmentation techniques as well as modern deep learning-based approaches, showing its effectiveness for multifractal image segmentation.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "贝叶斯多重分形图像分割",
        "abstract_cn": "多重分形分析（MFA）通过基于多重分形谱描述图像纹理局部规律性的空间波动，为图像纹理的全局表征提供了一个框架。一些作品已经显示出使用 MFA 来描述图像中的均匀纹理的兴趣。然而，自然图像可以由多个纹理以及与这些纹理相关的多重分形属性组成。本文介绍了一种无监督贝叶斯多重分形分割方法，通过在像素级联合估计图像上的多重分形参数和标签来建模和分割多重分形纹理。为此，首先开发了一种计算和统计上有效的小波前导多重分形参数估计模型，为图像的不同区域定义不同的多重分形参数。然后，引入多尺度 Potts Markov 随机场作为先验，对小波前导标签之间固有的空间和尺度相关性（称为跨尺度相关性）进行建模。最后使用吉布斯抽样方法从未知模型参数的后验分布中抽取样本。在合成多重分形图像上进行数值实验，以评估所提出的分割方法的性能。与传统的无监督分割技术以及现代基于深度学习的方法相比，所提出的方法实现了优越的性能，显示了其对于多重分形图像分割的有效性。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3645599",
        "title": "Unlocking Cross-Domain Synergies for Domain Adaptive Semantic Segmentation",
        "link": "https://doi.org/10.1109/tip.2025.3645599",
        "published": "2026",
        "author": "Qin Xu, Qihang Wu, Bo Jiang, Jiahui Wang, Yuan Chen, Jinhui Tang",
        "summary": "Unsupervised domain adaptation semantic segmentation (UDASS) aims to perform dense prediction on the unlabeled target domain by training the model on a labeled source domain. In this field, self-training approaches have demonstrated strong competitiveness and advantages. However, existing methods often rely on additional training data (such as reference datasets or depth maps) to rectify the unreliable pseudo-labels, ignoring the cross-domain interaction between the target and source domains. To address this issue, in this paper, we propose a novel method for unsupervised domain adaptation semantic segmentation, termed Unlocking Cross-Domain Synergies (UCDS). Specifically, in the UCDS network, we design a new Dynamic Self-Correction (DSC) module that effectively transfers source domain knowledge and generates high-confidence pseudo-labels without additional training resources. Unlike the existing methods, DSC proposes a Dynamic Noisy Label Detection method for the target domain. To correct the noisy pseudo-labels, we design a Dual Bank mechanism that explores the reliable and unreliable predictions of the source domain, and conducts cross-domain synergy through Weighted Reassignment Self-Correction and Negative Correction Prevention strategies. To enhance the discriminative ability of features and amplify the dissimilarity of different categories, we propose Discrepancy-based Contrastive Learning (DCL). The DCL selects positive and negative samples in the source and target domains based on the semantic discrepancies among different categories, effectively avoiding the numerous false negative samples found in existing methods. Extensive experimental results on three commonly used datasets demonstrate the superiority of the proposed UCDS in comparison with the state-of-the-art methods. The project and code are available at https://github.com/wqh011128/UCDS",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "释放域自适应语义分割的跨域协同作用",
        "abstract_cn": "无监督域适应语义分割（UDASS）旨在通过在标记的源域上训练模型来对未标记的目标域执行密集预测。在这一领域，自学培训方式已经展现出较强的竞争力和优势。然而，现有的方法通常依赖于额外的训练数据（例如参考数据集或深度图）来纠正不可靠的伪标签，忽略了目标域和源域之间的跨域交互。为了解决这个问题，在本文中，我们提出了一种无监督域适应语义分割的新方法，称为解锁跨域协同（UCDS）。具体来说，在 UCDS 网络中，我们设计了一个新的动态自校正（DSC）模块，该模块可以有效地传输源领域知识并生成高置信度的伪标签，而无需额外的训练资源。与现有方法不同，DSC提出了一种针对目标域的动态噪声标签检测方法。为了纠正噪声伪标签，我们设计了一种双银行机制，探索源域的可靠和不可靠预测，并通过加权重新分配自校正和负校正预防策略进行跨域协同。为了增强特征的判别能力并放大不同类别的差异性，我们提出了基于差异的对比学习（DCL）。 DCL根据不同类别之间的语义差异在源域和目标域中选择正负样本，有效避免了现有方法中出现的大量假负样本。对三个常用数据集的广泛实验结果证明了所提出的 UCDS 与最先进的方法相比的优越性。项目和代码可在 https://github.com/wqh011128/UCDS 获取"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3645572",
        "title": "Toward Unified Co-Speech Gesture Generation via Hierarchical Implicit Periodicity Learning",
        "link": "https://doi.org/10.1109/tip.2025.3645572",
        "published": "2026",
        "author": "Xin Guo, Yifan Zhao, Jia Li",
        "summary": "Generating 3D-based body movements from speech shows great potential in extensive downstream applications, while it still suffers challenges in imitating realistic human movements. Predominant research efforts focus on end-to-end generation schemes to generate co-speech gestures, spanning GANs, VQ-VAE, and recent diffusion models. As an ill-posed problem, in this paper, we argue that these prevailing learning schemes fail to model crucial inter- and intra-correlations across different motion units, i.e. head, body, and hands, thus leading to unnatural movements and poor coordination. To delve into these intrinsic correlations, we propose a unified Hierarchical Implicit Periodicity (HIP) learning approach for audio-inspired 3D gesture generation. Different from predominant research, our approach models this multi-modal implicit relationship by two explicit technique insights: i) To disentangle the complicated gesture movements, we first explore the gesture motion phase manifolds with periodic autoencoders to imitate human natures from realistic distributions while incorporating non-period ones from current latent states for instance-level diversities. ii) To model the hierarchical relationship of face motions, body gestures, and hand movements, driving the animation with cascaded guidance during learning. We exhibit our proposed approach on 3D avatars and extensive experiments show our method outperforms the state-of-the-art co-speech gesture generation methods by both quantitative and qualitative evaluations. Code and models will be publicly available.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "通过分层隐式周期性学习实现统一的共同语音手势生成",
        "abstract_cn": "从语音生成基于 3D 的身体动作在广泛的下游应用中显示出巨大的潜力，但在模仿真实的人类动作方面仍然面临挑战。主要研究工作集中在生成协同语音手势的端到端生成方案，涵盖 GAN、VQ-VAE 和最近的扩散模型。作为一个不适定问题，在本文中，我们认为这些流行的学习方案无法模拟不同运动单元（即头部、身体和手）之间关键的相互和内部相关性，从而导致不自然的运动和协调性差。为了深入研究这些内在相关性，我们提出了一种统一的分层隐式周期性 (HIP) 学习方法，用于音频启发的 3D 手势生成。与主流研究不同，我们的方法通过两种显式技术见解对这种多模态隐式关系进行建模：i）为了理清复杂的手势运动，我们首先使用周期性自动编码器探索手势运动相位流形，以模仿现实分布中的人性，同时结合当前潜在状态中的非周期相位流形以实现实例级多样性。 ii）对面部动作、身体姿势和手部动作的层次关系进行建模，在学习过程中通过级联指导驱动动画。我们展示了我们提出的 3D 化身方法，大量实验表明，我们的方法在定量和定性评估方面均优于最先进的协同语音手势生成方法。代码和模型将公开。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3645574",
        "title": "Fast Blind Image Deblurring Based on Cross Partial Derivative",
        "link": "https://doi.org/10.1109/tip.2025.3645574",
        "published": "2025",
        "author": "Kuan-Chung Ting, Sheng-Jyh Wang, Ruey-Bing Hwang",
        "summary": "In this paper, based on second-order cross-partial derivative (CPD), we propose an efficient blind image deblurring algorithm for uniform blur. The proposed method consists of two stages. We first apply a novel blur kernel estimation method to quickly estimate the blur kernel. Then, we use the estimated kernel to perform non-blind deconvolution to restore the image. A key discovery of the proposed kernel estimation method is that the blur kernel information is usually embedded in the cross-partial-derivative (CPD) image of the blurred image. By exploiting this property, we propose a pipeline to extract a set of kernel candidates directly from the CPD image and then select the most suitable kernel as the estimated blur kernel. Since our kernel estimation method can obtain a fairly accurate blur kernel, we can achieve effective image restoration using a relatively simple Tikhonov regularization in the subsequent non-blind deconvolution process. To improve the quality of the restored image, we further adopt an efficient filtering technique to suppress periodic artifacts that may appear in the restored images. Experimental results demonstrate that our algorithm can efficiently restore high-quality sharp images on standard CPUs without relying on GPU acceleration or parallel computation. For blurred images of approximately $800\\times 800$ resolution, the proposed method can complete image deblurring within 1 to 5 seconds, which is significantly faster than most state-of-the-art methods. Our MATLAB codes are available at https://github.com/e11tkcee06-a11y/CPD-Deblur.git.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "基于交叉偏导数的快速盲图像去模糊",
        "abstract_cn": "在本文中，基于二阶交叉偏导数（CPD），我们提出了一种有效的均匀模糊盲图像去模糊算法。所提出的方法由两个阶段组成。我们首先应用一种新颖的模糊核估计方法来快速估计模糊核。然后，我们使用估计的核进行非盲反卷积来恢复图像。所提出的核估计方法的一个关键发现是模糊核信息通常嵌入在模糊图像的交叉偏导（CPD）图像中。通过利用这一特性，我们提出了一种直接从 CPD 图像中提取一组候选内核的管道，然后选择最合适的内核作为估计的模糊内核。由于我们的核估计方法可以获得相当准确的模糊核，因此我们可以在后续的非盲反卷积过程中使用相对简单的Tikhonov正则化来实现有效的图像恢复。为了提高恢复图像的质量，我们进一步采用有效的滤波技术来抑制恢复图像中可能出现的周期性伪影。实验结果表明，我们的算法可以在标准CPU上高效地恢复高质量清晰图像，而无需依赖GPU加速或并行计算。对于分辨率约为 800×800 美元的模糊图像，所提出的方法可以在 1 到 5 秒内完成图像去模糊，这比大多数最先进的方法要快得多。我们的 MATLAB 代码可从 https://github.com/e11tkcee06-a11y/CPD-Deblur.git 获取。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3645560",
        "title": "E\n                    <sup>2</sup>\n                    MPL: An Enduring and Efficient Meta Prompt Learning Framework for Few-Shot Unsupervised Domain Adaptation",
        "link": "https://doi.org/10.1109/tip.2025.3645560",
        "published": "2025",
        "author": "Wanqi Yang, Haoran Wang, Wei Wang, Lei Wang, Ge Song, Ming Yang, Yang Gao",
        "summary": "Few-shot unsupervised domain adaptation (FS-UDA) leverages a limited amount of labeled data from a source domain to enable accurate classification in an unlabeled target domain. Despite recent advancements, current approaches of FS-UDA continue to confront a major challenge: models often demonstrate instability when adapted to new FS-UDA tasks and necessitate considerable time investment. To address these challenges, we put forward a novel framework called Enduring and Efficient Meta-Prompt Learning (E2MPL) for FS-UDA. Within this framework, we utilize the pre-trained CLIP model as the backbone of feature learning. Firstly, we design domain-shared prompts, consisting of virtual tokens, which primarily capture meta-knowledge from a wide range of meta-tasks to mitigate the domain gaps. Secondly, we develop a task prompt learning network that adaptively learns task-specific prompts with the goal of achieving fast and stable task generalization. Thirdly, we formulate the meta-prompt learning process as a bilevel optimization problem, consisting of (outer) meta-prompt learner and (inner) task-specific classifier and domain adapter. Also, the inner objective of each meta-task has the closed-form solution, which enables efficient prompt learning and adaptation to new tasks in a single step. Extensive experimental studies demonstrate the promising performance of our framework in a domain adaptation benchmark dataset DomainNet. Compared with state-of-the-art methods, our approach has improved the average accuracy by at least 15 percentage points and reduces the average time by 64.67% in the 5-way 1-shot task; in the 5-way 5-shot task, it achieves at least a 9-percentage-point improvement in average accuracy and reduces the average time by 63.18%. Moreover, our method exhibits more enduring and stable performance than the other methods, i.e., reducing the average IQR value by over 40.80% and 25.35% in the 5-way 1-shot and 5-shot task, respectively.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "E <sup>2</sup> MPL：一种持久且高效的元快速学习框架，用于少样本无监督域适应",
        "abstract_cn": "少样本无监督域适应 (FS-UDA) 利用来自源域的有限数量的标记数据来实现在未标记的目标域中的准确分类。尽管最近取得了进展，当前的 FS-UDA 方法仍然面临着重大挑战：模型在适应新的 FS-UDA 任务时经常表现出不稳定，并且需要大量的时间投入。为了应对这些挑战，我们为 FS-UDA 提出了一个名为持久高效元提示学习 (E2MPL) 的新颖框架。在此框架内，我们利用预先训练的 CLIP 模型作为特征学习的支柱。首先，我们设计由虚拟令牌组成的域共享提示，主要从各种元任务中捕获元知识，以缩小域差距。其次，我们开发了一个任务提示学习网络，可以自适应地学习特定于任务的提示，以实现快速稳定的任务泛化。第三，我们将元提示学习过程表述为双层优化问题，由（外部）元提示学习器和（内部）特定于任务的分类器和域适配器组成。此外，每个元任务的内部目标都有封闭形式的解决方案，可以一步实现高效的快速学习和适应新任务。广泛的实验研究证明了我们的框架在域适应基准数据集 DomainNet 中的良好性能。与最先进的方法相比，我们的方法在 5-way 1-shot 任务中将平均准确率提高了至少 15 个百分点，并将平均时间减少了 64.67%；在5路5次射击任务中，它的平均准确率至少提高了9个百分点，平均时间减少了63.18%。此外，我们的方法比其他方法表现出更持久和稳定的性能，即在 5 路 1-shot 和 5-shot 任务中，平均 IQR 值分别降低了 40.80% 和 25.35% 以上。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3645630",
        "title": "A Cosine Network for Image Super-Resolution",
        "link": "https://doi.org/10.1109/tip.2025.3645630",
        "published": "2026",
        "author": "Chunwei Tian, Chengyuan Zhang, Bob Zhang, Zhiwu Li, C. L. Philip Chen, David Zhang",
        "summary": "Deep convolutional neural networks can use hierarchical information to progressively extract structural information to recover high-quality images. However, preserving the effectiveness of the obtained structural information is important in image super-resolution. In this paper, we propose a cosine network for image super-resolution (CSRNet) by improving a network architecture and optimizing the training strategy. To extract complementary homologous structural information, odd and even heterogeneous blocks are designed to enlarge the architectural differences and improve the performance of image super-resolution. Combining linear and non-linear structural information can overcome the drawback of homologous information and enhance the robustness of the obtained structural information in image super-resolution. Taking into account the local minimum of gradient descent, a cosine annealing mechanism is used to optimize the training procedure by performing warm restarts and adjusting the learning rate. Experimental results illustrate that the proposed CSRNet is competitive with state-of-the-art methods in image super-resolution.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "用于图像超分辨率的余弦网络",
        "abstract_cn": "深度卷积神经网络可以利用层次信息逐步提取结构信息来恢复高质量图像。然而，保持所获得的结构信息的有效性在图像超分辨率中非常重要。在本文中，我们通过改进网络架构和优化训练策略，提出了一种用于图像超分辨率的余弦网络（CSRNet）。为了提取互补的同源结构信息，设计了奇数和偶数异质块以放大结构差异并提高图像超分辨率的性能。将线性和非线性结构信息结合起来可以克服同源信息的缺点，增强所获得的结构信息在图像超分辨率中的鲁棒性。考虑到梯度下降的局部最小值，余弦退火机制用于通过执行热重启和调整学习率来优化训练过程。实验结果表明，所提出的 CSRNet 在图像超分辨率方面与最先进的方法具有竞争力。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3645583",
        "title": "TSFormer: Efficient Ultra-High-Definition Image Restoration via Trusted Min-\n                    <i>p</i>",
        "link": "https://doi.org/10.1109/tip.2025.3645583",
        "published": "2026",
        "author": "Zhuoran Zheng, Pu Wang, Liubing Hu, Xin Su",
        "summary": "Ultra-high-definition (UHD) image restoration is vital for applications demanding exceptional visual fidelity, yet existing methods often face a trade-off between restoration quality and efficiency, limiting their practical deployment. In this paper, we propose TSFormer, an all-in-one framework that integrates Trusted learning with Sparsification to boost both generalization capability and computational efficiency in UHD image restoration. The key to sparsification is that only a small amount of token movement is allowed within the model. To efficiently filter tokens, we use Min-<inline-formula> <tex-math notation=\"LaTeX\">$p$ </tex-math></inline-formula> with random matrix theory to quantify the uncertainty of tokens (lower trustworthiness), thereby improving the robustness of the model. Our model can run a 4K (<inline-formula> <tex-math notation=\"LaTeX\">$3840\\times 2160$ </tex-math></inline-formula>) image in real time (40fps) with 3.38 M parameters. Extensive experiments demonstrate that TSFormer achieves state-of-the-art restoration quality while enhancing generalization and reducing computational demands. In addition, our token filtering method can be applied to other image restoration models to effectively accelerate inference and maintain performance.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "TSFormer：通过可信 Min-<i>p</i> 进行高效的超高清图像恢复",
        "abstract_cn": "超高清（UHD）图像恢复对于要求卓越视觉保真度的应用至关重要，但现有方法经常面临恢复质量和效率之间的权衡，限制了其实际部署。在本文中，我们提出了 TSFormer，这是一种一体化框架，它将可信学习与稀疏化相结合，以提高超高清图像恢复的泛化能力和计算效率。稀疏化的关键是模型内只允许少量的令牌移动。为了有效过滤 token，我们使用 Min-<inline-formula> <tex-math notation=\"LaTeX\">$p$ </tex-math></inline-formula> 结合随机矩阵理论来量化 token 的不确定性（可信度较低），从而提高模型的鲁棒性。我们的模型可以实时 (40fps) 运行具有 338 M 参数的 4K (<inline-formula> <tex-math notation=\"LaTeX\">$3840\\times 2160$ </tex-math></inline-formula>) 图像。大量实验表明 TSFormer 实现了最先进的恢复质量，同时增强了泛化性并降低了计算需求。此外，我们的令牌过滤方法可以应用于其他图像恢复模型，以有效加速推理并保持性能。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3646073",
        "title": "FRFSL: Feature Reconstruction-Based Cross-Domain Few-Shot Learning for Coastal Wetland Hyperspectral Image Classification",
        "link": "https://doi.org/10.1109/tip.2025.3646073",
        "published": "2026",
        "author": "Qixing Yu, Zhongwei Li, Ziqi Xin, Fangming Guo, Guangbo Ren, Jianbu Wang, Zhenggang Bi",
        "summary": "Hyperspectral image classification (HSIC) is a valuable method for identifying coastal wetland vegetation, but challenges like environmental complexity and difficulty in distinguishing land cover types make large-scale labeling difficult. Cross-domain few-shot learning (CDFSL) offers a potential solution to limited labeling. Existing CDFSL HSIC methods have made significant progress, but still face challenges like prototype deviation, covariate shifts, and rely on complex domain alignment (DA) methods. To address these issues, a feature reconstruction-based CDFSL (FRFSL) algorithm is proposed. Within FRFSL, a Prototype Calibration Module (PCM) is designed for the prototype deviation, which employs a Bayesian inference-enhanced Gaussian Mixture Model to select reliable query features for prototype reconstruction, aligning the prototypes more closely with the actual distribution. Additionally, a ridge regression closed-form solution is incorporated into the Distance Metric Module (DMM), employing a projection matrix for prototype reconstruction to mitigate covariate shifts between the support and query sets. Features from both source and target domains are reconstructed into dynamic graphs, transforming DA into a graph matching problem guided by optimal transport theory. A novel shared transport matrix implementation algorithm is developed to achieve lightweight and interpretable alignment. Extensive experiments on three self-constructed coastal wetland datasets and one public dataset show that FRFSL outperforms eleven state-of-the-art algorithms. The code will be available at https://github.com/Yqx-ACE/TIP_2025_FRFSL",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "FRFSL：基于特征重建的滨海湿地高光谱图像分类的跨域小样本学习",
        "abstract_cn": "高光谱图像分类（HSIC）是识别沿海湿地植被的一种有价值的方法，但环境复杂性和区分土地覆盖类型的困难等挑战使得大规模标记变得困难。跨域少样本学习（CDFSL）为有限标记提供了潜在的解决方案。现有的 CDFSL HSIC 方法已经取得了重大进展，但仍然面临原型偏差、协变量偏移以及依赖复杂域对齐 (DA) 方法等挑战。为了解决这些问题，提出了一种基于特征重建的CDFSL（FRFSL）算法。在FRFSL中，针对原型偏差设计了原型校准模块（PCM），该模块采用贝叶斯推理增强高斯混合模型来选择可靠的查询特征进行原型重建，使原型与实际分布更紧密地对齐。此外，岭回归封闭式解决方案被纳入距离度量模块 (DMM)，采用投影矩阵进行原型重建，以减轻支持集和查询集之间的协变量偏移。来自源域和目标域的特征被重构为动态图，将 DA 转化为由最优传输理论指导的图匹配问题。开发了一种新颖的共享传输矩阵实现算法来实现轻量级和可解释的对齐。对三个自建的沿海湿地数据集和一个公共数据集的大量实验表明，FRFSL 优于 11 种最先进的算法。代码可在 https://github.com/Yqx-ACE/TIP_2025_FRFSL 获取"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3635475",
        "title": "Enhanced Geometry and Semantics for Camera-Based 3D Semantic Scene Completion",
        "link": "https://doi.org/10.1109/tip.2025.3635475",
        "published": "2026",
        "author": "Haihong Xiao, Wenxiong Kang, Yulan Guo, Hao Liu, Ying He",
        "summary": "Giving machines the ability to infer the complete 3D geometry and semantics of complex scenes is crucial for many downstream tasks, such as decision-making and planning. Vision-centric Semantic Scene Completion (SSC) has emerged as a trendy 3D perception paradigm due to its compatibility with task properties, low cost, and rich visual cues. Despite impressive results, current approaches inevitably suffer from problems such as depth errors or depth ambiguities during the 2D-to-3D transformation process. To overcome these limitations, in this paper, we first introduce an Optical Flow-Guided (OFG) DepthNet that leverages the strengths of pretrained depth estimation models, while incorporating optical flow images to improve depth prediction accuracy in regions with significant depth changes. Then, we propose a depth ambiguity-mitigated feature lifting strategy that implements deformable cross-attention in 3D pixel space to avoid depth ambiguities caused by the projection process from 3D to 2D and further enhances the effectiveness of feature updating through the utilization of prior mask indices. Moreover, we customize two subnetworks: a residual voxel network and a sparse UNet, to enhance the network’s geometric prediction capabilities and ensure consistent semantic reasoning across varying scales. By doing so, our method achieves performance improvements over state-of-the-art methods on the SemanticKITTI, SSCBench-KITTI-360 and Occ3D-nuScene benchmarks.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "增强的几何和语义，用于基于相机的 3D 语义场景完成",
        "abstract_cn": "让机器能够推断复杂场景的完整 3D 几何和语义对于许多下游任务（例如决策和规划）至关重要。以视觉为中心的语义场景完成（SSC）由于其与任务属性的兼容性、低成本和丰富的视觉线索而成为一种流行的3D感知范例。尽管取得了令人印象深刻的结果，但当前的方法在 2D 到 3D 转换过程中不可避免地会遇到深度错误或深度模糊等问题。为了克服这些限制，在本文中，我们首先引入光流引导（OFG）深度网络，它利用预训练深度估计模型的优势，同时结合光流图像来提高深度变化显着的区域的深度预测精度。然后，我们提出了一种减轻深度模糊性的特征提升策略，该策略在 3D 像素空间中实现可变形交叉注意力，以避免从 3D 到 2D 的投影过程引起的深度模糊性，并通过利用先验掩模索引进一步增强特征更新的有效性。此外，我们定制了两个子网络：残差体素网络和稀疏UNet，以增强网络的几何预测能力并确保在不同尺度上一致的语义推理。通过这样做，我们的方法在 SemanticKITTI、SSCBench-KITTI-360 和 Occ3D-nuScene 基准测试中实现了比最先进方法的性能改进。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3646471",
        "title": "AGAFNet: Adaptive Gated Attention Fusion Network for Accurate Nuclei Segmentation and Classification in Histology Images",
        "link": "https://doi.org/10.1109/tip.2025.3646471",
        "published": "2026",
        "author": "Nyi Nyi Naing, Huazhen Chen, Qing Cai, Lili Xia, Zhongke Gao, Jianpeng An",
        "summary": "Nuclei segmentation and classification in Hematoxylin and Eosin (H&E) stained histology images play a vital role in cancer diagnosis, treatment planning, and research. However, accurate segmentation can be hindered by factors like irregular cell shapes, unclear boundaries, and class imbalance. To address these challenges, we propose the Adaptive Gated Attention Fusion Network (AGAFNet), which integrates three innovative attention-based blocks into a U-shaped architecture complemented by dedicated decoders for both segmentation and classification tasks. These blocks comprise the Channel-wise and Spatial Attention Integration Block (CSAIB) for enhanced feature representation and selective focus on informative regions; the Adaptive Gated Convolutional Block (AGCB) for robust feature selection throughout the network; and the Fusion Attention Refinement Block (FARB) for effective information fusion. AGAFNet leverages these elements to provide a robust solution for precise nuclei segmentation and classification in H&E stained histology images. We evaluate the performance of AGAFNet on three large-scale multi-tissue datasets: PanNuke, CoNSeP, and Lizard. The experimental results demonstrate our proposed AGAFNet achieves comparable performance to state-of-the-art methods.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "AGAFNet：自适应门控注意力融合网络，用于组织学图像中准确的细胞核分割和分类",
        "abstract_cn": "苏木精和伊红 (H&E) 染色组织学图像中的细胞核分割和分类在癌症诊断、治疗计划和研究中发挥着至关重要的作用。然而，不规则的细胞形状、边界不清晰和类别不平衡等因素可能会阻碍准确的分割。为了应对这些挑战，我们提出了自适应门控注意力融合网络（AGAFNet），它将三个基于注意力的创新块集成到 U 形架构中，并辅以用于分割和分类任务的专用解码器。这些模块包括通道方式和空间注意力集成模块（CSAIB），用于增强特征表示和选择性关注信息区域；自适应门控卷积块（AGCB）用于在整个网络中进行稳健的特征选择；以及用于有效信息融合的融合注意力细化块（FARB）。 AGAFNet 利用这些元素为 H&E 染色组织学图像中的精确细胞核分割和分类提供强大的解决方案。我们评估了 AGAFNet 在三个大型多组织数据集上的性能：PanNuke、CoNSeP 和 Lizard。实验结果表明，我们提出的 AGAFNet 实现了与最先进方法相当的性能。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3646455",
        "title": "Multi-Stage Group Interaction and Cross-Domain Fusion Network for Real-Time Smoke Segmentation",
        "link": "https://doi.org/10.1109/tip.2025.3646455",
        "published": "2026",
        "author": "Kang Li, Feiniu Yuan, Chunmei Wang, Chunli Meng",
        "summary": "Lightweight smoke image segmentation is essential for fire warning systems, particularly on mobile devices. In recent years, although numerous high-precision, large-scale smoke segmentation models have been developed, there are few lightweight solutions specifically designed for mobile applications. Therefore, we propose a Multi-stage Group Interaction and Cross-domain Fusion Network (MGICFN) with low computational complexity for real-time smoke segmentation. To improve the model’s ability to effectively analyze smoke features, we incorporate a Cross-domain Interaction Attention Module (CIAM) to merge spatial and frequency domain features for creating a lightweight smoke encoder. To alleviate the loss of critical information from small smoke objects during downsampling, we design a Multi-stage Group Interaction Module (MGIM). The MGIM calibrates the information discrepancies between high and low-dimensional features. To enhance the boundary information of smoke targets, we introduce an Edge Enhancement Module (EEM), which utilizes predicted target boundaries as advanced guidance to refine lower-level smoke features. Furthermore, we implement a Group Convolutional Block Attention Module (GCBAM) and a Group Fusion Module (GFM) to connect the encoder and decoder efficiently. Experimental results demonstrate that MGICFN achieves an 88.70% Dice coefficient (Dice), an 81.16% mean Intersection over Union (mIoU), and a 91.93% accuracy (Acc) on the SFS3K dataset. It also achieves an 87.30% Dice, a 78.68% mIoU, and a 92.95% Acc on the SYN70K test dataset. Our MGICFN model has 0.73M parameters and requires 0.3G FLOPs.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "用于实时烟雾分割的多级组交互和跨域融合网络",
        "abstract_cn": "轻量级烟雾图像分割对于火灾预警系统至关重要，尤其是在移动设备上。近年来，虽然已经开发出众多高精度、大规模的烟雾分割模型，但专门针对移动应用设计的轻量级解决方案却很少。因此，我们提出了一种计算复杂度较低的多级群组交互和跨域融合网络（MGICFN），用于实时烟雾分割。为了提高模型有效分析烟雾特征的能力，我们采用了跨域交互注意模块（CIAM）来合并空间和频域特征，以创建轻量级烟雾编码器。为了减少下采样过程中小烟雾物体的关键信息丢失，我们设计了多级组交互模块（MGIM）。 MGIM 校准高维特征和低维特征之间的信息差异。为了增强烟雾目标的边界信息，我们引入了边缘增强模块（EEM），该模块利用预测的目标边界作为高级指导来细化较低级别的烟雾特征。此外，我们实现了组卷积块注意模块（GCBAM）和组融合模块（GFM）来有效连接编码器和解码器。实验结果表明，MGICFN 在 SFS3K 数据集上实现了 88.70% 的 Dice 系数（Dice）、81.16% 的平均交集（mIoU）和 91.93% 的准确率（Acc）。它还在 SYN70K 测试数据集上实现了 87.30% Dice、78.68% mIoU 和 92.95% Acc。我们的 MGICFN 模型有 0.73M 参数，需要 0.3G FLOP。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3644791",
        "title": "Embracing the Power of Known Class Bias in Open Set Recognition From a Reconstruction Perspective",
        "link": "https://doi.org/10.1109/tip.2025.3644791",
        "published": "2026",
        "author": "Heyang Sun, Chuanxing Geng, Songcan Chen",
        "summary": "The open set known class bias is conventionally viewed as a fatal problem i.e., the models trained solely on known classes tend to fit unknown classes to known classes with high confidence in inference. Thus existing methods, without exception make a choice in two manners: most methods opt for eliminating the known class bias as much as possible with tireless efforts, while others circumvent the known class bias by employing a reconstruction method. However, in this paper, we challenge the two widely accepted approaches and present a novel proposition: the so-called harmful known class bias for most methods is, exactly conversely, beneficial for the reconstruction-based method and thus such known class bias can serve as a positive-incentive to the Open set recognition (OSR) models from a reconstruction perspective. Along this line, we propose the Bias Enhanced Reconstruction Learning (BERL) framework to enhance the known class bias respectively from the class level, model level and sample level. Specifically, at the class level, a specific representation is constructed in a supervised contrastive manner to avoid overgeneralization, while a diffusion model is employed by injecting the class prior to guide the biased reconstruction at the model level. Additionally, we leverage the advantages of the diffusion model to design a self-adaptive strategy, enabling effective sample-level biased sampling based on the information bottleneck theory. Experiments on various benchmarks demonstrate the effectiveness and performance superiority of the proposed method.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "从重构的角度拥抱开放集识别中已知类偏差的力量",
        "abstract_cn": "开放集已知类偏差通常被视为致命问题，即仅在已知类上训练的模型倾向于以高可信度的推理将未知类拟合到已知类。因此，现有的方法无一例外地以两种方式进行选择：大多数方法选择通过不懈的努力尽可能消除已知的类偏差，而另一些方法则通过采用重建方法来规避已知的类偏差。然而，在本文中，我们挑战了两种广泛接受的方法，并提出了一个新颖的命题：对于大多数方法来说，所谓的有害已知类偏差恰恰相反，对基于重构的方法有益，因此从重构的角度来看，这种已知类偏差可以作为开放集识别（OSR）模型的积极激励。沿着这个思路，我们提出了偏差增强重建学习（BERL）框架，分别从类级别、模型级别和样本级别增强已知的类偏差。具体来说，在类级别，以有监督对比的方式构建特定表示，以避免过度概括，而扩散模型则通过在模型级别注入类之前指导有偏差的重建来采用。此外，我们利用扩散模型的优势设计了自适应策略，基于信息瓶颈理论实现了有效的样本级有偏采样。各种基准的实验证明了所提出方法的有效性和性能优越性。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3646940",
        "title": "Few-Shot Fine-Grained Classification With Foreground-Aware Kernelized Feature Reconstruction Network",
        "link": "https://doi.org/10.1109/tip.2025.3646940",
        "published": "2026",
        "author": "Yangfan Li, Wei Li",
        "summary": "Feature reconstruction networks have achieved remarkable performance in few-shot fine-grained classification tasks. Nonetheless, traditional feature reconstruction networks rely on linear regression. This linearity may cause the loss of subtle discriminative cues, ultimately resulting in less precise reconstructed features. Moreover, in situations where the background predominantly occupies the image, the background reconstruction errors tend to overshadow foreground reconstruction errors, resulting in inaccurate reconstruction errors. In order to address the two key issues, a novel approach called the Foreground-Aware Kernelized Feature Reconstruction Network (FKFRN) is proposed. Specifically, to address the problem of imprecise reconstructed features, we introduce kernel methods into linear feature reconstruction, extending it to nonlinear feature reconstruction, thus enabling the reconstruction of richer, finer-grained discriminative features. To tackle the issue of inaccurate reconstruction errors, the foreground-aware reconstruction error is proposed. Specifically, the model assigns higher weights to features containing more foreground information and lower weights to those dominated by background content, which reduces the impact of background errors on the overall reconstruction. To estimate these weights accurately, we design two complementary strategies: an explicit probabilistic graphical model and an implicit neural network–based approach. Extensive experimental results on eight datasets validate the effectiveness of the proposed approach for few-shot fine-grained classification.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "具有前景感知内核化特征重建网络的少样本细粒度分类",
        "abstract_cn": "特征重建网络在少样本细粒度分类任务中取得了显着的性能。尽管如此，传统的特征重建网络依赖于线性回归。这种线性可能会导致细微辨别线索的丢失，最终导致重建特征不太精确。此外，在背景主要占据图像的情况下，背景重建误差往往会掩盖前景重建误差，导致重建误差不准确。为了解决这两个关键问题，提出了一种称为前景感知内核化特征重建网络（FKFRN）的新方法。具体来说，为了解决重建特征不精确的问题，我们将核方法引入线性特征重建，并将其扩展到非线性特征重建，从而能够重建更丰富、更细粒度的判别特征。为了解决重建误差不准确的问题，提出了前景感知重建误差。具体来说，该模型为包含更多前景信息的特征分配较高的权重，为那些以背景内容为主的特征分配较低的权重，从而减少了背景误差对整体重建的影响。为了准确估计这些权重，我们设计了两种互补策略：显式概率图形模型和基于隐式神经网络的方法。在八个数据集上的广泛实验结果验证了所提出的少样本细粒度分类方法的有效性。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3646861",
        "title": "FocusPatch AD: Few-Shot Multi-Class Anomaly Detection With Unified Keywords Patch Prompts",
        "link": "https://doi.org/10.1109/tip.2025.3646861",
        "published": "2026",
        "author": "Xicheng Ding, Xiaofan Li, Mingang Chen, Jingyu Gong, Yuan Xie",
        "summary": "Industrial few-shot anomaly detection (FSAD) requires identifying various abnormal states by leveraging as few normal samples as possible (abnormal samples are unavailable during training). However, current methods often require training a separate model for each category, leading to increased computation and storage overhead. Thus, designing a unified anomaly detection model that supports multiple categories remains a challenging task, as such a model must recognize anomalous patterns across diverse objects and domains. To tackle these challenges, this paper introduces FocusPatch AD, a unified anomaly detection framework based on vision-language models, achieving anomaly detection under few-shot multi-class settings. FocusPatch AD links anomaly state keywords to highly relevant discrete local regions within the image, guiding the model to focus on cross-category anomalies while filtering out background interference. This approach mitigates the false detection issues caused by global semantic alignment in vision-language models. We evaluate the proposed method on the MVTec, VisA, and Real-IAD datasets, comparing them against several prevailing anomaly detection methods. In both image-level and pixel-level anomaly detection tasks, FocusPatch AD achieves significant gains in classification and localization performance, demonstrating excellent generalization and adaptability.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "FocusPatch AD：具有统一关键字补丁提示的少样本多类异常检测",
        "abstract_cn": "工业少样本异常检测（FSAD）需要利用尽可能少的正常样本（训练期间无法获得异常样本）来识别各种异常状态。然而，当前的方法通常需要为每个类别训练单独的模型，导致计算和存储开销增加。因此，设计支持多个类别的统一异常检测模型仍然是一项具有挑战性的任务，因为这样的模型必须识别跨不同对象和域的异常模式。为了应对这些挑战，本文引入了 FocusPatch AD，一种基于视觉语言模型的统一异常检测框架，实现了少样本多类设置下的异常检测。 FocusPatch AD 将异常状态关键字链接到图像内高度相关的离散局部区域，引导模型专注于跨类别异常，同时滤除背景干扰。这种方法减轻了视觉语言模型中全局语义对齐引起的错误检测问题。我们在 MVTec、VisA 和 Real-IAD 数据集上评估所提出的方法，并将其与几种流行的异常检测方法进行比较。在图像级和像素级异常检测任务中，FocusPatch AD 在分类和定位性能方面都取得了显着的提升，表现出了出色的泛化性和适应性。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3646893",
        "title": "LNet: Lightweight Network for Driver Attention Estimation via Scene and Gaze Consistency",
        "link": "https://doi.org/10.1109/tip.2025.3646893",
        "published": "2026",
        "author": "Daosong Hu, Xi Li, Mingyue Cui, Kai Huang",
        "summary": "In resource-constrained vehicle systems, establishing consistency between multi-view scenes and driver gaze remains challenging. Prior methods mainly focus on cross-source data fusion, estimating gaze or attention maps through unidirectional implicit links between scene and facial features. Although bidirectional projection can correct misalignment between predictions and ground truth, the high resolution of scene images and complex semantic extraction incur heavy computational loads. To address these issues, we propose a lightweight driver-attention estimation framework that leverages geometric consistency between scene and gaze to guide feature extraction bidirectionally, thereby strengthening representation. Specifically, we first introduce a lightweight feature extraction module that captures global and local information in parallel through dual asymmetric branches to efficiently extract facial and scene features. An information cross fusion module is then designed to promote interaction between the scene and gaze streams. The multi-branch architecture extracts gaze and geometric cues at multiple scales, reducing the computational redundancy caused by mixed features when modeling geometric consistency across both views. Experiments on a large public dataset show that incorporating scene information introduces no significant computational overhead and yields a better trade-off between accuracy and efficiency. Moreover, leveraging bidirectional projection and the temporal continuity of gaze, we preliminarily explore the framework’s potential for predicting attention trends.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "LNet：通过场景和注视一致性进行驾驶员注意力估计的轻量级网络",
        "abstract_cn": "在资源有限的车辆系统中，建立多视图场景和驾驶员注视之间的一致性仍然具有挑战性。现有方法主要集中于跨源数据融合，通过场景和面部特征之间的单向隐式链接来估计凝视或注意力图。尽管双向投影可以纠正预测与地面实况之间的偏差，但场景图像的高分辨率和复杂的语义提取会带来繁重的计算负载。为了解决这些问题，我们提出了一种轻量级的驾驶员注意力估计框架，该框架利用场景和注视之间的几何一致性来引导双向特征提取，从而加强表示。具体来说，我们首先引入一个轻量级特征提取模块，该模块通过双不对称分支并行捕获全局和局部信息，以有效地提取面部和场景特征。然后设计信息交叉融合模块来促进场景和注视流之间的交互。多分支架构提取多个尺度的注视和几何线索，减少了在两个视图之间建模几何一致性时由混合特征引起的计算冗余。对大型公共数据集的实验表明，合并场景信息不会带来显着的计算开销，并且可以在准确性和效率之间实现更好的权衡。此外，利用双向投影和注视的时间连续性，我们初步探索了该框架预测注意力趋势的潜力。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3646889",
        "title": "M3D: A Benchmark Dataset and Model for Microscopic 3D Shape Reconstruction",
        "link": "https://doi.org/10.1109/tip.2025.3646889",
        "published": "2026",
        "author": "Tao Yan, Yingying Wang, Yuhua Qian, Jiangfeng Zhang, Feijiang Li, Peng Wu, Lu Chen, Jieru Jia, Xiaoying Guo",
        "summary": "Microscopic 3D shape reconstruction using depth from focus (DFF) is crucial in precision manufacturing for 3D modeling and quality control. However, the absence of high-precision microscopic DFF datasets and the significant differences between existing DFF datasets and microscopic DFF data in optical design, imaging principles and scene characteristics hinder the performance of current DFF models in microscopic tasks. To address this, we introduce M3D, a novel microscopic DFF dataset, constructed using a self-developed microscopic device. It includes multi-focus image sequences of 1,952 scenes across five categories, with depth labels obtained through the 3D TFT algorithm applied to dense image sequences for initial depth estimation and calibration. All labels are then compared and analyzed against the design values, and those with large errors are eliminated. We also propose M3DNet, a frequency-aware end-to-end network, to tackle challenges like shallow depth-of-field (DoF) and weak textures. Results show that M3D compensates for the limitations of macroscopic DFF datasets and extends DFF applications to microscopic scenarios. M3DNet effectively captures rapid focus decay and improves performance on public DFF datasets by leveraging superior global feature extraction. Additionally, it exhibits strong robustness even in extreme conditions. Dataset and code are available at https://github.com/jiangfeng-Z/M3D",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "M3D：微观 3D 形状重建的基准数据集和模型",
        "abstract_cn": "使用焦深 (DFF) 进行微观 3D 形状重建对于 3D 建模和质量控制的精密制造至关重要。然而，高精度微观DFF数据集的缺乏以及现有DFF数据集与微观DFF数据在光学设计、成像原理和场景特征上的显着差异阻碍了当前DFF模型在微观任务中的性能。为了解决这个问题，我们引入了 M3D，一种新颖的微观 DFF 数据集，使用自主开发的微观设备构建。它包括跨五个类别的 1,952 个场景的多焦点图像序列，通过 3D TFT 算法获得的深度标签应用于密集图像序列，以进行初始深度估计和校准。然后将所有标签与设计值进行比较和分析，剔除误差较大的标签。我们还提出了 M3DNet，一种频率感知的端到端网络，用于解决浅景深 (DoF) 和弱纹理等挑战。结果表明，M3D弥补了宏观DFF数据集的局限性，并将DFF应用扩展到微观场景。 M3DNet 通过利用卓越的全局特征提取，有效捕获快速焦点衰减并提高公共 DFF 数据集的性能。此外，即使在极端条件下，它也表现出很强的鲁棒性。数据集和代码可在https://github.com/jianfeng-Z/M3D获取"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3646890",
        "title": "Cross-Modality Feature Aggregation for Cross-Domain Point Cloud Representation Learning",
        "link": "https://doi.org/10.1109/tip.2025.3646890",
        "published": "2026",
        "author": "Guoqing Wang, Chao Ma, Xiaokang Yang",
        "summary": "Existing methods for learning 3D point cloud representation often use a single dataset-specific training and testing approach, leading to performance drops due to significant domain shifts between training and testing data. While recent cross-domain methods have made promising progress, the lack of inherent semantic information in point clouds makes models prone to overfitting specific datasets. As such, we introduce 3D-CFA, a simple yet effective cross-modality feature aggregation method for cross-domain 3D point cloud representation learning. 3D-CFA aggregates the geometry tokens with semantic tokens derived from multi-view images, which are projected from the point cloud, thus generating more transferable features for cross-domain 3D point cloud representation learning. Specifically, 3D-CFA consists of two main components: a cross-modality feature aggregation module and an elastic domain alignment module. The cross-modality feature aggregation module converts unordered points into multi-view images using the modality transformation module. Then, the geometry tokens and semantic tokens extracted from the geometry encoder and semantic encoder are fed into the cross-modal projector to get the transferable 3D tokens. A key insight of this design is that the semantic tokens can serve as a bridge between the 3D point cloud model and the 2D foundation model, greatly promoting the generalization of cross-domain models facing the severe domain shift. Finally, the elastic domain alignment module learns the hierarchical domain-invariant features of different training domains for either domain adaptation or domain generalization protocols. 3D-CFA finds a better way to transfer the knowledge of the 2D foundation model pre-trained at scale, meanwhile only introducing a few extra trainable parameters. Comprehensive experiments on several cross-domain point cloud benchmarks demonstrate the effectiveness of the proposed method compared to the state-of-the-art methods.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "用于跨域点云表示学习的跨模态特征聚合",
        "abstract_cn": "现有的学习 3D 点云表示的方法通常使用单一数据集特定的训练和测试方法，由于训练和测试数据之间的显着域转移而导致性能下降。虽然最近的跨域方法取得了可喜的进展，但点云中固有语义信息的缺乏使得模型容易过度拟合特定数据集。因此，我们引入了 3D-CFA，这是一种简单而有效的跨模态特征聚合方法，用于跨域 3D 点云表示学习。 3D-CFA 将几何标记与从点云投影的多视图图像派生的语义标记聚合在一起，从而为跨域 3D 点云表示学习生成更多可转移的特征。具体来说，3D-CFA由两个主要组件组成：跨模态特征聚合模块和弹性域对齐模块。跨模态特征聚合模块使用模态转换模块将无序点转换为多视图图像。然后，从几何编码器和语义编码器中提取的几何标记和语义标记被输入到跨模态投影仪中以获得可传输的3D标记。该设计的一个关键见解是，语义标记可以充当3D点云模型和2D基础模型之间的桥梁，极大地促进面对严重领域转移的跨领域模型的泛化。最后，弹性域对齐模块学习域适应或域泛化协议的不同训练域的分层域不变特征。 3D-CFA 找到了一种更好的方法来转移大规模预训练的 2D 基础模型的知识，同时仅引入一些额外的可训练参数。对多个跨域点云基准的综合实验证明了所提出的方法与最先进的方法相比的有效性。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3647367",
        "title": "Token Calibration for Transformer-Based Domain Adaptation",
        "link": "https://doi.org/10.1109/tip.2025.3647367",
        "published": "2026",
        "author": "Xiaowei Fu, Shiyu Ye, Chenxu Zhang, Fuxiang Huang, Xin Xu, Lei Zhang",
        "summary": "Unsupervised Domain Adaptation (UDA) aims to transfer knowledge from a labeled source domain to an unlabeled target domain by learning domain-invariant representations. Motivated by the recent success of Vision Transformers (ViTs), several UDA approaches have adopted ViT architectures to exploit fine-grained patch-level representations, which are unified as <italic>Trans</italic>former-based <inline-formula> <tex-math notation=\"LaTeX\">$D$ </tex-math></inline-formula>omain <inline-formula> <tex-math notation=\"LaTeX\">$A$ </tex-math></inline-formula>daptation (TransDA) independent of CNN-based. However, we have a key observation in TransDA: due to inherent domain shifts, patches (tokens) from different semantic categories across domains may exhibit abnormally high similarities, which can mislead the self-attention mechanism and degrade adaptation performance. To solve that, we propose a novel <inline-formula> <tex-math notation=\"LaTeX\">$P$ </tex-math></inline-formula>atch-<inline-formula> <tex-math notation=\"LaTeX\">$A$ </tex-math></inline-formula>daptation <italic>Trans</italic>former (PATrans), which first <italic>identifies</italic> similarity-anomalous patches and then adaptively <italic>suppresses</italic> their negative impact to domain alignment, i.e. <italic>token calibration</italic>. Specifically, we introduce a <inline-formula> <tex-math notation=\"LaTeX\">$P$ </tex-math></inline-formula>atch-<inline-formula> <tex-math notation=\"LaTeX\">$A$ </tex-math></inline-formula>daptation <inline-formula> <tex-math notation=\"LaTeX\">$A$ </tex-math></inline-formula>ttention (<italic>PAA</italic>) mechanism to replace the standard self-attention mechanism, which consists of a weight-shared triple-branch mixed attention mechanism and a patch-level domain discriminator. The mixed attention integrates self-attention and cross-attention to enhance intra-domain feature modeling and inter-domain similarity estimation. Meanwhile, the patch-level domain discriminator quantifies the anomaly probability of each patch, enabling dynamic reweighting to mitigate the impact of unreliable patch correspondences. Furthermore, we introduce a contrastive attention regularization strategy, which leverages category-level information in a contrastive learning framework to promote class-consistent attention distributions. Extensive experiments on four benchmark datasets demonstrate that PATrans attains significant improvements over existing state-of-the-art UDA methods (e.g., 89.2% on the VisDA-2017). Code is available at: <uri>https://github.com/YSY145/PATrans</uri>",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "基于变压器的域适应的令牌校准",
        "abstract_cn": "无监督域适应（UDA）旨在通过学习域不变表示将知识从标记的源域转移到未标记的目标域。受 Vision Transformers (ViT) 最近成功的推动，一些 UDA 方法采用了 ViT 架构来利用细粒度的补丁级表示，这些表示被统一为基于 Trans 的 <inline-formula> <tex-math notation=\"LaTeX\">$D$ </tex-math></inline-formula>omain <inline-formula> <tex-math notation=\"LaTeX\">$A$ </tex-math></inline-formula>适应（TransDA）独立于基于CNN的。然而，我们在 TransDA 中有一个关键的观察结果：由于固有的领域转移，跨领域的不同语义类别的补丁（令牌）可能表现出异常高的相似性，这可能会误导自注意力机制并降低适应性能。为了解决这个问题，我们提出了一种新颖的 <inline-formula> <tex-math notation=\"LaTeX\">$P$ </tex-math></inline-formula>atch-<inline-formula> <tex-math notation=\"LaTeX\">$A$ </tex-math></inline-formula>daptation <italic>Trans</italic>former (PATrans)，它首先<italic>识别</italic>相似性异常补丁，然后自适应<斜体>抑制</斜体>它们对域对齐的负面影响，即<斜体>令牌校准</斜体>。具体来说，我们引入了 <inline-formula> <tex-math notation=\"LaTeX\">$P$ </tex-math></inline-formula>atch-<inline-formula> <tex-math notation=\"LaTeX\">$A$ </tex-math></inline-formula>daptation <inline-formula> <tex-math notation=\"LaTeX\">$A$ </tex-math></inline-formula>注意力（<斜体>PAA</斜体>）机制取代了标准的自注意力机制，该机制由权重共享的三分支混合注意力机制和补丁级域鉴别器组成。混合注意力集成了自注意力和交叉注意力，以增强域内特征建模和域间相似性估计。同时，补丁级域鉴别器量化每个补丁的异常概率，从而实现动态重新加权以减轻不可靠补丁对应的影响。此外，我们引入了对比注意力正则化策略，该策略利用对比学习框架中的类别级信息来促进类别一致的注意力分布。对四个基准数据集的大量实验表明，PATrans 比现有最先进的 UDA 方法取得了显着改进（例如，VisDA-2017 上的改进为 89.2%）。代码位于：<uri>https://github.com/YSY145/PATrans</uri>"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3647323",
        "title": "Task-Driven Underwater Image Enhancement via Hierarchical Semantic Refinement",
        "link": "https://doi.org/10.1109/tip.2025.3647323",
        "published": "2026",
        "author": "Meng Yu, Liquan Shen, Yihan Yu, Yu Zhang, Rui Le",
        "summary": "Underwater image enhancement (UIE) is crucial for robust marine exploration, yet existing methods prioritize perceptual quality while overlooking irreversible semantic corruption that impairs downstream tasks. Unlike terrestrial images, underwater semantics exhibit layer-specific degradations: shallow features suffer from color shifts and edge erosion, while deep features face semantic ambiguity. These distortions entangle with semantic content across feature hierarchies, where direct enhancement amplifies interference in downstream tasks. Even if distortions are removed, the damaged semantic structures cannot be fully recovered, making it imperative to further enhance corrupted content. To address these challenges, we propose a task-driven UIE framework that redefines enhancement as machine-interpretable semantic recovery rather than mere distortion removal. First, we introduce a multi-scale underwater distortion-aware generator to perceive distortions across feature levels and provide a prior for distortion removal. Second, leveraging this prior and the absence of clean underwater references, we propose a stable self-supervised disentanglement strategy to explicitly separate distortions from corrupted content through CLIP-based semantic constraints and identity consistency. Finally, to compensate for the irreversible semantic loss, we design a task-aware hierarchical enhancement module that refines shallow details via spatial-frequency fusion and strengthens deep semantics through multi-scale context aggregation, aligning results with machine vision requirements. Extensive experiments on segmentation, detection, and saliency tasks demonstrate the superiority of our method in restoring machine-friendly semantics from degraded underwater images. Our code is available at https://github.com/gemyumeng/HSRUIE",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "通过分层语义细化任务驱动的水下图像增强",
        "abstract_cn": "水下图像增强（UIE）对于稳健的海洋探索至关重要，但现有方法优先考虑感知质量，而忽视了损害下游任务的不可逆语义损坏。与陆地图像不同，水下语义表现出特定于层的退化：浅层特征遭受颜色变化和边缘侵蚀，而深层特征面临语义模糊。这些扭曲与跨特征层次结构的语义内容纠缠在一起，其中直接增强会放大对下游任务的干扰。即使消除扭曲，损坏的语义结构也无法完全恢复，因此必须进一步增强损坏的内容。为了应对这些挑战，我们提出了一个任务驱动的 UIE 框架，它将增强重新定义为机器可解释的语义恢复，而不仅仅是失真消除。首先，我们引入了多尺度水下失真感知生成器来感知跨特征级别的失真，并为失真消除提供先验。其次，利用这一先验和干净水下参考的缺乏，我们提出了一种稳定的自监督解缠策略，通过基于 CLIP 的语义约束和身份一致性，明确地将扭曲与损坏的内容分开。最后，为了补偿不可逆的语义损失，我们设计了一个任务感知的分层增强模块，该模块通过空间频率融合细化浅层细节，并通过多尺度上下文聚合增强深层语义，使结果与机器视觉要求保持一致。关于分割、检测和显着性任务的大量实验证明了我们的方法在从退化的水下图像中恢复机器友好的语义方面的优越性。我们的代码可在 https://github.com/gemyumeng/HSRUIE 获取"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3648141",
        "title": "Implicit Neural Compression of Point Clouds",
        "link": "https://doi.org/10.1109/tip.2025.3648141",
        "published": "2026",
        "author": "Hongning Ruan, Yulin Shao, Qianqian Yang, Liang Zhao, Zhaoyang Zhang, Dusit Niyato",
        "summary": "Point clouds have gained prominence across numerous applications due to their ability to accurately represent 3D objects and scenes. However, efficiently compressing unstructured, high-precision point cloud data remains a significant challenge. In this paper, we propose NeRC<inline-formula> <tex-math notation=\"LaTeX\">${}^{\\textbf {3}}$ </tex-math></inline-formula>, a novel point cloud compression framework that leverages implicit neural representations (INRs) to encode both geometry and attributes of dense point clouds. Our approach employs two coordinate-based neural networks: one maps spatial coordinates to voxel occupancy, while the other maps occupied voxels to their attributes, thereby implicitly representing the geometry and attributes of a voxelized point cloud. The encoder quantizes and compresses network parameters alongside auxiliary information required for reconstruction, while the decoder reconstructs the original point cloud by inputting voxel coordinates into the neural networks. Furthermore, we extend our method to dynamic point cloud compression through techniques that reduce temporal redundancy, including a 4D spatio-temporal representation termed 4D-NeRC<inline-formula> <tex-math notation=\"LaTeX\">${}^{\\textbf {3}}$ </tex-math></inline-formula>. Experimental results validate the effectiveness of our approach: For static point clouds, NeRC<inline-formula> <tex-math notation=\"LaTeX\">${}^{\\textbf {3}}$ </tex-math></inline-formula> outperforms octree-based G-PCC standard and existing INR-based methods. For dynamic point clouds, 4D-NeRC<inline-formula> <tex-math notation=\"LaTeX\">${}^{\\textbf {3}}$ </tex-math></inline-formula> achieves superior geometry compression performance compared to the latest G-PCC and V-PCC standards, while matching state-of-the-art learning-based methods. It also demonstrates competitive performance in joint geometry and attribute compression.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "点云的隐式神经压缩",
        "abstract_cn": "点云由于能够准确表示 3D 对象和场景，因此在众多应用中获得了突出地位。然而，有效压缩非结构化、高精度点云数据仍然是一个重大挑战。在本文中，我们提出了 NeRC<inline-formula> <tex-math notation=\"LaTeX\">${}^{\\textbf {3}}$ </tex-math></inline-formula>，一种新颖的点云压缩框架，利用隐式神经表示（INR）对密集点云的几何形状和属性进行编码。我们的方法采用两种基于坐标的神经网络：一种将空间坐标映射到体素占用，而另一种将占用体素映射到其属性，从而隐式表示体素化点云的几何形状和属性。编码器量化和压缩网络参数以及重建所需的辅助信息，而解码器通过将体素坐标输入神经网络来重建原始点云。此外，我们通过减少时间冗余的技术将我们的方法扩展到动态点云压缩，包括称为 4D-NeRC<inline-formula> <tex-math notation=\"LaTeX\">${}^{\\textbf {3}}$ </tex-math></inline-formula> 的 4D 时空表示。实验结果验证了我们方法的有效性：对于静态点云，NeRC<inline-formula> <tex-math notation=\"LaTeX\">${}^{\\textbf {3}}$ </tex-math></inline-formula> 优于基于八叉树的 G-PCC 标准和现有的基于 INR 的方法。对于动态点云，4D-NeRC<inline-formula> <tex-math notation=\"LaTeX\">${}^{\\textbf {3}}$ </tex-math></inline-formula> 与最新的 G-PCC 和 V-PCC 标准相比，实现了卓越的几何压缩性能，同时匹配最先进的基于学习的方法。它还展示了关节几何和属性压缩方面的竞争性能。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3647207",
        "title": "Coupled Diffusion Posterior Sampling for Unsupervised Hyperspectral and Multispectral Images Fusion",
        "link": "https://doi.org/10.1109/tip.2025.3647207",
        "published": "2026",
        "author": "Yang Xu, Jian Zhu, Danfeng Hong, Zhihui Wei, Zebin Wu",
        "summary": "Hyperspectral images (HSIs) and multispectral images (MSIs) fusion is a hot topic in the remote sensing society. A high-resolution HSI (HR-HSI) can be obtained by fusing a low-resolution HSI (LR-HSI) and a high-resolution MSI (HR-MSI) or RGB image. However, most deep learning-based methods require a large amount of HR-HSIs for supervised training, which is very rare in practice. In this paper, we propose a coupled diffusion posterior sampling (CDPS) method for HSI and MSI fusion in which the HR-HSIs are no longer required in the training process. Because the LR-HSI contains the spectral information and HR-MSI contains the spatial information of the captured scene, we design an unsupervised strategy that learns the required diffusion priors directly and solely from the input test image pair (the LR-HSI and HR-MSI themselves). Then, a coupled diffusion posterior sampling method is proposed to introduce the two priors in the diffusion posterior sampling which leverages the observed LR-HSI and HR-MSI as fidelity terms. Experimental results demonstrate that the proposed method outperforms other state-of-the-art unsupervised HSI and MSI fusion methods. Additionally, this method utilizes smaller networks that are simpler and easier to train without other data.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "用于无监督高光谱和多光谱图像融合的耦合扩散后采样",
        "abstract_cn": "高光谱图像（HSIs）和多光谱图像（MSI）融合是遥感界的热门话题。高分辨率 HSI (HR-HSI) 可以通过融合低分辨率 HSI (LR-HSI) 和高分辨率 MSI (HR-MSI) 或 RGB 图像来获得。然而，大多数基于深度学习的方法需要大量的 HR-HSI 进行监督训练，这在实践中非常罕见。在本文中，我们提出了一种用于 HSI 和 MSI 融合的耦合扩散后验采样（CDPS）方法，其中训练过程中不再需要 HR-HSI。由于 LR-HSI 包含光谱信息，而 HR-MSI 包含捕获场景的空间信息，因此我们设计了一种无监督策略，直接且仅从输入测试图像对（LR-HSI 和 HR-MSI 本身）学习所需的扩散先验。然后，提出了一种耦合扩散后验采样方法，在扩散后验采样中引入两个先验，利用观察到的 LR-HSI 和 HR-MSI 作为保真度项。实验结果表明，所提出的方法优于其他最先进的无监督 HSI 和 MSI 融合方法。此外，该方法利用更小的网络，更简单、更容易训练，无需其他数据。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3648203",
        "title": "Reflectance Prediction-based Knowledge Distillation for Robust 3D Object Detection in Compressed Point Clouds",
        "link": "https://doi.org/10.1109/tip.2025.3648203",
        "published": "2026",
        "author": "Hao Jing, Anhong Wang, Yifan Zhang, Donghan Bu, Junhui Hou",
        "summary": "Regarding intelligent transportation systems, low-bitrate transmission via lossy point cloud compression is vital for facilitating real-time collaborative perception among connected agents, such as vehicles and infrastructures, under restricted bandwidth. In existing compression transmission systems, the sender lossily compresses point coordinates and reflectance to generate a transmission code stream, which faces transmission burdens from reflectance encoding and limited detection robustness due to information loss. To address these issues, this paper proposes a 3D object detection framework with reflectance prediction-based knowledge distillation (RPKD). We compress point coordinates while discarding reflectance during low-bitrate transmission, and feed the decoded non-reflectance compressed point clouds into a student detector. The discarded reflectance is then reconstructed by a geometry-based reflectance prediction (RP) module within the student detector for precise detection. A teacher detector with the same structure as the student detector is designed for performing reflectance knowledge distillation (RKD) and detection knowledge distillation (DKD) from raw to compressed point clouds. Our cross-source distillation training strategy (CDTS) equips the student detector with robustness to low-quality compressed data while preserving the accuracy benefits of raw data through transferred distillation knowledge. Experimental results on the KITTI and DAIR-V2X-V datasets demonstrate that our method can boost detection accuracy for compressed point clouds across multiple code rates. We will release the code publicly at https://github.com/HaoJing-SX/RPKD.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "基于反射率预测的知识蒸馏，用于压缩点云中鲁棒的 3D 对象检测",
        "abstract_cn": "对于智能交通系统，通过有损点云压缩进行低比特率传输对于在有限带宽下促进车辆和基础设施等互联代理之间的实时协作感知至关重要。在现有的压缩传输系统中，发送方有损地压缩点坐标和反射率来生成传输码流，这面临着反射率编码的传输负担以及由于信息丢失而导致的检测鲁棒性有限。为了解决这些问题，本文提出了一种具有基于反射预测的知识蒸馏（RPKD）的 3D 对象检测框架。我们压缩点坐标，同时在低比特率传输期间丢弃反射率，并将解码的非反射率压缩点云馈送到学生检测器中。然后，丢弃的反射率由学生检测器内基于几何的反射率预测 (RP) 模块重建，以实现精确检测。与学生检测器结构相同的教师检测器被设计用于执行从原始点云到压缩点云的反射知识蒸馏（RKD）和检测知识蒸馏（DKD）。我们的跨源蒸馏训练策略（CDTS）使学生检测器具有对低质量压缩数据的鲁棒性，同时通过转移蒸馏知识保留原始数据的准确性优势。 KITTI 和 DAIR-V2X-V 数据集上的实验结果表明，我们的方法可以提高跨多种码率的压缩点云的检测精度。我们将在 https://github.com/HaoJing-SX/RPKD 公开发布代码。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3650664",
        "title": "Reviewer Summary for Transactions on Image Processing",
        "link": "https://doi.org/10.1109/tip.2025.3650664",
        "published": "2025",
        "author": "Unknown",
        "summary": "Abstract not available.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "图像处理汇刊审稿人摘要",
        "abstract_cn": "（摘要暂缺，等待官方补全）"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3650023",
        "title": "Image Representation Induced Subspaces for Practical Classification Robustness",
        "link": "https://doi.org/10.1109/tip.2025.3650023",
        "published": "2026",
        "author": "Mohamed-Hicham Leghettas, Markus Püschel",
        "summary": "Both classical and learned image transformations such as the discrete wavelet transforms (DWTs) and flow-based generative models provide semantically meaningful representations of images. In this paper, we exploit the expressiveness of these representations to propose a general method for improving the classification robustness of neural network against real-world corruptions. The key idea is a novel adversarial attack that targets suitable low-dimensional subspaces in the transformed space while at the same time obeying the L∞-box in the pixel space. Subsequent training for adversarial robustness with this attack is then used as a proxy for achieving corruption robustness. We apply this approach with the discrete cosine transform (DCT), DWTs, and Glow with attacks that preserve low frequencies or the most relevant features, respectively. The resulting models are significantly more robust against a broad class of unseen common image perturbations compared to using the standard L∞-box, with only a minor sacrifice of natural accuracy. We provide an extensive ablation study, which shows that our method applies quite generally for two different color systems and choice of relevant parameters and also provides insight into why our method works.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "用于实际分类鲁棒性的图像表示诱导子空间",
        "abstract_cn": "经典图像变换和学习图像变换（例如离散小波变换 (DWT) 和基于流的生成模型）都提供了语义上有意义的图像表示。在本文中，我们利用这些表示的表达能力提出了一种通用方法来提高神经网络针对现实世界腐败的分类鲁棒性。关键思想是一种新颖的对抗性攻击，其目标是变换空间中合适的低维子空间，同时遵守像素空间中的 L∞ 框。随后对该攻击的对抗鲁棒性进行训练，然后将其用作实现腐败鲁棒性的代理。我们将此方法与离散余弦变换 (DCT)、DWT 和 Glow 结合使用，并分别进行保留低频或最相关特征的攻击。与使用标准 L∞-box 相比，所得模型对于一大类不可见的常见图像扰动明显更加稳健，并且仅略微牺牲了自然精度。我们提供了广泛的消融研究，表明我们的方法非常普遍地适用于两种不同的颜色系统和相关参数的选择，并且还深入了解了我们的方法为何有效。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3649363",
        "title": "Subjective-objective Emotion Correlated Generation Network for Subjective Video Captioning",
        "link": "https://doi.org/10.1109/tip.2025.3649363",
        "published": "2026",
        "author": "Weidong Chen, Cheng Ye, Peipei Song, Lei Zhang, Yongdong Zhang, Zhendong Mao",
        "summary": "The emotional video captioning (EVC) task, which aims to generate factual descriptions based on the perceived subtle visual emotion cues, has received more and more attention and research. However, EVC is essentially an objective video captioning task, and ignores the subjective emotional reactions of video viewers, which cannot reflect personalized affective understandings of different viewers on the same video. To fill the research gap, we investigate the subjective video captioning (SVC) task in this paper, which aims to generate emotional captions by incorporating viewers' personalized emotional reactions upon the EVC task. SVC is extremely challenging, which lies in two aspects: 1) the correlative emotion perception between subjective and objective emotions; and 2) the collaborative generation between emotional and factual information. To this end, we propose the Subjective-Objective Emotion-Correlated Generation Network (SO-ECGN) in this paper. Specifically, our SO-ECGN leverages the proposed dynamic mask attention and emotion domain shifting module to achieve the objective emotion incremental learning, and then, a subjective-objective emotions correlation module is proposed to adaptively combine two perspective emotions to provide accurate emotion guidance (i.e., emotional polarity and intensity) for each generation step. Furthermore, an emotion-correlated decoder is proposed to generate subjective captions by adaptively referring to factual information and emotional information. Extensive experiments on three challenging datasets demonstrate the superiority of our approach and each proposed module, i.e., reaching 79.2%, 45.1% on BLEU-1, CIDEr metrics on EmVidCap-L dataset.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "用于主观视频字幕的主客观情感相关生成网络",
        "abstract_cn": "情感视频字幕（EVC）任务旨在根据感知的微妙视觉情感线索生成事实描述，受到越来越多的关注和研究。然而，EVC本质上是一种客观的视频字幕任务，忽略了视频观看者的主观情感反应，无法反映不同观看者对同一视频的个性化情感理解。为了填补研究空白​​，我们在本文中研究了主观视频字幕（SVC）任务，其目的是通过将观众的个性化情感反应融入到 EVC 任务中来生成情感字幕。 SVC极具挑战性，主要体现在两个方面：1）主观情绪和客观情绪之间的关联情绪感知； 2）情感信息和事实信息之间的协作生成。为此，我们在本文中提出了主客观情感相关生成网络（SO-ECGN）。具体来说，我们的SO-ECGN利用所提出的动态掩模注意和情感域转移模块来实现客观情感增量学习，然后提出主客观情感相关模块来自适应地组合两种视角情感，为每个生成步骤提供准确的情感指导（即情感极性和强度）。此外，提出了一种情感相关解码器，通过自适应地参考事实信息和情感信息来生成主观描述。对三个具有挑战性的数据集的广泛实验证明了我们的方法和每个提出的模块的优越性，即在 EmVidCap-L 数据集上的 BLEU-1、CIDEr 指标上达到 79.2%、45.1%。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3644175",
        "title": "RAR: Retrieving And Ranking Augmented MLLMs for Visual Recognition",
        "link": "https://doi.org/10.1109/tip.2025.3644175",
        "published": "2026",
        "author": "Ziyu Liu, Zeyi Sun, Yuhang Zang, Wei Li, Pan Zhang, Xiaoyi Dong, Yuanjun Xiong, Dahua Lin, Jiaqi Wang",
        "summary": "CLIP (Contrastive Language-Image Pre-training) uses contrastive learning from noise image-text pairs to excel at recognizing a wide array of candidates, yet its focus on broad associations hinders the precision in distinguishing subtle differences among fine-grained items. Conversely, Multimodal Large Language Models (MLLMs) excel at classifying fine-grained categories, thanks to their substantial knowledge from pre-training on web-level corpora. However, the performance of MLLMs declines with an increase in category numbers, primarily due to growing complexity and constraints of limited context window size. To synergize the strengths of both approaches and enhance the few-shot/zero-shot recognition abilities for datasets characterized by extensive and fine-grained vocabularies, this paper introduces RAR, a Retrieving And Ranking augmented method for MLLMs. We initially establish a multi-modal retriever based on CLIP to create and store explicit memory for different categories beyond the immediate context window. During inference, RAR retrieves the top-k similar results from the memory and uses MLLMs to rank and make the final predictions. Our proposed approach not only addresses the inherent limitations in fine-grained recognition but also preserves the models comprehensive knowledge base, significantly boosting accuracy across a range of vision-language recognition tasks. Notably, our approach demonstrates a significant improvement in performance on 5 fine-grained visual recognition benchmarks, 11 few-shot image recognition datasets, and the 2 object detection datasets under the zero-shot recognition setting.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "RAR：检索和排序用于视觉识别的增强 MLLM",
        "abstract_cn": "CLIP（对比语言-图像预训练）使用噪声图像-文本对的对比学习来擅长识别广泛的候选者，但其对广泛关联的关注阻碍了区分细粒度项目之间细微差异的精度。相反，多模态大型语言模型 (MLLM) 擅长对细粒度类别进行分类，这要归功于它们通过网络级语料库预训练获得的丰富知识。然而，MLLM 的性能随着类别数量的增加而下降，这主要是由于复杂性的增加和上下文窗口大小有限的限制。为了协同这两种方法的优势，增强对具有广泛和细粒度词汇特征的数据集的少样本/零样本识别能力，本文引入了 RAR，一种用于 MLLM 的检索和排名增强方法。我们最初建立了一个基于 CLIP 的多模式检索器，为直接上下文窗口之外的不同类别创建和存储显式记忆。在推理过程中，RAR 从内存中检索前 k 个相似结果，并使用 MLLM 进行排序并做出最终预测。我们提出的方法不仅解决了细粒度识别的固有局限性，而且保留了模型的综合知识库，显着提高了一系列视觉语言识别任务的准确性。值得注意的是，我们的方法在 5 个细粒度视觉识别基准、11 个少样本图像识别数据集以及零样本识别设置下的 2 个对象检测数据集上表现出了显着的性能改进。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3648562",
        "title": "CoFaCo: Controllable Generative Talking Face Video Coding",
        "link": "https://doi.org/10.1109/tip.2025.3648562",
        "published": "2026",
        "author": "Xiaona Li, Xihua Sheng, Meng Wang, Fu-Zhao Ou, Bolin Chen, Shiqi Wang, Sam Kwong",
        "summary": "Efficient talking face video coding and control are crucial in modern video communication, reshaping how individuals connect, collaborate, and interact. Coding seeks to reduce transmission costs, while control enables the realization of user-customizable facial expressions and head poses in the transmitted videos. However, the compression efficiency of the common paradigm of applying control algorithms before video coding is not satisfactory. In this paper, we propose an efficient, Controllable Generative Talking Face Video Coding (CoFaCo) framework, which seamlessly integrates control into the coding process. Specifically, CoFaCo projects talking face videos into ultra-compact and semantic feature representations that can be customized by users before compression. To enable independent controls of pose and expression, we design a set of sophisticated losses to accurately decouple the pose and expression direction codes. Once the decoupled direction codes and the semantic face representations are obtained, the pose and expression control modules can be effectively learned to generate decoupled, controlled pose and expression direction codes. The controlled direction codes are subsequently smoothed to enhance temporal consistency in the controlled video output by the generators. Experimental results demonstrate that CoFaCo achieves competitive compression efficiency in ultra-low bit rate video reconstruction and control tasks, providing valuable insights for advancing face video communication with diverse control capabilities.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "CoFaCo：可控生成说话人脸视频编码",
        "abstract_cn": "高效的人脸视频编码和控制对于现代视频通信至关重要，它重塑了个人的联系、协作和交互方式。编码旨在降低传输成本，而控制则可以在传输的视频中实现用户可定制的面部表情和头部姿势。然而，在视频编码之前应用控制算法的常见范例的压缩效率并不令人满意。在本文中，我们提出了一种高效、可控的生成说话人脸视频编码（CoFaCo）框架，它将控制无缝集成到编码过程中。具体来说，CoFaCo 将说话的面部视频投影为超紧凑的语义特征表示，用户可以在压缩之前对其进行自定义。为了实现姿势和表情的独立控制，我们设计了一组复杂的损失来准确解耦姿势和表情方向代码。一旦获得解耦的方向代码和语义人脸表示，就可以有效地学习姿势和表情控制模块，以生成解耦的受控姿势和表情方向代码。随后对受控方向代码进行平滑，以增强发生器输出的受控视频的时间一致性。实验结果表明，CoFaCo在超低比特率视频重建和控制任务中实现了具有竞争力的压缩效率，为推进具有多样化控制能力的人脸视频通信提供了宝贵的见解。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3648582",
        "title": "P-CLIP: Progressive Discrepancy Learning for One-Shot Text-to-Image Person Re-identification",
        "link": "https://doi.org/10.1109/tip.2025.3648582",
        "published": "2026",
        "author": "Chengji Wang, Ming Dong, Mang Ye, Hao Sun, Xingpeng Jiang",
        "summary": "One-shot Text-to-Image Person Re-Identification (One-shot TIReID) aims to construct a TIReID model using only a single labeled image-text pair per identity, along with a large pool of unlabeled person images. While supervised learning in text-to-image person re-identification has demonstrated high effectiveness, the requirement for extensive annotated data, both in terms of identities and corresponding textual descriptions, makes it impractical for large-scale camera networks. One-shot TIReID presents a promising approach to reduce the annotation burden. The primary challenge in one-shot TIReID lies in establishing consistent visual-textual correspondences across diverse viewing conditions, particularly in the absence of cross-view paired data. To address this challenge, we propose a novel progressive discrepancy learning framework, termed P-CLIP, which aims to establish a shared embedding space that is robust to view-specific biases. To achieve this goal, we dynamically construct multi-view image-text pairs based on a single labeled pair and simultaneously project the multi-view data into a unified embedding space. Specifically, we propose a Progressive Multi-View Generation method (MVG) to generate multiple noisy views from a single labeled instance for training. To mitigate cross-view ambiguities, we introduce a Cross-View Discrepancy Learning module (CDL) that leverages the discrepancies among different views to guide the learning of cross-view visual-textual correspondences. This approach effectively integrates multimodal error correction into the person re-identification domain. Furthermore, to enhance the effectiveness of visual-textual correspondence learning, we propose a Compact Cross-Modal Matching Loss (CCM), which suppresses unmatched pairs while emphasizing matched ones. Extensive experiments were conducted on three benchmark datasets, and the experimental results demonstrate the effectiveness of our proposed method. The data and codes are available at https://github.com/Itachjw/P-CLIP/tree/main.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "P-CLIP：用于一次性文本到图像人员重新识别的渐进差异学习",
        "abstract_cn": "单次文本到图像人员重新识别（One-shot TIReID）旨在构建一个 TIReID 模型，每个身份仅使用单个标记的图像文本对以及大量未标记的人员图像。虽然文本到图像行人重新识别中的监督学习已表现出很高的有效性，但在身份和相应的文本描述方面对大量注释数据的要求使得它对于大规模相机网络来说不切实际。 One-shot TIReID 提出了一种有前途的减少注释负担的方法。一次性 TIReID 的主要挑战在于在不同的观看条件下建立一致的视觉文本对应关系，特别是在缺乏跨视图配对数据的情况下。为了应对这一挑战，我们提出了一种新颖的渐进式差异学习框架，称为 P-CLIP，其旨在建立一个对特定视图偏差具有鲁棒性的共享嵌入空间。为了实现这一目标，我们基于单个标记对动态构建多视图图像文本对，并同时将多视图数据投影到统一的嵌入空间中。具体来说，我们提出了一种渐进多视图生成方法（MVG），从单个标记实例生成多个噪声视图以进行训练。为了减轻跨视图模糊性，我们引入了跨视图差异学习模块（CDL），该模块利用不同视图之间的差异来指导跨视图视觉文本对应的学习。这种方法有效地将多模态纠错集成到人员重新识别领域。此外，为了提高视觉文本对应学习的有效性，我们提出了一种紧凑的跨模态匹配损失（CCM），它抑制不匹配的对，同时强调匹配的对。在三个基准数据集上进行了大量的实验，实验结果证明了我们提出的方法的有效性。数据和代码可在 https://github.com/Itachjw/P-CLIP/tree/main 获取。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3648497",
        "title": "FCS-edNET: Exploring Magnetic Particle Imaging Deblurring with Neural Network",
        "link": "https://doi.org/10.1109/tip.2025.3648497",
        "published": "2026",
        "author": "Xiting Peng, Yandi Zhang, Xiaoyu Zhang, Junyi Wang, Shi Bai, Yubo Cao, Hongye Chen, Tianshu Li",
        "summary": "Magnetic particle imaging technology, a novel medical imaging technology, possesses rapid imaging, high penetration depth, and is free from ionizing radiation. However, the system point spread function causes imaging blurring, which can be further exacerbated by external environmental interferences. Although hardware improvements and system optimization can mitigate blurring, these approaches are often expensive and time-consuming, particularly for low-field imaging in large-scale systems. This article proposes a Fast Context-aware Saliency-enhanced Deblurring Network, FCS-edNET, to solve the challenging issue by deblurring the reconstructed images. The network introduces the Multi-scale Global module to enhance the multi-scale feature perception ability. The Multi-scale Denoising Prior algorithm, which employs a low-frequency filter operator to restrict image noise and offers priors for each layer of subnetworks, is designed to improve the model robustness. Finally, proposing a Multi-level Joint loss optimizes model parameters to promote model convergence speed and space distribution simulation capability. Extensive experiments on multiple public and private datasets demonstrate that FCS-edNET outperforms the state-of-the-art methods in MPI image deblurring efficiently, suggesting its potential to support future research toward clinical imaging applications. The code is available at https://github.com/ydz1118/FCS-edNET.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "FCS-edNET：利用神经网络探索磁粒子成像去模糊",
        "abstract_cn": "磁粒子成像技术是一种新型医学成像技术，具有成像速度快、穿透深度高、不受电离辐射等优点。然而，系统点扩散函数会导致成像模糊，而外部环境干扰又会进一步加剧成像模糊。尽管硬件改进和系统优化可以减轻模糊，但这些方法通常既昂贵又耗时，特别是对于大型系统中的低场成像。本文提出了一种快速上下文感知显着性增强去模糊网络 FCS-edNET，通过对重建图像进行去模糊来解决这一具有挑战性的问题。网络引入Multi-scale Global模块，增强多尺度特征感知能力。多尺度去噪先验算法采用低频滤波器算子来限制图像噪声，并为每层子网络提供先验，旨在提高模型的鲁棒性。最后，提出多级联合损失优化模型参数，以提高模型收敛速度和空间分布模拟能力。对多个公共和私人数据集的广泛实验表明，FCS-edNET 在 MPI 图像去模糊方面的性能优于最先进的方法，这表明它有可能支持未来临床成像应用的研究。该代码可从 https://github.com/ydz1118/FCS-edNET 获取。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3648882",
        "title": "Dual Domain-attribute Learning Framework with Asynchronous Adapters for Continual Test-time Adaptation",
        "link": "https://doi.org/10.1109/tip.2025.3648882",
        "published": "2026",
        "author": "Yuntong Tian, Kang Li, Tianyang He, Liang Wan, Pheng-Ann Heng, Wei Feng",
        "summary": "Continual test-time domain adaptation (CTTA) aims to adapt a pre-trained source model to a stream of continually evolving unlabeled target domains, facilitating model deployment in dynamic and non-stationary environments. Contemporary works usually encode domain-specific (DS) style information in a domain-agnostic manner, synchronizing with the learning of domain-invariant (DI) semantic information. This scheme forces DS information to be optimized using the weights of the previous domain, corrupted by cross-domain discrepancies, and hence leads to error accumulation and catastrophic forgetting issues. Inspired by the Attribute Memory Model (AMM) in brain neuroscience, we propose a dual domain-attribute learning framework based on independent asynchronous updates, aiming to imitate how brain learns new knowledge without forgetting. Concretely, we explicitly decompose the continual adaptation process into two complementary systems: an event-based learning system (ELS) that captures DS style representations and a knowledge-based learning system (KLS) that concentrates on the DI structural characteristics. The ELS first detects differences in the distribution of data streams, and actively builds an adapter pool for new latent domains. The KLS adopts a cross-domain shared adapter emphasizing general knowledge, and cooperates with the adapter from ELS to jointly guide adaptation. To make DS and DI knowledge collaboratively working, we exploit a gradient conflict solver to ease the conflict between the past and current DI knowledge, realizing a win-win game (i.e., no interference adaptation) across evolving domains. Our framework have been extensively evaluated on four benchmarks and outperformed the state-of-the-art approaches on both segmentation and classification CTTA tasks.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "具有异步适配器的双域属性学习框架，用于持续测试时间适应",
        "abstract_cn": "持续测试时域适应（CTTA）旨在使预先训练的源模型适应不断发展的未标记目标域流，从而促进动态和非静态环境中的模型部署。当代作品通常以与领域无关的方式编码特定领域（DS）风格的信息，与领域不变（DI）语义信息的学习同步。该方案迫使 DS 信息使用前一个域的权重进行优化，并因跨域差异而损坏，从而导致错误累积和灾难性遗忘问题。受脑神经科学中属性记忆模型（AMM）的启发，我们提出了一种基于独立异步更新的双域属性学习框架，旨在模仿大脑如何在不遗忘的情况下学习新知识。具体来说，我们明确地将持续适应过程分解为两个互补的系统：一个捕获 DS 风格表示的基于事件的学习系统（ELS）和一个专注于 DI 结构特征的基于知识的学习系统（KLS）。 ELS首先检测数据流分布的差异，并主动为新的潜在域构建适配器池。 KLS采用强调通用知识的跨域共享适配器，并与ELS的适配器配合，共同指导适配。为了使 DS 和 DI 知识协同工作，我们利用梯度冲突求解器来缓解过去和当前 DI 知识之间的冲突，实现跨不断发展的领域的双赢游戏（即无干扰适应）。我们的框架已在四个基准上进行了广泛评估，并且在分割和分类 CTTA 任务上均优于最先进的方法。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3648584",
        "title": "Learning Decoupled Features with Perceptual Distillation for Blind Image Quality Assessment",
        "link": "https://doi.org/10.1109/tip.2025.3648584",
        "published": "2026",
        "author": "Jianjun Xiang, Yuanjie Dang, Peng Chen, Ronghua Liang, Weisi Lin",
        "summary": "Existing Blind Image Quality Assessment (BIQA) approaches typically employ subjective scores as optimization targets to train the model, aiming for results consistent with human judgments. Such judgments are derived from a comprehensive analysis of complex distortions and diverse semantics from images, whereas subjective scores represent the overall quality. This poses a significant challenge for a single model to learn diverse perceptual cues under weak supervision. To address this, we propose a Decoupled Feature Learning (DFL) framework that learns compact global content-aware and local distortion-aware features in a disentangled modeling for BIQA. Our key insight is to leverage global-local input pairs to decompose content-aware and distortion-aware cues entangled in distorted images, and aggregate decoupled perceptual features into a single network. We design a perceptual knowledge distillation strategy that progressively guides the student from fragmented representations to build local-to-global correspondences by distilling self-supervised semantic knowledge, while incorporating the Just-Noticeable-Difference (JND) model to highlight the transfer of perceptually sensitive content features. Finally, we introduce a local distortion-guided attention module to model synergistic effects of different perceptual features from the student for quality evaluation. Extensive experiments on eight benchmark datasets demonstrate the superior performance of the proposed model over the state-of-the-arts. In addition, the DFL framework is flexibly used to improve the perception ability of other Transformer variants. The code is released at https://github.com/JianjunXiang/DFT.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "通过感知蒸馏学习解耦特征以进行盲图像质量评估",
        "abstract_cn": "现有的盲图像质量评估（BIQA）方法通常采用主观评分作为优化目标来训练模型，旨在获得与人类判断一致的结果。这种判断是对图像的复杂失真和多样化语义进行综合分析而得出的，而主观评分则代表了整体质量。这对单一模型在弱监督下学习不同的感知线索提出了重大挑战。为了解决这个问题，我们提出了一个解耦特征学习（DFL）框架，该框架在 BIQA 的解耦建模中学习紧凑的全局内容感知和局部失真感知特征。我们的主要见解是利用全局本地输入对分解扭曲图像中纠缠的内容感知和扭曲感知线索，并将解耦的感知特征聚合到单个网络中。我们设计了一种感知知识提炼策略，通过提炼自我监督的语义知识，逐步引导学生从碎片化的表征中构建局部到全局的对应关系，同时结合Just-Noticeable-Difference（JND）模型来突出感知敏感内容特征的转移。最后，我们引入了一个局部失真引导的注意力模块来模拟学生不同感知特征的协同效应，以进行质量评估。对八个基准数据集的广泛实验证明了所提出的模型比最先进的模型具有优越的性能。此外，灵活运用DFL框架来提高其他Transformer变体的感知能力。代码发布于https://github.com/JianjunXiang/DFT。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3650051",
        "title": "Robust Self-Supervised Monocular Depth Estimation for Endoscopic Soft Tissue Deformation Scenes with Biomechanical Constraints",
        "link": "https://doi.org/10.1109/tip.2025.3650051",
        "published": "2026",
        "author": "Enpeng Wang, Jiangchang Xu, Yueang Liu, Puxun Tu, Junfeng Wang, Xiaoyi Jiang, Xiaojun Chen",
        "summary": "Self-supervised learning technology has been applied to calculate depth and ego-motion from monocular videos, achieving remarkable performance in various real-world scenarios. Unfortunately, challenges such as specular reflections and soft tissue deformations in endoscopic scenes greatly undermine the performance of these methods, inevitably compromising the accuracy of depth and ego-motion estimation. To address these two problems, we introduce a novel strategy based on image distance transform for robust self-supervised learning for monocular depth estimation, effectively handling specular reflections in endoscopic scenes. Furthermore, we propose a soft tissue deformation constraint based on biomechanical principles, which mitigates the adverse effects of deformed region pixels, ultimately enhancing the model's depth estimation precision. Additionally, our method employs a lightweight architecture ensuring a reduced number of model parameters and faster inference time. Extensive experiments are conducted on both public datasets (SCARED, SERV-CT) and our own datasets to validate the effectiveness of our method. Compared with other SOTA methods, our approach demonstrates comparable accuracy and robustness while ensuring faster inference time. On the SCARED dataset, our approach attains an RMSE of 4.96 mm with only 2.25M model parameters for depth estimation. Especially, experiment results on SERV-CT dataset and our own datasets further demonstrate the model's generalization ability and potential clinical value in computer-assisted surgical navigation.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "具有生物力学约束的内窥镜软组织变形场景的鲁棒自监督单目深度估计",
        "abstract_cn": "自监督学习技术已应用于计算单目视频的深度和自我运动，在各种现实场景中取得了出色的性能。不幸的是，内窥镜场景中的镜面反射和软组织变形等挑战极大地削弱了这些方法的性能，不可避免地损害了深度和自我运动估计的准确性。为了解决这两个问题，我们引入了一种基于图像距离变换的新策略，用于单目深度估计的鲁棒自监督学习，有效处理内窥镜场景中的镜面反射。此外，我们提出了一种基于生物力学原理的软组织变形约束，减轻了变形区域像素的不利影响，最终提高了模型的深度估计精度。此外，我们的方法采用轻量级架构，确保减少模型参数数量和更快的推理时间。在公共数据集（SCARED、SERV-CT）和我们自己的数据集上进行了大量的实验，以验证我们方法的有效性。与其他 SOTA 方法相比，我们的方法表现出相当的准确性和鲁棒性，同时确保更快的推理时间。在 SCARED 数据集上，我们的方法仅使用 225 万个用于深度估计的模型参数即可获得 4.96 mm 的 RMSE。特别是，在 SERV-CT 数据集和我们自己的数据集上的实验结果进一步证明了该模型在计算机辅助手术导航中的泛化能力和潜在的临床价值。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3649346",
        "title": "MCFL: Multimodal Collaborative Fusion Learning for Hashimoto’s Thyroiditis Recognition",
        "link": "https://doi.org/10.1109/tip.2025.3649346",
        "published": "2026",
        "author": "Wenchao Jiang, Guanjie Zhou, Honghua Bai, Ji He, Chao Huang, Feng Han, Wei Song, Song Guo",
        "summary": "Ultrasound imaging and biochemical examinations are the primary methods for diagnosing Hashimoto's thyroiditis (HT). However, neither of them is sufficient to accurately diagnose HT alone. Most existing multimodal models for HT diagnosis focus primarily on extracting and concatenating features from different modalities, which are ineffective due to the dimensional imbalance of the features between the textual and image data. To address this issue, we propose a novel Multimodal Collaborative Fusion Learning (MCFL) approach, which can enhance and recalibrate the biochemical indicators using ultrasound images, effectively improving the significance and specificity of biochemical indicators for the diagnosis of HT. Specifically, MCFL first constructs a novel INNet to convert the image-level characteristics of the HT ultrasound image into two numerical indicators, i.e., the Local prominent inflammatory (Lpi) and the Global diffuse lesion (Gdl), unifying image data and textual data into a single representation space. Then, a decision tree-based optimization strategy is employed to supervise the training of INNet, interactively recalibrating biochemical indicators with the guidance of the two numerical indicators mentioned above and obtaining a more accurate feature representation of HT. Finally, based on the deep Q-learning framework, a reward mechanism is established to guide the HT diagnostic process, in which the experience replay mechanism and the ϵ-greedy strategy are utilized collaboratively to improve the accuracy and robustness of the model. Extensive experiments are conducted on a multimodal dataset from multiple medical centers, and the results demonstrate that MCFL achieves state-of-the-art performance, setting a new benchmark.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "MCFL：桥本甲状腺炎识别的多模式协作融合学习",
        "abstract_cn": "超声影像和生化检查是诊断桥本甲状腺炎（HT）的主要方法。然而，它们都不足以单独准确诊断 HT。大多数现有的HT诊断多模态模型主要集中于从不同模态中提取和连接特征，由于文本和图像数据之间特征的维度不平衡，这些模型是无效的。针对这一问题，我们提出了一种新颖的多模态协作融合学习（MCFL）方法，该方法可以利用超声图像增强和重新校准生化指标，有效提高生化指标对HT诊断的意义和特异性。具体来说，MCFL首先构建了一个新颖的INNet，将HT超声图像的图像级特征转换为两个数值指标，即局部突出炎症（Lpi）和全局弥漫性病变（Gdl），将图像数据和文本数据统一到单个表示空间中。然后，采用基于决策树的优化策略来监督INNet的训练，在上述两个数值指标的指导下交互式地重新校准生化指标，并获得更准确的HT特征表示。最后，基于深度Q学习框架，建立奖励机制来指导HT诊断过程，其中经验重放机制和ε-贪婪策略协同利用，以提高模型的准确性和鲁棒性。在来自多个医疗中心的多模态数据集上进行了大量实验，结果表明 MCFL 实现了最先进的性能，树立了新的基准。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3648926",
        "title": "Masked Self-Attention Fusion Network for Joint Classification of Hyperspectral and LiDAR Data",
        "link": "https://doi.org/10.1109/tip.2025.3648926",
        "published": "2026",
        "author": "Lulu Shi, Chunchao Li, Zhengchao Zeng, Puhong Duan, Behnood Rasti, Antonio Plaza",
        "summary": "Hyperspectral imaging (HSI) captures abundant spectral information of land covers while light detection and ranging (LiDAR) provides elevation and structural characteristics. Joint classification of HSI and LiDAR data can effectively merge spectral and elevation information to enhance the outcome of land cover classification. Current HSI and LiDAR joint classification approaches mainly employ a three-layer deep network to extract high-order features, followed by a concatenation or weighted fusion scheme which cannot fully exploit the unique properties of different data modalities. Meanwhile, these methods usually require high computational resources. To alleviate these issues, this paper proposes a masked self-attention fusion network (MSAF) for joint HSI and LiDAR classification, where a cascaded cross-attention fusion framework is designed to fully merge different stages of features. First, a mobile convolution block is developed to extract multi-modal data features. Then, a multi-view sequence embedding method is proposed to effectively integrate elevation information and spectral-spatial information so as to obtain token sequences. Finally, an effective masked self-attention mechanism is designed to fuse token sequences. Experimental results on multiple datasets indicate that the proposed framework significantly outperforms other advanced multi-modal fusion methods in terms of classification performance and computing efficiency. The code of this manuscript is available on https://github.com/lulushh/MSAF.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "用于高光谱和激光雷达数据联合分类的掩模自注意力融合网络",
        "abstract_cn": "高光谱成像 (HSI) 捕获土地覆盖的丰富光谱信息，而光探测和测距 (LiDAR) 则提供高程和结构特征。 HSI和LiDAR数据的联合分类可以有效地合并光谱和高程信息，以增强土地覆盖分类的结果。目前的HSI和LiDAR联合分类方法主要采用三层深度网络来提取高阶特征，然后采用级联或加权融合方案，无法充分利用不同数据模态的独特属性。同时，这些方法通常需要较高的计算资源。为了缓解这些问题，本文提出了一种用于 HSI 和 LiDAR 联合分类的掩码自注意力融合网络（MSAF），其中设计了级联交叉注意力融合框架来完全融合不同阶段的特征。首先，开发移动卷积块来提取多模态数据特征。然后，提出一种多视图序列嵌入方法，有效整合高程信息和光谱空间信息，从而获得令牌序列。最后，设计了一种有效的屏蔽自注意力机制来融合令牌序列。多个数据集上的实验结果表明，所提出的框架在分类性能和计算效率方面显着优于其他先进的多模态融合方法。该手稿的代码可在 https://github.com/lulushh/MSAF 上获取。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3650372",
        "title": "Learnable Object Queries for Few-Shot Semantic Segmentation",
        "link": "https://doi.org/10.1109/tip.2025.3650372",
        "published": "2026",
        "author": "Yadang Chen, Wenbo Chen, Yuhui Zheng, Zhi-Xin Yang, Enhua Wu",
        "summary": "Few-shot semantic segmentation (FSS) aims to segment unseen-category objects given only a few annotated samples. Although significant progress has been made in the field of FSS, selecting an appropriate feature matching method remains a challenge. Traditional prototype-based methods can preserve high-level semantic features, but they tend to lose detailed information. On the other hand, pixel-level comparison methods retain fine-grained details but are vulnerable to distractors and noise, leading to poor robustness. To address these issues, this paper proposes a target-agnostic object-based method. Specifically, we propose a set of learnable \"object queries\" to extract object features, which preserve both high-level semantic information and fine-grained details. Additionally, during the training phase, we exploit the prior knowledge of foreground and background embedded in the samples to enhance the model's performance. In the inference phase, the model utilizes both the support set and the learned prior knowledge to perform segmentation tasks, mitigating the data distribution bias caused by limited samples. Extensive experiments on benchmark datasets demonstrate that our method outperforms state-of-the-art approaches in both accuracy and robustness. Code is available at https://github.com/wenbo456/OTBNet.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "用于少样本语义分割的可学习对象查询",
        "abstract_cn": "少样本语义分割（FSS）旨在仅在给定少量带注释的样本的情况下分割未见过的类别对象。尽管 FSS 领域已经取得了重大进展，但选择合适的特征匹配方法仍然是一个挑战。传统的基于原型的方法可以保留高级语义特征，但它们往往会丢失详细信息。另一方面，像素级比较方法保留了细粒度的细节，但容易受到干扰和噪声的影响，导致鲁棒性较差。为了解决这些问题，本文提出了一种与目标无关的基于对象的方法。具体来说，我们提出了一组可学习的“对象查询”来提取对象特征，它保留了高级语义信息和细粒度细节。此外，在训练阶段，我们利用样本中嵌入的前景和背景的先验知识来增强模型的性能。在推理阶段，模型利用支持集和学习到的先验知识来执行分割任务，减轻样本有限造成的数据分布偏差。对基准数据集的大量实验表明，我们的方法在准确性和鲁棒性方面都优于最先进的方法。代码可在 https://github.com/wenbo456/OTBNet 获取。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3648557",
        "title": "3D-SLARM: Practical Lossless Volumetric Image Compression via a 3D-Scanning Lightweight Autoregressive Model",
        "link": "https://doi.org/10.1109/tip.2025.3648557",
        "published": "2026",
        "author": "Kai Wang, Yuanchao Bai, Daxin Li, Deming Zhai, Junjun Jiang, Xianming Liu",
        "summary": "Volumetric images often encapsulate critical information, making it essential to employ lossless compression to preserve data integrity. Although various learned methods have demonstrated effective lossless compression for volumetric images, balancing high compression ratios with rapid coding speeds and lightweight architectures remains challenging. In this paper, we propose a 3D-scanning lightweight autoregressive model (3D-SLARM) for practical lossless volumetric image compression. 3D-SLARM integrates a novel 3D plane scanning module, a lightweight feature extraction (FE) module, and a lightweight distribution parameter and adaptive range predictor (DPARP) module. Initially, 3D-SLARM leverages a 3D plane scanning module to determine the scanning order of each voxel, allowing parallel coding of voxels within the same plane. Next, the lightweight FE module captures both intra-slice and inter-slice dependencies in the receptive field defined by the 3D plane scanning module. By incorporating our proposed serial re-parameterization (SerRep) technology alongside non-centric masked convolution (NCMC), the FE module attains a lightweight design while effectively capturing complex dependencies. Finally, 3D-SLARM employs a lightweight DPARP module to compute distribution parameters for both 8-bit and high bit-depth volumetric images. For high bit-depth images, the module further generates an adaptive probability range for each voxel, resulting in compact, voxel-specific PMF tables that facilitate efficient compression. Extensive experiments demonstrate that our 3D-SLARM achieves state-of-the-art lossless compression performance on majority volumetric image datasets and maintains fast coding speed with a lightweight design, underscoring its practical applicability.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "3D-SLAARM：通过 3D 扫描轻量级自回归模型实现实用的无损体积图像压缩",
        "abstract_cn": "体积图像通常封装关键信息，因此必须采用无损压缩来保持数据完整性。尽管各种学习方法已经证明了对体积图像的有效无损压缩，但在高压缩比与快速编码速度和轻量级架构之间取得平衡仍然具有挑战性。在本文中，我们提出了一种用于实用无损体积图像压缩的 3D 扫描轻量级自回归模型 (3D-SLAARM)。 3D-SLAARM集成了新颖的3D平面扫描模块、轻量级特征提取（FE）模块以及轻量级分布参数和自适应范围预测器（DPARP）模块。最初，3D-SLAARM 利用 3D 平面扫描模块来确定每个体素的扫描顺序，从而允许在同一平面内对体素进行并行编码。接下来，轻量级 FE 模块捕获 3D 平面扫描模块定义的感受野中的切片内和切片间依赖性。通过将我们提出的串行重新参数化（SerRep）技术与非中心掩模卷积（NCMC）相结合，有限元模块实现了轻量级设计，同时有效捕获复杂的依赖关系。最后，3D-SLAARM 采用轻量级 DPARP 模块来计算 8 位和高位深度体积图像的分布参数。对于高位深图像，该模块进一步为每个体素生成自适应概率范围，从而产生紧凑的、特定于体素的 PMF 表，从而促进高效压缩。大量实验表明，我们的 3D-SLAARM 在大多数体积图像数据集上实现了最先进的无损压缩性能，并通过轻量级设计保持快速编码速度，强调了其实际适用性。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3648880",
        "title": "Turbidity–Similarity Decoupling: Feature-Consistent Mutual Learning for Underwater Salient Object Detection",
        "link": "https://doi.org/10.1109/tip.2025.3648880",
        "published": "2026",
        "author": "Wujie Zhou, Beibei Tang, Runmin Cong, Qiuping Jiang",
        "summary": "Underwater salient object detection (USOD) faces two major challenges that hinder accurate detection: substantial image noise owing to water turbidity and low foreground-background contrast caused by high visual similarity. In this study, a dual-model architecture based on mutual learning is proposed to address these issues. First, DenoisedNet, which focuses on addressing water turbidity issues, is developed. Using a separation-denoising-enhancement processing framework, it suppresses noise while maintaining target feature integrity through domain separation and cleaning enhancement modules. Second, SearchNet is designed to address the foreground-background similarity issue. It achieves precise localization through pseudo-label generation and layer-by-layer search mechanisms. To enable both networks to address these challenges collaboratively, a feature-consistent mutual-learning strategy is proposed, which aligns encoded features and prediction results, via evaluation and cross modes, respectively. This strategy enables their respective strengths to be complemented and the challenges of USOD to be solved more comprehensively. Our DenoisedNet and SearchNet outperform the best existing methods on the USOD10K and USOD benchmarks, achieving MAE improvements of 4.52%/5.52% and 1.61%/8.94%, respectively. The source code is available at https://github.com/BeibeiIsFreshman/DSNet_CL.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "浊度-相似性解耦：用于水下显着物体检测的特征一致的相互学习",
        "abstract_cn": "水下显着目标检测（USOD）面临着阻碍准确检测的两大挑战：水体浑浊度导致的大量图像噪声和高视觉相似性导致的低前景-背景对比度。在本研究中，提出了一种基于相互学习的双模型架构来解决这些问题。首先，开发了专注于解决水浊度问题的 DenoishedNet。它使用分离去噪增强处理框架，通过域分离和清洁增强模块抑制噪声，同时保持目标特征完整性。其次，SearchNet 旨在解决前景-背景相似性问题。它通过伪标签生成和逐层搜索机制实现精确定位。为了使两个网络能够协作应对这些挑战，提出了一种特征一致的相互学习策略，该策略分别通过评估和交叉模式来对齐编码特征和预测结果。这一战略使双方优势互补，更全面地解决USOD面临的挑战。我们的 DenoishedNet 和 SearchNet 在 USOD10K 和 USOD 基准上优于现有的最佳方法，分别实现了 4.52%/5.52% 和 1.61%/8.94% 的 MAE 改进。源代码可在 https://github.com/BeibeiIsFreshman/DSNet_CL 获取。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3648554",
        "title": "Hi-RWKV: Hierarchical RWKV Modeling for Hyperspectral Image Classification",
        "link": "https://doi.org/10.1109/tip.2025.3648554",
        "published": "2026",
        "author": "Yunbiao Wang, Dongbo Yu, Ye Tao, Hengyu Niu, Daifeng Xiao, Lupeng Liu, Jun Xiao",
        "summary": "Hyperspectral image (HSI) classification demands models that can jointly capture long-range spatial relations and high-dimensional spectral structures while remaining scalable to large scenes and robust under limited supervision. Existing CNN-, Transformer-, and state-space-based approaches either suffer from restricted receptive fields, quadratic attention complexity, or directional biases that hinder dense pixel-wise prediction. To address these limitations, we propose Hi-RWKV, a hierarchical recurrent weighted key-value framework tailored for hyperspectral analysis. Hi-RWKV introduces three key innovations: (1) a spatial structure-guided bidirectional propagation mechanism that integrates global spatial context while preserving boundary fidelity via edge-aware gating; (2) a spectral identity-driven channel mixing module that incorporates learnable band embeddings and whitening transforms to enhance cross-band discriminability; and (3) a multi-stage hierarchical encoder that progressively refines spectral-spatial representations with strictly linear complexity. Together, these designs enable efficient, direction-free spectral-spatial reasoning essential for large-scale HSI interpretation. Extensive experiments on four benchmarks demonstrate that Hi-RWKV consistently achieves state-of-the-art accuracy under diverse training regimes. Ablation studies confirm that each proposed module offers complementary gains in boundary preservation, spectral discrimination, and data efficiency. By unifying scalable recurrence with hyperspectral-specific structural modeling, Hi-RWKV establishes a strong and efficient paradigm for high-resolution remote sensing. The logs and source data of this article are available at https://github.com/HSI-Lab/Hi-RWKV.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "Hi-RWKV：用于高光谱图像分类的分层 RWKV 建模",
        "abstract_cn": "高光谱图像（HSI）分类需要模型能够联合捕获长距离空间关系和高维光谱结构，同时保持对大场景的可扩展性和在有限监督下的鲁棒性。现有的基于 CNN、Transformer 和状态空间的方法要么受到受限的感受野、二次注意力复杂性的困扰，要么受到阻碍密集像素级预测的方向偏差的影响。为了解决这些限制，我们提出了 Hi-RWKV，这是一种专为高光谱分析量身定制的分层循环加权键值框架。 Hi-RWKV 引入了三项关键创新：（1）空间结构引导的双向传播机制，集成全局空间上下文，同时通过边缘感知门控保持边界保真度； (2) 光谱身份驱动的通道混合模块，结合可学习的频带嵌入和白化变换以增强跨频带辨别能力； (3) 多级分层编码器，以严格的线性复杂度逐步细化频谱空间表示。这些设计共同实现了高效、无方向的光谱空间推理，这对于大规模 HSI 解释至关重要。对四个基准的大量实验表明，Hi-RWKV 在不同的训练方案下始终能够达到最先进的准确性。消融研究证实，每个提出的模块都在边界保留、光谱辨别和数据效率方面提供了互补的增益。通过将可扩展的重现与高光谱特定的结构模型相结合，Hi-RWKV 为高分辨率遥感建立了强大而高效的范例。本文的日志和源数据可在https://github.com/HSI-Lab/Hi-RWKV获取。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3650395",
        "title": "Prototype-based Meta-Prompt Tuning: Toward Rehearsal-free Few-Shot Class-Incremental Learning for Multimodal Remote Sensing Image",
        "link": "https://doi.org/10.1109/tip.2025.3650395",
        "published": "2026",
        "author": "Yuanbo Yang, Jiahui Qu, Wenqian Dong, Ling Huang, Yunsong Li",
        "summary": "Recent research on the joint classification of multi-modal remote sensing data has achieved outstanding performance in tasks within predefined label spaces. However, surface conditions are dynamic and change over time, resulting in variations in land cover classes collected from the same region at different time points. As a result, when new classes are discovered, the previous works must use a combination of old and new class data to retrain the model, which incurs high computational costs and raises concerns about data privacy. In this work, we propose the prototype-based meta-prompt tuning (PMPT) framework, which fine-tunes only a few session-relevant visual prompts to adapt to incremental classes, while simultaneously learning prototype embeddings for each class to preserve historical knowledge. Specifically, the PMPT consists of a meta-learning-based feature representation backbone and an incrementally updated nearest-class-mean (NCM) classifier. The backbone is trained on base class data to learn shared and stable global knowledge, then frozen, with only the prompts fine-tuned to extract sessions-specific local knowledge from incremental sessions. The NCM classifier is a globally shared classifier that measures the similarity between test samples and prototypes, effectively alleviating the issues of knowledge forgetting and overfitting. Additionally, we propose an incremental prototype contrastive loss to reduce semantic drift and prototype overlap in the embedding space. During the testing phase, the PMPT reproduces the complete embedding function by matching samples, class prototypes, and visual prompts, thereby enabling accurate classification of unknown samples. The method has been tested on widely used multimodal remote sensing datasets, demonstrating the effectiveness of the proposed PMPT in addressing the dilemma of stability-plasticity with limited incremental samples.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "基于原型的元提示调整：面向多模态遥感图像的免排演少镜头类增量学习",
        "abstract_cn": "最近关于多模态遥感数据联合分类的研究在预定义标签空间内的任务中取得了出色的性能。然而，地表条件是动态的，并随着时间的推移而变化，导致在不同时间点从同一地区收集的土地覆盖类别发生变化。因此，当发现新的类别时，以前的工作必须使用新旧类别数据的组合来重新训练模型，这会产生高昂的计算成本并引发对数据隐私的担忧。在这项工作中，我们提出了基于原型的元提示调整（PMPT）框架，该框架仅微调一些与会话相关的视觉提示以适应增量类，同时学习每个类的原型嵌入以保留历史知识。具体来说，PMPT 由基于元学习的特征表示主干和增量更新的最近类均值 (NCM) 分类器组成。骨干网络接受基类数据的训练，以学习共享且稳定的全局知识，然后冻结，仅对提示进行微调，以从增量会话中提取特定于会话的本地知识。 NCM分类器是一个全局共享的分类器，可以衡量测试样本和原型之间的相似度，有效缓解知识遗忘和过度拟合的问题。此外，我们提出了一种增量原型对比损失，以减少嵌入空间中的语义漂移和原型重叠。在测试阶段，PMPT通过匹配样本、类原型和视觉提示来重现完整的嵌入功能，从而实现对未知样本的准确分类。该方法已在广泛使用的多模态遥感数据集上进行了测试，证明了所提出的 PMPT 在解决有限增量样本的稳定性-可塑性困境方面的有效性。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3648164",
        "title": "Completing Missing Entities: Exploring Consistency Reasoning for Remote Sensing Object Detection",
        "link": "https://doi.org/10.1109/tip.2025.3648164",
        "published": "2026",
        "author": "Peng Sun, Yongbin Zheng, Wanying Xu, Jian Li, Jiansong Yang",
        "summary": "Recent studies in remote sensing object detection have made excellent progress and shown promising performance. However, most current detectors only explore rotation-invariant feature extraction but disregard the valuable spatial and semantic prior knowledge in remote sensing images (RSIs), which limits the detection performance when encountering blurred or heavy occluded objects. To address this issue, we propose a mask-reconstruction relation learning (MRRL) framework to learn such prior knowledge among objects and a consistency-reasoning transformer over relation proposals (CTRP) to recognize objects with limited visual features via consistency reasoning. Specifically, MRRL framework applies random mask to some objects in the training dataset and performs masked objects reconstruction to guide the network to learn the distribution consistency of objects. CTRP is the core component of the MRRL framework, which models the interaction between spatial and semantic priors, and uses easy detected objects to reason hard detected objects. The trained CTRP can be integrated into the existing detector to improve the ability of object detection with limited visual features in RSIs. Extensive experiments on widely-used datasets for two distinct tasks, namely remote sensing object detection task and occluded object detection task, demonstrate the effectiveness of the proposed method. Source code is available at https://github.com/sunpeng96/CTRP_mmrotate.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "完成缺失实体：探索遥感物体检测的一致性推理",
        "abstract_cn": "最近在遥感目标检测方面的研究取得了巨大的进展并显示出有希望的性能。然而，当前大多数检测器仅探索旋转不变特征提取，而忽略了遥感图像（RSI）中有价值的空间和语义先验知识，这限制了遇到模糊或严重遮挡物体时的检测性能。为了解决这个问题，我们提出了一个掩模重建关系学习（MRRL）框架来学习对象之间的先验知识，并提出了一个一致性推理关系建议变换器（CTRP）来通过一致性推理来识别具有有限视觉特征的对象。具体来说，MRRL框架对训练数据集中的某些对象应用随机掩码，并进行掩码对象重建，以指导网络学习对象的分布一致性。 CTRP 是 MRRL 框架的核心组件，它对空间先验和语义先验之间的交互进行建模，并使用容易检测到的对象来推理难以检测到的对象。经过训练的 CTRP 可以集成到现有检测器中，以提高 RSI 中有限视觉特征的目标检测能力。在广泛使用的数据集上针对两个不同任务（即遥感目标检测任务和遮挡目标检测任务）进行的大量实验证明了该方法的有效性。源代码可在 https://github.com/sunpeng96/CTRP_mmrotate 获取。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3650045",
        "title": "IAP: Improving Continual Learning of Vision-Language Models via Instance-Aware Prompting",
        "link": "https://doi.org/10.1109/tip.2025.3650045",
        "published": "2026",
        "author": "Hao Fu, Hanbin Zhao, Jiahua Dong, Henghui Ding, Chao Zhang, Hui Qian",
        "summary": "pre-trained vision-language models (PT-VLMs) often face a Multi-Domain Task Incremental Learning (MTIL) scenario in practice, where several classes and domains of multi-modal tasks are incrementally arrived. Without access to previously seen tasks and unseen tasks, memory-constrained MTIL suffers from forward and backward forgetting. To alleviate the above challenges, parameter-efficient fine-tuning techniques (PEFT), such as prompt tuning, are employed to adapt the PT-VLM to the diverse incrementally learned tasks. To achieve effective new task adaptation, existing methods only consider the effect of PEFT strategy selection, but neglect the influence of PEFT parameter setting (e.g., prompting). In this paper, we tackle the challenge of optimizing prompt designs for diverse tasks in MTIL and propose an Instance-Aware Prompting (IAP) framework. Specifically, our Instance-Aware Gated Prompting (IA-GP) strategy enhances adaptation to new tasks while mitigating forgetting by adaptively assigning prompts across transformer layers at the instance level. Our Instance-Aware Class-Distribution-Driven Prompting (IA-CDDP) improves the task adaptation process by determining an accurate task-label-related confidence score for each instance. Experimental evaluations across 11 datasets, using three performance metrics, demonstrate the effectiveness of our proposed method. The source codes are available at https://github.com/FerdinandZJU/IAP.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "IAP：通过实例感知提示改进视觉语言模型的持续学习",
        "abstract_cn": "预训练视觉语言模型（PT-VLM）在实践中经常面临多域任务增量学习（MTIL）场景，其中多模态任务的多个类和域被增量地到达。由于无法访问之前见过的任务和未见过的任务，内存受限的 MTIL 会遭受前向和后向遗忘的困扰。为了缓解上述挑战，采用参数高效微调技术（PEFT）（例如即时调整）来使 PT-VLM 适应各种增量学习任务。为了实现有效的新任务适应，现有方法仅考虑PEFT策略选择的效果，而忽略了PEFT参数设置（例如提示）的影响。在本文中，我们解决了针对 MTIL 中的各种任务优化提示设计的挑战，并提出了一个实例感知提示（IAP）框架。具体来说，我们的实例感知门控提示（IA-GP）策略增强了对新任务的适应，同时通过在实例级别跨变压器层自适应地分配提示来减少遗忘。我们的实例感知类分布驱动提示 (IA-CDDP) 通过为每个实例确定准确的任务标签相关置信度分数来改进任务适应过程。使用三个性能指标对 11 个数据集进行的实验评估证明了我们提出的方法的有效性。源代码可在 https://github.com/FerdinandZJU/IAP 获取。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3648875",
        "title": "DCD-UIE: Decoupled Chromatic Diffusion Model for Underwater Image Enhancement",
        "link": "https://doi.org/10.1109/tip.2025.3648875",
        "published": "2026",
        "author": "Guodong Fan, Yu Zhou, Jingchun Zhou, Yakun Ju, Guang-Yong Chen, Jinjiang Li, Alex C. Kot",
        "summary": "Color distortion and structural degradation in underwater images are classic challenges in underwater image enhancement (UIE). The core goal is to restore degraded images to high-quality images with both color and structure that conform to visual perception. However, in the traditional RGB space, these two issues are highly coupled, resulting in existing enhancement methods often neglecting one over the other. To address this challenge, we propose a guided diffusion model based on the principle of decoupling. Our key insight is that in perceptual color spaces such as HSV, color (H, S) and structure (V) are naturally separated. To exploit this property, we first design an adaptive perceptual guidance module (APGM), which analyzes the degraded HSV image and generates two orthogonal guidance signals: a color guide and a structure guide, which guide the denoising process of the diffusion model. To ensure that this decoupled guidance is faithfully implemented, we propose a corresponding decoupled loss optimization module, which uses independent loss functions to supervise the final output color and structure. By combining the forward decoupled guidance with the backward decoupled supervision, we construct a closed-loop optimization framework. This framework enables the model to collaboratively optimize color and structure under various degradation scenarios. Extensive experiments demonstrate that our proposed method outperforms existing state-of-the-art approaches in a variety of underwater scenes, particularly those degraded by color casts and haze. Furthermore, it exhibits superior performance on no-reference image quality assessment metrics. The source code is available at https://github.com/zy-world/DCD-UIE.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "DCD-UIE：用于水下图像增强的解耦色扩散模型",
        "abstract_cn": "水下图像的颜色失真和结构退化是水下图像增强（UIE）的典型挑战。核心目标是将退化图像恢复为颜色和结构符合视觉感知的高质量图像。然而，在传统的RGB空间中，这两个问题是高度耦合的，导致现有的增强方法往往忽略其中一个。为了应对这一挑战，我们提出了一种基于解耦原理的引导扩散模型。我们的主要见解是，在 HSV 等感知色彩空间中，颜色（H、S）和结构（V）自然分离。为了利用这一特性，我们首先设计了一个自适应感知引导模块（APGM），它分析退化的 HSV 图像并生成两个正交引导信号：颜色引导和结构引导，用于指导扩散模型的去噪过程。为了确保这种解耦指导得到忠实执行，我们提出了相应的解耦损失优化模块，该模块使用独立的损失函数来监督最终输出的颜色和结构。通过将前向解耦指导与后向解耦监督相结合，我们构建了闭环优化框架。该框架使模型能够在各种退化场景下协同优化颜色和结构。大量的实验表明，我们提出的方法在各种水下场景中都优于现有的最先进的方法，特别是那些因色偏和雾霾而退化的场景。此外，它在无参考图像质量评估指标上表现出卓越的性能。源代码可在 https://github.com/zy-world/DCD-UIE 获取。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3650387",
        "title": "TSCCD: Temporal Self-Construction Cross Domain Learning for Unsupervised Hyperspectral Change Detection",
        "link": "https://doi.org/10.1109/tip.2025.3650387",
        "published": "2026",
        "author": "Tianyuan Zhou, Fulin Luo, Chuan Fu, Tan Guo, Bo Du, Xinbo Gao, Liangpei Zhang",
        "summary": "Multi-temporal hyperspectral imagery (HSI) has become a powerful tool for change detection (CD) owing to its rich spectral signatures and detailed spatial information. Nevertheless, the application of paired HSIs is constrained by the scarcity of annotated training data. While unsupervised domain adaptation (UDA) offers a potential solution by transferring change detection knowledge from source to target domains, two critical limitations persist: (1) the labor-intensive process of acquiring and annotating source-domain paired samples, and (2) the suboptimal transfer performance caused by substantial cross-domain distribution discrepancies. To address these challenges, we present a Temporal Self-Construction Cross-Domain learning (TSCCD) framework for UDA-based HSI-CD. Our TSCCD framework introduces an innovative temporal self-construction mechanism that synthesizes bi-temporal source-domain data from existing HSI classification datasets while simultaneously performing initial data-level alignment. Furthermore, we develop a reweighted amplitude maximum mean discrepancy (MMD) metric to enhance feature-level domain adaptation. The proposed architecture incorporates an attention-based Kolmogorov-Arnold network (KAN) with high-frequency feature augmentation within an encoder-decoder structure to effectively capture change characteristics. Comprehensive experiments conducted on three benchmark HSI datasets demonstrate that TSCCD achieves superior performance compared to current state-of-the-art methods in HSI change detection tasks. Codes are available at https://github.com/Zhoutya/TSCCD.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "TSCCD：用于无监督高光谱变化检测的时间自构建跨域学习",
        "abstract_cn": "多时相高光谱图像（HSI）因其丰富的光谱特征和详细的空间信息而成为变化检测（CD）的强大工具。然而，配对 HSI 的应用受到注释训练数据稀缺的限制。虽然无监督域适应（UDA）通过将变化检测知识从源域转移到目标域提供了潜在的解决方案，但仍然存在两个关键限制：（1）获取和注释源域配对样本的劳动密集型过程，以及（2）由于大量跨域分布差异而导致传输性能不佳。为了应对这些挑战，我们提出了一个基于 UDA 的 HSI-CD 的时间自构建跨域学习 (TSCCD) 框架。我们的 TSCCD 框架引入了一种创新的时间自构造机制，该机制可以从现有 HSI 分类数据集中合成双时间源域数据，同时执行初始数据级别对齐。此外，我们开发了重新加权的幅度最大平均差异（MMD）度量来增强特征级域适应。所提出的架构将基于注意力的柯尔莫哥洛夫-阿诺德网络（KAN）与编码器-解码器结构中的高频特征增强相结合，以有效捕获变化特征。在三个基准 HSI 数据集上进行的综合实验表明，与当前 HSI 变化检测任务中最先进的方法相比，TSCCD 实现了卓越的性能。代码可在 https://github.com/Zhoutya/TSCCD 获取。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3648138",
        "title": "Information-Maximized Soft Variable Discretization for Self-Supervised Image Representation Learning",
        "link": "https://doi.org/10.1109/tip.2025.3648138",
        "published": "2026",
        "author": "Chuang Niu, Wenjun Xia, Hongming Shan, Ge Wang",
        "summary": "Self-supervised learning (SSL) has emerged as a crucial technique in image processing, encoding, and understanding, especially for developing today’s vision foundation models that utilize large-scale datasets without annotations to enhance various downstream tasks. This study introduces a novel SSL approach, Information-Maximized Soft Variable Discretization (IMSVD), for image representation learning. Specifically, IMSVD softly discretizes each variable in the latent space, enabling the estimation of their probability distributions over training batches and allowing the learning process to be directly guided by information measures. Motivated by the MultiView assumption, we propose an information-theoretic objective function to learn transform-invariant, non-trivial, and redundancy-minimized representation features. We then derive a joint-cross entropy loss function for self-supervised image representation learning, which theoretically enjoys superiority over the existing methods in reducing feature redundancy. Notably, our non-contrastive IMSVD method statistically performs contrastive learning. Extensive experimental results demonstrate the effectiveness of IMSVD on various downstream tasks in terms of both accuracy and efficiency. Thanks to our variable discretization, the embedding features optimized by IMSVD offer unique explainability at the variable level. IMSVD has the potential to be adapted to other learning paradigms. Our code is publicly available at https://github.com/niuchuangnn/IMSVD.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "用于自监督图像表示学习的信息最大化软变量离散化",
        "abstract_cn": "自监督学习 (SSL) 已成为图像处理、编码和理解领域的一项关键技术，特别是对于开发当今的视觉基础模型而言，这些模型利用无注释的大规模数据集来增强各种下游任务。本研究介绍了一种用于图像表示学习的新型 SSL 方法，即信息最大化软变量离散化 (IMSVD)。具体来说，IMSVD 软离散化潜在空间中的每个变量，从而能够估计它们在训练批次上的概率分布，并允许学习过程直接由信息测量指导。受多视图假设的启发，我们提出了一种信息论目标函数来学习变换不变、非平凡和冗余最小化的表示特征。然后，我们推导了用于自监督图像表示学习的联合交叉熵损失函数，理论上它在减少特征冗余方面比现有方法具有优越性。值得注意的是，我们的非对比 IMSVD 方法在统计上执行对比学习。大量的实验结果证明了 IMSVD 在各种下游任务上的准确性和效率方面的有效性。由于我们的变量离散化，IMSVD 优化的嵌入特征在变量级别提供了独特的可解释性。 IMSVD 有潜力适应其他学习范式。我们的代码可在 https://github.com/niuchuannn/IMSVD 上公开获取。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3648200",
        "title": "COME: A Collaborative Optimization Framework with Low-rank MoE for Indoor 3D Object Detection",
        "link": "https://doi.org/10.1109/tip.2025.3648200",
        "published": "2026",
        "author": "Hongbo Gao, Zimeng Tong, Fuyuan Qiu, Tao Xie, Ruifeng Li, Lijun Zhao",
        "summary": "Indoor 3D object detection serves as a fundamental task in computer vision and robotics. Existing research predominantly focuses on training domain-specific optimal models for individual datasets, yet it overlooks the potential value of capturing universal geometric attributes that can substantially enhance object detection performance across diverse domains. To resolve this gap, we propose COME, a novel and effective collaborative optimization framework designed to seamlessly integrate these universal attributes while preserving the domain-specific characteristics of each dataset domain. COME is built on VoteNet and incorporates a Cross-Domain Expert Parameter Sharing Strategy (CEPSS) that draws inspiration from the Mixture of Experts (MoE) framework. Its core innovation resides in the dual-expert design of CEPSS: domain-shared experts capture universal geometric relationships across datasets, whereas domain-specific experts encode unique features for individual datasets. This separation enables the model to focus on learning both generic and domain-specialized visual cues, without mutual interference. In addition, to dynamically adapt to different domains, we design a lightweight gating network that automatically selects relevant experts, eliminating irrelevant feature interference and enhancing model specialization. Compared to standard parameter-sharing architectures, this design significantly reduces gradient conflicts during multi-domain training. We further optimize computational efficiency by implementing low-rank structures for domain-shared and domain-specific experts, thus striking a better balance between memory overhead and detection performance. Experiments show that COME achieves state-of-the-art results across benchmarks, with acceptable parameter growth, and outperforms existing multi-domain detection methods.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "COME：用于室内 3D 物体检测的低秩 MoE 协作优化框架",
        "abstract_cn": "室内 3D 物体检测是计算机视觉和机器人技术的一项基本任务。现有的研究主要集中于训练单个数据集的特定领域的最佳模型，但它忽视了捕获通用几何属性的潜在价值，这些属性可以显着增强跨不同领域的对象检测性能。为了解决这一差距，我们提出了 COME，一种新颖且有效的协作优化框架，旨在无缝集成这些通用属性，同时保留每个数据集域的特定领域特征。 COME 基于 VoteNet 构建，并结合了跨域专家参数共享策略 (CEPSS)，该策略从专家混合 (MoE) 框架中汲取灵感。其核心创新在于CEPSS的双专家设计：领域共享专家捕获跨数据集的通用几何关系，而领域特定专家则为各个数据集编码独特的特征。这种分离使模型能够专注于学习通用和特定领域的视觉线索，而不会相互干扰。此外，为了动态适应不同领域，我们设计了一个轻量级门网络，自动选择相关专家，消除不相关的特征干扰并增强模型专业化。与标准参数共享架构相比，这种设计显着减少了多域训练期间的梯度冲突。我们通过为域共享和特定域专家实现低秩结构来进一步优化计算效率，从而在内存开销和检测性能之间取得更好的平衡。实验表明，COME 在各个基准测试中实现了最先进的结果，具有可接受的参数增长，并且优于现有的多域检测方法。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3649364",
        "title": "Revisiting Fine-grained Image Analysis by Semantic-Part Alignment",
        "link": "https://doi.org/10.1109/tip.2025.3649364",
        "published": "2026",
        "author": "Qi Bi, Jingjun Yi, Haolan Zhan, Wei Ji, Gui-Song Xia",
        "summary": "Fine-grained image analysis is widely recognized as highly challenging, since distinguishing individual differences within a certain category, species, or type often depends on tiny, subtle patterns. However, learning fine-grained semantic categories from these subtle part patterns is inherently fragile, as they can easily be overwhelmed by the dominant patterns resting in the coarse-category information. Therefore, how to enhance the relation between the fine-grained semantics and these subtle patterns is the key. To push this frontier, a novel semantic-part alignment (SPA) learning scheme is proposed in this paper. Its general idea is to firstly measure the relevance of each part to the fine-grained semantics, and then regularize the fine-grained visual representation learning. Specifically, it consists of three key components, namely, joint semantic-part modeling, semantic-part set modeling, and optimal semantic-part transport. The joint semantic-part modeling associates each part in an image with the fine-grained semantics in a latent space. Then, the optimal semantic-part transport component is devised to enhance the relation between fine-grained semantic embeddings and the discriminative part embeddings. Notably, the proposed SPA is plug-in-and-play, easy-to-implement, and insensitive to the latent embedding dimension and loss weight. Experiments show the proposed method can substantially boost performance on multiple fine-grained image analysis tasks across various baselines.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "通过语义部分对齐重新审视细粒度图像分析",
        "abstract_cn": "细粒度图像分析被广泛认为是极具挑战性的，因为区分特定类别、物种或类型内的个体差异通常取决于微小、微妙的模式。然而，从这些微妙的部分模式中学习细粒度的语义类别本质上是脆弱的，因为它们很容易被粗类别信息中的主导模式所淹没。因此，如何增强细粒度语义与这些微妙模式之间的关系是关键。为了推动这一前沿，本文提出了一种新颖的语义部分对齐（SPA）学习方案。其总体思路是首先衡量各个部分与细粒度语义的相关性，然后对细粒度视觉表示学习进行正则化。具体来说，它由三个关键组成部分组成，即联合语义部分建模、语义部分集合建模和最优语义部分传输。联合语义部分建模将图像中的每个部分与潜在空间中的细粒度语义相关联。然后，设计最佳语义部分传输组件来增强细粒度语义嵌入和判别部分嵌入之间的关系。值得注意的是，所提出的 SPA 是即插即用的，易于实施，并且对潜在嵌入尺寸和损失重量不敏感。实验表明，所提出的方法可以显着提高跨各种基线的多个细粒度图像分析任务的性能。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3651959",
        "title": "BELE: Blur Equivalent Linearized Estimator",
        "link": "https://doi.org/10.1109/tip.2026.3651959",
        "published": "2026",
        "author": "Paolo Giannitrapani, Elio D. Di Claudio, Giovanni Jacovitti",
        "summary": "In Full-Reference Image Quality Assessment (FR-IQA), subjective Mean Opinion Scores (MOS) reflect human retinal perception, whereas objective metrics operate on the displayed image. Bridging these domains requires parametric mappings that are sensitive to viewing distance. This paper introduces Blur-Equivalent Linearized Estimator (BELE), a lightweight and perceptually interpretable FR-IQA model that disentangles the impact of strong edge degradations from that of texture distortions. BELE computes two indices: a blur index derived from a linearized estimator of Positional Fisher Information loss on strong edges, explicitly accounting for viewing distance; and a texture index based on a Complex Peak Signal-to-Noise Ratio (CPSNR) that captures distortions affecting fine spatial details in textured regions. All distortion estimates are combined via low-order polynomial fitting, with a focalization term applied in this final stage to replace the VQEG rectification, thereby eliminating its limitations such as overfitting and lack of interpretability. BELE is entirely training-free, requiring only five interpretable parameters, and achieves very low computational complexity. Extensive experiments on six benchmark datasets demonstrate that BELE attains competitive or superior correlation with MOS compared to both classical and deep learning-based FR-IQA methods, while offering strong generalization, real-time feasibility, and minimal resource demands.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "BELE：模糊等效线性化估计器",
        "abstract_cn": "在全参考图像质量评估 (FR-IQA) 中，主观平均意见分数 (MOS) 反映人类视网膜感知，而客观指标则对显示的图像进行操作。桥接这些域需要对观看距离敏感的参数映射。本文介绍了模糊等效线性估计器 (BELE)，这是一种轻量级且可感知解释的 FR-IQA 模型，可将强烈边缘退化的影响与纹理扭曲的影响区分开来。 BELE 计算两个指数：模糊指数，源自强边缘位置费舍尔信息损失的线性估计器，明确考虑了观看距离；以及基于复杂峰值信噪比 (CPSNR) 的纹理索引，可捕获影响纹理区域中精细空间细节的失真。所有失真估计均通过低阶多项式拟合进行组合，并在最后阶段应用聚焦项来取代 VQEG 校正，从而消除其过度拟合和缺乏可解释性等局限性。 BELE 完全无需训练，只需要五个可解释的参数，并且计算复杂度非常低。对六个基准数据集的大量实验表明，与经典和基于深度学习的 FR-IQA 方法相比，BELE 与 MOS 具有竞争性或优越的相关性，同时提供强大的泛化性、实时可行性和最小的资源需求。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3651985",
        "title": "Diagnosing and Improving Vector-Quantization Based Blind Image Restoration",
        "link": "https://doi.org/10.1109/tip.2026.3651985",
        "published": "2026",
        "author": "Hongyu Li, Zengyou Wang, Tianyi Xu, Xiantong Zhen, Ran Gu, David Zhang, Jun Xu",
        "summary": "Vector-Quantization (VQ) based discrete generative models are widely used to learn powerful high-quality (HQ) priors for blind image restoration (BIR). In this paper, we diagnose the side-effects of discrete VQ process essential to VQ-based BIR methods: 1) confining the representation capacity of HQ codebook, 2) being error-prone for code index prediction on low-quality (LQ) images, and 3) under-valuing the importance of input LQ image. These motivate us to learn continuous feature representation of HQ codebook for better restoration performance than using discrete VQ process. To further improve the restoration fidelity, we propose a new Self-in-Cross-Attention (SinCA) module to augment the HQ codebook with the feature of input LQ image, and perform cross-attention between LQ feature and input-augmented codebook. By this way, our SinCA leverages the input LQ image to enhance the representation of codebook for restoration fidelity. Experiments on four typical VQ-based BIR methods demonstrate that, by replacing the VQ process with a transformer using our SinCA, they achieve better quantitative and qualitative performance on blind image super-resolution and blind face restoration. The code and pre-trained models will be publicly released.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "基于矢量量化的盲图像恢复的诊断和改进",
        "abstract_cn": "基于矢量量化 (VQ) 的离散生成模型被广泛用于学习盲图像恢复 (BIR) 的强大高质量 (HQ) 先验。在本文中，我们诊断了基于 VQ 的 BIR 方法所必需的离散 VQ 过程的副作用：1）限制了 HQ 码本的表示能力，2）对低质量（LQ）图像的代码索引预测容易出错，3）低估了输入 LQ 图像的重要性。这些促使我们学习 HQ 码本的连续特征表示，以获得比使用离散 VQ 过程更好的恢复性能。为了进一步提高恢复保真度，我们提出了一种新的自交叉注意（SinCA）模块，用输入LQ图像的特征来增强HQ码本，并在LQ特征和输入增强码本之间执行交叉注意。通过这种方式，我们的 SinCA 利用输入的 LQ 图像来增强码本的表示，以实现恢复保真度。对四种典型的基于 VQ 的 BIR 方法的实验表明，通过使用我们的 SinCA 用变压器替换 VQ 过程，它们在盲图像超分辨率和盲人脸恢复方面取得了更好的定量和定性性能。代码和预训练模型将公开发布。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3651950",
        "title": "COSOS-1k: A Benchmark Dataset and Occlusion-aware Uncertainty Learning for Multi-view Video Object Detection",
        "link": "https://doi.org/10.1109/tip.2026.3651950",
        "published": "2026",
        "author": "Wenjie Yang, Yueying Kao, Tong Liu, Yuanlong Yu, Kaiqi Huang",
        "summary": "Confined spaces refer to partially or fully enclosed areas, e.g., sewage wells, where working conditions pose significant risks to the workers. The evaluation of COfined Space Operational Safety (COSOS) refers to verifying whether workers are properly equipped with safety equipment before entering a confined space, which is crucial for protecting their safety and health. Due to the crowded nature of such environments and the small size of certain safety equipment, existing methods face significant challenges. Moreover, there is a lack of dedicated datasets to support research in this domain. In this paper, in order to advance research in this challenging task, we present COSOS-1k, an extensive dataset constructed from diverse confined space scenarios. It comprises multi-view videos for each scenario, covers 10 essential safety protective equipments and 6 attributes of worker, and is annotated with expressive object locations, fine-grained attributes, and occlusion status. The COSOS-1k is the first dataset known to date, tailored explicitly for the real-world COSOS scenarios. In addition, we address the challenge of occlusion from three perspectives: instance, video, and view. Firstly, at the instance level, we propose Occlusion-aware Uncertainty Estimation (OUE) method, which leverages box-level occlusion annotations to enable part-level occlusion prediction for objects. Secondly, at the video level, we introduce Cross-Frame Cluster (CFC) attention, which integrates temporal context features from the same object category to mitigate the impact of occlusions in the current frame. Finally, we extend CFC to the view level and form Cross-View Cluster (CVC) attention, where complementary information is mined from another view. Extensive experiments demonstrate the effectiveness of the proposed methods and provide insights into the importance of dataset diversity and expressivity. The COSOS-1k dataset and code are available at https://github.com/deepalchemist/cosos-1k.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "COSOS-1k：用于多视图视频对象检测的基准数据集和遮挡感知不确定性学习",
        "abstract_cn": "密闭空间是指部分或完全封闭的区域，例如污水井，这些区域的工作条件对工人构成重大风险。有限空间操作安全（COSOS）评估是指验证工作人员在进入密闭空间之前是否配备了适当的安全设备，这对于保护他们的安全和健康至关重要。由于此类环境的拥挤性质和某些安全设备的尺寸较小，现有方法面临着重大挑战。此外，缺乏专门的数据集来支持该领域的研究。在本文中，为了推进这项具有挑战性的任务的研究，我们提出了 COSOS-1k，这是一个根据不同的有限空间场景构建的广泛数据集。它由每个场景的多视图视频组成，涵盖了10种基本安全防护设备和工人的6个属性，并标注了富有表现力的物体位置、细粒度属性和遮挡状态。 COSOS-1k 是迄今为止已知的第一个数据集，专为现实世界的 COSOS 场景量身定制。此外，我们从实例、视频和视图三个角度解决遮挡的挑战。首先，在实例级别，我们提出了遮挡感知不确定性估计（OUE）方法，该方法利用框级遮挡注释来实现对象的部分级遮挡预测。其次，在视频层面，我们引入了跨帧聚类（CFC）注意力，它集成了来自同一对象类别的时间上下文特征，以减轻当前帧中遮挡的影响。最后，我们将 CFC 扩展到视图级别并形成跨视图集群（CVC）注意力，其中从另一个视图挖掘补充信息。大量的实验证明了所提出方法的有效性，并提供了对数据集多样性和表现力重要性的见解。 COSOS-1k 数据集和代码可从 https://github.com/deepalchemist/cosos-1k 获取。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3651963",
        "title": "Blind Inversion using Latent Diffusion Priors",
        "link": "https://doi.org/10.1109/tip.2026.3651963",
        "published": "2026",
        "author": "Weimin Bai, Siyi Chen, Wenzheng Chen, He Sun",
        "summary": "Diffusion models have emerged as powerful tools for solving inverse problems due to their exceptional ability to model complex prior distributions. However, existing methods predominantly assume known forward operators (<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">i.e.</i>, non-blind), limiting their applicability in practical settings where acquiring such operators is costly. Additionally, many current approaches rely on pixel-space diffusion models, leaving the potential of more powerful latent diffusion models (LDMs) underexplored. In this paper, we introduce LatentDEM, an innovative technique that addresses more challenging blind inverse problems using latent diffusion priors. At the core of our method is solving blind inverse problems within an iterative Expectation-Maximization (EM) framework: (1) the E-step recovers clean images from corrupted observations using LDM priors and a known forward model, and (2) the M-step estimates the forward operator based on the recovered images. Additionally, we propose two novel optimization techniques tailored for LDM priors and EM frameworks, yielding more accurate and efficient blind inversion results. As a general framework, LatentDEM supports both linear and non-linear inverse problems. Beyond common 2D image restoration tasks, it enables new capabilities in non-linear 3D inverse rendering problems. We validate LatentDEM’s performance on representative 2D blind deblurring and 3D pose-free sparse-view reconstruction tasks, demonstrating its superior efficacy over prior arts. The project page can be found at https://ai4imaging.github.io/latentdem/.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "使用潜在扩散先验的盲反演",
        "abstract_cn": "扩散模型因其对复杂先验分布建模的卓越能力而成为解决反问题的强大工具。然而，现有方法主要假设已知的前向算子（<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">即</i>，非盲），限制了它们在获取此类算子成本高昂的实际环境中的适用性。此外，当前的许多方法都依赖于像素空间扩散模型，而更强大的潜在扩散模型（LDM）的潜力尚未得到充分开发。在本文中，我们介绍了 LatentDEM，这是一种利用潜在扩散先验解决更具挑战性的盲逆问题的创新技术。我们方法的核心是在迭代期望最大化 (EM) 框架内解决盲逆问题：(1) E 步使用 LDM 先验和已知的前向模型从损坏的观测中恢复干净的图像，(2) M 步根据恢复的图像估计前向算子。此外，我们提出了两种针对 LDM 先验和 EM 框架量身定制的新颖优化技术，产生更准确、更高效的盲反演结果。作为通用框架，LatentDEM 支持线性和非线性反问题。除了常见的 2D 图像恢复任务之外，它还支持解决非线性 3D 逆渲染问题的新功能。我们验证了 LatentDEM 在代表性 2D 盲去模糊和 3D 无姿态稀疏视图重建任务上的性能，证明了其优于现有技术的功效。项目页面可以在 https://ai4imaging.github.io/latentdem/ 找到。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3651981",
        "title": "Automated Orthognathic Surgery Planning based on Shape-Aware Morphology Prediction and Anatomy-Constrained Registration",
        "link": "https://doi.org/10.1109/tip.2026.3651981",
        "published": "2026",
        "author": "Yan Guo, Chenyao Li, Haitao Li, Weiwen Ge, Bolun Zeng, Jiaxuan Liu, Tianhao Wan, Shanyong Zhang, Xiaojun Chen",
        "summary": "Orthognathic surgery demands precise preoperative planning to achieve optimal functional and aesthetic results, yet current practices remain labor-intensive and highly dependent on surgical expertise. To address these challenge, we propose OrthoPlanner, a novel two-stage framework for automated orthognathic surgical planning. In the first stage, we develop JawFormer, a shape sensitive transformer network that predicts postoperative bone morphology directly from preoperative 3D point cloud data. Built upon a point cloud encoder-decoder architecture, the network integrates anatomical priors through a region-based feature alignment module. This enables precise modeling of structural changes while preserving critical anatomical features. In the second stage, we introduce a symmetry-constrained rigid alignment algorithm that automatically outputs the precise translation and rotation of each osteotomized bone segment required to match the predicted morphology. This ensures bilateral anatomical consistency and facilitates interpretable surgical plans. Compared with existing approaches, our method achieves superior quantitative performance and enhanced visualization results, as demonstrated by 65 experiments on real clinical datasets. Moreover, OrthoPlanner significantly reduces planning time and manual workload, while ensuring reproducible and clinically acceptable outcomes.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "基于形状感知形态预测和解剖约束配准的自动化正颌手术规划",
        "abstract_cn": "正颌手术需要精确的术前计划，以实现最佳的功能和美观效果，但目前的实践仍然是劳动密集型的，并且高度依赖于手术专业知识。为了应对这些挑战，我们提出了 OrthoPlanner，这是一种用于自动化正颌手术规划的新型两阶段框架。在第一阶段，我们开发了 JawFormer，这是一种形状敏感的变压器网络，可以直接根据术前 3D 点云数据预测术后骨形态。该网络建立在点云编码器-解码器架构之上，通过基于区域的特征对齐模块集成解剖先验。这使得能够对结构变化进行精确建模，同时保留关键的解剖特征。在第二阶段，我们引入了一种对称约束的刚性对齐算法，该算法自动输出匹配预测形态所需的每个截骨骨段的精确平移和旋转。这确保了双侧解剖结构的一致性并有利于可解释的手术计划。与现有方法相比，我们的方法实现了卓越的定量性能和增强的可视化结果，如在真实临床数据集上的 65 个实验所证明的那样。此外，OrthoPlanner 显着减少了规划时间和手动工作量，同时确保结果可重复且临床可接受。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3652014",
        "title": "Multi-Stage Knowledge Integration of Vision-Language Models for Continual Learning",
        "link": "https://doi.org/10.1109/tip.2026.3652014",
        "published": "2026",
        "author": "Hongsheng Zhang, Zhong Ji, Jingren Liu, Yanwei Pang, Jungong Han",
        "summary": "Vision Language Models (VLMs), pre-trained on large-scale image-text datasets, enable zero-shot predictions for unseen data but may underperform on specific unseen tasks. Continual learning (CL) can help VLMs effectively adapt to new data distributions without joint training, but faces challenges of catastrophic forgetting and generalization forgetting. Although significant progress has been achieved by distillation-based methods, they exhibit two severe limitations. One is the popularly adopted single-teacher paradigm fails to impart comprehensive knowledge, The other is the existing methods inadequately leverage the multimodal information in the original training dataset, instead they rely on additional data for distillation, which increases computational and storage overhead. To mitigate both limitations, by drawing on Knowledge Integration Theory (KIT), we propose a Multi-Stage Knowledge Integration network (MulKI) to emulate the human learning process in distillation methods. MulKI achieves this through four stages, including Eliciting Ideas, Adding New Ideas, Distinguishing Ideas, and Making Connections. During the four stages, we first leverage prototypes to align across modalities, eliciting cross-modal knowledge, then adding new knowledge by constructing fine-grained intra- and inter-modality relationships with prototypes. After that, knowledge from two teacher models is adaptively distinguished and re-weighted. Finally, we connect between models from intra- and inter-task, integrating preceding and new knowledge. Our method demonstrates significant improvements in maintaining zero-shot capabilities while supporting continual learning across diverse downstream tasks, showcasing its potential in adapting VLMs to evolving data distributions.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "用于持续学习的视觉语言模型的多阶段知识整合",
        "abstract_cn": "在大规模图像文本数据集上进行预训练的视觉语言模型 (VLM) 可以对看不见的数据进行零样本预测，但在特定的看不见的任务上可能表现不佳。持续学习（CL）可以帮助VLM在无需联合训练的情况下有效适应新的数据分布，但面临灾难性遗忘和泛化遗忘的挑战。尽管基于蒸馏的方法已经取得了重大进展，但它们表现出两个严重的局限性。一是普遍采用的单教师范式无法传授全面的知识，二是现有方法不能充分利用原始训练数据集中的多模态信息，而是依赖额外的数据进行蒸馏，这增加了计算和存储开销。为了缓解这两个限制，通过利用知识集成理论（KIT），我们提出了多阶段知识集成网络（MulKI）来模拟蒸馏方法中的人类学习过程。 MulKI 通过四个阶段实现这一目标，包括引发想法、添加新想法、区分想法和建立联系。在这四个阶段中，我们首先利用原型来协调跨模态，引出跨模态知识，然后通过与原型构建细粒度的模态内和模间关系来添加新知识。之后，来自两个教师模型的知识被自适应地区分并重新加权。最后，我们连接任务内和任务间的模型，整合先前的知识和新的知识。我们的方法展示了在维持零样本能力方面的显着改进，同时支持跨不同下游任务的持续学习，展示了其在使 VLM 适应不断变化的数据分布方面的潜力。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3651956",
        "title": "Progressive Feature Encoding with Background Perturbation Learning for Ultra-Fine-Grained Visual Categorization",
        "link": "https://doi.org/10.1109/tip.2026.3651956",
        "published": "2026",
        "author": "Xin Jiang, Ziye Fang, Fei Shen, Junyao Gao, Zechao Li",
        "summary": "Ultra-Fine-Grained Visual Categorization (Ultra-FGVC) aims to classify objects into sub-granular categories, presenting the challenge of distinguishing visually similar objects with limited data. Existing methods primarily address sample scarcity but often overlook the importance of leveraging intrinsic object features to construct highly discriminative representations. This limitation significantly constrains their effectiveness in Ultra-FGVC tasks. To address these challenges, we propose SV-Transformer that progressively encodes object features while incorporating background perturbation modeling to generate robust and discriminative representations. At the core of our approach is a progressive feature encoder, which hierarchically extracts global semantic structures and local discriminative details from backbone-generated representations. This design enhances inter-class separability while ensuring resilience to intra-class variations. Furthermore, our background perturbation learning mechanism introduces controlled variations in the feature space, effectively mitigating the impact of sample limitations and improving the model's capacity to capture fine-grained distinctions. Comprehensive experiments demonstrate that SV-Transformer achieves state-of-the-art performance on benchmark Ultra-FGVC datasets, showcasing its efficacy in addressing the challenges of Ultra-FGVC task.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "具有背景扰动学习的渐进特征编码，用于超细粒度视觉分类",
        "abstract_cn": "超细粒度视觉分类（Ultra-FGVC）旨在将对象分类为亚粒度类别，这提出了用有限数据区分视觉相似对象的挑战。现有方法主要解决样本稀缺问题，但往往忽视利用内在对象特征来构建高度辨别性表示的重要性。这一限制极大地限制了它们在 Ultra-FGVC 任务中的有效性。为了应对这些挑战，我们提出了 SV-Transformer，它可以逐步编码对象特征，同时结合背景扰动模型来生成鲁棒且有辨别力的表示。我们方法的核心是渐进式特征编码器，它从骨干生成的表示中分层提取全局语义结构和局部判别性细节。这种设计增强了类间可分离性，同时确保了对类内变化的弹性。此外，我们的背景扰动学习机制引入了特征空间中的受控变化，有效减轻了样本限制的影响，并提高了模型捕捉细粒度差异的能力。综合实验表明，SV-Transformer 在基准 Ultra-FGVC 数据集上实现了最先进的性能，展示了其在解决 Ultra-FGVC 任务挑战方面的功效。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3651835",
        "title": "SAMURAI: Motion-Aware Memory for Training-Free Visual Object Tracking with SAM 2",
        "link": "https://doi.org/10.1109/tip.2026.3651835",
        "published": "2026",
        "author": "Cheng-Yeng Yang, Hsiang-Wei Huang, Zhongyu Jiang, Wenhao Chai, Jenq-Neng Hwang",
        "summary": "The Segment Anything Model 2 (SAM 2) has demonstrated exceptional performance in object segmentation tasks but encounters challenges in visual object tracking, particularly in handling crowded scenes with fast-moving or self-occluding objects. Additionally, its fixed-window memory mechanism indiscriminately retains past frames, leading to error accumulation. This issue results in incorrect memory retention during occlusions, causing the model to condition future predictions on unreliable features and leading to identity switches or drift in crowded scenes. This paper introduces SAMURAI, an enhanced adaptation of SAM 2 that integrates temporal motion cues with a novel motion-aware memory selection strategy. SAMURAI effectively predicts object motion and refines mask selection, achieving robust and precise tracking without requiring retraining or fine-tuning. It demonstrates strong training-free performance across multiple VOT benchmark datasets, underscoring its generalization capability. SAMURAI achieves state-of-the-art performance on LaSOText, GOT-10k, and TrackingNet, while also delivering competitive results on LaSOT, VOT2020-ST, VOT2022-ST, and VOS benchmarks such as SA-V. These results highlight SAMURAI's robustness in complex tracking scenarios and its potential for real-world applications in dynamic environments with an optimized memory selection mechanism. Code and results are available at https://github.com/yangchris11/samurai.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "SAMURAI：使用 SAM 2 进行免训练视觉对象跟踪的运动感知内存",
        "abstract_cn": "Segment Anything Model 2 (SAM 2) 在对象分割任务中表现出了卓越的性能，但在视觉对象跟踪方面遇到了挑战，特别是在处理具有快速移动或自遮挡对象的拥挤场景时。此外，其固定窗口内存机制不加区别地保留过去的帧，导致错误累积。此问题会导致遮挡期间的内存保留不正确，从而导致模型根据不可靠的特征来调整未来的预测，并导致拥挤场景中的身份切换或漂移。本文介绍了 SAMURAI，它是 SAM 2 的增强版，它将时间运动线索与新颖的运动感知内存选择策略集成在一起。 SAMURAI 有效预测物体运动并优化掩模选择，无需重新训练或微调即可实现稳健且精确的跟踪。它在多个 VOT 基准数据集上展示了强大的免训练性能，强调了其泛化能力。 SAMURAI 在 LaSOText、GOT-10k 和 TrackingNet 上实现了最先进的性能，同时还在 LaSOT、VOT2020-ST、VOT2022-ST 和 VOS 基准（例如 SA-V）上提供了具有竞争力的结果。这些结果凸显了 SAMURAI 在复杂跟踪场景中的稳健性，以及其在动态环境中通过优化的内存选择机制在实际应用中的潜力。代码和结果可在 https://github.com/yangchris11/samurai 获取。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3652021",
        "title": "Self-Supervised Unfolding Network with Shared Reflectance Learning for Low-Light Image Enhancement",
        "link": "https://doi.org/10.1109/tip.2026.3652021",
        "published": "2026",
        "author": "Jia Liu, Yu Luo, Guanghui Yue, Jie Ling, Liang Liao, Chia-Wen Lin, Guangtao Zhai, Wei Zhou",
        "summary": "Recently, incorporating Retinex theory with unfolding networks has attracted increasing attention in the low-light image enhancement field. However, existing methods have two limitations, i.e., ignoring the modeling of the physical prior of Retinex theory and relying on a large amount of paired data. To advance this field, we propose a novel self-supervised unfolding network, named S2UNet, for the LIE task. Specifically, we formulate a novel optimization model based on the principle that content-consistent images under different illumination should share the same reflectance. The model simultaneously decomposes two illumination-different images into a shared reflectance component and two independent illumination components. Due to the absence of the normal-light image, we process the low-light image with gamma correction to create the illumination-different image pair. Then, we translate this model into a multi-stage unfolding network, in which each stage alternately optimizes the shared reflectance component and the respective illumination components of the two images. During progressive multi-stage optimization, the network inherently encodes the reflectance consistency prior by jointly estimating an optimal reflectance across varying illumination conditions. Finally, considering the presence of noise in low-light images and to suppress noise amplification, we propose a self-supervised denoising mechanism. Extensive experiments on nine benchmark datasets demonstrate that our proposed S2UNet outperforms state-of-the-art unsupervised methods in terms of both quantitative metrics and visual quality, while achieving competitive performance compared to supervised methods. The source code will be available at https: //github.com/J-Liu-DL/S2UNet.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "用于低光图像增强的具有共享反射率学习的自监督展开网络",
        "abstract_cn": "近年来，将Retinex理论与展开网络相结合在弱光图像增强领域引起了越来越多的关注。然而，现有方法有两个局限性，即忽略了Retinex理论物理先验的建模以及依赖大量的配对数据。为了推进这一领域的发展，我们针对 LIE 任务提出了一种新颖的自监督展开网络，名为 S2UNet。具体来说，我们基于不同光照下内容一致的图像应具有相同反射率的原则，制定了一种新颖的优化模型。该模型同时将两个照明不同的图像分解为一个共享的反射率分量和两个独立的照明分量。由于不存在正常光图像，我们通过伽玛校正处理低光图像以创建照明不同的图像对。然后，我们将该模型转换为多级展开网络，其中每个阶段交替优化两个图像的共享反射率分量和各自的照明分量。在渐进式多阶段优化过程中，网络通过联合估计不同照明条件下的最佳反射率来固有地对反射率一致性进行编码。最后，考虑到低光图像中存在噪声并抑制噪声放大，我们提出了一种自监督去噪机制。对九个基准数据集的广泛实验表明，我们提出的 S2UNet 在定量指标和视觉质量方面都优于最先进的无监督方法，同时与监督方法相比，实现了有竞争力的性能。源代码可在 https://github.com/J-Liu-DL/S2UNet 获取。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3652357",
        "title": "Towards Generative Understanding: Incremental Few-shot Semantic Segmentation with Diffusion Models",
        "link": "https://doi.org/10.1109/tip.2026.3652357",
        "published": "2026",
        "author": "Qun Li, Lu Huang, Fu Xiao, Na Zhao, Bir Bhanu",
        "summary": "Incremental Few-shot Semantic Segmentation (iFSS) aims to learn novel classes with limited samples while preserving segmentation capability for base classes, addressing the challenge of continual learning of novel classes and catastrophic forgetting of previously seen classes. Existing methods mainly rely on techniques such as knowledge distillation and background learning, which, while partially effective, still suffer from issues such as feature drift and limited generalization to real-world novel classes, primarily due to a bidirectional coupling bottleneck between the learning of base classes and novel classes. To address these challenges, we propose, for the first time, a diffusion-based generative framework for iFSS. Specifically, we bridge the gap between generative and discriminative tasks through an innovative binary-to-RGB mask mapping mechanism, enabling pre-trained diffusion models to focus on target regions via class-specific semantic embedding optimization while sharpening foreground-background contrast with color embeddings. A lightweight post-processor then refines the generated images into high-quality binary masks. Crucially, by leveraging diffusion priors, our framework avoids complex training strategies. The optimization of class-specific semantic embeddings decouples the embedding spaces of base and novel classes, inherently preventing feature drift, mitigating catastrophic forgetting, and enabling rapid novel-class adaptation. Experimental results show that our method achieves state-of-the-art performance on the PASCAL-5i and COCO-20i datasets using much less data than other methods, and exhibiting competitive results in cross-domain few-shot segmentation tasks. Project page: https://ifss-diff.github.io/.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "迈向生成理解：使用扩散模型进行增量少样本语义分割",
        "abstract_cn": "增量少样本语义分割（iFSS）旨在用有限的样本学习新类，同时保留基类的分割能力，解决持续学习新类和灾难性遗忘先前见过的类的挑战。现有的方法主要依赖于知识蒸馏和背景学习等技术，虽然部分有效，但仍然存在特征漂移和对现实世界小说类的泛化有限等问题，这主要是由于基类和小说类的学习之间存在双向耦合瓶颈。为了应对这些挑战，我们首次提出了基于扩散的 iFSS 生成框架。具体来说，我们通过创新的二进制到 RGB 掩码映射机制弥合了生成任务和判别任务之间的差距，使预先训练的扩散模型能够通过特定于类的语义嵌入优化来关注目标区域，同时通过颜色嵌入来锐化前景-背景对比度。然后，轻量级后处理器将生成的图像细化为高质量的二进制掩模。至关重要的是，通过利用扩散先验，我们的框架避免了复杂的训练策略。特定于类的语义嵌入的优化将基础类和新类的嵌入空间解耦，从本质上防止特征漂移，减轻灾难性遗忘，并实现快速新类适应。实验结果表明，我们的方法在 PASCAL-5i 和 COCO-20i 数据集上使用比其他方法少得多的数据实现了最先进的性能，并且在跨域少样本分割任务中表现出有竞争力的结果。项目页面：https://ifss-diff.github.io/。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3652371",
        "title": "EinsPT: Efficient Instance-Aware Pre-Training of Vision Foundation Models",
        "link": "https://doi.org/10.1109/tip.2026.3652371",
        "published": "2026",
        "author": "Zhaozhi Wang, Yunjie Tian, Lingxi Xie, Yaowei Wang, Qixiang Ye",
        "summary": "In this study, we introduce EinsPT, an efficient instance-aware pre-training paradigm designed to reduce the transfer gap between vision foundation models and downstream instance-level tasks. Unlike conventional image-level pre-training that relies solely on unlabeled images, EinsPT leverages both image reconstruction and instance annotations to learn representations that are spatially coherent and instance discriminative. To achieve this efficiently, we propose a proxy-foundation architecture that decouples high-resolution and low-resolution learning: the foundation model processes masked low-resolution images for global semantics, while a lightweight proxy model operates on complete high-resolution images to preserve fine-grained details. The two branches are jointly optimized through reconstruction and instance-level prediction losses on fused features. Extensive experiments demonstrate that EinsPT consistently enhances recognition accuracy across various downstream tasks with substantially reduced computational cost, while qualitative results further reveal improved instance perception and completeness in visual representations. Code is available at github.com/feufhd/EinsPT.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "EinsPT：视觉基础模型的高效实例感知预训练",
        "abstract_cn": "在本研究中，我们引入了 EinsPT，这是一种高效的实例感知预训练范例，旨在减少视觉基础模型与下游实例级任务之间的传输差距。与仅依赖于未标记图像的传统图像级预训练不同，EinsPT 利用图像重建和实例注释来学习空间连贯和实例判别性的表示。为了有效地实现这一目标，我们提出了一种代理基础架构，将高分辨率和低分辨率学习解耦：基础模型处理屏蔽的低分辨率图像以实现全局语义，而轻量级代理模型对完整的高分辨率图像进行操作以保留细粒度的细节。这两个分支通过融合特征的重建和实例级预测损失来联合优化。大量实验表明，EinsPT 能够持续提高各种下游任务的识别准确性，同时大幅降低计算成本，而定性结果进一步揭示了视觉表示中实例感知和完整性的改进。代码可在 github.com/feufhd/EinsPT 获取。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3646474",
        "title": "Harnessing Group-Oriented Consistency Constraints for Semi-Supervised Semantic Segmentation in CdZnTe Semiconductors",
        "link": "https://doi.org/10.1109/tip.2025.3646474",
        "published": "2026",
        "author": "Peihao Li, Yan Fang, Man Liu, Huihui Bai, Anhong Wang, Yunchao Wei, Yao Zhao",
        "summary": "Labeling Cadmium Zinc Telluride (CdZnTe) semiconductor images is challenging due to the low-contrast defect boundaries, necessitating annotators to cross-reference multiple views. These views share a single ground truth (GT), forming a unique “many-to-one” relationship. This characteristic renders advanced semi-supervised semantic segmentation (SSS) methods suboptimal, as they are generally limited by a “one-to-one” relationship, where each image is independently associated with its GT. Such limitation may lead to error accumulation in low-contrast regions, further exacerbating confirmation bias. To address this issue, we revisit the SSS pipeline from a group-oriented perspective and propose a human-inspired solution: the Intra-group Consistency Augmentation Framework (ICAF). First, we experimentally validate the inherent consistency constraints within CdZnTe groups, establishing a group-oriented baseline using the Intra-group View Sampling (IVS). Building on this insight, we introduce the Pseudo-label Correction Network (PCN) to enhance consistency representation, which consists of two key modules. The View Augmentation Module (VAM) improves boundary details by dynamically synthesizing a boundary-aware view through the aggregation of multiple views. In the View Correction Module (VCM), this synthesized view is paired with other views for information interaction, effectively emphasizing salient regions while minimizing noise. Extensive experiments demonstrate the effectiveness of our solution for CdZnTe materials. Leveraging DeepLabV3+ with a ResNet-101 backbone as our segmentation model, we achieve a 70.6% mIoU on the CdZnTe dataset using only 2 group-annotated data (5‰). The code is available at <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/pipixiapipi/ICAF</uri>",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "利用面向群体的一致性约束进行 CdZnTe 半导体半监督语义分割",
        "abstract_cn": "由于缺陷边界对比度低，标记碲化镉锌 (CdZnTe) 半导体图像具有挑战性，需要注释者交叉引用多个视图。这些视图共享一个基本事实（GT），形成独特的“多对一”关系。这一特性使得先进的半监督语义分割（SSS）方法不是最理想的，因为它们通常受到“一对一”关系的限制，其中每个图像都与其 GT 独立关联。这种限制可能会导致低对比度区域的错误累积，进一步加剧确认偏差。为了解决这个问题，我们从面向群体的角度重新审视 SSS 管道，并提出了一种受人启发的解决方案：群体内一致性增强框架（ICAF）。首先，我们通过实验验证 CdZnTe 组内固有的一致性约束，使用组内视图采样 (IVS) 建立面向组的基线。基于这一见解，我们引入了伪标签校正网络（PCN）来增强一致性表示，它由两个关键模块组成。视图增强模块 (VAM) 通过聚合多个视图动态合成边界感知视图，从而改善边界细节。在视图校正模块（VCM）中，该合成视图与其他视图配对以进行信息交互，有效地强调显着区域，同时最大限度地减少噪声。大量实验证明了我们的 CdZnTe 材料解决方案的有效性。利用 DeepLabV3+ 和 ResNet-101 主干作为我们的分割模型，我们仅使用 2 个组注释数据 (5‰) 在 CdZnTe 数据集上实现了 70.6% mIoU。该代码位于 <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/pipixiapipi/ICAF</uri>"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3651951",
        "title": "Boosting Segment Anything Model to Generalize Visually Non-Salient Scenarios",
        "link": "https://doi.org/10.1109/tip.2026.3651951",
        "published": "2026",
        "author": "Guangqian Guo, Pengfei Chen, Yong Guo, Huafeng Chen, Boqiang Zhang, Shan Gao",
        "summary": "Segment Anything Model (SAM), known for its remarkable zero-shot segmentation capabilities, has garnered significant attention in the community. Nevertheless, its performance is challenged when dealing with what we refer to as visually non-salient scenarios, where there is low contrast between the foreground and background. In these cases, existing methods often cannot capture accurate contours and fail to produce promising segmentation results. In this paper, we propose Visually Non-Salient SAM (VNS-SAM), aiming to enhance SAM's perception of visually non-salient scenarios while preserving its original zero-shot generalizability. We achieve this by effectively exploiting SAM's low-level features through two designs: Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module. These designs help the SAM decoder gain a deeper understanding of non-salient characteristics with only marginal parameter increments and computational requirements. The additional parameters of VNS-SAM can be optimized within 4 hours, demonstrating its feasibility and practicality. In terms of data, we established VNS-SEG, a unified dataset for various VNS scenarios, with more than 35K images, in contrast to previous single-task adaptations. It is designed to make the model learn more robust VNS features and comprehensively benchmark the model's segmentation performance and generalizability on VNS scenarios. Extensive experiments across various VNS segmentation tasks demonstrate the superior performance of VNS-SAM, particularly under zero-shot settings, highlighting its potential for broad real-world applications. Codes and datasets will be publicly available at https://guangqian-guo.github.io/VNS-SAM/.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "Boosting Segment Anything 模型来概括视觉上不显着的场景",
        "abstract_cn": "Segment Anything Model (SAM) 以其卓越的零样本分割能力而闻名，引起了社区的广泛关注。然而，在处理我们所说的视觉上不显着的场景（前景和背景之间的对比度较低）时，其性能会受到挑战。在这些情况下，现有方法通常无法捕获准确的轮廓，并且无法产生有希望的分割结果。在本文中，我们提出了视觉非显着 SAM（VNS-SAM），旨在增强 SAM 对视觉非显着场景的感知，同时保留其原始的零样本泛化性。我们通过两种设计有效地利用 SAM 的低级功能来实现这一目标：Mask-Edge Token Interactive 解码器和非显着特征挖掘模块。这些设计有助于 SAM 解码器更深入地了解非显着特征，只需边际参数增量和计算要求。 VNS-SAM的附加参数可以在4小时内完成优化，证明了其可行性和实用性。在数据方面，我们建立了VNS-SEG，这是一个针对各种VNS场景的统一数据集，拥有超过35K的图像，与之前的单任务适应形成鲜明对比。旨在使模型学习更鲁棒的VNS特征，并全面基准测试模型在VNS场景上的分割性能和泛化性。跨各种 VNS 分割任务的大量实验证明了 VNS-SAM 的卓越性能，特别是在零样本设置下，突显了其在广泛的现实世界应用中的潜力。代码和数据集将在 https://guangqian-guo.github.io/VNS-SAM/ 公开提供。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3648872",
        "title": "FourierSR: A Fourier Token-based Plugin for Efficient Image Super-Resolution",
        "link": "https://doi.org/10.1109/tip.2025.3648872",
        "published": "2026",
        "author": "Wenjie Li, Heng Guo, Yuefeng Hou, Zhanyu Ma",
        "summary": "Image super-resolution (SR) aims to recover low-resolution images to high-resolution images, where improving SR efficiency is a high-profile challenge. However, commonly used units in SR, like convolutions and window-based Transformers, have limited receptive fields, making it challenging to apply them to improve SR under extremely limited computational cost. To address this issue, inspired by modeling convolution theorem through token mix, we propose a Fourier token-based plugin called FourierSR to improve SR uniformly, which avoids the instability or inefficiency of existing token mix technologies when applied as plug-ins. Furthermore, compared to convolutions and windows-based Transformers, our FourierSR only utilizes Fourier transform and multiplication operations, greatly reducing complexity while having global receptive fields. Experimental results show that our FourierSR as a plug-and-play unit brings an average PSNR gain of 0.34dB for existing efficient SR methods on Manga109 test set at the scale of <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\times 4$ </tex-math></inline-formula>, while the average increase in the number of Params and FLOPs is only 0.6% and 1.5% of original sizes. We will release our codes upon acceptance.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "FourierSR：基于傅里叶令牌的高效图像超分辨率插件",
        "abstract_cn": "图像超分辨率（SR）旨在将低分辨率图像恢复为高分辨率图像，其中提高 SR 效率是一个备受瞩目的挑战。然而，SR 中常用的单元（如卷积和基于窗口的 Transformer）的感受野有限，这使得在极其有限的计算成本下应用它们来提高 SR 具有挑战性。为了解决这个问题，受到通过令牌混合建模卷积定理的启发，我们提出了一种名为 FourierSR 的基于傅立叶令牌的插件来统一提高 SR，避免了现有令牌混合技术作为插件应用时不稳定或低效的问题。此外，与卷积和基于窗口的 Transformer 相比，我们的 FourierSR 仅利用傅里叶变换和乘法运算，在具有全局感受野的同时大大降低了复杂性。实验结果表明，我们的 FourierSR 作为即插即用单元，在 Manga109 测试集上为现有高效 SR 方法带来了 0.34dB 的平均 PSNR 增益 <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\times 4$ </tex-math></inline-formula>，而 Params 和 FLOP 数量的平均增加仅为原始大小的 0.6% 和 1.5%。我们将在接受后发布我们的代码。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3650668",
        "title": "Hippocampal Memory-Like Separation-Completion Collaborative Network for Unbiased Scene Graph Generation",
        "link": "https://doi.org/10.1109/tip.2025.3650668",
        "published": "2026",
        "author": "Ruonan Zhang, Gaoyun An, Yiqing Hao, Dapeng Oliver Wu",
        "summary": "Scene Graph Generation (SGG) is a challenging cross-modal task, which aims to identify entities and relationships in a scene simultaneously. Due to highly skewed long-tailed distribution, the generated scene graphs are dominated by relation categories of head samples. Current works address this problem by designing re-balancing strategies at the data level or refining relation representations at the feature level. Different from them, we attribute this impact to catastrophic interference, that is, the subsequent learning of dominant relations tends to overwrite the earlier learning of rare relations. To address it at the modeling level, a Hippocampal Memory-Like Separation-Completion Collaborative Network (HMSC2) is proposed here, which imitates the hippocampal encoding and retrieval process. Inspired by the pattern separation of dentate gyrus during memory encoding, a Gradient Separation Classifier and a Prototype Separation Learning module are proposed to relieve the catastrophic interference of tail categories by modeling the separated classifier and prototypes. In addition, inspired by the pattern completion of area CA3 of hippocampus during memory retrieval, a Prototype Completion Module is designed to supplement the incomplete information of prototypes by introducing relation representations as cues. Finally, the completed prototype and relation representations are connected within a hypersphere space by a Contrastive Connected Module. Experimental results on Visual Genome and GQA datasets show our HMSC2 achieves state-of-the-art performance on the unbiased SGG task, effectively relieving the long-tailed problem. The source codes are released on GitHub: https://github.com/Nora-Zhang98/HMSC2.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "用于无偏场景图生成的类海马记忆分离完成协作网络",
        "abstract_cn": "场景图生成（SGG）是一项具有挑战性的跨模态任务，旨在同时识别场景中的实体和关系。由于高度倾斜的长尾分布，生成的场景图以头部样本的关系类别为主。当前的工作通过在数据级别设计重新平衡策略或在特征级别细化关系表示来解决这个问题。与它们不同的是，我们将这种影响归因于灾难性干扰，即随后对主导关系的学习往往会覆盖早期对稀有关系的学习。为了在建模层面解决这个问题，这里提出了一种海马记忆分离完成协作网络（HMSC2），它模仿海马编码和检索过程。受记忆编码过程中齿状回模式分离的启发，提出了梯度分离分类器和原型分离学习模块，通过对分离的分类器和原型进行建模来减轻尾部类别的灾难性干扰。此外，受记忆检索过程中海马CA3区模式补全的启发，设计了原型补全模块，通过引入关系表示作为线索来补充原型的不完整信息。最后，完成的原型和关系表示通过对比连接模块在超球面空间内连接。 Visual Genome 和 GQA 数据集上的实验结果表明，我们的 HMSC2 在无偏 SGG 任务上实现了最先进的性能，有效缓解了长尾问题。源代码发布在GitHub上：https://github.com/Nora-Zhang98/HMSC2。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3649365",
        "title": "Fast Track Anything with Sparse Spatio-Temporal Propagation for Unified Video Segmentation",
        "link": "https://doi.org/10.1109/tip.2025.3649365",
        "published": "2026",
        "author": "Jisheng Dang, Huicheng Zheng, Zhixuan Chen, Zhang Li, Yulan Guo, Tat-Seng Chua",
        "summary": "advances in \"track-anything\" models have significantly improved fine-grained video understanding by simultaneously handling multiple video segmentation and tracking tasks. However, existing models often struggle with robust and efficient temporal propagation. To address these challenges, we propose the Sparse Spatio-Temporal Propagation (SSTP) method, which achieves robust and efficient unified video segmentation by selectively leveraging key spatio-temporal features in videos. Specifically, we design a dynamic 3D spatio-temporal convolution to aggregate global multi-frame spatio-temporal information into memory frames during memory construction. Additionally, we introduce a spatio-temporal aggregation reading strategy to efficiently aggregate the relevant spatio-temporal features from multiple memory frames during memory retrieval. By combining SSTP with an image segmentation foundation model, such as the segment anything model, our method effectively addresses multiple data-scarce video segmentation tasks. Our experimental results demonstrate state-of-the-art performance on five video segmentation tasks across eleven datasets, outperforming both task-specific and unified methods. Notably, SSTP exhibits strong robustness in handling sparse, low-frame-rate videos, making it well-suited for real-world applications.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "通过稀疏时空传播快速跟踪任何内容，实现统一视频分割",
        "abstract_cn": "“跟踪任何内容”模型的进步通过同时处理多个视频分割和跟踪任务，显着提高了细粒度视频理解。然而，现有模型常常难以实现稳健且高效的时间传播。为了应对这些挑战，我们提出了稀疏时空传播（SSTP）方法，该方法通过选择性地利用视频中的关键时空特征来实现稳健且高效的统一视频分割。具体来说，我们设计了动态 3D 时空卷积，在内存构建过程中将全局多帧时空信息聚合到内存帧中。此外，我们引入了时空聚合读取策略，以在记忆检索过程中有效地聚合来自多个记忆帧的相关时空特征。通过将 SSTP 与图像分割基础模型（例如分段任何模型）相结合，我们的方法有效地解决了多个数据稀缺的视频分割任务。我们的实验结果证明了跨 11 个数据集的 5 个视频分割任务的最先进性能，优于特定于任务的方法和统一方法。值得注意的是，SSTP 在处理稀疏、低帧率视频方面表现出强大的鲁棒性，使其非常适合实际应用。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3652008",
        "title": "Dual Domain Optimization Algorithm for CBCT Ring Artifact Correction",
        "link": "https://doi.org/10.1109/tip.2026.3652008",
        "published": "2026",
        "author": "Yanwei Qin, Xiaohui Su, Xin Lu, Baodi Yu, Yunsong Zhao, Fanyong Meng",
        "summary": "Compared to traditional computed tomography (CT), photon-counting detector (PCD)-based CT provides significant advantages, including enhanced CT image contrast and reduced radiation dose. However, owing to the current immaturity of PCD technology, scanned PCD data often contain stripe artifacts resulting from non-functional or defective detector units, which subsequently introduce ring artifacts in reconstructed CT images. The presence of ring artifact may compromise the accuracy of CT values and even introduce pseudo-structures, thereby reducing the application value of CT images. In this paper, we propose a dual-domain optimization model that takes advantage of the distribution characteristics of stripe artifact in 3D projection data and the prior features of reconstructed 3D CT images. Specifically, we demonstrate that stripe artifact in 3D projection data exhibit both group sparsity and low-rank properties. Building on this observation, we propose a TLT (TV-l2,1- Tucker) model to eliminate ring artifact in PCD-based cone beam CT (CBCT). In addition, an efficient iterative algorithm is designed to solve the proposed model. The effectiveness of both the model and the algorithm is evaluated through simulated and real data experiments. Experimental results demonstrate that the proposed method outperforms existing state-of-the-art approaches.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "CBCT环伪影校正的双域优化算法",
        "abstract_cn": "与传统计算机断层扫描 (CT) 相比，基于光子计数探测器 (PCD) 的 CT 具有显着优势，包括增强 CT 图像对比度和减少辐射剂量。然而，由于当前 PCD 技术的不成熟，扫描的 PCD 数据通常包含由非功能或有缺陷的探测器单元产生的条纹伪影，这随后在重建的 CT 图像中引入环形伪影。环形伪影的存在可能会影响CT值的准确性，甚至引入伪结构，从而降低CT图像的应用价值。在本文中，我们提出了一种双域优化模型，该模型利用 3D 投影数据中条纹伪影的分布特征和重建 3D CT 图像的先验特征。具体来说，我们证明 3D 投影数据中的条纹伪影表现出组稀疏性和低秩属性。基于这一观察，我们提出了 TLT (TV-l2,1- Tucker) 模型来消除基于 PCD 的锥形束 CT (CBCT) 中的环形伪影。此外，还设计了一种有效的迭代算法来求解所提出的模型。通过模拟和真实数据实验评估模型和算法的有效性。实验结果表明，所提出的方法优于现有的最先进的方法。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3651208",
        "title": "IEEE Transactions on Image Processing publication information",
        "link": "https://doi.org/10.1109/tip.2026.3651208",
        "published": "2025",
        "author": "Unknown",
        "summary": "Abstract not available.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "IEEE 图像处理交易出版物信息",
        "abstract_cn": "（摘要暂缺，等待官方补全）"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3652431",
        "title": "Token-Level Prompt Mixture with Parameter-Free Routing for Federated Domain Generalization",
        "link": "https://doi.org/10.1109/tip.2026.3652431",
        "published": "2026",
        "author": "Shuai Gong, Chaoran Cui, Xiaolin Dong, Xiushan Nie, Lei Zhu, Xiaojun Chang",
        "summary": "Domain Generalization (FedDG) aims to train a globally generalizable model on data from decentralized, heterogeneous clients. While recent work has adapted vision-language models for FedDG using prompt learning, the prevailing “one-prompt-fits-all” paradigm struggles with sample diversity, causing a marked performance decline on personalized samples. The Mixture of Experts (MoE) architecture offers a promising solution for specialization. However, existing MoE-based prompt learning methods suffer from two key limitations: coarse image-level expert assignment and high communication costs from parameterized routers. To address these limitations, we propose TRIP, a Token-level pRompt mIxture with Parameter-free routing framework for FedDG. TRIP treats prompts as multiple experts, and assigns individual tokens within an image to distinct experts, facilitating the capture of fine-grained visual patterns. To ensure communication efficiency, TRIP introduces a parameter-free routing mechanism based on capacity-aware clustering and Optimal Transport (OT). First, tokens are grouped into capacity-aware clusters to ensure balanced workloads. These clusters are then assigned to experts via OT, stabilized by mapping cluster centroids to static, non-learnable keys. The final instance-specific prompt is synthesized by aggregating experts, weighted by the number of tokens assigned to each. Extensive experiments across four benchmarks demonstrate that TRIP achieves optimal generalization results, with communicating as few as 1K parameters. Our code is available at https://github.com/GongShuai8210/TRIP.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "用于联合域泛化的令牌级提示混合与无参数路由",
        "abstract_cn": "领域泛化（FedDG）旨在针对来自分散、异构客户端的数据训练一个全球可泛化的模型。虽然最近的工作使用即时学习为 FedDG 调整了视觉语言模型，但流行的“一刀切”范式与样本多样性作斗争，导致个性化样本的性能显着下降。专家混合 (MoE) 架构为专业化提供了一种有前途的解决方案。然而，现有的基于 MoE 的即时学习方法存在两个关键限制：粗图像级专家分配和参数化路由器的高通信成本。为了解决这些限制，我们提出了 TRIP，一种用于 FedDG 的具有无参数路由框架的代币级提示混合体。 TRIP 将提示视为多个专家，并将图像中的各个标记分配给不同的专家，从而有助于捕获细粒度的视觉模式。为了保证通信效率，TRIP引入了基于容量感知集群和最优传输（OT）的无参数路由机制。首先，令牌被分组到容量感知集群中，以确保平衡的工作负载。然后，这些集群通过 OT 分配给专家，并通过将集群质心映射到静态的、不可学习的键来稳定。最终的特定于实例的提示由聚合专家合成，并按分配给每个专家的令牌数量进行加权。跨越四个基准的大量实验表明，TRIP 可以实现最佳的泛化结果，通信参数少至 1K。我们的代码可在 https://github.com/GongShuai8210/TRIP 获取。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3652360",
        "title": "Boosting HDR Image Reconstruction via Semantic Knowledge Transfer",
        "link": "https://doi.org/10.1109/tip.2026.3652360",
        "published": "2026",
        "author": "Tao Hu, Longyao Wu, Wei Dong, Peng Wu, Jinqiu Sun, Xiaogang Xu, Qingsen Yan, Yanning Zhang",
        "summary": "Recovering High Dynamic Range (HDR) images from multiple Standard Dynamic Range (SDR) images becomes challenging when the SDR images exhibit noticeable degradation and missing content. Leveraging scene-specific semantic priors offers a promising solution for restoring heavily degraded regions. However, these priors are typically extracted from sRGB SDR images, the domain/format gap poses a significant challenge when applying it to HDR imaging. To address this issue, we propose a general framework that transfers semantic knowledge derived from SDR domain via self-distillation to boost existing HDR reconstruction. Specifically, the proposed framework first introduces the Semantic Priors Guided Reconstruction Model (SPGRM), which leverages SDR image semantic knowledge to address ill-posed problems in the initial HDR reconstruction results. Subsequently, we leverage a self-distillation mechanism that constrains the color and content information with semantic knowledge, aligning the external outputs between the baseline and SPGRM. Furthermore, to transfer the semantic knowledge of the internal features, we utilize a Semantic Knowledge Alignment Module (SKAM) to fill the missing semantic contents with the complementary masks. Extensive experiments demonstrate that our framework significantly boosts HDR imaging quality for existing methods without altering the network architecture.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "通过语义知识迁移促进 HDR 图像重建",
        "abstract_cn": "当 SDR 图像表现出明显的退化和内容丢失时，从多个标准动态范围 (SDR) 图像中恢复高动态范围 (HDR) 图像变得具有挑战性。利用特定于场景的语义先验为恢复严重退化的区域提供了一种有前景的解决方案。然而，这些先验通常是从 sRGB SDR 图像中提取的，当将其应用于 HDR 成像时，域/格式差距构成了重大挑战。为了解决这个问题，我们提出了一个通用框架，通过自蒸馏传输从 SDR 域衍生的语义知识，以促进现有的 HDR 重建。具体来说，所提出的框架首先引入了语义先验引导重建模型（SPGRM），该模型利用SDR图像语义知识来解决初始HDR重建结果中的不适定问题。随后，我们利用自蒸馏机制，用语义知识约束颜色和内容信息，从而在基线和 SPGRM 之间调整外部输出。此外，为了传递内部特征的语义知识，我们利用语义知识对齐模块（SKAM）来用互补掩码填充缺失的语义内容。大量实验表明，我们的框架在不改变网络架构的情况下显着提高了现有方法的 HDR 成像质量。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3653198",
        "title": "Particle Diffusion Matching: Random Walk Correspondence Search for the Alignment of Standard and Ultra-Widefield Fundus Images",
        "link": "https://doi.org/10.1109/tip.2026.3653198",
        "published": "2026",
        "author": "Kang Geon Lee, Soochahn Lee, Kyoung Mu Lee",
        "summary": "We propose a robust alignment technique for Standard Fundus Images (SFIs) and Ultra-Widefield Fundus Images (UWFIs), which are challenging to align due to differences in scale, appearance, and the scarcity of distinctive features. Our method, termed Particle Diffusion Matching (PDM), performs alignment through an iterative Random Walk Correspondence Search (RWCS) guided by a diffusion model. At each iteration, the model estimates displacement vectors for particle points by considering local appearance, the structural distribution of particles, and an estimated global transformation, enabling progressive refinement of correspondences even under difficult conditions. PDM achieves state-of-the-art performance across multiple retinal image alignment benchmarks, showing substantial improvement on a primary dataset of SFI-UWFI pairs and demonstrating its effectiveness in real-world clinical scenarios. By providing accurate and scalable correspondence estimation, PDM overcomes the limitations of existing methods and facilitates the integration of complementary retinal image modalities. This diffusion-guided search strategy offers a new direction for improving downstream supervised learning, disease diagnosis, and multi-modal image analysis in ophthalmology.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "粒子扩散匹配：标准和超广角眼底图像对齐的随机游走对应搜索",
        "abstract_cn": "我们为标准眼底图像（SFI）和超广角眼底图像（UWFI）提出了一种强大的对齐技术，由于尺度、外观的差异和独特特征的缺乏，对齐这些图像具有挑战性。我们的方法称为粒子扩散匹配 (PDM)，通过扩散模型引导的迭代随机游走对应搜索 (RWCS) 来执行对齐。在每次迭代中，模型都会通过考虑局部外观、粒子的结构分布和估计的全局变换来估计粒子点的位移矢量，即使在困难的条件下也能逐步细化对应关系。 PDM 在多个视网膜图像对齐基准上实现了最先进的性能，在 SFI-UWFI 对的主要数据集上显示出显着的改进，并证明了其在现实临床场景中的有效性。通过提供准确且可扩展的对应估计，PDM 克服了现有方法的局限性，并促进互补视网膜图像模态的集成。这种扩散引导的搜索策略为改善眼科下游监督学习、疾病诊断和多模态图像分析提供了新的方向。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3653189",
        "title": "Selecting and Pruning: A Differentiable Causal Sequentialized State-Space Model for Two-View Correspondence Learning",
        "link": "https://doi.org/10.1109/tip.2026.3653189",
        "published": "2026",
        "author": "Xiang Fang, Shihua Zhang, Hao Zhang, Xiaoguang Mei, Huabing Zhou, Jiayi Ma",
        "summary": "Two-view correspondence learning aims to discern true and false correspondences between image pairs by recognizing their underlying different information. Previous methods either treat the information equally or require the explicit storage of the entire context, tending to be laborious in real-world scenarios. Inspired by Mamba’s inherent selectivity, we propose CorrMamba, a <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Corr</i>espondence filter leveraging <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Mamba</i>’s ability to selectively mine information from true correspondences while mitigating interference from false ones, thus achieving adaptive focus at a lower cost. To prevent Mamba from being potentially impacted by unordered keypoints that obscured its ability to mine spatial information, we customize a causal sequential learning approach based on the Gumbel-Softmax technique to establish causal dependencies between features in a fully autonomous and differentiable manner. Additionally, a local-context enhancement module is designed to capture critical contextual cues essential for correspondence pruning, complementing the core framework. Extensive experiments on relative pose estimation, visual localization, and analysis demonstrate that CorrMamba achieves state-of-the-art performance. Notably, in outdoor relative pose estimation, our method surpasses the previous SOTA by 2.58 absolute percentage points in AUC@20°, highlighting its practical superiority. Our code will be publicly available.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "选择和剪枝：用于双视图对应学习的可微因果序列化状态空间模型",
        "abstract_cn": "双视图对应学习旨在通过识别图像对之间潜在的不同信息来辨别图像对之间的真假对应关系。以前的方法要么平等地对待信息，要么需要显式存储整个上下文，这在现实场景中往往很费力。受 Mamba 固有选择性的启发，我们提出了 CorrMamba，这是一种利用 <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Corr</i>响应过滤器 <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Mamba 能够选择性地从真实对应关系中挖掘信息，同时减轻虚假对应关系的干扰，从而以较低的成本实现自适应聚焦。为了防止 Mamba 受到无序关键点的潜在影响，从而掩盖其挖掘空间信息的能力，我们基于 Gumbel-Softmax 技术定制了一种因果顺序学习方法，以完全自主和可微分的方式建立特征之间的因果依赖关系。此外，本地上下文增强模块旨在捕获对应修剪所必需的关键上下文线索，补充核心框架。关于相对姿态估计、视觉定位和分析的大量实验表明 CorrMamba 实现了最先进的性能。值得注意的是，在室外相对位姿估计中，我们的方法在 AUC@20° 方面超越了之前的 SOTA 2.58 个绝对百分点，凸显了其实用优势。我们的代码将公开。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3652417",
        "title": "A Complex-valued SAR Foundation Model Based on Physically Inspired Representation Learning",
        "link": "https://doi.org/10.1109/tip.2026.3652417",
        "published": "2026",
        "author": "Mengyu Wang, Hanbo Bi, Yingchao Feng, Linlin Xin, Shuo Gong, Tianqi Wang, Zhiyuan Yan, Peijin Wang, Wenhui Diao, Xian Sun",
        "summary": "Vision foundation models in remote sensing have been extensively studied due to their superior generalization on various downstream tasks. Synthetic Aperture Radar (SAR) offers all-day, all-weather imaging capabilities, providing significant advantages for Earth observation. However, establishing a foundation model for SAR image interpretation inevitably encounters the challenges of insufficient information utilization and poor interpretability. In this paper, we propose a remote sensing foundation model based on complex-valued SAR data, which simulates the polarimetric decomposition process for pre-training, i.e., characterizing pixel scattering intensity as a weighted combination of scattering bases and scattering coefficients, thereby endowing the foundation model with physical interpretability. Specifically, we construct a series of scattering queries, each representing an independent and meaningful scattering basis, which interact with SAR features in the scattering query decoder and output the corresponding scattering coefficient. To guide the pre-training process, polarimetric decomposition loss and power self-supervised loss are constructed. The former aligns the predicted coefficients with Yamaguchi coefficients, while the latter reconstructs power from the predicted coefficients and compares it to the input image’s power. The performance of our foundation model is validated on nine typical downstream tasks, achieving state-of-the-art results. Notably, the foundation model can extract stable feature representations and exhibits strong generalization, even in data-scarce conditions.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "基于物理启发表示学习的复值SAR基础模型",
        "abstract_cn": "遥感中的视觉基础模型由于其对各种下游任务的优异泛化性而得到了广泛的研究。合成孔径雷达（SAR）提供全天时、全天候的成像能力，为地球观测提供了显着的优势。然而，建立SAR图像解译基础模型不可避免地遇到信息利用率不足、可解译性差的挑战。本文提出了一种基于复值SAR数据的遥感基础模型，模拟预训练的极化分解过程，即将像素散射强度表征为散射基数和散射系数的加权组合，从而赋予基础模型物理可解释性。具体来说，我们构建了一系列散射查询，每个散射查询代表一个独立且有意义的散射基础，它们与散射查询解码器中的SAR特征交互并输出相应的散射系数。为了指导预训练过程，构建了极化分解损失和功率自监督损失。前者将预测系数与 Yamaguchi 系数对齐，而后者根据预测系数重建功率并将其与输入图像的功率进行比较。我们的基础模型的性能在九个典型的下游任务上进行了验证，取得了最先进的结果。值得注意的是，即使在数据稀缺的条件下，基础模型也可以提取稳定的特征表示并表现出很强的泛化性。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3649356",
        "title": "Vision Enhancing LLMs: Empowering Multimodal Knowledge Storage and Sharing in LLMs",
        "link": "https://doi.org/10.1109/tip.2025.3649356",
        "published": "2026",
        "author": "Yunxin Li, Zhenyu Liu, Baotian Hu, Wei Wang, Yuxin Ding, Xiaochun Cao, Min Zhang",
        "summary": "Recent advancements in multimodal large language models (MLLMs) have achieved significant multimodal generation capabilities, akin to GPT-4. These models predominantly map visual information into language representation space, leveraging the vast knowledge and powerful text generation abilities of LLMs to produce multimodal instruction-following responses. We could term this method as LLMs for Vision because of its employing LLMs for visual understanding and reasoning, yet observe that these MLLMs neglect the potential of harnessing visual knowledge to enhance the overall capabilities of LLMs, which could be regarded as Vision Enhancing LLMs. In this paper, we propose an approach called MKS2, aimed at enhancing LLMs through empowering Multimodal Knowledge Storage and Sharing in LLMs. Specifically, we introduce Modular Visual Memory (MVM), a component integrated into the internal blocks of LLMs, designed to store open-world visual information efficiently. Additionally, we present a soft Mixture of Multimodal Experts (MoMEs) architecture in LLMs to invoke multimodal knowledge collaboration during text generation. Our comprehensive experiments demonstrate that MKS2 substantially augments the reasoning capabilities of LLMs in contexts necessitating physical or commonsense knowledge. It also delivers competitive results on image-text understanding multimodal benchmarks. The codes will be available at: https://github.com/HITsz-TMG/ MKS2-Multimodal-Knowledge-Storage-and-Sharing.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "增强法学硕士的愿景：增强法学硕士的多模式知识存储和共享",
        "abstract_cn": "多模态大语言模型 (MLLM) 的最新进展已经实现了类似于 GPT-4 的显着多模态生成功能。这些模型主要将视觉信息映射到语言表示空间中，利用法学硕士的丰富知识和强大的文本生成能力来产生多模式指令跟踪响应。我们可以将这种方法称为视觉法学硕士，因为它利用法学硕士进行视觉理解和推理，但观察到这些MLLM忽视了利用视觉知识来增强法学硕士整体能力的潜力，这可以被视为视觉增强法学硕士。在本文中，我们提出了一种名为 MKS2 的方法，旨在通过增强法学硕士的多模式知识存储和共享来增强法学硕士。具体来说，我们引入了模块化视觉内存（MVM），这是一个集成到法学硕士内部模块中的组件，旨在有效地存储开放世界的视觉信息。此外，我们在法学硕士中提出了一种软多模态专家混合（MoME）架构，以在文本生成过程中调用多模态知识协作。我们的综合实验表明，MKS2 极大地增强了法学硕士在需要物理或常识知识的情况下的推理能力。它还在图像文本理解多模式基准方面提供了具有竞争力的结果。这些代码可在以下网址获取：https://github.com/HITsz-TMG/MKS2-Multimodal-Knowledge-Storage-and-Sharing。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3650052",
        "title": "A variational multi-scale model for multi-exposure image fusion",
        "link": "https://doi.org/10.1109/tip.2025.3650052",
        "published": "2026",
        "author": "Yuming Yang, Wei Wang",
        "summary": "Multi-exposure image fusion (MEF) is the main method to obtain High Dynamic Range (HDR) images by fusing multiple images taken under various exposure values. In this paper, we propose and develop a novel variational model based on detail-base decomposition for MEF. The main idea is to incorporate the decomposition procedure and the reconstruction procedure into a unified framework, and to interact the detail information and the base information at the same time. Specifically, we make use of Tikhonov regularization to model the base layer, and we present an efficient design to obtain the detail layer, which is able to capture more detailed information effectively. Meanwhile, we incorporate multi-scale techniques to remove halo artifacts. Numerically, we apply alternating direction method of multipliers (ADMM) to solve the proposed minimization problem. Theoretically, we study the existence of the solution of the proposed model and the convergence of the proposed ADMM algorithm. Experimental examples are presented to demonstrate that the performance of the proposed model is better than that by using other testing methods in terms of visual quality and some criteria, e. g., the proposed model gives the best Natural image quality evaluator (NIQE) values with 1% - 10% improvement for real image fusion experiments and gives the best PSNR values with 13% - 20% improvement for the synthetic image fusion experiment.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "多曝光图像融合的变分多尺度模型",
        "abstract_cn": "多重曝光图像融合（MEF）是通过融合在不同曝光值下拍摄的多幅图像来获得高动态范围（HDR）图像的主要方法。在本文中，我们提出并开发了一种基于 MEF 细节基础分解的新型变分模型。其主要思想是将分解过程和重构过程纳入一个统一的框架中，同时实现细节信息和基础信息的交互。具体来说，我们利用Tikhonov正则化对基础层进行建模，并提出了一种有效的设计来获得细节层，能够有效地捕获更详细的信息。同时，我们采用多尺度技术来消除光晕伪影。在数值上，我们应用乘子交替方向法（ADMM）来解决所提出的最小化问题。理论上，我们研究了所提出模型的解的存在性以及所提出的ADMM算法的收敛性。实验示例证明所提出的模型在视觉质量和一些标准（例如，视觉质量）方面的性能优于使用其他测试方法的性能。 g.，所提出的模型为真实图像融合实验提供了最佳自然图像质量评估器（NIQE）值，提高了1％ - 10％，并为合成图像融合实验提供了最佳PSNR值，提高了13％ - 20％。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3654373",
        "title": "Reliable Pseudo-supervision for Unsupervised Domain Adaptive Person Search",
        "link": "https://doi.org/10.1109/tip.2026.3654373",
        "published": "2026",
        "author": "Qixian Zhang, Duoqian Miao, Qi Zhang, Xuan Tan, Hongyun Zhang, Cairong Zhao",
        "summary": "Unsupervised Domain Adaptation (UDA) person search aims to adapt models trained on labeled source data to unlabeled target domains. Existing approaches typically rely on clustering-based proxy learning, but their performance is often undermined by unreliable pseudo-supervision. This unreliability mainly stems from two challenges: (i) spectral shift bias, where low- and high-frequency components behave differently under domain shifts but are rarely considered, degrading feature stability; and (ii) static proxy updates, which make clustering proxies highly sensitive to noise and less adaptable to domain shifts. To address these challenges, we propose the Reliable Pseudo-supervision in UDA Person Search (RPPS) framework. At the feature level, a Dual-branch Wavelet Enhancement Module (DWEM) embedded in the backbone applies discrete wavelet transform (DWT) to decompose features into low- and high-frequency components, followed by differentiated enhancements that improve cross-domain robustness and discriminability. At the proxy level, a Dynamic Confidence-weighted Clustering Proxy (DCCP) employs confidence-guided initialization and a two-stage online–offline update strategy to stabilize proxy optimization and suppress proxy noise. Extensive experiments on the CUHK-SYSU and PRW benchmarks demonstrate that RPPS achieves state-of-the-art performance and strong robustness, underscoring the importance of enhancing pseudo-supervision reliability in UDA person search. Our code is accessible at https://github.com/zqx951102/RPPS.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "无监督域自适应人员搜索的可靠伪监督",
        "abstract_cn": "无监督域适应 (UDA) 人员搜索旨在将标记源数据训练的模型适应未标记的目标域。现有的方法通常依赖于基于集群的代理学习，但它们的性能常常受到不可靠的伪监督的影响。这种不可靠性主要源于两个挑战：（i）频谱偏移偏差，低频和高频分量在域偏移下表现不同，但很少被考虑，从而降低了特征稳定性； (ii) 静态代理更新，这使得集群代理对噪声高度敏感并且不太适应域转移。为了应对这些挑战，我们提出了 UDA 人员搜索中的可靠伪监督（RPPS）框架。在特征层面，嵌入主干的双分支小波增强模块（DWEM）应用离散小波变换（DWT）将特征分解为低频和高频分量，然后进行差异化增强，以提高跨域鲁棒性和可辨别性。在代理级别，动态置信加权聚类代理（DCCP）采用置信引导初始化和两阶段在线离线更新策略来稳定代理优化并抑制代理噪声。在 CUHK-SYSU 和 PRW 基准上的大量实验表明，RPPS 实现了最先进的性能和强大的鲁棒性，强调了增强 UDA 人员搜索中伪监督可靠性的重要性。我们的代码可在 https://github.com/zqx951102/RPPS 访问。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2025.3649360",
        "title": "Video Decoupling Networks for Accurate, Efficient, Generalizable, and Robust Video Object Segmentation",
        "link": "https://doi.org/10.1109/tip.2025.3649360",
        "published": "2026",
        "author": "Jisheng Dang, Huicheng Zheng, Yulan Guo, Jianhuang Lai, Bin Hu, Tat-Seng Chua",
        "summary": "object segmentation (VOS) is a fundamental task in video analysis, aiming to accurately recognize and segment objects of interest within video sequences. Conventional methods, relying on memory networks to store single-frame appearance features, face challenges in computational efficiency and capturing dynamic visual information effectively. To address these limitations, we present a Video Decoupling Network (VDN) with a per-clip memory updating mechanism. Our approach is inspired by the dual-stream hypothesis of the human visual cortex and decomposes multiple previous video frames into fundamental elements: scene, motion, and instance. We propose the Unified Prior-based Spatio-temporal Decoupler (UPSD) algorithm, which parses multiple frames into basic elements in a unified manner. UPSD continuously stores elements over time, enabling adaptive integration of different cues based on task requirements. This decomposition mechanism facilitates comprehensive spatial-temporal information capture and rapid updating, leading to notable enhancements in overall VOS performance. Extensive experiments conducted on multiple VOS benchmarks validate the state-of-the-art accuracy, efficiency, generalizability, and robustness of our approach. Remarkably, VDN demonstrates a significant performance improvement and a substantial speed-up compared to previous state-of-the-art methods on multiple VOS benchmarks. It also exhibits excellent generalizability under domain shift and robustness against various noise types.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "用于准确、高效、可泛化且鲁棒的视频对象分割的视频解耦网络",
        "abstract_cn": "对象分割（VOS）是视频分析中的一项基本任务，旨在准确识别和分割视频序列中感兴趣的对象。传统方法依靠记忆网络存储单帧外观特征，在计算效率和有效捕获动态视觉信息方面面临挑战。为了解决这些限制，我们提出了具有每个剪辑内存更新机制的视频解耦网络（VDN）。我们的方法受到人类视觉皮层双流假设的启发，并将多个先前的视频帧分解为基本元素：场景、运动和实例。我们提出了基于统一先验的时空解耦器（UPSD）算法，该算法以统一的方式将多个帧解析为基本元素。 UPSD 随着时间的推移不断存储元素，从而能够根据任务要求自适应集成不同的线索。这种分解机制有利于全面的时空信息捕获和快速更新，从而显着提高了 VOS 的整体性能。在多个 VOS 基准上进行的大量实验验证了我们方法的最先进的准确性、效率、通用性和稳健性。值得注意的是，与之前最先进的方法相比，VDN 在多个 VOS 基准测试中表现出显着的性能改进和显着的加速。它还在域转移下表现出出色的泛化性以及对各种噪声类型的鲁棒性。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3654348",
        "title": "UGAE: Unified Geometry and Attribute Enhancement for G-PCC Compressed Point Clouds",
        "link": "https://doi.org/10.1109/tip.2026.3654348",
        "published": "2026",
        "author": "Pan Zhao, Hui Yuan, Chongzhen Tian, Tian Guo, Raouf Hamzaoui, Zhigeng Pan",
        "summary": "Lossy compression of point clouds reduces storage and transmission costs; however, it inevitably leads to irreversible distortion in geometry structure and attribute information. To address these issues, we propose a unified geometry and attribute enhancement (UGAE) framework, which consists of three core components: post-geometry enhancement (PoGE), pre-attribute enhancement (PAE), and post-attribute enhancement (PoAE). In PoGE, a Transformer-based sparse convolutional U-Net is used to reconstruct the geometry structure with high precision by predicting voxel occupancy probabilities. Building on the refined geometry structure, PAE introduces an innovative enhanced geometry-guided recoloring strategy, which uses a detail-aware K-Nearest Neighbors (DA-KNN) method to achieve accurate recoloring and effectively preserve high-frequency details before attribute compression. Finally, at the decoder side, PoAE uses an attribute residual prediction network with a weighted mean squared error (W-MSE) loss to enhance the quality of high-frequency regions while maintaining the fidelity of low-frequency regions. UGAE significantly outperformed existing methods on three benchmark datasets: 8iVFB, Owlii, and MVUB. Compared to the latest G-PCC test model (TMC13v29), in terms of total bitrate setting, UGAE achieved an average BD-PSNR gain of 9.98 dB and -90.54% BD-bitrate for geometry under the D1 metric, as well as a 3.34 dB BD-PSNR improvement with -55.53% BD-bitrate for attributes. Additionally, it improved perceptual quality significantly. Our source code will be released on GitHub at: https://github.com/yuanhui0325/UGAE.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "UGAE：G-PCC 压缩点云的统一几何和属性增强",
        "abstract_cn": "点云有损压缩，降低存储和传输成本；然而，它不可避免地导致几何结构和属性信息的不可逆失真。为了解决这些问题，我们提出了一个统一的几何和属性增强（UGAE）框架，它由三个核心组件组成：几何后增强（PoGE）、属性前增强（PAE）和属性后增强（PoAE）。在PoGE中，基于Transformer的稀疏卷积U-Net用于通过预测体素占用概率来高精度地重建几何结构。在精细化几何结构的基础上，PAE引入了一种创新的增强型几何引导重着色策略，该策略使用细节感知的K最近邻（DA-KNN）方法来实现精确的重着色，并在属性压缩之前有效保留高频细节。最后，在解码器侧，PoAE使用具有加权均方误差（W-MSE）损失的属性残差预测网络来增强高频区域的质量，同时保持低频区域的保真度。 UGAE 在三个基准数据集上显着优于现有方法：8iVFB、Owlii 和 MVUB。与最新的G-PCC测试模型（TMC13v29）相比，在总码率设置方面，UGAE在D1指标下实现了平均BD-PSNR增益9.98 dB和几何BD码率-90.54%，以及属性BD-PSNR提升3.34 dB和-55.53% BD码率。此外，它还显着提高了感知质量。我们的源代码将在 GitHub 上发布：https://github.com/yuanhui0325/UGAE。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3654367",
        "title": "SigMa: Semantic Similarity-Guided Semi-Dense Feature Matching",
        "link": "https://doi.org/10.1109/tip.2026.3654367",
        "published": "2026",
        "author": "Xiang Fang, Zizhuo Li, Jiayi Ma",
        "summary": "Recent advancements have led the image matching community to increasingly focus on obtaining subpixel-level correspondences in a detector-free manner, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">i.e.</i>, semi-dense feature matching. Existing methods tend to overfocus on low-level local features while ignoring equally important high-level semantic information. To tackle these shortcomings, we propose <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">SigMa</i>, a semantic similarity-guided semi-dense feature matching method, which leverages the strengths of both local features and high-level semantic features. First, we design a dual-branch feature extractor, comprising a convolutional network and a vision foundation model, to extract low-level local features and high-level semantic features, respectively. To fully retain the advantages of these two features and effectively integrate them, we also introduce a cross-domain feature adapter, which could overcome their spatial resolution mismatches, channel dimensionality variations, and inter-domain gaps. Furthermore, we observe that performing the transformer on the whole feature map is unnecessary because of the similarity of local representations. We design a guided pooling method based on semantic similarity. This strategy performs attention computation by selecting highly semantically similar regions, aiming to minimize information loss while maintaining computational efficiency. Extensive experiments on multiple datasets demonstrate that our method achieves a competitive accuracy-efficiency trade-off across various tasks and exhibits strong generalization capabilities across different datasets. Additionally, we conduct a series of ablation studies and analysis experiments to validate the effectiveness and rationality of our method’s design. Our code will be publicly available.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "Sigma：语义相似性引导的半密集特征匹配",
        "abstract_cn": "最近的进展使得图像匹配社区越来越关注以无检测器的方式获取子像素级对应关系，<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">即</i>，半密集特征匹配。现有方法往往过度关注低级局部特征，而忽略同样重要的高级语义信息。为了解决这些缺点，我们提出了SigMa，一种语义相似性引导的半密集特征匹配方法，它利用了局部特征和高级语义特征的优点。首先，我们设计了一个双分支特征提取器，包括卷积网络和视觉基础模型，分别提取低级局部特征和高级语义特征。为了充分保留这两个特征的优点并有效地集成它们，我们还引入了跨域特征适配器，它可以克服它们的空间分辨率不匹配、通道维度变化和域间差距。此外，我们观察到，由于局部表示的相似性，在整个特征图上执行变换器是不必要的。我们设计了一种基于语义相似性的引导池方法。该策略通过选择语义高度相似的区域来执行注意力计算，旨在最大限度地减少信息损失，同时保持计算效率。对多个数据集的广泛实验表明，我们的方法在各种任务中实现了有竞争力的准确性-效率权衡，并在不同数据集上表现出强大的泛化能力。此外，我们还进行了一系列的消融研究和分析实验，以验证我们方法设计的有效性和合理性。我们的代码将公开。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3654402",
        "title": "Imbalanced Multiclassification Challenges in Whole Slide Image: Cross-Patient Pseudo Bags Generation and Curriculum Contrastive Learning with Dynamic Rebalancing",
        "link": "https://doi.org/10.1109/tip.2026.3654402",
        "published": "2026",
        "author": "Yonghuang Wu, Xuan Xie, Chengqian Zhao, Pengfei Song, Feiyu Yin, Guoqing Wu, Jinhua Yu",
        "summary": "The multi-classification of histopathological images under imbalanced sample conditions remains a long-standing unresolved challenge in computational pathology. In this paper, we propose for the first time a cross-patient pseudo-bag generation technique to address this challenge. Our key innovation lies in a cross-patient pseudo-bag generation framework that extracts complementary pathological features to construct distributionally consistent pseudo-bags. To resolve the critical challenge of distributional alignment in pseudo-bag generation, we propose an affinity-driven curriculum contrastive learning strategy, integrating sample affinity metrics with progressive training to stabilize representation learning. Unlike prior methods focused on bag-level embeddings, our framework pioneers a paradigm shift toward multi-instance feature distribution mining, explicitly modeling inter-bag heterogeneity to address class imbalance. Our method demonstrates significant performance improvements on three datasets with multiple classification difficulties, outperforming the second-best method by an average of 1.95 percentage points in F1 score and 2.07 percentage points in ACC.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "整个幻灯片图像中不平衡的多分类挑战：跨患者伪袋生成和动态重新平衡的课程对比学习",
        "abstract_cn": "不平衡样本条件下组织病理学图像的多分类仍然是计算病理学中长期未解决的挑战。在本文中，我们首次提出一种跨患者伪袋生成技术来应对这一挑战。我们的关键创新在于跨患者伪袋生成框架，该框架提取互补的病理特征来构建分布一致的伪袋。为了解决伪袋生成中分布对齐的关键挑战，我们提出了一种亲和力驱动的课程对比学习策略，将样本亲和力指标与渐进式训练相结合以稳定表示学习。与之前专注于包级嵌入的方法不同，我们的框架开创了向多实例特征分布挖掘的范式转变，明确地建模包间异构性以解决类不平衡问题。我们的方法在具有多种分类困难的三个数据集上展示了显着的性能改进，在 F1 分数中比第二好的方法平均高出 1.95 个百分点，在 ACC 中平均高出 2.07 个百分点。"
    },
    {
        "id": "https://doi.org/10.1109/tip.2026.3654473",
        "title": "Interpretable Few-Shot Image Classification via Prototypical Concept-Guided Mixture of LoRA Experts",
        "link": "https://doi.org/10.1109/tip.2026.3654473",
        "published": "2026",
        "author": "Zhong Ji, Rongshuai Wei, Jingren Liu, Yanwei Pang, Jungong Han",
        "summary": "Self-Explainable Models (SEMs) rely on Prototypical Concept Learning (PCL) to enable their visual recognition processes more interpretable, but they often struggle in data-scarce settings where insufficient training samples lead to suboptimal performance. To address this limitation, we propose a Few-Shot Prototypical Concept Classification (FSPCC) framework that systematically mitigates two key challenges under low-data regimes: parametric imbalance and representation misalignment. Specifically, our approach leverages a Mixture of LoRA Experts (MoLE) for parameter-efficient adaptation, ensuring a balanced allocation of trainable parameters between the backbone and the PCL module. Meanwhile, cross-module concept guidance enforces tight alignment between the backbone’s feature representations and the prototypical concept activation patterns. In addition, we incorporate a multi-level feature preservation strategy that fuses spatial and semantic cues across various layers, thereby enriching the learned representations and mitigating the challenges posed by limited data availability. Finally, to enhance interpretability and minimize concept overlap, we introduce a geometry-aware concept discrimination loss that enforces orthogonality among concepts, encouraging more disentangled and transparent decision boundaries. Experimental results on six popular benchmarks (CUB-200-2011, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">mini</i>-ImageNet, CIFAR-FS, Stanford Cars, FGVC-Aircraft, and DTD) demonstrate that our approach consistently outperforms existing SEMs by a notable margin, with 4.2%–8.7% relative gains in 5-way 5-shot classification. These findings highlight the efficacy of coupling concept learning with few-shot adaptation to achieve both higher accuracy and clearer model interpretability, paving the way for more transparent visual recognition systems.",
        "journal": "IEEE Trans. Image Processing",
        "title_cn": "通过 LoRA 专家的原型概念引导混合进行可解释的少样本图像分类",
        "abstract_cn": "自解释模型 (SEM) 依靠原型概念学习 (PCL) 来使其视觉识别过程更具可解释性，但它们经常在数据稀缺的环境中陷入困境，因为训练样本不足会导致性能不佳。为了解决这一限制，我们提出了一种少样本原型概念分类（FSPCC）框架，该框架系统地缓解了低数据情况下的两个关键挑战：参数不平衡和表示错位。具体来说，我们的方法利用 LoRA 专家混合体 (MoLE) 进行参数高效适应，确保主干网和 PCL 模块之间可训练参数的平衡分配。同时，跨模块概念指导强制主干的特征表示和原型概念激活模式之间的紧密结合。此外，我们采用了多级特征保留策略，该策略融合了各个层的空间和语义线索，从而丰富了学习到的表示并减轻了有限数据可用性带来的挑战。最后，为了增强可解释性并最大限度地减少概念重叠，我们引入了一种几何感知的概念辨别损失，它强制概念之间的正交性，鼓励更加清晰和透明的决策边界。六个流行基准（CUB-200-2011、<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">mini</i>-ImageNet、CIFAR-FS、Stanford Cars、FGVC-Aircraft 和 DTD）的实验结果表明，我们的方法始终优于现有方法SEM 的优势显着，5 路 5 镜头分类的相对增益为 4.2%–8.7%。这些发现强调了将概念学习与小样本适应相结合的功效，以实现更高的准确性和更清晰的模型可解释性，为更透明的视觉识别系统铺平道路。"
    },
    {
        "id": "https://doi.org/10.1364/ol.591422",
        "title": "Femtosecond laser inscribed fiber Bragg gratings based on precise spatial apodization: publisher’s note",
        "link": "https://doi.org/10.1364/ol.591422",
        "published": "2026-01-22",
        "author": "Daniel Franzen",
        "summary": "Abstract not available.",
        "journal": "Optics Letters",
        "title_cn": "基于精确空间变迹的飞秒激光刻写光纤布拉格光栅：出版商注释",
        "abstract_cn": "（摘要暂缺，等待官方补全）"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02004-8",
        "title": "Light structuring via nonlinear total angular momentum addition with flat optics",
        "link": "https://doi.org/10.1038/s41377-025-02004-8",
        "published": "2025-11-12",
        "author": "Evgenii Menshikov, Paolo Franceschini, Kristina Frizyuk, Ivan Fernandez-Corbaton, Andrea Tognazzi, Alfonso Carmelo Cino, Denis Garoli, Mihail Petrov, Domenico de Ceglia, Costantino De Angelis",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Shaping the structure of light with flat optical devices has driven significant advancements in our fundamental understanding of light and light-matter interactions, and enabled a broad range of applications, from image processing and microscopy to optical communication, quantum information processing, and the manipulation of microparticles. Yet, pushing the boundaries of structured light beyond the linear optical regime remains an open challenge. Nonlinear optical interactions, such as wave mixing in nonlinear flat optics, offer a powerful platform to unlock new degrees of freedom and functionalities for generating and detecting structured light. In this study, we experimentally demonstrate the non-trivial structuring of third-harmonic light enabled by the addition of total angular momentum projection in a nonlinear, isotropic flat optics element—a single thin film of amorphous silicon. We identify the total angular momentum projection and helicity as the most critical properties for analyzing the experimental results. The theoretical approach we propose, supported by numerical simulations, offers quantitative predictions for light structuring through nonlinear wave mixing under various pumping conditions, including vectorial and non-paraxial pump light. Notably, we reveal that the shape of third-harmonic light is highly sensitive to the polarization state of the pump. Our findings demonstrate that harnessing the addition of total angular momentum projection in nonlinear wave mixing can be a powerful strategy for generating and detecting precisely controlled structured light.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "通过平面光学器件的非线性总角动量相加进行光结构化",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>用平面光学器件塑造光的结构推动了我们对光和光与物质相互作用的基本理解的重大进步，并实现了广泛的应用，从图像处理和显微镜到光通信、量子信息处理和微粒操纵。然而，将结构光的边界推向线性光学范围之外仍然是一个开放的挑战。非线性光学相互作用，例如非线性平面光学中的波混合，提供了一个强大的平台来释放新的自由度和生成和检测结构光的功能。在这项研究中，我们通过实验证明了三次谐波光的重要结构，这是通过在非线性、各向同性平面光学元件（单片非晶硅薄膜）中添加总角动量投影来实现的。我们将总角动量投影和螺旋度确定为分析实验结果的最关键属性。我们提出的理论方法在数值模拟的支持下，通过各种泵浦条件（包括矢量和非近轴泵浦光）下的非线性波混合提供光结构的定量预测。值得注意的是，我们发现三次谐波光的形状对泵浦的偏振态高度敏感。我们的研究结果表明，利用非线性波混合中的总角动量投影可以成为生成和检测精确控制的结构光的强大策略。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02078-4",
        "title": "Double-chirped mirrors expand the bandwidth of infrared frequency combs",
        "link": "https://doi.org/10.1038/s41377-025-02078-4",
        "published": "2025-11-13",
        "author": "Jacob B. Khurgin",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>A novel dispersion-compensation scheme based on double-chirped Bragg mirrors is implemented in a mid-infrared quantum cascade laser. As a result, stable and broadband frequency combs are generated, which are indispensable for high-precision applications in spectroscopy and metrology.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "双啁啾镜扩展了红外频率梳的带宽",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>一种基于双啁啾布拉格镜的新型色散补偿方案在中红外量子级联激光器中实现。由此产生稳定且宽带的频率梳，这对于光谱学和计量学的高精度应用是必不可少的。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-01960-5",
        "title": "Non-Hermitian systems based on 3D chirality enabled asymmetrical polarization switching and omni-polarizer action at an EP",
        "link": "https://doi.org/10.1038/s41377-025-01960-5",
        "published": "2025-11-18",
        "author": "Xianhui Fu, Hao Hu, Jiawei Zhang, Jiwei Qi, Sihao Zhang, Qiang Wu, Yao Lu, Zongqiang Chen, Jing Chen, Xuanyi Yu, Qian Sun, Jingjun Xu",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Asymmetric mode/state switching and omni-polarizer action have demonstrated application potential and can be realized in non-Hermitian systems, which required a slow encircling process in the non-Hermitian parameter space in general. Is it possible to achieve the above functions only at an exceptional point (EP) without the encircling process? Here, we propose constructing a non-Hermitian system using three-dimensional (3D) chiral materials to realize the above functions at an EP instead of through the encircling process. Our results show that the 3D chiral non-Hermitian system exhibits properties that are quite different from those of traditional non-Hermitian optical systems. In our system, the eigenstates are different when propagating forward and backward, thus enabling asymmetric state switching. At the EP, the degenerate eigenstates of forward and backward propagations of the system become mutually orthogonal, which enables the system to act as an omni-polarizer. Crucially, to validate our claims, we propose a straightforward and widely applicable method to adjust a 3D chiral non-Hermitian system from a state far from an EP to near an EP. Based on this, we construct a free-space optical 3D chiral non-Hermitian system experimentally to directly observe the evolution of light polarization states near the EP. The experimental results prove that the proposed optical systems can achieve asymmetric state switching and omni polarizers at the EP, which is consistent with our theoretical expectations. Our work holds promise for various 3D chiral non-Hermitian optical applications, such as highly sensitive chirality measurements and polarization manipulation.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "基于 3D 手性的非厄米系统可在 EP 处实现不对称偏振切换和全偏振器动作",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>非对称模式/状态切换和全偏振器作用已展现出应用潜力，并且可以在非厄米系统中实现，这通常需要在非厄米参数空间中缓慢的环绕过程。是否可以只在异常点（EP）处实现上述功能，而不需要进行包围过程？在这里，我们建议使用三维（3D）手性材料构造一个非厄米系统，以在EP上实现上述功能，而不是通过环绕过程。我们的结果表明，3D 手性非厄米光学系统表现出与传统非厄米光学系统截然不同的特性。在我们的系统中，向前和向后传播时本征态是不同的，从而实现不对称状态切换。在 EP 处，系统的前向和后向传播的简并本征态变得相互正交，这使得系统能够充当全偏振器。至关重要的是，为了验证我们的主张，我们提出了一种简单且广泛适用的方法，将 3D 手性非厄米系统从远离 EP 的状态调整到接近 EP 的状态。在此基础上，我们通过实验构建了自由空间光学3D手性非厄米系统，以直接观察EP附近光偏振态的演化。实验结果证明，所提出的光学系统可以在EP处实现非对称状态切换和全向偏振器，这与我们的理论预期一致。我们的工作为各种 3D 手性非厄米光学应用带来了希望，例如高灵敏度手性测量和偏振操纵。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02042-2",
        "title": "Fast ultraviolet-C photonics: generating and sensing laser pulses on femtosecond timescales",
        "link": "https://doi.org/10.1038/s41377-025-02042-2",
        "published": "2025-11-19",
        "author": "Benjamin T. Dewes, Tim Klee, Nathan D. Cottam, Joseph J. Broughton, Mustaqeem Shiffa, Tin S. Cheng, Sergei V. Novikov, Oleg Makarovsky, John W. G. Tisch, Amalia Patané",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Photonic devices operating in the ultraviolet UV-C range (100–280 nm) have diverse applications from super-resolution microscopy to optical communications, and their advances promise to unlock new opportunities across science and technology. However, generating and detecting ultrafast light signals in this spectral range remains a major challenge. Here, we report an integrated UV-C source-sensor platform that combines phase-matched second-order processes in nonlinear optical crystals for the efficient generation of femtosecond UV-C laser pulses with a new class of room temperature photodetectors based on two-dimensional (2D) semiconductors. Unexpectedly, these 2D sensors exhibit a linear to super-linear photocurrent response to pulse energy, a highly desirable property, laying the foundation for UV-C-based photonics operating on femtosecond timescales over a wide range of pulse energies and repetition rates. As proof of concept, we demonstrate a free-space communication system.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "快速紫外-C 光子学：在飞秒时间尺度上生成和感测激光脉冲",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>在紫外 UV-C 范围（100–280nm）运行的光子器件具有从超分辨率显微镜到光通信的多种应用，它们的进步有望在科学和技术领域释放新的机遇。然而，生成和检测该光谱范围内的超快光信号仍然是一个重大挑战。在此，我们报告了一种集成的 UV-C 源传感器平台，该平台将非线性光学晶体中的相位匹配二阶过程与基于二维 (2D) 半导体的新型室温光电探测器相结合，以有效生成飞秒 UV-C 激光脉冲。出乎意料的是，这些二维传感器对脉冲能量表现出线性到超线性光电流响应，这是一种非常理想的特性，为在飞秒时间尺度上、广泛的脉冲能量和重复率范围内运行的基于 UV-C 的光子学奠定了基础。作为概念证明，我们演示了一个自由空间通信系统。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02022-6",
        "title": "Open-source sub-nanometer stabilization system for super-resolution fluorescence microscopy",
        "link": "https://doi.org/10.1038/s41377-025-02022-6",
        "published": "2025-11-20",
        "author": "Florencia Edorna, Florencia D. Choque, Giovanni Ferrari, Luciano A. Masullo, Piotr Zdańkowski, Guillermo P. Acuna, Philip Tinnefeld, Alan M. Szalai, Lucía F. Lopez, Andrés Zelcer, Fernando D. Stefani",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Recent advances in fluorescence nanoscopy have pushed resolution to the 1–10 nm range, enabling the direct visualization of individual molecules even in crowded biological environments. Achieving this level of precision requires rigorous sample drift control. Techniques such as MINFLUX and RASTMIN, which rely on keeping the sample fixed within an excitation pattern, demand active drift correction to achieve their theoretical nanometer-scale resolution limits. Here, we present an active stabilization system for super-resolution microscopy that delivers sub-nm precision for hours. Featuring a simple optical design, the system can be added as a separate module to any fluorescence microscope. We also provide an open-source control software including a user-friendly graphical interface readily adaptable to different setups. We demonstrate the adaptability and performance of the stabilization system with p-MINFLUX and RASTMIN measurements performed in two different setups, reaching the theoretical Cramér-Rao Bound and resolving ~10 nm distances within DNA origami structures.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于超分辨率荧光显微镜的开源亚纳米稳定系统",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>荧光纳米显微镜的最新进展已将分辨率提高到 1–10nm 范围，即使在拥挤的生物环境中也能够直接可视化单个分子。达到这种精度水平需要严格的样品漂移控制。 MINFLUX 和 RASTMIN 等技术依赖于将样品固定在激发模式内，需要主动漂移校正才能达到其理论纳米级分辨率极限。在这里，我们提出了一种用于超分辨率显微镜的主动稳定系统，可在数小时内提供亚纳米精度。该系统采用简单的光学设计，可以作为单独的模块添加到任何荧光显微镜中。我们还提供开源控制软件，包括易于适应不同设置的用户友好图形界面。我们通过在两种不同设置中进行的 p-MINFLUX 和 RASTMIN 测量来证明稳定系统的适应性和性能，达到理论 Cramér-Rao 界限并解析 DNA 折纸结构内约 10nm 的距离。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02072-w",
        "title": "Metasurface-assisted bioelectronics: bridging photonic innovation with biomedical implants",
        "link": "https://doi.org/10.1038/s41377-025-02072-w",
        "published": "2025-11-24",
        "author": "Mohammad Mohammadiaria, Shashi Bhushan Srivastava",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Wireless cellular stimulation has been widely applied for bioengineering and bidirectional communication with the brain. Different technologies, such as photoelectrical stimulation as an alternative to optogenetics, have emerged for a wide range of remote therapeutic applications using light. Metasurfaces enable pixel-wise control of electric field distribution by engineering absorption and wavefront shaping, with responses tuned to incident light polarization, frequency, and phase, offering precise stimulation and wireless control in retinal, cochlear, and cardiac implants. Moreover, by leveraging terahertz (THz) band patches, reconfigurable metasurfaces controlled via FPGA and holography, and virtual reality-assisted designs, these interfaces can revolutionize bioelectronic medicine.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "超表面辅助生物电子学：将光子创新与生物医学植入物联系起来",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>无线细胞刺激已广泛应用于生物工程和与大脑的双向通信。不同的技术，例如作为光遗传学替代方案的光电刺激，已经出现在各种使用光的远程治疗应用中。超表面通过工程吸收和波前整形实现电场分布的像素级控制，并根据入射光偏振、频率和相位调整响应，从而在视网膜、耳蜗和心脏植入物中提供精确的刺激和无线控制。此外，通过利用太赫兹 (THz) 频段补片、通过 FPGA 和全息术控制的可重构超表面以及虚拟现实辅助设计，这些接口可以彻底改变生物电子医学。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02076-6",
        "title": "Strong coupling of collective optical resonances in dielectric metasurfaces",
        "link": "https://doi.org/10.1038/s41377-025-02076-6",
        "published": "2025-11-24",
        "author": "Izzatjon Allayarov, Vittorio Aita, Diane J. Roth, Boaz van Casteren, Anton Yu. Bykov, Andrey B. Evlyukhin, Anatoly V. Zayats, Antonio Calà Lesina",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Dielectric metasurfaces can achieve strong light-matter interaction based on several types of collective (nonlocal) resonances, such as surface lattice resonances (SLRs) and quasi-bound states in the continuum (quasi-BICs). Spectral selectivity, field enhancement, and high and controllable Q-factors make these resonances appealing for technological applications in lasing, sensing, nonlinear optics, and quantum photon sources. An emerging challenge focuses on tailoring light-matter interaction via mode coupling and hybridisation between the fundamental resonances of a metasurface. While strong coupling phenomena have been demonstrated between various resonant modes, the interplay between collective resonances of different natures has not been observed to date. Here, we theoretically, numerically, and experimentally demonstrate the onset of coupling and hybridisation between symmetry-protected quasi-BICs and SLRs in a dielectric metasurface. We show the emergence of anticrossing (or Rabi splitting) in the strong coupling regime with suppression of reflection, observed under TE-polarised excitation, and the manifestation of an accidental BIC under TM-polarised illumination as a result of energy exchange between the participating collective resonances in the weak coupling regime. The first effect is accompanied by hybridised near fields of the modes. The observed coupling mechanisms can be controlled by modifying the angle of incidence, polarisation, and the surrounding environment. This foundational study on the coupling and hybridisation of collective resonances offers insights that can be leveraged for the design of metasurfaces with targeted quasi-aBIC and collective hybridised resonances. It could also open new possibilities to control the near fields associated with such resonances, with promising applications in tunable nanophotonics and light manipulation.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "介电超表面中集体光学共振的强耦合",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>介电超表面可以基于几种类型的集体（非局域）共振实现强光-物质相互作用，例如表面晶格共振（SLR）和连续体中的准束缚态（准BIC）。光谱选择性、场增强以及高且可控的 Q 因子使这些共振对于激光、传感、非线性光学和量子光子源中的技术应用具有吸引力。一个新兴的挑战集中在通过超表面基本共振之间的模式耦合和杂交来定制光与物质的相互作用。虽然各种共振模式之间已经证明了强耦合现象，但迄今为止尚未观察到不同性质的集体共振之间的相互作用。在这里，我们从理论上、数值上和实验上证明了介电超表面中对称保护的准 BIC 和 SLR 之间耦合和杂化的开始。我们展示了在 TE 偏振激发下观察到的强耦合区域中反交叉（或拉比分裂）的出现以及反射的抑制，以及由于弱耦合区域中参与的集体共振之间的能量交换而在 TM 偏振照明下出现的意外 BIC 的表现。第一个效应伴随着模式的混合近场。观察到的耦合机制可以通过改变入射角、偏振和周围环境来控制。这项关于集体共振耦合和杂化的基础研究提供了见解，可用于设计具有目标准 aBIC 和集体杂化共振的超表面。它还可以为控制与此类共振相关的近场开辟新的可能性，并在可调谐纳米光子学和光操纵方面具有广阔的应用前景。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02082-8",
        "title": "Ratiometric Boltzmann thermometry with Cr3+ in strong ligand fields: Efficient nonradiative coupling for record dynamic working ranges",
        "link": "https://doi.org/10.1038/s41377-025-02082-8",
        "published": "2025-11-25",
        "author": "Gülsüm Kinik, Ingo Widmann, Benedikt Bendel, Hubert Huppertz, Andries Meijerink, Markus Suta",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    A new ratiometric Boltzmann thermometry approach is presented for the narrow-line red-emitting bright phosphor Al\n                    <jats:sub>0.993</jats:sub>\n                    Cr\n                    <jats:sub>0.007</jats:sub>\n                    B\n                    <jats:sub>4</jats:sub>\n                    O\n                    <jats:sub>6</jats:sub>\n                    N. It relies on thermalization between the two excited states\n                    <jats:sup>2</jats:sup>\n                    <jats:italic>E</jats:italic>\n                    <jats:sub>\n                      <jats:italic>g</jats:italic>\n                    </jats:sub>\n                    (\n                    <jats:sup>2</jats:sup>\n                    G) and\n                    <jats:sup>2</jats:sup>\n                    <jats:italic>T</jats:italic>\n                    <jats:sub>\n                      1\n                      <jats:italic>g</jats:italic>\n                    </jats:sub>\n                    (\n                    <jats:sup>2</jats:sup>\n                    G) of Cr\n                    <jats:sup>3+</jats:sup>\n                    with an energy gap of 620 cm\n                    <jats:sup>−1</jats:sup>\n                    for optimized thermometry at room temperature. It is shown that nonradiative coupling between these excited states is very fast, with rates in the order of several µs\n                    <jats:sup>−1</jats:sup>\n                    . Due to the comparably slow radiative decay (\n                    <jats:italic>k</jats:italic>\n                    <jats:sub>r</jats:sub>\n                     = 0.033 ms\n                    <jats:sup>−</jats:sup>\n                    <jats:sup>1</jats:sup>\n                    ) of the lowest excited\n                    <jats:sup>2</jats:sup>\n                    <jats:italic>E</jats:italic>\n                    <jats:sub>\n                      <jats:italic>g</jats:italic>\n                    </jats:sub>\n                    (\n                    <jats:sup>2</jats:sup>\n                    G) state, the dynamic working range of this Boltzmann thermometer for the deep red spectral range is exceptionally wide, between &lt;77 K and &gt;873 K, even outperforming the classic workhorse example of Er\n                    <jats:sup>3+</jats:sup>\n                    . At temperatures above 340 K, also spectrally well-resolved broad-band emission due to the spin-allowed\n                    <jats:sup>4</jats:sup>\n                    <jats:italic>T</jats:italic>\n                    <jats:sub>\n                      2\n                      <jats:italic>g</jats:italic>\n                    </jats:sub>\n                    (\n                    <jats:sup>4</jats:sup>\n                    F) →\n                    <jats:sup>4</jats:sup>\n                    <jats:italic>A</jats:italic>\n                    <jats:sub>\n                      2\n                      <jats:italic>g</jats:italic>\n                    </jats:sub>\n                    (\n                    <jats:sup>4</jats:sup>\n                    F) transition is detectable, which simultaneously offers a possibility of very sensitive (\n                    <jats:italic>S</jats:italic>\n                    <jats:sub>r</jats:sub>\n                    (500 K) &gt; 2% K\n                    <jats:sup>−1</jats:sup>\n                    ) ratiometric Boltzmann-type crossover thermometry for higher temperatures. These findings imply that Al\n                    <jats:sub>0.993</jats:sub>\n                    Cr\n                    <jats:sub>0.007</jats:sub>\n                    B\n                    <jats:sub>4</jats:sub>\n                    O\n                    <jats:sub>6</jats:sub>\n                    N is a particularly robust and bright red luminescent thermometer with a record-breaking dynamic working range for a luminescent transition metal ion.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "强配体场中 Cr3+ 的比率玻尔兹曼测温：高效非辐射耦合，实现创纪录的动态工作范围",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    提出了一种新的比率玻尔兹曼测温方法，用于窄线红光荧光粉 Al\n                    <贾茨：子>0.993</贾茨：子>\n                    铬\n                    <jats:sub>0.007</jats:sub>\n                    乙\n                    <贾茨：子>4</贾茨：子>\n                    氧\n                    <贾茨：子>6</贾茨：子>\n                    N.它依赖于两个激发态之间的热化\n                    <贾茨：sup>2</贾茨：sup>\n                    <jats:斜体>E</jats:斜体>\n                    <贾茨：子>\n                      <jats：斜体>g</jats：斜体>\n                    </贾茨：子>\n                    （\n                    <贾茨：sup>2</贾茨：sup>\n                    G）和\n                    <贾茨：sup>2</贾茨：sup>\n                    <贾茨：斜体>T</贾茨：斜体>\n                    <贾茨：子>\n                      1\n                      <jats：斜体>g</jats：斜体>\n                    </贾茨：子>\n                    （\n                    <贾茨：sup>2</贾茨：sup>\n                    G) 铬\n                    <贾茨：sup>3+</贾茨：sup>\n                    能隙为 620 cm\n                    <jats:sup>−1</jats:sup>\n                    用于优化室温下的测温。结果表明，这些激发态之间的非辐射耦合非常快，速率约为几 µs\n                    <jats:sup>−1</jats:sup>\n                    。由于相对缓慢的辐射衰变（\n                    <jats：斜体>k</jats：斜体>\n                    <jats:sub>r</jats:sub>\n                     = 0.033 ms\n                    <jats:sup>−</jats:sup>\n                    <贾茨：sup>1</贾茨：sup>\n                    ）的最低兴奋\n                    <贾茨：sup>2</贾茨：sup>\n                    <jats:斜体>E</jats:斜体>\n                    <贾茨：子>\n                      <jats：斜体>g</jats：斜体>\n                    </贾茨：子>\n                    （\n                    <贾茨：sup>2</贾茨：sup>\n                    G) 状态下，该玻尔兹曼温度计在深红色光谱范围内的动态工作范围非常宽，介于 <77 K 和 >873 K 之间，甚至优于 Er 的经典主力示例\n                    <贾茨：sup>3+</贾茨：sup>\n                    。在高于 340 K 的温度下，由于自旋允许，光谱上也能很好地解析宽带发射\n                    <贾茨：sup>4</贾茨：sup>\n                    <贾茨：斜体>T</贾茨：斜体>\n                    <贾茨：子>\n                      2\n                      <jats：斜体>g</jats：斜体>\n                    </贾茨：子>\n                    （\n                    <贾茨：sup>4</贾茨：sup>\n                    F）→\n                    <贾茨：sup>4</贾茨：sup>\n                    <jats：斜体>A</jats：斜体>\n                    <贾茨：子>\n                      2\n                      <jats：斜体>g</jats：斜体>\n                    </贾茨：子>\n                    （\n                    <贾茨：sup>4</贾茨：sup>\n                    F) 转变是可检测的，同时提供了非常敏感的可能性（\n                    <jats:斜体>S</jats:斜体>\n                    <jats:sub>r</jats:sub>\n                    (500 K) > 2%钾\n                    <jats:sup>−1</jats:sup>\n                    ) 适用于较高温度的比例玻尔兹曼型交叉测温法。这些发现表明铝\n                    <贾茨：子>0.993</贾茨：子>\n                    铬\n                    <jats:sub>0.007</jats:sub>\n                    乙\n                    <贾茨：子>4</贾茨：子>\n                    氧\n                    <贾茨：子>6</贾茨：子>\n                    N 是一款特别坚固且亮红色的发光温度计，具有破纪录的发光过渡金属离子动态工作范围。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-01989-6",
        "title": "Emerging frontiers in SERS-integrated optical waveguides: advancing portable and ultra-sensitive detection for trace liquid analysis",
        "link": "https://doi.org/10.1038/s41377-025-01989-6",
        "published": "2025-11-26",
        "author": "Danheng Gao, Jiahao Liu, Xiao Liu, Kang He, Zhanyu Ma, Huan Liu, Jihou Wang, Qihan Zhang, Zhaonan Huang, Meng Luo, Haoran Meng, Rui Du, Juntao Gao, Qing Wu, Xinghua Yang",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Surface-Enhanced Raman Scattering (SERS) integrated with optical waveguide sensing offers a transformative approach to overcoming the limitations of conventional SERS techniques, such as complex alignment requirements and limited signal collection efficiency. By leveraging the unique properties of optical waveguides, this integration significantly enhances detection sensitivity, simplifies sensor design, and enables the analysis of ultra-low concentration analytes in trace-volume samples. This review explores the latest advancements in combining diverse optical waveguide architectures with SERS technology, focusing on strategies to optimize the sensing interface and SERS substrate design for maximal Raman signal enhancement. By enabling efficient analyte excitation and enhanced scattered signal collection through waveguide-mediated light-matter interactions, this approach unlocks new possibilities for high-sensitivity Raman detection. Furthermore, we discuss the potential of this integration to drive breakthroughs in fields such as biomedical diagnostics, environmental monitoring, and chemical sensing, paving the way for next-generation, portable and ultra-sensitive sensing platforms.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "SERS 集成光波导的新兴前沿：推进痕量液体分析的便携式超灵敏检测",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>与光波导传感集成的表面增强拉曼散射 (SERS) 提供了一种革命性的方法来克服传统 SERS 技术的局限性，例如复杂的对准要求和有限的信号收集效率。通过利用光波导的独特特性，这种集成显着提高了检测灵敏度，简化了传感器设计，并能够分析痕量样品中的超低浓度分析物。本综述探讨了将不同光波导架构与 SERS 技术相结合的最新进展，重点关注优化传感接口和 SERS 基板设计以实现最大拉曼信号增强的策略。通过波导介导的光-物质相互作用实现有效的分析物激发和增强的散射信号收集，这种方法为高灵敏度拉曼检测带来了新的可能性。此外，我们还讨论了这种集成在推动生物医学诊断、环境监测和化学传感等领域取得突破的潜力，为下一代便携式超灵敏传感平台铺平道路。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-01992-x",
        "title": "Toward noninvasive optoacoustic imaging of whole-heart dynamics in mice",
        "link": "https://doi.org/10.1038/s41377-025-01992-x",
        "published": "2025-11-27",
        "author": "Sandeep Kumar Kalva, Cagla Özsoy, Daniil Nozdriukhin, Savannah Tiemann, Lin Tang, Xosé Luís Deán-Ben, Daniel Razansky",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>High-speed volumetric optoacoustic tomography (VOT) offers powerful means for noninvasive, detailed visualization of rapid cardiac dynamics in mice. However, current implementations suffer from non-uniform light delivery into the thoracic area, which results in diminished penetration depth, limited field-of-view, and compromised quantification abilities. In this work, we devised a new VOT approach featuring hexagonally-shaped light delivery optimized for whole-heart imaging and an expedited imaging speed of 200 volumes per second using a custom-made spherical array transducer. The enhanced imaging performance was confirmed with calibration phantoms and noninvasive imaging of the murine heart. We capitalized on the reduced hemoglobin absorption in the second near-infrared (NIR-II) spectral window to mitigate the strong light attenuation by whole blood within the cardiac chambers while further employing copper sulfide nanoparticles featuring a strong NIR-II absorption to quantify cardiac functional parameters across the entire heart in vivo. The new approach can thus facilitate the monitoring of cardiac abnormalities and assessment of therapeutic interventions.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "小鼠全心脏动力学的无创光声成像",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>高速体积光声断层扫描 (VOT) 为小鼠快速心脏动态的无创、详细可视化提供了强大的手段。然而，当前的实施方案存在进入胸部区域的光不均匀传输的问题，这导致穿透深度减小、视野有限和量化能力受损。在这项工作中，我们设计了一种新的 VOT 方法，该方法具有针对全心脏成像优化的六边形光传输，以及使用定制的球形阵列换能器每秒 200 个体积的快速成像速度。通过校准模型和小鼠心脏的无创成像证实了增强的成像性能。我们利用第二近红外 (NIR-II) 光谱窗口中血红蛋白吸收的减少来减轻心室内全血的强光衰减，同时进一步采用具有强 NIR-II 吸收的硫化铜纳米粒子来量化体内整个心脏的心脏功能参数。因此，新方法可以促进心脏异常的监测和治疗干预的评估。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02129-w",
        "title": "A farewell to Co-Editor-in-Chief (Nov. 14, 2025)",
        "link": "https://doi.org/10.1038/s41377-025-02129-w",
        "published": "2025-11-27",
        "author": "Xi-Cheng Zhang",
        "summary": "Abstract not available.",
        "journal": "Light: Science & Applications",
        "title_cn": "告别联合主编（2025 年 11 月 14 日）",
        "abstract_cn": "（摘要暂缺，等待官方补全）"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02008-4",
        "title": "LSTM-assisted optical fiber interferometric sensing: breaking the limitation of free spectral range",
        "link": "https://doi.org/10.1038/s41377-025-02008-4",
        "published": "2025-12-01",
        "author": "Junling Hu, Sa Zhang, Meiyu Cai, Mingjian Ma, Shuguang Li, Hailiang Chen, Sigang Yang",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Optical fiber interferometric sensors are of great importance in chemistry, biology, and medicine disciplines owing to high-sensitivity and high-quality factor. However, due to the limitation of free spectral range, the inherent trade-off between wide measurement range and high sensitivity poses a persistent challenge in interference sensor development, which has fundamentally hindered their widespread adoption in precision measurement applications. In this work, a long short-term memory neural network is utilized in a Mach-Zehnder interference-based refractive index sensor to break the free spectral range limitation. Unique gating mechanism in long short-term memory neural network enables it to efficiently process long-term dependent sequence information, such as interference spectrum, avoiding the need for complex spectral signal analysis. A one-to-one mapping relationship is established between the interference spectrum and refractive index with root mean square error of 3.029 × 10\n                    <jats:sup>−4</jats:sup>\n                    and a coefficient of determination of 0.99971. The measurement range is extended from a single free spectral range of 1.3333–1.3561 to approximately three free spectral ranges of 1.3333–1.3921 without sacrificing sensitivity. Moreover, a wider measurement range can be achieved with sufficient training data. This work successfully resolves the inherent contradiction between high sensitivity and wide dynamic measurement range in optical interference-based sensors, opening up a path for the next generation of intelligent sensing systems.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "LSTM辅助光纤干涉传感：突破自由光谱范围的限制",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    光纤干涉传感器由于高灵敏度和高质量因素在化学、生物学和医学领域具有重要意义。然而，由于自由光谱范围的限制，宽测量范围和高灵敏度之间固有的权衡对干扰传感器的开发提出了持续的挑战，这从根本上阻碍了它们在精密测量应用中的广泛采用。在这项工作中，长短期记忆神经网络被用于基于马赫-曾德干涉的折射率传感器，以打破自由光谱范围的限制。长短期记忆神经网络独特的门控机制使其能够高效处理长期依赖的序列信息，例如干扰谱，从而避免了复杂的谱信号分析。干涉光谱与折射率建立一一对应关系，均方根误差为3.029 × 10\n                    <jats:sup>−4</jats:sup>\n                    决定系数为 0.99971。测量范围从 1.3333–1.3561 的单个自由光谱范围扩展到 1.3333–1.3921 的大约三个自由光谱范围，而不会牺牲灵敏度。此外，通过足够的训练数据可以实现更广泛的测量范围。这项工作成功解决了基于光学干涉的传感器中高灵敏度和宽动态测量范围之间的固有矛盾，为下一代智能传感系统开辟了道路。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02060-0",
        "title": "Reconfigurable SiC gratings in PDMS: a portable approach for atmospheric optical communication networks",
        "link": "https://doi.org/10.1038/s41377-025-02060-0",
        "published": "2025-12-02",
        "author": "Wanzhuo Ma, Yanwei Fu, Dongdong Han, Keyan Dong, Jiaqing Zeng, Qiang Wang, Peng Lin, Yonglai Zhang, Ye Gu, Zhi Liu, Xianzhu Liu, Huilin Jiang",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Free-space optical communication (FSOC) enables high-speed, secure, and scalable data transmission, with great potential for space–ground networks. However, existing FSOC systems predominantly employ point-to-point transmitters, each requiring bulky beam steering devices with complex control mechanisms, which severely limits their feasibility for multi-node micro-platform applications. Here, to address such a challenge, we propose a novel point-to-multipoint FSOC scheme based on reconfigurable SiC gratings, which are directly fabricated in stretchable PDMS films via femtosecond laser-induced carbide precipitation. The reconfigurable SiC transmission gratings are with good transparency (~91.9% at 1550 nm), dynamic beam steering capability (hundred-milliradian level), and an ultralightweight design (single grating: 0.4 g). The SiC fringes are specially fabricated within the internally symmetric region of the PDMS film to mitigate the structure distortion during stress regulation, significantly enhancing the long-range transmission capability in degraded atmospheric channels. The system supports 1-to-7 and 1-to-9 dynamic optical communication for 1D and 2D configurations, respectively. In a state-of-the-art 225-meter outdoor experiment, the system achieves reliable 10 Gbps transmission for each node. This portable FSOC system overcomes the limitations of conventional systems, enabling scalable and flexible multibeam steering. This approach establishes a robust foundation for long-range, multinode, and high-capacity FSOC networks among spatial micro-platforms such as unmanned aerial vehicles and micro-satellites.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "PDMS 中的可重构 SiC 光栅：大气光通信网络的便携式方法",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>自由空间光通信（FSOC）可实现高速、安全和可扩展的数据传输，在天地网络方面具有巨大潜力。然而，现有的FSOC系统主要采用点对点发射器，每个发射器都需要具有复杂控制机制的笨重波束控制装置，这严重限制了它们在多节点微平台应用中的可行性。在这里，为了解决这一挑战，我们提出了一种基于可重构 SiC 光栅的新型点对多点 FSOC 方案，该方案通过飞秒激光诱导碳化物沉淀直接制造在可拉伸 PDMS 薄膜中。可重构SiC透射光栅具有良好的透明度（1550nm处~91.9%）、动态光束控制能力（百毫弧度级）和超轻设计（单光栅：0.4g）。 SiC条纹是在PDMS薄膜的内部对称区域内专门制造的，以减轻应力调节过程中的结构变形，显着增强退化大气通道中的长距离传输能力。该系统分别支持一维和二维配置的1对7和1对9动态光通信。在最先进的225米户外实验中，该系统实现了每个节点10Gbps的可靠传输。这种便携式 FSOC 系统克服了传统系统的局限性，实现了可扩展且灵活的多波束转向。这种方法为无人机和微型卫星等空间微平台之间的长距离、多节点和大容量FSOC网络奠定了坚实的基础。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02088-2",
        "title": "Laser-driven resonant soft-X-ray scattering for probing picosecond dynamics of nanometre-scale order",
        "link": "https://doi.org/10.1038/s41377-025-02088-2",
        "published": "2025-12-02",
        "author": "Leonid Lunin, Martin Borchert, Niklas Schneider, Konstanze Korell, Michael Schneider, Dieter Engel, Stefan Eisebitt, Bastian Pfau, Daniel Schick",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>X-ray scattering has been an indispensable tool in advancing our understanding of matter, from the first evidence of the crystal lattice to recent discoveries of nuclei’s fastest dynamics. In addition to the lattice, ultrafast resonant elastic scattering of soft X-rays provides a sensitive probe of charge, spin, and orbital order with unparalleled nanometre spatial and femto- to picosecond temporal resolution. However, the full potential of this technique remains largely unexploited due to its high demand on the X-ray source. Only a selected number of instruments at large-scale facilities can deliver the required short-pulsed and wavelength-tunable radiation, rendering laboratory-scale experiments elusive so far. Here, we demonstrate time-resolved X-ray scattering with spectroscopic contrast at a laboratory-based instrument using the soft-X-ray radiation emitted from a laser-driven plasma source. Specifically, we investigate the photo-induced response of magnetic domains emerging in a ferrimagnetic FeGd heterostructure with 9 ps temporal resolution. The achieved sensitivity allows for tracking the reorganisation of the domain network on pico- to nanosecond time scales in great detail. This instrumental development and experimental demonstration break new ground for studying material dynamics in a wide range of laterally ordered systems in a flexible laboratory environment.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于探测纳米级皮秒动力学的激光驱动共振软 X 射线散射",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>X 射线散射一直是推进我们对物质理解的不可或缺的工具，从晶格的第一个证据到最近发现的原子核最快的动力学。除了晶格之外，软 X 射线的超快共振弹性散射还提供了电荷、自旋和轨道顺序的敏感探针，具有无与伦比的纳米空间和飞秒至皮秒时间分辨率。然而，由于对 X 射线源的高要求，该技术的全部潜力在很大程度上仍未得到充分利用。只有大型设施中选定数量的仪器才能提供所需的短脉冲和波长可调辐射，使得迄今为止实验室规模的实验难以实现。在这里，我们使用激光驱动等离子体源发射的软 X 射线辐射，在实验室仪器上演示了具有光谱对比度的时间分辨 X 射线散射。具体来说，我们研究了时间分辨率为 9 ps 的亚铁磁 FeGd 异质结构中出现的磁域的光致响应。所达到的灵敏度允许在皮秒到纳秒时间尺度上详细跟踪域网络的重组。该仪器开发和实验演示为在灵活的实验室环境中研究各种横向有序系统中的材料动力学开辟了新天地。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02054-y",
        "title": "Topology-driven energy transfer networks for upconversion stimulated emission depletion microscopy",
        "link": "https://doi.org/10.1038/s41377-025-02054-y",
        "published": "2025-12-04",
        "author": "Weizhao Gu, Simone Lamon, Haoyi Yu, Qiming Zhang, Min Gu",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Lanthanide-doped upconversion nanoparticles enable upconversion stimulated emission depletion microscopy with high photostability and low-intensity near-infrared continuous-wave lasers. Controlling energy transfer dynamics in these nanoparticles is crucial for super-resolution microscopy with minimal laser intensities and high photon budgets. However, traditional methods neglect the spatial distribution of lanthanide ions and its effect on energy transfer dynamics. Here, we introduce topology-driven energy transfer networks in lanthanide-doped upconversion nanoparticles for upconversion stimulated emission depletion microscopy with reduced laser intensities, maintaining a high photon budget. Spatial separation of Yb\n                    <jats:sup>3+</jats:sup>\n                    sensitizers and Tm\n                    <jats:sup>3+</jats:sup>\n                    emitters in 50-nm core-shell nanoparticles enhance energy transfer dynamics for super-resolution microscopy. Topology-dependent energy migration produces strong 450-nm upconversion luminescence under low-power 980-nm excitation. Enhanced cross-relaxation improves optical switching efficiency, achieving a saturation intensity of 0.06 MW cm\n                    <jats:sup>−2</jats:sup>\n                    under excitation at 980 nm and depletion at 808 nm. Super-resolution imaging with a 65-nm lateral resolution is achieved using intensities of 0.03 MW cm\n                    <jats:sup>−2</jats:sup>\n                    for a Gaussian-shaped excitation laser at 980 nm and 1 MW cm\n                    <jats:sup>−2</jats:sup>\n                    for a donut-shaped depletion laser at 808 nm, representing a 10-fold reduction in excitation intensity and a 3-fold reduction in depletion intensity compared to conventional methods. These findings demonstrate the potential of harnessing topology-dependent energy transfer dynamics in upconversion nanoparticles for advancing low-power super-resolution applications.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于上转换受激发射损耗显微镜的拓扑驱动的能量传输网络",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    稀土元素掺杂的上转换纳米颗粒使上转换受激发射损耗显微镜具有高光稳定性和低强度近红外连续波激光器。控制这些纳米颗粒中的能量传递动力学对于具有最小激光强度和高光子预算的超分辨率显微镜至关重要。然而，传统方法忽略了镧系离子的空间分布及其对能量传递动力学的影响。在这里，我们在镧系元素掺杂的上转换纳米粒子中引入了拓扑驱动的能量转移网络，用于上转换受激发射耗尽显微镜，降低了激光强度，保持了高光子预算。 Yb 的空间分离\n                    <贾茨：sup>3+</贾茨：sup>\n                    敏化剂和Tm\n                    <贾茨：sup>3+</贾茨：sup>\n                    50 纳米核壳纳米粒子中的发射器增强了超分辨率显微镜的能量传递动力学。拓扑相关的能量迁移在低功率 980 nm 激发下产生强烈的 450 nm 上转换发光。增强的交叉弛豫提高了光开关效率，实现了 0.06 MW cm 的饱和强度\n                    <jats:sup>−2</jats:sup>\n                    激发波长为 980 nm，耗尽波长为 808 nm。使用 0.03 MW cm 的强度可实现横向分辨率为 65 nm 的超分辨率成像\n                    <jats:sup>−2</jats:sup>\n                    用于 980nm 和 1MWcm 的高斯形激发激光\n                    <jats:sup>−2</jats:sup>\n                    对于 808 nm 的环形耗尽激光器，与传统方法相比，激发强度降低了 10 倍，耗尽强度降低了 3 倍。这些发现证明了利用上转换纳米颗粒中拓扑相关的能量转移动力学来推进低功耗超分辨率应用的潜力。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02064-w",
        "title": "Advancements in transfer printing techniques and their applications in photonic integrated circuits",
        "link": "https://doi.org/10.1038/s41377-025-02064-w",
        "published": "2025-12-05",
        "author": "Can Yu, Meng Zhang, Lei Liang, Li Qin, Yongyi Chen, Yuxin Lei, Yubing Wang, Yue Song, Cheng Qiu, Peng Jia, Dabing Li, Lijun Wang",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Transfer printing is a powerful and versatile integration method that is attracting increasing attention as regards both scientific research and industrial manufacturing. The transfer printing technique utilizes the viscoelastic properties of a stamp to pick devices (ink) from a donor substrate and print them onto a target substrate, exploiting the competition between several interfacial adhesion forces. The overall yield can be improved through the introduction of external stimuli such as light, heat, solution, pressure, and magnetic fields during the transfer printing operation. This review summarizes different transfer printing methods based on their working principles and discusses their detailed applications in photonic integrated circuits, taking lasers, semiconductor optical amplifiers, photodetectors, and other optical electronic elements as examples. Hence, the feasibility and viability of transfer printing are illustrated. Additionally, future challenges and opportunities for innovative development are discussed.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "转移印刷技术的进展及其在光子集成电路中的应用",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>转移印刷是一种强大且多功能的集成方法，在科学研究和工业制造方面越来越受到关注。转移印刷技术利用印模的粘弹性特性从供体基板上拾取器件（墨水）并将其印刷到目标基板上，利用几种界面粘附力之间的竞争。在转移印刷操作过程中，可以通过引入光、热、溶液、压力和磁场等外部刺激来提高总体产量。本文根据其工作原理总结了不同的转移印刷方法，并以激光器、半导体光放大器、光电探测器和其他光学电子元件为例，讨论了它们在光子集成电路中的详细应用。由此可见，转移印花的可行性和可行性。此外，还讨论了未来创新发展的挑战和机遇。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-01978-9",
        "title": "Whispering-gallery-mode resonators for detection and classification of free-flowing nanoparticles and cells through photoacoustic signatures",
        "link": "https://doi.org/10.1038/s41377-025-01978-9",
        "published": "2025-12-11",
        "author": "Jie Liao, Maxwell Adolphson, Hangyue Li, Dipayon Kumar Sikder, Chenyang Lu, Lan Yang",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Micro and nanoscale particles have played crucial roles across diverse fields, from biomedical imaging and environmental processes to early disease diagnosis, influencing numerous scientific research and industrial applications. Their unique characteristics demand accurate detection, characterization, and identification. However, conventional spectroscopy and microscopy commonly used to characterize and identify tiny objects often involve bulky equipment and intricate, time-consuming sample preparation. Over the past two decades, optical micro-sensors have emerged as a promising sensor technology with their high sensitivity and compact configuration. However, their broad applicability is constrained by the requirement of surface binding for selective sensing and the difficulty in differentiating between various sensing targets, which limits their application in detecting targets in their native state or in complex biological samples. Developing label-free and immobilization-free sensing techniques that can directly detect target particles in complex solutions is crucial for overcoming the inherent limitations of current biosensors. In this study, we design and demonstrate an optofluidic, high throughput, ultra-sensitive optical microresonator sensor that can capture subtle acoustic signals, generated by tiny particles from the absorption of pulsed light energy, providing photoacoustic spectroscopy information for real-time, label-free detection and interrogation of particles and cells in their native solution environments across an extended sensing volume. Leveraging unique optical absorption of the targets, our technique can selectively detect and classify particles flowing through the sensor systems without the need for surface binding, even in a complex sample matrix, such as whole blood samples. We showcase the measurement of gold nanoparticles with diverse geometries and different species of red blood cells in the presence of other cellular elements and a wide variety of proteins. These particles are effectively identified and classified based on their photoacoustic fingerprint that captures particle shape, composition, molecule properties, and morphology features. This work opens up new avenues to achieve rapid, reliable, and high-throughput particle and cell identification in clinical and industrial applications, offering a valuable tool for understanding complex biological and environmental systems.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "回音壁模式谐振器，用于通过光声特征对自由流动的纳米粒子和细胞进行检测和分类",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>微米和纳米级颗粒在从生物医学成像和环境过程到早期疾病诊断的各个领域发挥着至关重要的作用，影响着众多的科学研究和工业应用。它们独特的特性需要准确的检测、表征和识别。然而，通常用于表征和识别微小物体的传统光谱学和显微镜通常涉及笨重的设备和复杂且耗时的样品制备。在过去的二十年里，光学微传感器以其高灵敏度和紧凑的结构而成为一种有前途的传感器技术。然而，它们的广泛适用性受到选择性传感表面结合的要求以及区分各种传感目标的难度的限制，这限制了它们在检测天然状态或复杂生物样品中的目标中的应用。开发可直接检测复杂溶液中目标颗粒的无标记和无固定化传感技术对于克服当前生物传感器的固有局限性至关重要。在这项研究中，我们设计并演示了一种光流控、高通量、超灵敏的光学微谐振器传感器，该传感器可以捕获微小颗粒吸收脉冲光能产生的微妙声学信号，提供光声光谱信息，以便在扩展的传感体积内实时、无标记地检测和询问原生溶液环境中的颗粒和细胞。利用目标独特的光学吸收，我们的技术可以选择性地检测和分类流经传感器系统的颗粒，无需表面结合，即使在复杂的样品基质（例如全血样品）中也是如此。我们展示了在其他细胞元素和多种蛋白质存在的情况下，对具有不同几何形状和不同种类红细胞的金纳米颗粒的测量。这些颗粒根据其光声指纹进行有效识别和分类，捕获颗粒形状、成分、分子特性和形态特征。这项工作开辟了在临床和工业应用中实现快速、可靠和高通量的颗粒和细胞识别的新途径，为理解复杂的生物和环境系统提供了有价值的工具。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-01988-7",
        "title": "V-band ultra-fast tunable thin-film lithium niobate Fourier-domain mode-locked optoelectronic oscillator",
        "link": "https://doi.org/10.1038/s41377-025-01988-7",
        "published": "2025-12-11",
        "author": "Rui Ma, Zijun Huang, X. Steve Yao, Peng Hao, Wei Ke, Xinlun Cai",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>We demonstrate the first Fourier-domain mode-locked optoelectronic oscillator (FDML OEO) fabricated on the thin-film lithium niobate (TFLN) platform, deploying an electrically tuned ultra-fast frequency-scanning filter, thanks to the high-speed Pockels effect in TFLN. Record-breaking high radiofrequency oscillations up to 65 GHz are achieved, with a phase noise more than 14 dB less at 50 GHz than that of a high-performance commercial signal source at an offset frequency of 10 kHz away from the carrier. A linearly chirped microwave waveform with an unprecedented scanning bandwidth of 30 GHz, corresponding to an impressive chirp rate of 5.7 GHz/μs and a large time-bandwidth product of 159054, is successfully generated by the FDML OEO. These results validate the feasibility of utilizing TFLN to fabricate integrated FDML OEOs capable of delivering ultra-wide scanning bandwidth at chirp rates and frequencies not attainable with any other approaches to date.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "V波段超快可调谐薄膜铌酸锂傅里叶域锁模光电振荡器",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>我们展示了第一个在薄膜铌酸锂 (TFLN) 平台上制造的傅里叶域锁模光电振荡器 (FDML OEO)，由于 TFLN 中的高速普克尔斯效应，部署了电调谐超快频率扫描滤波器。实现了高达 65GHz 的破纪录高射频振荡，在 50GHz 时相位噪声比远离载波 10kHz 偏移频率的高性能商用信号源低 14dB 以上。 FDML OEO 成功生成了具有前所未有的 30GHz 扫描带宽的线性啁啾微波波形，对应于 5.7GHz/μs 的令人印象深刻的啁啾速率和 159054 的大时间带宽积。这些结果验证了利用 TFLN 制造集成 FDML OEO 的可行性，该集成 FDML OEO 能够以迄今为止任何其他方法都无法达到的啁啾速率和频率提供超宽扫描带宽。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02116-1",
        "title": "The plasmonic BTO-on-SiN platform – beyond 200 GBd modulation for optical communications",
        "link": "https://doi.org/10.1038/s41377-025-02116-1",
        "published": "2025-12-16",
        "author": "Manuel Kohli, Daniel Chelladurai, Laurenz Kulmer, Tobias Blatter, Yannik Horst, Killian Keller, Michael Doderer, Joel Winiger, David Moor, Andreas Messner, Tatiana Buriakova, Clarissa Convertino, Felix Eltes, Yuriy Fedoryshyn, Ueli Koch, Juerg Leuthold",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>An integrated photonics platform that offers high-speed modulators in addition to low-loss and versatile passive components is highly sought after for different applications ranging from AI to next-generation Tbit/s links in optical fiber communication. For this purpose, we introduce the plasmonic BTO-on-SiN platform for high-speed electro-optic modulators. This platform combines the advantages provided by low-loss silicon nitride (SiN) photonics with the highly nonlinear barium titanate (BTO) as the active material. Nanoscale plasmonics enables high-speed modulators operating at electro-optical bandwidths up to 110 GHz with active lengths as short as 5 µm. Here, we demonstrate three different modulators: a 256 GBd C-band Mach-Zehnder (MZ) modulator, a 224 GBd C-band IQ modulator – being both the first BTO IQ and the first IQ modulator on SiN for data communication – and finally, a 200 GBd O-band racetrack (RT) modulator. With this approach we show record data rates of 448 Gbit/s with the IQ modulator and 340 Gbit/s with the MZ modulator. Furthermore, we demonstrate the first plasmonic RT modulator with BTO and how it is ideally suited for low complexity communication in the O-band with low device loss of 2 dB. This work leverages the SiN platform and shows the potential of this technology to serve as a solution to combat the ever-increasing demand for fast modulators.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "SiN 上的等离子体 BTO 平台 – 超过 200 GBd 的光通信调制",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>除了低损耗和多功能无源元件之外，还提供高速调制器的集成光子平台受到从人工智能到光纤通信中的下一代 Tbit/s 链路等不同应用的高度追捧。为此，我们推出了用于高速电光调制器的等离子体 BTO-on-SiN 平台。该平台结合了低损耗氮化硅（SiN）光子学与作为活性材料的高度非线性钛酸钡（BTO）所提供的优势。纳米级等离子体激元使高速调制器能够在高达 110GHz 的电光带宽下运行，有效长度短至 5μm。在这里，我们演示了三种不同的调制器：256 GBd C 波段 Mach-Zehnder (MZ) 调制器、224 GBd C 波段 IQ 调制器（既是第一个 BTO IQ 也是 SiN 上用于数据通信的第一个 IQ 调制器），最后是 200 GBd O 波段赛道 (RT) 调制器。通过这种方法，我们使用 IQ 调制器实现了 448 Gbit/s 的创纪录数据速率，使用 MZ 调制器实现了 340 Gbit/s 的创纪录数据速率。此外，我们还展示了首款采用 BTO 的等离子体 RT 调制器，以及它如何非常适合 O 频段的低复杂性通信，且器件损耗低至 2 dB。这项工作利用了 SiN 平台，并展示了该技术作为解决方案的潜力，以满足对快速调制器不断增长的需求。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02089-1",
        "title": "Large-area photonic circuits for terahertz detection and beam profiling",
        "link": "https://doi.org/10.1038/s41377-025-02089-1",
        "published": "2026-01-01",
        "author": "Alessandro Tomasino, Amirhassan Shams-Ansari, Marko Lončar, Ileana-Cristina Benea-Chelmus",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Deployment of terahertz communication and spectroscopy systems relies on the availability of low-noise and fast detectors, with plug-and-play capabilities. However, most current technologies are stand-alone, discrete components. They are often slow or susceptible to temperature drifts and require tight beam focusing to maximize the signal-to-noise of the detector. Here, we demonstrate an integrated photonic architecture in thin-film lithium niobate that addresses these challenges by exploiting the electro-optic modulation induced by a terahertz signal onto an optical beam at telecom frequencies. Leveraging on the low optical losses provided by this platform, we integrate a double array of up to 18 terahertz antennas within a Mach–Zehnder interferometer, considerably extending the device collection area and boosting the interaction efficiency between the terahertz signal and the optical beam. We show that the double array coherently builds up the probe modulation through a mechanism of quasi-phase-matching, driven by a periodic terahertz near-field pattern, circumventing physical inversion of the crystallographic domains. This provides means to fully custom-tailor the frequency response of the device, limit it to a desired frequency band and effectively suppress out-of-band signals. The large detection area ensures correct operation with diverse terahertz beam settings. Furthermore, we show that the antennas act as pixels that allow reconstruction of the terahertz beam profile impinging on the detector area. Our on-chip design in thin-film lithium niobate overcomes the detrimental effects of two-photon absorption and fixed phase-matching conditions, which have plagued previously explored electro-optic detection systems, especially in the telecom band, paving the way for more advanced on-chip terahertz systems.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于太赫兹检测和光束分析的大面积光子电路",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>太赫兹通信和光谱系统的部署依赖于具有即插即用功能的低噪声、快速探测器的可用性。然而，大多数当前技术都是独立的分立组件。它们通常速度缓慢或容易受到温度漂移的影响，并且需要严格的光束聚焦以最大限度地提高探测器的信噪比。在这里，我们展示了薄膜铌酸锂中的集成光子架构，该架构通过利用太赫兹信号在电信频率光束上引起的电光调制来解决这些挑战。利用该平台提供的低光学损耗，我们在马赫-曾德干涉仪内集成了多达 18 个太赫兹天线的双阵列，大大扩展了设备收集面积并提高了太赫兹信号与光束之间的交互效率。我们表明，双阵列通过准相位匹配机制相干地建立探针调制，由周期性太赫兹近场模式驱动，避免了晶体域的物理反转。这提供了完全定制设备频率响应、将其限制在所需频带并有效抑制带外信号的方法。大的检测区域确保了不同太赫兹光束设置的正确操作。此外，我们还表明，天线充当像素，允许重建撞击探测器区域的太赫兹光束轮廓。我们的薄膜铌酸锂片上设计克服了双光子吸收和固定相位匹配条件的不利影响，这些影响一直困扰着之前探索的电光检测系统，特别是在电信频段，为更先进的片上太赫兹系统铺平了道路。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02077-5",
        "title": "FACE-ing the future of single-pixel complex-field microscopy beyond the visible spectrum",
        "link": "https://doi.org/10.1038/s41377-025-02077-5",
        "published": "2026-01-01",
        "author": "Stefan G. Stanciu, Edoardo Charbon",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Single-pixel imaging (SPI) has long been recognized for its potential in spectral regions where conventional imaging sensors fall short, such as the near-infrared spectrum. Yet, despite its sensitivity, SPI and its complex-field variants have faced critical bottlenecks in speed and throughput, hindering their adoption for real-time applications. A recently proposed approach—frequency-comb acousto-optic coherent encoding (FACE)—places an important step in overcoming these barriers, delivering an unprecedented space-bandwidth-time product. By showcasing its versatility through several compelling proof-of-concept demonstrations in real-time complex-field microscopy, this advance paves the way for transformative progress in optical imaging beyond the visible spectrum. We discuss here advantages, challenges and potential future directions for scaling up this technology.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "面对可见光谱之外的单像素复杂视场显微镜的未来",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>单像素成像 (SPI) 长期以来因其在传统成像传感器无法满足的光谱区域（例如近红外光谱）中的潜力而得到认可。然而，尽管具有敏感性，SPI 及其复杂字段变体在速度和吞吐量方面仍面临关键瓶颈，阻碍了它们在实时应用中的采用。最近提出的一种方法——频率梳声光相干编码（FACE）——在克服这些障碍方面迈出了重要的一步，提供了前所未有的空间带宽时间乘积。通过实时复杂视场显微镜中几个令人信服的概念验证演示，展示了其多功能性，这一进步为可见光谱以外的光学成像的变革性进展铺平了道路。我们在这里讨论扩大这项技术的优势、挑战和潜在的未来方向。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02148-7",
        "title": "Model-free optical processors using in situ reinforcement learning with proximal policy optimization",
        "link": "https://doi.org/10.1038/s41377-025-02148-7",
        "published": "2026-01-01",
        "author": "Yuhang Li, Shiqi Chen, Tingyu Gong, Aydogan Ozcan",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Optical computing holds promise for high-speed, energy-efficient information processing, with diffractive optical networks emerging as a flexible platform for implementing task-specific transformations. A challenge, however, is the effective optimization and alignment of the diffractive layers, which is hindered by the difficulty of accurately modeling physical systems with their inherent hardware imperfections, noise, and misalignments. While existing in situ optimization methods offer the advantage of direct training on the physical system without explicit system modeling, they are often limited by slow convergence and unstable performance due to inefficient use of limited measurement data. Here, we introduce a model-free reinforcement learning approach utilizing Proximal Policy Optimization (PPO) for the in situ training of diffractive optical processors. PPO efficiently reuses in situ measurement data and constrains policy updates to ensure more stable and faster convergence. We validated our method through both simulations and experiments across a range of in situ learning tasks, including targeted energy focusing through a random diffuser, image generation, aberration correction, and optical image classification, demonstrating in each task better convergence and performance. Our strategy operates directly on the physical system and naturally accounts for unknown real-world imperfections, eliminating the need for prior system knowledge or modeling. By enabling faster and more accurate training under realistic experimental constraints, this in situ reinforcement learning approach could offer a scalable framework for various optical and physical systems governed by complex, feedback-driven dynamics.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "使用具有近端策略优化的原位强化学习的无模型光学处理器",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>光学计算有望实现高速、节能的信息处理，衍射光学网络正在成为实现特定任务转换的灵活平台。然而，一个挑战是衍射层的有效优化和对准，由于物理系统固有的硬件缺陷、噪声和未对准，精确建模的困难阻碍了这一点。虽然现有的原位优化方法具有无需显式系统建模即可直接在物理系统上进行训练的优点，但由于有限测量数据的使用效率低下，它们通常受到收敛速度慢和性能不稳定的限制。在这里，我们介绍了一种利用近端策略优化（PPO）进行衍射光学处理器原位训练的无模型强化学习方法。 PPO有效地复用原位测量数据并约束策略更新，以确保更稳定和更快的收敛。我们通过一系列原位学习任务的模拟和实验验证了我们的方法，包括通过随机扩散器进行目标能量聚焦、图像生成、像差校正和光学图像分类，在每个任务中展示了更好的收敛和性能。我们的策略直接在物理系统上运行，自然地考虑了未知的现实世界缺陷，消除了对先前系统知识或建模的需要。通过在现实的实验约束下实现更快、更准确的训练，这种原位强化学习方法可以为由复杂的反馈驱动动力学控制的各种光学和物理系统提供可扩展的框架。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02080-w",
        "title": "Frequency-comb enabled spectrum-correlation reflectometry for distributed fiber-optic sensing",
        "link": "https://doi.org/10.1038/s41377-025-02080-w",
        "published": "2026-01-01",
        "author": "Zhonghong Lin, Zhiyong Zhao, Huan He, Can Chen, Ming Tang, Marcelo A. Soto",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Distributed fiber-optic sensing has become an indispensable tool for large-scale structural and environmental monitoring, where spectral interrogation of backscattering light enables high-precision quantitative measurement of external perturbations. Conventional spectral analysis methods, typically based on frequency-domain serial interrogation or time-to-frequency mapping, face inherent trade-offs between measurement speed, dynamic strain measurement range, and system complexity. Here, we present a distributed frequency comb enabled spectrum-correlation reflectometry as a universal spectral analysis framework that leverages optical frequency comb for parallel multi-frequency interrogation, which is experimentally demonstrated in a phase-sensitive optical time-domain reflectometry (φ-OTDR) system. This method eliminates the need for large frequency scans, achieving more than tenfold improvement in measurement speed over the state-of-the-art spectral analysis methods. Compared to existing phase-demodulated φ-OTDR systems, this method enables vibration amplitude monitoring with a dynamic strain measurement range expanded by more than an order of magnitude, while intrinsically circumventing phase unwrapping issues and interference fading. This work establishes a new paradigm for distributed spectral analysis, providing a flexible and robust platform for a wide range of sensing technologies, including Rayleigh and Brillouin-based schemes, which may have significant impact for geophysics, seismology, civil engineering, and other fields.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于分布式光纤传感的频率梳光谱相关反射计",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>分布式光纤传感已成为大规模结构和环境监测不可或缺的工具，其中反向散射光的光谱询问能够对外部扰动进行高精度定量测量。传统的频谱分析方法通常基于频域串行询问或时频映射，面临测量速度、动态应变测量范围和系统复杂性之间固有的权衡。在这里，我们提出了一种分布式频率梳启用频谱相关反射计作为通用频谱分析框架，利用光学频率梳进行并行多频询问，这在相敏光学时域反射计（φ-OTDR）系统中进行了实验证明。该方法无需进行大频率扫描，测量速度比最先进的频谱分析方法提高十倍以上。与现有的相位解调 φ-OTDR 系统相比，该方法能够实现振动幅度监测，动态应变测量范围扩大了一个数量级以上，同时从本质上避免了相位展开问题和干扰衰落。这项工作建立了分布式谱分析的新范式，为各种传感技术提供了灵活而强大的平台，包括基于瑞利和布里渊的方案，这可能对地球物理学、地震学、土木工程和其他领域产生重大影响。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02073-9",
        "title": "Mode splitting in optical microcavities for speckle-free wavelength reconstruction",
        "link": "https://doi.org/10.1038/s41377-025-02073-9",
        "published": "2026-01-01",
        "author": "Ivan Saetchnikov, Elina Tcherniavskaia, Andreas Ostendorf, Anton Saetchnikov",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Accurate wavelength measurement is critical for spectroscopy, optical communications, semiconductor manufacturing, and quantum research. Emerging reconstructive wavemeters are compact, cost-effective devices that utilize pseudo-random wavelength patterns and computational techniques to provide high-resolution, broadband alternatives to solutions based on frequency beating and interferometry. We propose a novel reconstructive wavemeter that synergizes the advantages of both approaches. Its physical model is based on the integration of thousands of high-quality-factor optical microcavities, which are deformed to stimulate whispering gallery mode splitting. For realizing a wavelength interpreter, we developed a hybrid machine learning approach utilizing boosting methods and variational autoencoders. This enabled the implementation of wavelength interpretation as a rigorous regression task for the first time. The introduced novel concept ensures the uniqueness of the wavelength patterns up to ultra-wide (~100 nm) spectral window while guarantees high (~100 fm) intrinsic sensitivity. The latter allocates the proposed solution right next to the ultimate reconstructive wavemeters based on integrating spheres, but with less calibration efforts, featuring superior miniaturization options and chip-scale integrability.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "光学微腔中的模式分裂用于无散斑波长重建",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>准确的波长测量对于光谱学、光通信、半导体制造和量子研究至关重要。新兴的重构波长计是紧凑、经济高效的设备，利用伪随机波长模式和计算技术为基于频率跳动和干涉测量的解决方案提供高分辨率、宽带替代方案。我们提出了一种新颖的重构波长计，可以协同两种方法的优点。其物理模型基于数千个高质量因数光学微腔的集成，这些微腔变形以刺激回音壁模式分裂。为了实现波长解释器，我们开发了一种利用增强方法和变分自动编码器的混合机器学习方法。这使得波长解释首次成为严格的回归任务。引入的新颖概念确保了高达超宽（~100 nm）光谱窗口的波长模式的独特性，同时保证了高（~100 fm）固有灵敏度。后者将所提出的解决方案分配给基于积分球的最终重构波长计，但校准工作量较少，具有卓越的小型化选项和芯片级可集成性。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02106-3",
        "title": "Quantum walk with coherent multiple translations induces fast quantum gate operations",
        "link": "https://doi.org/10.1038/s41377-025-02106-3",
        "published": "2026-01-01",
        "author": "Yixiang Zhang, Xin Qiao, Luojia Wang, Yanyan He, Zhaohui Dong, Xianfeng Chen, Luqi Yuan",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Quantum walks with one-dimensional translational symmetry are important for quantum algorithms, where the speed-up of the diffusion speed can be reached if long-range couplings are added. Our work studies a scheme of a ring under the strong resonant modulation that can support a discrete-time quantum walk including coherent multiple long-range translations in a natural way along the synthetic frequency dimension. These multiple translation paths are added in a coherent way, which makes the walker evolve under the topological band. Therein, not only the fast diffusion speed is expected, but more importantly, we find that single quantum gate operations can be performed in the quasi-momentum space. In particular, we show the arbitrary single-qubit state preparation and an example of CNOT two-qubit gate with only one time step, dramatically increasing quantum algorithms. Our study uses the modulated ring to provide fast quantum gate operations based on coherent multiple path quantum walk, which may provide unique designs for efficient quantum operations on photonic chips.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "具有相干多重平移的量子行走引发快速量子门操作",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>具有一维平移对称性的量子行走对于量子算法非常重要，如果添加长程耦合，就可以实现扩散速度的加速。我们的工作研究了强谐振调制下的环方案，该方案可以支持离散时间量子行走，包括沿合成频率维度以自然方式进行相干多个长程平移。这些多个平移路径以连贯的方式添加，使得步行者在拓扑带下进化。其中，不仅期望快速的扩散速度，更重要的是，我们发现可以在准动量空间中进行单量子门操作。特别是，我们展示了任意单量子位状态准备和仅一个时间步的 CNOT 双量子位门的示例，极大地增加了量子算法。我们的研究使用调制环提供基于相干多路量子行走的快速量子门操作，这可能为光子芯片上的高效量子操作提供独特的设计。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02100-9",
        "title": "Programmable optoelectronic Ising machine for optimization of real-world problems",
        "link": "https://doi.org/10.1038/s41377-025-02100-9",
        "published": "2026-01-01",
        "author": "Zhewen Hu, Yanbo Ren, Yao Meng, Tiejun Wang, Yanchen Jiang, Miaomiao Wei, Ye Xiao, Zhentong Li, Ming Li",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Ising machines offer a paradigm shift from traditional computing methods, tackling complex combinatorial optimization problems (COPs). Despite the proliferation of various Ising machine implementations, their application to solve real-world COPs has been limited. Here, we introduce a high-performance optoelectronic Ising machine (OEIM), based on optoelectronic parametric oscillators, that represents a significant advancement in this field. With 4096 Ising spins, arbitrary coupling capabilities, and unparalleled long-term stability, our OEIM outperforms traditional computing approaches in both accuracy and speed. By solving the benchmark maximum cut problem, we demonstrate its superior performance. More importantly, we apply the OEIM to a real-world traffic optimization problem, using real traffic data and a classical traffic model, and achieve results that far surpass those of conventional computers. This work not only validates the OEIM’s capability to solve complex practical challenges but also heralds a new era in real-time traffic management, where high-performance optoelectronic Ising machines enable rapid and efficient solutions to critical societal issues.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于优化现实世界问题的可编程光电伊辛机",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>伊辛机提供了传统计算方法的范式转变，可解决复杂的组合优化问题 (COP)。尽管各种伊辛机实现不断涌现，但它们在解决现实世界 COP 问题上的应用仍然受到限制。在这里，我们介绍了一种基于光电参量振荡器的高性能光电伊辛机（OEIM），它代表了该领域的重大进步。凭借 4096 个伊辛自旋、任意耦合能力和无与伦比的长期稳定性，我们的 OEIM 在精度和速度方面均优于传统计算方法。通过解决基准最大割问题，我们展示了其优越的性能。更重要的是，我们使用真实的交通数据和经典的交通模型，将OEIM应用于现实世界的交通优化问题，并取得了远远超过传统计算机的结果。这项工作不仅验证了 OEIM 解决复杂实际挑战的能力，而且预示着实时交通管理的新时代，高性能光电 Ising 机器能够快速有效地解决关键的社会问题。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02144-x",
        "title": "Exceptional-point-encirclement emulation tailoring: multidimensional asymmetric switching of all-fiber devices",
        "link": "https://doi.org/10.1038/s41377-025-02144-x",
        "published": "2026-01-01",
        "author": "Kang Li, Yuchen Zhang, Siwei Wang, Jian Wang",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>In non-Hermitian systems, the dynamic encircling of exceptional points (EPs) engenders intriguing chiral phenomena, where the resultant state characteristics are intrinsically dependent upon the encircling handedness. An ingenious approach using simple leaky optical elements has been presented to emulate this chiral behavior without physically encircling an EP. This innovative simplification of EP properties enables a more straightforward implementation of asymmetric switching of polarization and path. Given that photons inherently possess multiple physical degrees of freedom, the research focus has shifted from single-dimensional to multidimensional asymmetric switching. Hence, there is a fundamental challenge of how to achieve multidimensional asymmetric switching through a simple and universally applicable architecture. Here, we propose and experimentally demonstrate a novel topology-optimized architecture, termed EP-encirclement emulation tailoring, enabling multidimensional asymmetric switching. Theoretical analysis reveals that our architecture eliminates the 3-dB inherent loss in conventional architecture by replacing couplers with (de)multiplexers. Building upon this architecture, we harness all-fiber devices to implement a high-performance asymmetric switching of polarization, mode, and orbital angular momentum (OAM). To our knowledge, this is the first experimental demonstration of asymmetric OAM switching to date. Our work provides an efficient topology architecture for emulating dynamic EP encirclement, paving the way for universal and flexible asymmetric switching devices.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "绝点包围仿真剪裁：全光纤器件的多维非对称切换",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>在非厄米系统中，异常点 (EP) 的动态环绕会产生有趣的手征现象，其中所产生的状态特征本质上取决于环绕的旋向。已经提出了一种使用简单漏光学元件的巧妙方法来模拟这种手性行为，而无需物理包围 EP。这种对 EP 属性的创新简化使得能够更直接地实现偏振和路径的非对称切换。鉴于光子本质上具有多个物理自由度，研究重点已从单维不对称切换转向多维不对称切换。因此，如何通过简单且普遍适用的架构来实现多维非对称切换是一个根本性的挑战。在这里，我们提出并实验演示了一种新颖的拓扑优化架构，称为 EP 包围仿真裁剪，可实现多维非对称切换。理论分析表明，我们的架构通过用（解）复用器替换耦合器，消除了传统架构中 3 dB 的固有损耗。在此架构的基础上，我们利用全光纤器件来实现偏振、模式和轨道角动量 (OAM) 的高性能非对称切换。据我们所知，这是迄今为止第一个非对称 OAM 切换的实验演示。我们的工作提供了一种高效的拓扑架构来模拟动态EP包围，为通用且灵活的非对称开关器件铺平了道路。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02083-7",
        "title": "Paintable soft photonic architectures featuring multi-stable light-actuation",
        "link": "https://doi.org/10.1038/s41377-025-02083-7",
        "published": "2026-01-01",
        "author": "Honglong Hu, Wentan Wan, Xuan Liu, Xinshi Liang, Conglong Yuan, Yiran Ren, Yuxing Zhan, Zhi-Gang Zheng, Wei-Hong Zhu",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Dynamic photoprogramming of paintable liquid crystal photonic devices with multi-stability shows practical application in smart soft materials and responsive optics. However, there exist three key challenges that limit their development: achieving precise paintability with controllable viscosity and resolution, maintaining well-ordered liquid crystal photonic structures, and enabling multi-stable photoresponsive behavior. Here, we address these limitations by incorporating an intrinsic photoswitch into a cellulose-based liquid crystal system, further constructing a unique paintable helical photonic architecture featuring both multi-stability and dynamic light-actuation. The intrinsic chiral photoswitch enables multi-stable modulation of helical pitch, while optimized viscosity restrains the remarkable fluidity of traditional liquid crystal systems and matches proper surface anchoring, thereby allowing for paintability and programming of a photonic device. The cutting-edge single-step painting enables highly efficient, large-area and well-defined patterning of helical architectures on diverse flexible substrates, thereby promoting prospective applications in anti-counterfeiting, information encryption, and smart window-film. This strategy establishes a robust and versatile foundation that integrates practical explorations in soft matter photonics with state-of-the-art engineering applications, such as multifunctional interactive optical information systems and advanced intelligent flexible sensors.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "具有多稳定光驱动功能的可绘制软光子架构",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>具有多稳定性的可绘制液晶光子器件的动态光编程显示了在智能软材料和响应光学中的实际应用。然而，存在限制其发展的三个关键挑战：通过可控的粘度和分辨率实现精确的可涂性、保持良好有序的液晶光子结构以及实现多稳定的光响应行为。在这里，我们通过将本征光开关合并到基于纤维素的液晶系统中来解决这些限制，进一步构建具有多稳定性和动态光驱动的独特的可绘制螺旋光子结构。固有的手性光开关能够实现螺旋螺距的多稳态调制，同时优化的粘度抑制了传统液晶系统的显着流动性并匹配适当的表面锚定，从而允许光子器件的可涂漆性和编程性。最先进的单步喷涂技术可以在多种柔性基材上实现高效、大面积、清晰的螺旋结构图案，从而促进其在防伪、信息加密和智能窗膜等领域的潜在应用。该策略建立了一个强大且多功能的基础，将软物质光子学的实践探索与最先进的工程应用相结合，例如多功能交互式光学信息系统和先进的智能柔性传感器。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02101-8",
        "title": "Polymer-based ultrawideband transducers for high resolution hemispherical optoacoustic tomography",
        "link": "https://doi.org/10.1038/s41377-025-02101-8",
        "published": "2026-01-01",
        "author": "Amanda P. Siegel, Rayyan Manwar, Kamran Avanaki",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Available transducers do not fulfill all of the necessary design criteria for high-performance hemispherical optoacoustic tomography, namely: an ultrawide bandwidth in order to acquire the full range of optoacoustic emissions from targets of interest, good impedance matching to minimize reverberation artifacts, and a modifiable form factor, for inclusion in non-flat geometries. Polyvinylidene fluoride (PVDF) transducers can, in principle, meet all of these criteria, but PVDF has known shortcomings. In\n                    <jats:italic>Ultrawideband high-density polymer-based spherical array for functional optoacoustic micro-angiography</jats:italic>\n                    , all of the challenges of working with PVDF are overcome with the demonstration of a high-performance PVDF-based hemispherical optoacoustic tomographic system.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于高分辨率半球形光声断层扫描的聚合物超宽带传感器",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    现有的传感器不满足高性能半球形光声层析成像的所有必要设计标准，即：超宽带宽，以获取感兴趣目标的全范围光声发射，良好的阻抗匹配，以最大限度地减少混响伪影，以及可修改的形状因数，以包含在非平面几何形状中。原则上，聚偏二氟乙烯 (PVDF) 传感器可以满足所有这些标准，但 PVDF 也有一些已知的缺点。在\n                    <jats:italic>用于功能性光声微血管造影的超宽带高密度聚合物球形阵列</jats:italic>\n                    ，通过基于 PVDF 的高性能半球形光声断层扫描系统的演示，克服了使用 PVDF 的所有挑战。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02065-9",
        "title": "Full-parameter-modulated three-dimensional vectorial generalized vortex array",
        "link": "https://doi.org/10.1038/s41377-025-02065-9",
        "published": "2026-01-01",
        "author": "Xue Zhang, Yang Cui, Yanjie Chen, Xiaowei Li, Junjie Li, Wenqiao Shi, Jian Chen, Zhaogang Dong, Yongtian Wang, Cheng-Wei Qiu, Shuang Zhang, Lingling Huang",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Orbital angular momentum, as an important spatial degree of freedom of light, has prompted various promising applications. The recently proposed generalized vortex beams may further enhance the flexibility by utilizing customer-defined angular phase gradients, enabling intuitive graphic representation of mathematical operations and other interesting functionalities. Here, based on Dammann optimization, we propose and demonstrate a three-dimensional generalized vortex beam array using a single-layer metasurface, with all-parameter modulation including polarization, phase, angular momentum, and stereoscopic space. Furthermore, simultaneous vectorial modulation within each order can be endowed through joint optimization to achieve arbitrary polarization information distribution. This novel approach to generating the 3D generalized vortex beam array offers great flexibility in utilizing multiple degrees of freedom of light, further expanding the information capacity and spatial mode features and facilitating applications such as optical wireless broadcasting, optical communication encryption, structured beam manipulation, etc.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "全参数调制三维矢量广义涡阵列",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>轨道角动量作为光的重要空间自由度，引发了各种有前景的应用。最近提出的广义涡旋光束可以通过利用客户定义的角相位梯度进一步增强灵活性，从而实现数学运算和其他有趣功能的直观图形表示。在这里，基于达曼优化，我们提出并演示了一种使用单层超表面的三维广义涡旋光束阵列，其全参数调制包括偏振、相位、角动量和立体空间。此外，可以通过联合优化赋予每个阶内的同时矢量调制，以实现任意偏振信息分布。这种生成3D广义涡旋光束阵列的新颖方法在利用光的多自由度方面提供了极大的灵活性，进一步扩展了信息容量和空间模式特征，并促进了光无线广播、光通信加密、结构光束操纵等应用。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02063-x",
        "title": "Simultaneous delayed fluorescence and phosphorescence in organic luminescent material employing multiple excited states",
        "link": "https://doi.org/10.1038/s41377-025-02063-x",
        "published": "2026-01-01",
        "author": "Dehai Dou, Wenlan Liu, Xin Zhou, Qiqi Yang, Xiao Tan, Naz Ugur, Chongyao Li, Charusheela Ramanan, Xiaomin Liu, Gert-Jan A. H. Wetzelaer, Denis Andrienko, Martin Baumgarten, Paul W. M. Blom, Yungui Li",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Triplet dynamics play a key role in room temperature phosphorescence (RTP) and thermally activated delayed fluorescence (TADF). In this work, we report a model emitter with three emission components: prompt fluorescence (PF) in nanoseconds, delayed fluorescence in microseconds, and RTP in milliseconds, with the emission spectrum ranging from ultraviolet to deep blue. We experimentally and theoretically verify that a second triplet excited state, T\n                    <jats:sub>2</jats:sub>\n                    , below the singlet state S\n                    <jats:sub>1</jats:sub>\n                    is involved in facilitating simultaneous PF, TADF, and RTP in the model emitter. The reverse intersystem crossing (rISC) from T\n                    <jats:sub>2</jats:sub>\n                    to S\n                    <jats:sub>1</jats:sub>\n                    contributes to the TADF, while the radiative transition from T\n                    <jats:sub>1</jats:sub>\n                    to the ground state is the origin of the long-lived RTP. By transferring the energy of multiple excited states to a series of conventional fluorescence emitters, a multi-color emissive system covering the entire visible wavelength range has been realized, with the photoluminescence decay ranging from 10\n                    <jats:sup>−9</jats:sup>\n                     s to 10\n                    <jats:sup>−1</jats:sup>\n                     s. By slightly tuning the energy difference between these excited states in the model molecule, a highly efficient organic luminescent material with only PF and RTP emission has been obtained with an RTP quantum yield above 30%. This work provides insights into the key role of higher-lying triplet states in the development of efficient TADF and RTP materials.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "采用多种激发态的有机发光材料同时延迟荧光和磷光",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    三重态动力学在室温磷光（RTP）和热激活延迟荧光（TADF）中发挥着关键作用。在这项工作中，我们报告了一种具有三种发射成分的模型发射器：纳秒级的即时荧光（PF）、微秒级的延迟荧光和毫秒级的RTP，发射光谱范围从紫外到深蓝色。我们通过实验和理论上验证了第二个三重激发态 T\n                    <贾茨：子>2</贾茨：子>\n                    ，低于单重态 S\n                    <jats:sub>1</jats:sub>\n                    参与促进模型发射器中同时进行 PF、TADF 和 RTP。来自 T 的反向系间穿越 (rISC)\n                    <贾茨：子>2</贾茨：子>\n                    至 S\n                    <jats:sub>1</jats:sub>\n                    贡献于 TADF，而 T 的辐射转变\n                    <jats:sub>1</jats:sub>\n                    到基态是长寿命RTP的起源。通过将多种激发态的能量转移到一系列常规荧光发射器上，实现了覆盖整个可见光波长范围的多色发射系统，光致发光衰减范围为10\n                    <jats:sup>−9</jats:sup>\n                     秒到 10\n                    <jats:sup>−1</jats:sup>\n                     s。通过稍微调整模型分子中这些激发态之间的能量差，获得了仅具有PF和RTP发射的高效有机发光材料，其RTP量子产率高于30%。这项工作深入了解了高位三线态在高效 TADF 和 RTP 材料开发中的关键作用。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02059-7",
        "title": "SUANPAN: scalable photonic linear vector machine",
        "link": "https://doi.org/10.1038/s41377-025-02059-7",
        "published": "2026-01-01",
        "author": "Ziyue Yang, Chen Li, Yuqia Ran, Yongzhuo Li, Xue Feng, Kaiyu Cui, Fang Liu, Hao Sun, Wei Zhang, Yu Ye, Fei Qiao, Jiaxing Wang, Cun-Zheng Ning, Connie J. Chang-Hasnain, Yidong Huang",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Photonics is promising to handle extensive vector multiplications in artificial intelligence (AI) techniques due to natural bosonic parallelism and high-speed information transmission. However, the dimensionality of current photonic linear operation is limited and tough to improve due to the complex beam interaction for implementing optical matrix operation and digital-analog conversions. Here, we propose a programmable and reconfigurable photonic linear vector machine with extreme scalability formed by a series of emitter-detector pairs as the independent basic computing units. The elemental values of two high-dimensional vectors are prepared on emitter-detector pairs by bit encoding and analog detecting method without requiring large-scale analog-to-digital converter or digital-to-analog converter arrays. Since there is no interaction among light beams inside, extreme scalability could be achieved by simply multiplicating the independent emitter-detector pair. The proposed architecture is inspired by the traditional Chinese Suanpan or abacus, and thus is denoted as photonic SUANPAN. Experimentally, the computing fidelities for vector inner products could achieve &gt;98% in our implementation with an 8 × 8 vertical cavity surface emission laser (VCSEL) array and an 8 × 8 MoTe\n                    <jats:sub>2</jats:sub>\n                    two-dimensional material photodetector array. Furthermore, such implementation is applied on two typical AI tasks as 1024-dimensional optimization problem is successfully solved and competitive classification accuracy of 88% is achieved for handwritten digit dataset. We believe that the photonic SUANPAN could serve as a fundamental linear vector machine and enhance various future AI applications.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "SUANPAN：可扩展光子线性矢量机",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    由于自然的玻色并行性和高速信息传输，光子学有望处理人工智能（AI）技术中广泛的矢量乘法。然而，由于实现光学矩阵运算和数模转换需要复杂的光束相互作用，当前光子线性运算的维数受到限制且难以提高。在这里，我们提出了一种可编程和可重构的光子线性矢量机，具有极高的可扩展性，由一系列发射器-探测器对作为独立的基本计算单元形成。通过比特编码和模拟检测方法在发射器-检测器对上准备两个高维向量的元素值，而不需要大规模的模数转换器或数模转换器阵列。由于内部光束之间没有相互作用，因此通过简单地增加独立的发射器-检测器对就可以实现极大的可扩展性。所提出的架构受到中国传统算盘或算盘的启发，因此被称为光子算盘。实验上，使用 8 × 8 垂直腔表面发射激光器 (VCSEL) 阵列和 8 × 8 MoTe 实现时，矢量内积的计算保真度可以达到 >98%\n                    <贾茨：子>2</贾茨：子>\n                    二维材料光电探测器阵列。此外，这种实现应用于两个典型的人工智能任务，成功解决了1024维优化问题，并且在手写数字数据集上实现了88%的竞争性分类准确率。我们相信光子 SUANPAN 可以作为基本的线性矢量机并增强未来的各种人工智能应用。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02075-7",
        "title": "Quartz-enhanced laser spectroscopy sensing",
        "link": "https://doi.org/10.1038/s41377-025-02075-7",
        "published": "2026-01-01",
        "author": "Shunda Qiao, Xiaonan Liu, Ziting Lang, Ying He, Weidong Chen, Yufei Ma",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Gas sensing technology is widely applied in various fields, including environmental monitoring, industrial process control, medical diagnostics, safety warnings, and more. As a detection element, the quartz tuning fork (QTF) offers advantages such as high-quality factor (Q-factor), strong noise immunity, compact size, and low cost. Notably, its resonant characteristics significantly enhance system signal strength. Two spectroscopic techniques based on QTF detection, Quartz-enhanced photoacoustic spectroscopy (QEPAS) and light-induced thermoelastic spectroscopy (LITES), are currently research hotspots in the field of spectral sensing. This paper provides a comprehensive and detailed review and highlights pivotal innovations in these two QTF-based spectroscopic techniques. For QEPAS, these encompass high-power excitation methods, novel excitation sources, advanced QTF detection elements, and acoustic wave amplification strategies. Regarding LITES, the researches on optical cavity-enhanced approaches, modified QTF improvement mechanisms, integration with heterodyne demodulation technique, and combination with QEPAS were analyzed. These advances have enabled quartz-enhanced laser spectroscopy to achieve detection limits ranging from parts-per-billion (ppb) to parts-per-trillion (ppt) levels for trace gases such as methane (CH₄), acetylene (C₂H₂), carbon monoxide (CO), and so on. Additionally, prospects for future technological developments are also discussed in the concluding section.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "石英增强激光光谱传感",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>气体传感技术广泛应用于各个领域，包括环境监测、工业过程控制、医疗诊断、安全预警等。作为检测元件，石英音叉（QTF）具有品质因数（Q-factor）高、抗噪声能力强、尺寸紧凑、成本低等优点。值得注意的是，其谐振特性显着增强了系统信号强度。石英增强光声光谱（QEPAS）和光致热弹性光谱（LITES）两种基于QTF检测的光谱技术是目前光谱传感领域的研究热点。本文提供了全面而详细的回顾，并重点介绍了这两种基于 QTF 的光谱技术的关键创新。对于 QEPAS，这些包括高功率激励方法、新颖的激励源、先进的 QTF 检测元件和声波放大策略。针对LITES，分析了光腔增强方法、改进的QTF改进机制、与外差解调技术的集成以及与QEPAS的结合等方面的研究。这些进步使得石英增强激光光谱法能够实现对甲烷 (CH₄)、乙炔 (C2H2)、一氧化碳 (CO) 等痕量气体的检测限从十亿分之一 (ppb) 到万亿分之一 (ppt) 水平。此外，结论部分还讨论了未来技术发展的前景。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02048-w",
        "title": "Advances in waveguide to waveguide couplers for 3D integrated photonic packaging",
        "link": "https://doi.org/10.1038/s41377-025-02048-w",
        "published": "2026-01-01",
        "author": "Drew Weninger, Samuel Serna, Luigi Ranno, Lionel Kimerling, Anuradha Agarwal",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>In this paper, we provide an overview and comparison of devices used for optical waveguide-to-waveguide coupling including inter-chip edge couplers, grating couplers, free form couplers, evanescent couplers, cantilever couplers, and optical wirebonds. In addition, technology for efficient transmission of light through chips is discussed including guided mode and free form photonic vias for substrates including silicon, glass, and organics. The results are discussed in the context of potential applications including co-packaged optics switch packages, replaceable biochemical sensors, optically connected memory, optical computing, integrated quantum photonics, and integrated LiDAR systems to show possible improvements in energy efficiency, performance, and cost.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于 3D 集成光子封装的波导到波导耦合器的进展",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>在本文中，我们对用于光波导到波导耦合的器件进行了概述和比较，包括芯片间边缘耦合器、光栅耦合器、自由形式耦合器、倏逝耦合器、悬臂耦合器和光学引线键合。此外，还讨论了通过芯片有效传输光的技术，包括用于硅、玻璃和有机材料等基板的引导模式和自由形式光子通孔。研究结果在潜在应用的背景下进行了讨论，包括共同封装的光学开关封装、可更换的生化传感器、光连接存储器、光学计算、集成量子光子学和集成激光雷达系统，以显示能源效率、性能和成本方面可能的改进。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02068-6",
        "title": "Topological photonics for single-photon sources",
        "link": "https://doi.org/10.1038/s41377-025-02068-6",
        "published": "2026-01-01",
        "author": "Fei Ding",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    The pursuit of high-quality single-photon sources has long been hampered by challenges in improving the performance and robustness. While traditional microcavity structures can achieve impressive performance, they suffer from extreme sensitivity to manufacturing uncertainty, structural disorders, and scatterings. Topological photonics potentially offers a powerful toolbox for solving these problems. A recent breakthrough by researchers from the Beijing Academy of Quantum Information Sciences, published in\n                    <jats:italic>Light: Science &amp; Applications</jats:italic>\n                    , exploits a topological bulk state rather than the already reported edge and corner states to enhance the single photon emission for a quantum dot.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "单光子源的拓扑光子学",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    对高质量单光子源的追求长期以来一直受到提高性能和鲁棒性方面的挑战的阻碍。虽然传统的微腔结构可以实现令人印象深刻的性能，但它们对制造不确定性、结构紊乱和散射极其敏感。拓扑光子学可能为解决这些问题提供强大的工具箱。北京量子信息科学研究院研究人员最新突破，发表在\n                    <jats:italic>光：科学与光应用</jats:italic>\n                    ，利用拓扑体状态而不是已经报道的边缘和角状态来增强量子点的单光子发射。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02085-5",
        "title": "Light storage in light cages: a scalable platform for multiplexed quantum memories",
        "link": "https://doi.org/10.1038/s41377-025-02085-5",
        "published": "2026-01-01",
        "author": "Esteban Gómez-López, Dominik Ritter, Jisoo Kim, Harald Kübler, Markus A. Schmidt, Oliver Benson",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Quantum memories are essential for photonic quantum technologies, enabling long-distance quantum communication and serving as delay units in quantum computing. Hot atomic vapors using electromagnetically induced transparency provide a simple platform with second-long photon storage capabilities. Light-guiding structures enhance performance, but current hollow-core fiber waveguides face significant limitations in filling time, physical size, fabrication versatility, and large-scale integration potential. In this work, we demonstrate the storage of attenuated coherent light pulses in a cesium (Cs) quantum memory based on a 3D-nanoprinted hollow-core waveguide, known as a light cage (LC), with several hundred nanoseconds of storage times. Leveraging the versatile fabrication process, we successfully integrated multiple LC memories onto a single chip within a Cs vapor cell, achieving consistent performance across all devices. We conducted a detailed investigation into storage efficiency, analyzing memory lifetime and bandwidth. These results represent a significant advancement toward spatially multiplexed quantum memories and have the potential to elevate memory integration to unprecedented levels. We anticipate applications in parallel single-photon synchronization for quantum repeater nodes and photonic quantum computing platforms.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "光笼中的光存储：用于多路复用量子存储器的可扩展平台",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>量子存储器对于光子量子技术至关重要，它能够实现长距离量子通信并充当量子计算中的延迟单元。使用电磁感应透明的热原子蒸气提供了一个具有秒长光子存储能力的简单平台。光导结构增强了性能，但当前的空心光纤波导在填充时间、物理尺寸、制造多功能性和大规模集成潜力方面面临着重大限制。在这项工作中，我们展示了基于 3D 纳米打印空心波导（称为光笼 (LC)）的铯 (Cs) 量子存储器中衰减相干光脉冲的存储，存储时间为数百纳秒。利用通用的制造工艺，我们成功地将多个 LC 存储器集成到 Cs 蒸汽单元内的单个芯片上，从而在所有设备上实现了一致的性能。我们对存储效率进行了详细调查，分析了内存寿命和带宽。这些结果代表了空间复用量子存储器的重大进步，并有可能将存储器集成度提升到前所未有的水平。我们预计量子中继器节点和光子量子计算平台的并行单光子同步应用。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02051-1",
        "title": "Bioinspired phototransistor with tunable sensitivity for low-contrast target detection",
        "link": "https://doi.org/10.1038/s41377-025-02051-1",
        "published": "2026-01-01",
        "author": "Ruyue Han, Dayu Jia, Bo Li, Shun Feng, Guoteng Zhang, Yun Sun, Zheng Han, Chi Liu, Hui-Ming Cheng, Dong-Ming Sun",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Accurate recognition of low-contrast targets in complex visual environments is essential for advanced intelligent machine vision systems. Conventional photodetectors often suffer from a weak photoresponse and a linear dependence of photocurrent on light intensity, which restricts their ability to capture low-contrast features and makes them susceptible to noise. Inspired by the adaptive mechanisms of the human visual system, we present a molybdenum disulfide (MoS\n                    <jats:sub>2</jats:sub>\n                    ) phototransistor with tunable sensitivity, in which the gate stack incorporates a heterostructure diode—composed of O-plasma-treated MoS\n                    <jats:sub>2</jats:sub>\n                    and pristine MoS\n                    <jats:sub>2</jats:sub>\n                    —that serves as the photosensitive layer. This configuration enables light-intensity-dependent modulation of the diode’s conductance, which dynamically in turn alters the voltage distribution across the gate dielectric and transistor channel, leading to a significant photoresponse. By modulating the gate voltage, the light response range can be finely tuned, maintaining high sensitivity to low-contrast targets while suppressing noise interference. Compared to conventional photodetectors, the proposed device achieves a 1000-fold improvement in sensitivity for low-contrast signal detection and exhibits significantly enhanced noise immunity. The intelligent machine vision system built on this device demonstrates exceptional performance in detecting low-contrast targets, underscoring its promise for next-generation machine vision applications.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "具有可调灵敏度的仿生光电晶体管，用于低对比度目标检测",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    复杂视觉环境中低对比度目标的准确识别对于先进的智能机器视觉系统至关重要。传统的光电探测器通常存在光响应较弱以及光电流对光强度的线性依赖性，这限制了它们捕获低对比度特征的能力，并使它们容易受到噪声的影响。受人类视觉系统自适应机制的启发，我们提出了一种二硫化钼（MoS\n                    <贾茨：子>2</贾茨：子>\n                    ）具有可调灵敏度的光电晶体管，其中栅极堆叠包含异质结构二极管——由 O 等离子体处理的 MoS2 组成\n                    <贾茨：子>2</贾茨：子>\n                    和原始的MoS2\n                    <贾茨：子>2</贾茨：子>\n                    ——用作感光层。这种配置能够对二极管的电导进行光强度相关的调制，从而动态地改变栅极电介质和晶体管沟道上的电压分布，从而产生显着的光响应。通过调制栅极电压，可以微调光响应范围，保持对低对比度目标的高灵敏度，同时抑制噪声干扰。与传统光电探测器相比，该器件的低对比度信号检测灵敏度提高了 1000 倍，并且抗噪能力显着增强。基于该设备构建的智能机器视觉系统在检测低对比度目标方面表现出卓越的性能，凸显了其对下一代机器视觉应用的承诺。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02081-9",
        "title": "Self-buffered epitaxy of barium titanate on oxide insulators enables high-performance electro-optic modulators",
        "link": "https://doi.org/10.1038/s41377-025-02081-9",
        "published": "2026-01-02",
        "author": "Chenguang Deng, Yutong He, Wenfeng Yang, Han Yu, Zijian Hong, Hao Liu, Haojie Han, Wei Li, Yunpeng Ma, Zhongshan Zhang, Yongjun Wu, Jing Ma, Bing Xiong, Changzheng Sun, Rong Yu, Jing-Feng Li, Ji Zhou, Yi Luo, Qian Li",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Integrated photonics has emerged as a promising alternative for data communication and computing, ferroelectric BaTiO\n                    <jats:sub>3</jats:sub>\n                    (BTO) stands out for its exceptional electro-optic response among candidate materials. However, direct epitaxial growth of BTO entails a fundamental trade-off: substrates with low refractive index are required for strong optical confinement, yet those with large lattice mismatch degrade film crystalline quality and electro-optic performance. We report a buffer-free, strain-engineered approach to integrate high-performance BTO thin films directly on LaAlO\n                    <jats:sub>3</jats:sub>\n                    -Sr\n                    <jats:sub>2</jats:sub>\n                    TaAlO\n                    <jats:sub>6</jats:sub>\n                    (LSAT) oxide-insulator substrates. By exploiting a self-buffer layer formed during the initial growth stage, we achieve periodic in-plane strain modulation that stabilizes a polymorphic phase boundary with orthorhombic polar nanoregions, yielding a Pockels coefficient exceeding 358 pm V⁻¹ and a Curie temperature raised to 200 °C. Leveraging this material platform, we demonstrate the first realization of a Mach–Zehnder modulator using epitaxial BTO on LSAT. The device exhibits a half-wave voltage–length product of 0.7 V cm at 1550 nm, which closely matches finite-element simulations, and supports a 6-dB electro-optic bandwidth of 28 GHz. Our results validate BTO on LSAT as a viable photonic platform for scalable, low-voltage and high-speed modulators.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "氧化物绝缘体上钛酸钡的自缓冲外延可实现高性能电光调制器",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    集成光子学已成为数据通信和计算、铁电 BaTiO 的有前途的替代方案\n                    <贾茨：子>3</贾茨：子>\n                    (BTO) 因其出色的电光响应而在候选材料中脱颖而出。然而，BTO 的直接外延生长需要一个基本的权衡：需要具有低折射率的衬底来实现强光学限制，而那些具有大晶格失配的衬底会降低薄膜的晶体质量和电光性能。我们报告了一种无缓冲、应变工程方法，可将高性能 BTO 薄膜直接集成在 LaAlO 上\n                    <贾茨：子>3</贾茨：子>\n                    -锶\n                    <贾茨：子>2</贾茨：子>\n                    铝酸钽\n                    <贾茨：子>6</贾茨：子>\n                    (LSAT) 氧化物绝缘体基板。通过利用初始生长阶段形成的自缓冲层，我们实现了周期性的面内应变调制，稳定了具有斜方极性纳米区域的多晶相边界，产生超过 358pm V--1 的普克尔斯系数，并将居里温度提升至 200℃。利用这个材料平台，我们展示了在 LSAT 上使用外延 BTO 的马赫-曾德调制器的首次实现。该器件在 1550nm 处表现出 0.7Vcm 的半波电压长度积，与有限元模拟非常匹配，并支持 28GHz 的 6dB 电光带宽。我们的结果验证了 LSAT 上的 BTO 作为可扩展、低电压和高速调制器的可行光子平台。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02087-3",
        "title": "Towards broadband artificial vision: CMOS-integrated SWIR-MWIR imaging",
        "link": "https://doi.org/10.1038/s41377-025-02087-3",
        "published": "2026-01-02",
        "author": "Di Sun, Wenxin Zheng, Hui Deng, Liangliang Liang",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Inspired by the snake pit organ’s remarkable ability to perceive mid-wave infrared (MWIR) radiation, researchers have developed a biomimetic artificial vision system that integrates infrared-to-visible upconverters with CMOS sensors. Operating at room temperature, this platform enables direct visualization of both short-wave infrared (SWIR) and MWIR, marking a pioneering demonstration of broadband infrared imaging with high resolution. Such a breakthrough paves the way for low-cost and flexible applications in night vision, agricultural monitoring, industrial inspection, and beyond.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "迈向宽带人工视觉：CMOS 集成 SWIR-MWIR 成像",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>受到蛇坑器官感知中波红外 (MWIR) 辐射的卓越能力的启发，研究人员开发了一种仿生人工视觉系统，该系统将红外到可见光上变频器与 CMOS 传感器集成在一起。该平台在室温下运行，可实现短波红外 (SWIR) 和 MWIR 的直接可视化，标志着高分辨率宽带红外成像的开创性演示。这一突破为夜视、农业监测、工业检测等领域的低成本、灵活应用铺平了道路。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02047-x",
        "title": "Magnetized plasma rotator for relativistic mid-infrared pulses via frequency-variable Faraday rotation",
        "link": "https://doi.org/10.1038/s41377-025-02047-x",
        "published": "2026-01-02",
        "author": "Dong-Ao Li, Guo-Bo Zhang, Francesco Pegoraro, Qian Zhao, Wen-Jun Liu, Xing-Long Zhu, De-Bin Zou, Jian-Xing Li, Alexander Pukhov, Zheng-Ming Sheng, Tong-Pu Yu",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Optical rotators based on the Faraday effect have been widely used in optical systems, such as optical isolation and circulators. However, due to the limitation of crystals, the application of such optical rotators in high-power lasers has been severely hindered. Here, we propose a novel plasma rotator based on the frequency-variable Faraday rotation (FVFR) in a compact manner, achieved by driving the magnetized underdense plasma with a relativistic linearly polarized laser. In the magnetized plasma, the drive laser undergoes photon deceleration and relativistic Faraday rotation, leading to the generation of relativistic polarization-tunable mid-infrared (mid-IR) pulse with intensity\n                    <jats:inline-formula>\n                      <jats:alternatives>\n                        <jats:tex-math>$$\\ge {10}^{16}$$</jats:tex-math>\n                        <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\">\n                          <mml:mrow>\n                            <mml:mo>≥</mml:mo>\n                            <mml:msup>\n                              <mml:mrow>\n                                <mml:mn>10</mml:mn>\n                              </mml:mrow>\n                              <mml:mrow>\n                                <mml:mn>16</mml:mn>\n                              </mml:mrow>\n                            </mml:msup>\n                          </mml:mrow>\n                        </mml:math>\n                      </jats:alternatives>\n                    </jats:inline-formula>\n                    W cm\n                    <jats:sup>−2</jats:sup>\n                    and a spectral width of 5–25 μm. With different magnetic fields, the polarization angle of the generated mid-IR pulse can be well controlled. Especially, one can obtain a circularly polarized mid-IR pulse with the spatial average polarization degree of\n                    <jats:inline-formula>\n                      <jats:alternatives>\n                        <jats:tex-math>$$\\ge 0.94$$</jats:tex-math>\n                        <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\">\n                          <mml:mrow>\n                            <mml:mo>≥</mml:mo>\n                            <mml:mn>0.94</mml:mn>\n                          </mml:mrow>\n                        </mml:math>\n                      </jats:alternatives>\n                    </jats:inline-formula>\n                    at a suitable external magnetic field. The robustness of the rotator has been well demonstrated through comprehensive three-dimensional particle-in-cell simulations across a wide range of laser and plasma parameters. Such a rotator via FVFR is valid from mid to far-infrared and even THz waveband, offering new opportunities for strong-field physics, attosecond science, laboratory astrophysics, etc, and paving the way for relativistic plasma magneto-optics and future relativistic plasma optical devices.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "通过变频法拉第旋转产生相对论中红外脉冲的磁化等离子体旋转器",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    基于法拉第效应的旋光器已广泛应用于光隔离、环行器等光学系统中。然而，由于晶体的限制，此类旋光器在高功率激光器中的应用受到了严重阻碍。在这里，我们提出了一种以紧凑方式基于变频法拉第旋转（FVFR）的新型等离子体旋转器，通过用相对论线偏振激光器驱动磁化低密度等离子体来实现。在磁化等离子体中，驱动激光器经历光子减速和相对论法拉第旋转，从而产生具有强度的相对论偏振可调谐中红外（mid-IR）脉冲\n                    <jats:内联公式>\n                      <贾茨：替代品>\n                        <jats:tex-math>$$\\ge {10}^{16}$$</jats:tex-math>\n                        <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\">\n                          <mml:mrow>\n                            <mml:月>≥</mml:月>\n                            <mml:msup>\n                              <mml:mrow>\n                                <mml:mn>10</mml:mn>\n                              </mml:mrow>\n                              <mml:mrow>\n                                <mml:mn>16</mml:mn>\n                              </mml:mrow>\n                            </mml：msup>\n                          </mml:mrow>\n                        </mml：数学>\n                      </jats：替代品>\n                    </jats:内联公式>\n                    宽厘米\n                    <jats:sup>−2</jats:sup>\n                    光谱宽度为 5–25 μm。通过不同的磁场，可以很好地控制所产生的中红外脉冲的偏振角。特别地，可以获得空间平均偏振度为的圆偏振中红外脉冲\n                    <jats:内联公式>\n                      <贾茨：替代品>\n                        <jats:tex-math>$$\\ge 0.94$$</jats:tex-math>\n                        <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\">\n                          <mml:mrow>\n                            <mml:月>≥</mml:月>\n                            <mml:mn>0.94</mml:mn>\n                          </mml:mrow>\n                        </mml：数学>\n                      </jats：替代品>\n                    </jats:内联公式>\n                    在合适的外部磁场下。通过广泛的激光和等离子体参数的全面三维颗粒细胞模拟，充分证明了旋转器的稳健性。这种基于FVFR的旋转器适用于中远红外甚至太赫兹波段，为强场物理、阿秒科学、实验室天体物理等提供了新的机遇，为相对论等离子体磁光和未来相对论等离子体光学器件铺平了道路。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02079-3",
        "title": "Electrically tunable strong coupling in a hybrid-2D excitonic metasurface for optical modulation",
        "link": "https://doi.org/10.1038/s41377-025-02079-3",
        "published": "2026-01-02",
        "author": "Tom Hoekstra, Jorik van de Groep",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Atomically thin semiconductors exhibit tunable exciton resonances that can be harnessed for dynamic manipulation of visible light in ultra-compact metadevices. However, the rapid nonradiative decay and dephasing of excitons at room temperature limit current active excitonic metasurfaces to a few-percent efficiencies. Here, we leverage the combined merits of pristine 2D heterostructures and non-local dielectric metasurfaces to enhance the excitonic light-matter interaction, achieving strong and electrically tunable exciton-photon coupling at ambient conditions in a hybrid-2D excitonic metasurface. Using this, we realize a free-space optical modulator and experimentally demonstrate 9.9 dB of reflectance modulation. The electro-optic response, characterized by a continuous transition from strong to weak coupling, is mediated by gating-induced variations in the free carrier concentration, altering the exciton’s nonradiative decay rate. These results highlight how hybrid-2D excitonic metasurfaces offer novel opportunities to realize nanophotonic devices for active wavefront manipulation and optical communication.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于光调制的混合二维激子超表面中的电可调强耦合",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>原子薄半导体表现出可调谐的激子共振，可用于动态操纵超紧凑元器件中的可见光。然而，室温下激子的快速非辐射衰变和相移将当前活性激子超表面的效率限制在百分之几。在这里，我们利用原始二维异质结构和非局域介电超表面的综合优点来增强激子光-物质相互作用，在混合二维激子超表面中在环境条件下实现强且电可调的激子-光子耦合。利用这一点，我们实现了自由空间光调制器，并通过实验证明了 9.9dB 的反射调制。电光响应的特点是从强耦合到弱耦合的连续转变，是由门控引起的自由载流子浓度变化介导的，改变了激子的非辐射衰减率。这些结果凸显了混合二维激子超表面如何为实现用于主动波前操纵和光通信的纳米光子器件提供新的机会。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02121-4",
        "title": "Ultrafast lasers for attosecond science",
        "link": "https://doi.org/10.1038/s41377-025-02121-4",
        "published": "2026-01-02",
        "author": "Xijie Hu, Ka Fai Mak, Jinwei Zhang, Zhiyi Wei, Ferenc Krausz",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>The first measurement of attosecond pulses in 2001 unleashed a new wave of exploration in the microcosmic world. The pulse width has since shrunk from an initial 650 to 43 as, and the flux, photon energy, and repetition rates have progressively been raised. The performance of attosecond pulses hinges upon the driving lasers, whose rapid development underlaid many advancements of attosecond technology. Yet the expansion of new applications in attosecond science demands driving lasers with ever better performance. Beginning with the fundamental principles of attosecond pulse generation and applications, this article reviews the evolution and trend of the driving lasers in terms of pulse energy, pulse width, wavelength, and repetition rate.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于阿秒科学的超快激光器",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>2001 年首次测量阿秒脉冲，掀起了微观世界探索的新浪潮。此后，脉冲宽度从最初的 650as 缩小到 43as，并且通量、光子能量和重复率逐渐提高。阿秒脉冲的性能取决于驱动激光器，驱动激光器的快速发展奠定了阿秒技术的许多进步的基础。然而，阿秒科学新应用的扩展要求驱动激光器具有更好的性能。本文从阿秒脉冲产生和应用的基本原理出发，从脉冲能量、脉冲宽度、波长和重复率等方面回顾了驱动激光器的演变和趋势。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02086-4",
        "title": "Dynamically reprogrammable nonlinear Pancharatnam–Berry phase via ferroelectric nematic liquid crystals: a new paradigm for reconfigurable nonlinear optics",
        "link": "https://doi.org/10.1038/s41377-025-02086-4",
        "published": "2026-01-02",
        "author": "Shuang Zhang",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>A dynamically programmable, nonlinear beam-shaping and steering system is demonstrated, based on photopatterned, electrically controlled, ion-doped liquid ferroelectrics. This innovative approach elevates the linear liquid-crystal Pancharatnam–Berry optics to the reconfigurable nonlinear Pancharatnam–Berry optics regime, creating new possibilities for dynamic light-matter interactions, multiplexing holography, tunable quantum optics, and many other reconfigurable photonic applications.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "通过铁电向列液晶动态可重编程非线性Pancharatnam-Berry相：可重配置非线性光学的新范例",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>展示了一种动态可编程、非线性光束整形和转向系统，该系统基于光图案化、电控、离子掺杂液体铁电体。这种创新方法将线性液晶 Pancharatnam-Berry 光学提升到可重构非线性 Pancharatnam-Berry 光学体系，为动态光-物质相互作用、复用全息术、可调谐量子光学和许多其他可重构光子应用创造了新的可能性。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02104-5",
        "title": "Topological edge state cavities: simultaneous enhancement of quality factor and free spectral range",
        "link": "https://doi.org/10.1038/s41377-025-02104-5",
        "published": "2026-01-02",
        "author": "Shaoqi Ding, Zhihao Wang, Cuicui Lu",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>A novel topological edge state cavity has been realized to enhance the quality factor and free-spectral range, simultaneously, which opens avenues for developing robust high-performance photonic integrated devices.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "拓扑边缘态腔：同时增强品质因数和自由光谱范围",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>一种新颖的拓扑边缘态腔已经实现，可以同时提高品质因数和自由光谱范围，这为开发鲁棒的高性能光子集成器件开辟了途径。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02011-9",
        "title": "Soft-matter-based topological vertical cavity surface emitting lasers",
        "link": "https://doi.org/10.1038/s41377-025-02011-9",
        "published": "2026-01-02",
        "author": "Yu Wang, Shiqi Xia, Qun Xie, Donghao Yang, Jingbin Shao, Xinzheng Zhang, Irena Drevensek-Olenik, Qiang Wu, Zhigang Chen, Jingjun Xu",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Polarized topological vertical cavity surface-emitting lasers (VCSELs) are promising candidates for stable and efficient on-chip light sources, with significant potential for advancing optical storage and communication technologies. However, most semiconductor-based topological lasers rely on intricate fabrication techniques and face limitations in providing the flexibility needed for diverse device applications. By drawing an analogy to two-dimensional Semenov insulators and the quantum valley Hall effect in a synthetic parameter space, we design and realize a one-dimensional optical superlattice using stacked polymerized cholesteric liquid crystal films and Mylar films. Such a one-dimensional optical superlattice is achieved by using films spin-coated with a Pyrromethene 597 solution, thus enabling the demonstration of a structure-flexible, low threshold, and circularly-polarized topological VCSEL. We demonstrate that such a topological VCSEL maintains excellent single-mode operation at low pump power, and its spatial profile aligns closely with that of the pump laser. Thanks to the soft-matter-based metastructure, the topological laser can be “attached” to substrates of various shapes, maintaining desired laser properties and beam steering even after undergoing multiple bends. These characteristics make the demonstrated topological laser ideal for applications in consumer electronics, laser scanning, displays, and photonic wearable devices, where both flexibility and performance are crucial.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "基于软物质的拓扑垂直腔表面发射激光器",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>偏振拓扑垂直腔表面发射激光器 (VCSEL) 是稳定、高效的片上光源的有前途的候选者，在推进光存储和通信技术方面具有巨大的潜力。然而，大多数基于半导体的拓扑激光器依赖于复杂的制造技术，并且在提供不同设备应用所需的灵活性方面面临限制。通过类比合成参数空间中的二维谢苗诺夫绝缘体和量子谷霍尔效应，我们利用堆叠聚合胆甾型液晶薄膜和聚酯薄膜设计并实现了一维光学超晶格。这种一维光学超晶格是通过使用吡咯亚甲基 597 溶液旋涂薄膜来实现的，从而能够演示结构灵活、低阈值和圆偏振拓扑 VCSEL。我们证明了这种拓扑 VCSEL 在低泵浦功率下保持出色的单模运行，并且其空间轮廓与泵浦激光器的空间轮廓紧密一致。得益于基于软物质的超结构，拓扑激光器可以“附着”到各种形状的基板上，即使在经历多次弯曲后也能保持所需的激光特性和光束转向。这些特性使得所展示的拓扑激光器非常适合消费电子产品、激光扫描、显示器和光子可穿戴设备等应用，其中灵活性和性能都至关重要。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02070-y",
        "title": "Breaking refractive index records with layered van der Waals GeS2 for blue and near-ultraviolet photonics",
        "link": "https://doi.org/10.1038/s41377-025-02070-y",
        "published": "2026-01-02",
        "author": "Pavel Shafirin, Mozakkar Hossain, Artur Davoyan",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    GeS\n                    <jats:sub>2</jats:sub>\n                    , a layered a wide bandgap van der Waals material, is now found to exhibit record-high refractive index and extreme optical anisotropy across blue and near-ultraviolet bands, promising bright future for short-wavelength photonics.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "利用层状范德华 GeS2 打破蓝光和近紫外光子学的折射率记录",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    硫化镓\n                    <贾茨：子>2</贾茨：子>\n                    一种层状宽带隙范德华材料，现已被发现在蓝色和近紫外波段表现出创纪录的高折射率和极端光学各向异性，为短波长光子学带来了光明的前景。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02107-2",
        "title": "OAM multiplication operator enabled holographic multiplexing",
        "link": "https://doi.org/10.1038/s41377-025-02107-2",
        "published": "2026-01-02",
        "author": "Feiyang Shen, Zhengyang Mao, Weiwen Fan, Jiangwei Wu, Zhifan Fang, Haigang Liu, Xianfeng Chen, Yong Zhang, Yuping Chen",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Holography has emerged as a vital platform for three-dimensional displays, optical encryption, and photonic information processing, leveraging diverse physical dimensions of light such as wavelength, polarization, and orbital angular momentum (OAM) to expand multiplexing capacity. However, the exhaustive utilization of these intrinsic degrees of freedom has saturated the parameter space for holographic encoding, leaving no room for further scalability. Here, we demonstrate an OAM multiplication operator enabled holographic multiplexing. We engineer the operator-specific hologram that selectively responds to the predefined operator pathway. Subsequent validation of orthogonality between distinct operator pathways ensures the multiplexing ability, thereby enabling the parallel encoding of multiple holographic images. In the experiment, we have successfully demonstrated a ninefold capacity enhancement over conventional OAM holography and a 2-bit operator-multiplexed hologram for high-security optical encryption. This work introduces operators as a synthetic dimension beyond light’s intrinsic properties into holography, unlocking a scalable and secure paradigm for ultrahigh-dimensional information technologies.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "OAM 乘法运算符启用全息复用",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>全息术已成为三维显示、光学加密和光子信息处理的重要平台，利用光的不同物理维度（例如波长、偏振和轨道角动量 (OAM)）来扩展复用能力。然而，对这些固有自由度的详尽利用已经饱和了全息编码的参数空间，没有留下进一步可扩展的空间。在这里，我们演示了支持全息复用的 OAM 乘法算子。我们设计了操作员特定的全息图，可以选择性地响应预定义的操作员路径。随后对不同算子路径之间的正交性进行验证可确保复用能力，从而实现多个全息图像的并行编码。在实验中，我们成功展示了传统 OAM 全息术的九倍容量增强以及用于高安全性光学加密的 2 位运算符复用全息图。这项工作将算子作为超越光固有属性的合成维度引入全息术，为超高维信息技术解锁了可扩展且安全的范例。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02133-0",
        "title": "Octave spanning operation of visible to SWIR integrated coil-stabilized Brillouin lasers",
        "link": "https://doi.org/10.1038/s41377-025-02133-0",
        "published": "2026-01-02",
        "author": "Meiting Song, Nitesh Chauhan, Mark W. Harrington, Nick Montifiore, Kaikai Liu, Andrew S. Hunter, Chris Caron, Andrei Isichenko, Robert J. Niffenegger, Daniel J. Blumenthal",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Narrow linewidth stabilized lasers are central to precision applications that operate across the visible to short-wave infrared wavelengths, including optical clocks, quantum sensing and computing, ultra-low noise microwave generation, and fiber sensing. Today, these spectrally pure sources are realized using multiple external cavity tabletop lasers locked to bulk-optic free-space reference cavities. Integration of this technology will enable portable precision applications with improved reliability and robustness. Here, we report wavelength-flexible design and operation, over more than an octave span, of an integrated coil-resonator-stabilized Brillouin laser architecture. Leveraging a versatile two-stage noise reduction approach, we achieve low linewidths and high stability with chip-scale laser designs based on the ultra-low-loss, CMOS-compatible silicon nitride platform. We report operation at 674 and 698 nm for applications to strontium neutral and trapped-ion clocks, quantum sensing and computing, and at 1550 nm for applications to fiber sensing and ultra-low phase noise microwave generation. Over this range we demonstrate frequency noise reduction from 1 to 10 MHz resulting in 1.0–17 Hz fundamental and 181–630 Hz integral linewidths and an Allan deviation of 6.5 × 10\n                    <jats:sup>−13</jats:sup>\n                    at 1 ms for 674 nm, 6.0 × 10\n                    <jats:sup>−13</jats:sup>\n                    at 15 ms for 698 nm, and 2.6 × 10\n                    <jats:sup>−13</jats:sup>\n                    at 15 ms for 1550 nm. This work demonstrates the lowest fundamental and integral linewidths and highest stability achieved to date for stabilized Brillouin lasers with integrated coil-resonator references, with over an order of magnitude improvement in the visible wavelength range. These results unlock the potential of integrated, ultra-low-phase-noise stabilized lasers for precision applications and further integration in systems-on-chip solutions.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "可见光到短波红外集成线圈稳定布里渊激光器的倍频程跨越操作",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    窄线宽稳定激光器是在可见光到短波红外波长范围内运行的精密应用的核心，包括光学时钟、量子传感和计算、超低噪声微波生成和光纤传感。如今，这些光谱纯源是使用锁定到体光学自由空间参考腔的多个外腔台式激光器来实现的。该技术的集成将使便携式精密应用具有更高的可靠性和稳健性。在这里，我们报告了集成线圈谐振器稳定布里渊激光器架构的波长灵活设计和操作，超过一个倍频程跨度。利用通用的两级降噪方法，我们通过基于超低损耗、CMOS 兼容氮化硅平台的芯片级激光器设计实现了低线宽和高稳定性。我们报告了在 674 和 698 nm 下的操作，适用于锶中性和俘获离子时钟、量子传感和计算的应用，以及在 1550 nm 下的操作，适用于光纤传感和超低相位噪声微波生成的应用。在此范围内，我们展示了从 1 到 10 MHz 的频率噪声降低，从而产生 1.0–17 Hz 基频和 181–630 Hz 积分线宽以及 6.5 × 10 的艾伦偏差\n                    <jats:sup>−13</jats:sup>\n                    1 ms，674 nm，6.0 × 10\n                    <jats:sup>−13</jats:sup>\n                    698 nm 为 15 ms，2.6 × 10\n                    <jats:sup>−13</jats:sup>\n                    1550nm 时为 15ms。这项工作展示了迄今为止具有集成线圈谐振器参考的稳定布里渊激光器所实现的最低基本线宽和积分线宽以及最高稳定性，并且在可见光波长范围内实现了超过一个数量级的改进。这些结果释放了集成超低相位噪声稳定激光器在精密应用和片上系统解决方案中进一步集成的潜力。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02135-y",
        "title": "Enhanced stability and linearly polarized emission from CsPbI3 perovskite nanoplatelets through A-site cation engineering",
        "link": "https://doi.org/10.1038/s41377-025-02135-y",
        "published": "2026-01-02",
        "author": "Woo Hyeon Jeong, Junzhi Ye, Jongbeom Kim, Rui Xu, Xinyu Shen, Chia-Yu Chang, Eilidh L. Quinn, Hyungju Ahn, Myoung Hoon Song, Peter D. Nellist, Henry J. Snaith, Yunwei Zhang, Bo Ram Lee, Robert L. Z. Hoye",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    The anisotropy of perovskite nanoplatelets (PeNPLs) opens up many opportunities in optoelectronics, including enabling the emission of linearly polarized light. But the limited stability of PeNPLs is a pressing challenge, especially for red-emitting CsPbI\n                    <jats:sub>3</jats:sub>\n                    . Herein, we address this limitation by alloying formamidinium (FA) into the perovskite cuboctahedral site. Unlike Cs/FA alloying in bulk thin films or nanocubes, FA incorporation in nanoplatelets requires meticulous control over the reaction conditions, given that nanoplatelets are obtained in kinetically-driven growth regimes instead of thermodynamically-driven conditions. Through in-situ photoluminescence (PL) measurements, we find that excess FA leads to uncontrolled growth, where phase impurities and nanoplatelets of multiple thicknesses co-exist. Restricting the FA content to up to 25% Cs substitution enables monodisperse PeNPLs, and increases the PL quantum yield (from 53% to 61%), exciton lifetime (from 18 ns to 27 ns), and stability in ambient air (from ~2 days to &gt;7 days) compared to CsPbI\n                    <jats:sub>3</jats:sub>\n                    . This arises due to hydrogen bonding between FA and the oleate and oleylammonium ligands, anchoring them to the surface to improve optoelectronic properties and stability. The reduction in non-radiative recombination, improvement in the nanoplatelet aspect ratio, and higher ligand density lead to FA-containing PeNPLs more effectively forming edge-up superlattices, enhancing the PL degree of linear polarization from 5.1% (CsPbI\n                    <jats:sub>3</jats:sub>\n                    ) to 9.4% (Cs\n                    <jats:sub>0.75</jats:sub>\n                    FA\n                    <jats:sub>0.25</jats:sub>\n                    PbI\n                    <jats:sub>3</jats:sub>\n                    ). These fundamental insights show how the stability limitations of PeNPLs could be addressed, and these materials grown more precisely to improve their performance as polarized light emitters, critical for utilizing them in next-generation display, bioimaging, and communications applications.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "通过 A 位阳离子工程增强 CsPbI3 钙钛矿纳米片的稳定性和线性偏振发射",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    钙钛矿纳米片 (PeNPL) 的各向异性为光电子学领域带来了许多机会，包括实现线偏振光的发射。但 PeNPL 的有限稳定性是一个紧迫的挑战，特别是对于发红光的 CsPbI 而言\n                    <贾茨：子>3</贾茨：子>\n                    。在这里，我们通过将甲脒（FA）合金化到钙钛矿立方八面体位点来解决这一限制。与块体薄膜或纳米立方体中的 Cs/FA 合金化不同，纳米片中的 FA 掺入需要对反应条件进行细致的控制，因为纳米片是在动力学驱动的生长方式而不是热力学驱动的条件下获得的。通过原位光致发光 (PL) 测量，我们发现过量的 FA 会导致生长不受控制，其中相杂质和多种厚度的纳米片共存。与 CsPbI 相比，将 FA 含量限制在最多 25% Cs 取代可实现单分散 PeNPL，并提高 PL 量子产率（从 53% 至 61%）、激子寿命（从 18ns 至 27ns）以及环境空气中的稳定性（从 ~2 天到 >7 天）\n                    <贾茨：子>3</贾茨：子>\n                    。这是由于 FA 与油酸盐和油铵配体之间的氢键作用而产生的，将它们锚定在表面以提高光电性能和稳定性。非辐射复合的减少、纳米片长宽比的提高和更高的配体密度导致含FA的PeNPL更有效地形成边缘向上的超晶格，将PL线性偏振度从5.1%（CsPbI\n                    <贾茨：子>3</贾茨：子>\n                    ）至 9.4%（铯\n                    <贾茨：子>0.75</贾茨：子>\n                    FA\n                    <贾茨：子>0.25</贾茨：子>\n                    碘化铅\n                    <贾茨：子>3</贾茨：子>\n                    ）。这些基本见解展示了如何解决 PeNPL 的稳定性限制，以及如何更精确地生长这些材料以提高其作为偏振光发射器的性能，这对于在下一代显示、生物成像和通信应用中使用它们至关重要。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02112-5",
        "title": "Point spread function decoupling in computational fluorescence microscopy",
        "link": "https://doi.org/10.1038/s41377-025-02112-5",
        "published": "2026-01-02",
        "author": "Ziwei Wang, Wanyu Gu, Shaolei Xu, Yupei Miao, Zewei Cai, Xiang Peng, Xiaoli Liu, Liwei Liu, Qifeng Yu",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Computational fluorescence microscopy constantly breaks through imaging performance through advanced optical modulation technologies; however, conventional theoretical modeling and experimental measurement approaches are challenging to meet the demand for accurate system characterization of diverse modulations. To this end, we propose a point spread function (PSF) decoupling method that is intrinsically compatible with the optimal demodulation in computational microscopic imaging modality. The critical core lies in designing a sample prior-based computational imaging strategy, in which a regular fluorescent sample instead of generally used sub-diffraction limited particles acts as a system modulator to demodulate the system response. PSF consequently can be computationally optimized through the strong support from the modulated sample prior, achieving accurate non-parametric system characterization and thereby avoiding the modeling difficulty and the low signal-to-noise ratio measurement errors of the system specificity. Experimental results across various biological tissues demonstrated and verified that the proposed PSF decoupling method enables excellent volumetric imaging comparable to confocal microscopy and multicolor, large depth-of-field imaging under aperture modulation. It provides a promising mechanism of system characterization and computational demodulation for high-contrast and high-resolution imaging of cellular and subcellular biological structures and life activities.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "计算荧光显微镜中的点扩散函数解耦",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>计算荧光显微镜通过先进的光学调制技术不断突破成像性能；然而，传统的理论建模和实验测量方法难以满足对各种调制的准确系统表征的需求。为此，我们提出了一种点扩散函数（PSF）解耦方法，该方法本质上与计算显微成像模态中的最佳解调兼容。关键核心在于设计一种基于样本先验的计算成像策略，其中常规荧光样本而不是常用的亚衍射受限粒子充当系统调制器来解调系统响应。因此，PSF可以通过调制样本先验的有力支持进行计算优化，实现精确的非参数系统表征，从而避免建模困难和系统特异性的低信噪比测量误差。各种生物组织的实验结果证明并验证了所提出的 PSF 去耦方法能够实现与共焦显微镜相当的出色体积成像以及孔径调制下的多色、大景深成像。它为细胞和亚细胞生物结构和生命活动的高对比度和高分辨率成像提供了一种有前景的系统表征和计算解调机制。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02040-4",
        "title": "Nonlinear light conversion and infrared photodetection with laser-printed plasmonic metasurfaces supporting bound states in the continuum",
        "link": "https://doi.org/10.1038/s41377-025-02040-4",
        "published": "2026-01-02",
        "author": "Dmitrii V. Pavlov, Kseniia A. Sergeeva, Albert A. Seredin, Artem B. Cherepakhin, Aleksandr A. Sergeev, Anastasiia V. Sokolova, Yuri N. Kulchin, Alexey Yu. Zhizhchenko, Mihail I. Petrov, Aleksandr A. Kuchmizhak, Andrey L. Rogach",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Plasmonic metasurfaces supporting high-quality (Q) resonances offer unprecedented ways for controlling light-matter interaction at the nanoscale, yet scalable fabrication of such sophisticated nanostructures still relies on expensive and multi-step fabrication routes, hindering their practical application. Here, we produced plasmonic metasurfaces composed of the regular arrangement of hollow protruding nanobumps via direct femtosecond laser patterning of thin gold films. By using comprehensive optical modeling, infrared spectroscopy and angle-resolved third harmonic generation experiments, we justified that such laser-printed nanostructures support symmetry-protected plasmonic quasi-bound states in the continuum (qBIC) with a measured Q-factor up to 20. Moreover, under critical coupling conditions that match the radiative and nonradiative losses of the high-Q mode, the metasurfaces demonstrate the third harmonic generation enhanced by a factor of ≈10\n                    <jats:sup>5</jats:sup>\n                    as compared to the smooth Au film benchmark, proving structure efficiency for nonlinear conversion. Finally, by taking advantage of the simplicity and straightforward character of the laser printing process, we realized a field-effect transistor device with HgTe quantum dots as an active medium and qBIC-supporting plasmonic metasurface imprinted over drain and source electrodes. The resulting metasurface-empowered device operates at 200 K and 5 V bias voltage and demonstrates superior specific detectivity around 8.7 × 10\n                    <jats:sup>11</jats:sup>\n                    at the plasmonic-qBIC spectral region and fast response time, holding promise for the realization of advanced shortwave infrared photodetectors.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "非线性光转换和红外光电探测，激光打印等离激元超表面支持连续介质中的束缚态",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    支持高质量（Q）共振的等离激元超表面为控制纳米尺度的光与物质相互作用提供了前所未有的方法，但这种复杂纳米结构的可扩展制造仍然依赖于昂贵的多步骤制造路线，阻碍了它们的实际应用。在这里，我们通过直接飞秒激光对金薄膜进行图案化，产生了由规则排列的中空突出纳米凸块组成的等离子体超表面。通过使用综合光学建模、红外光谱和角度分辨三次谐波产生实验，我们证明这种激光打印纳米结构支持连续体（qBIC）中对称保护的等离子体准束缚态，测量的 Q 因子高达 20。此外，在与高 Q 模式的辐射和非辐射损耗相匹配的临界耦合条件下，超表面表现出三次谐波的产生增强了约 10 倍\n                    <贾茨：sup>5</贾茨：sup>\n                    与光滑金膜基准相比，证明了非线性转换的结构效率。最后，利用激光打印工艺简单直接的特点，我们实现了一种场效应晶体管器件，以 HgTe 量子点作为活性介质，并在漏极和源极上压印了支持 qBIC 的等离子体超表面。由此产生的超表面赋能设备在 200 K 和 5 V 偏置电压下运行，并表现出约 8.7 × 10 的卓越比探测率\n                    <贾茨：sup>11</贾茨：sup>\n                    在等离激元-qBIC 光谱区域和快速响应时间，有望实现先进的短波红外光电探测器。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02103-6",
        "title": "Single-capillary endothelial dysfunction resolved by optoacoustic mesoscopy",
        "link": "https://doi.org/10.1038/s41377-025-02103-6",
        "published": "2026-01-03",
        "author": "Hailong He, Angelos Karlas, Nikolina-Alexia Fasoula, Chiara Fischer, Ulf Darsow, Michael Kallmayer, Juan Aguirre, Hans-Henning Eckstein, Vasilis Ntziachristos",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Microvascular endothelial dysfunction (MiVED) is an early marker of endothelial impairment, often preceding dysfunction in large arteries. Although MiVED assessment could reveal new insights into the pathophysiology of cardiovascular disease (CVD) or offer earlier detection and finer disease stratification, detailed in-vivo MiVED observation remains challenging due to a lack of suitable technologies. To address this gap, we hypothesized that accelerating ultra-wideband raster-scan optoacoustic mesoscopy (RSOM), i.e., fast RSOM (fRSOM), could resolve for the first time cutaneous MiVED features at single capillary resolution. We investigated whether we could record morphological features and dynamic responses during post-occlusive reactive hyperemia to achieve the most detailed observation of microvascular endothelial function to date. Our results show that using fRSOM on skin clearly measured the effects of smoking (N = 20) and atherosclerotic CVD (N = 20) on cutaneous endothelial function. For the first time, we found layer-specific effects, with smoking and CVD affecting the sub-papillary dermis differently than the reticular dermis; a finding not resolvable using “bulk” volumetric signals from laser Doppler flowmetry or tissue spectrometry. Interestingly, we observed no substantial structural changes in the microvasculature of smokers and volunteers with CVD, indicating that MiVED may be an earlier marker than morphology-based biomarkers typically assessed by histological studies. Our study introduces a non-invasive modality that enables the visualization and quantification of skin microvascular structure and function, bridging a technological gap and offering new insights into the effects of diseases on MiVED. This study potentially paves the way for fRSOM use as an early detection, diagnostic, or theranostic marker.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "光声介观镜解决单毛细血管内皮功能障碍",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>微血管内皮功能障碍 (MiVED) 是内皮损伤的早期标志，通常先于大动脉功能障碍。尽管 MiVED 评估可以揭示心血管疾病 (CVD) 病理生理学的新见解或提供早期检测和更精细的疾病分层，但由于缺乏合适的技术，详细的体内 MiVED 观察仍然具有挑战性。为了解决这一差距，我们假设加速超宽带光栅扫描光声介观镜 (RSOM)，即快速 RSOM (fRSOM)，可以首次以单毛细血管分辨率解析皮肤 MiVED 特征。我们研究了是否可以记录闭塞后反应性充血期间的形态特征和动态反应，以实现迄今为止最详细的微血管内皮功能观察。我们的结果表明，在皮肤上使用 fRSOM 可以清楚地测量吸烟 (N = 20) 和动脉粥样硬化 CVD (N = 20) 对皮肤内皮功能的影响。我们首次发现了特定层的影响，吸烟和心血管疾病对乳头下真皮的影响与对网状真皮的影响不同；使用来自激光多普勒血流测定或组织光谱测定的“大量”体积信号无法解决这一发现。有趣的是，我们观察到患有 CVD 的吸烟者和志愿者的微脉管系统没有发生实质性的结构变化，这表明 MiVED 可能是比通常通过组织学研究评估的基于形态的生物标志物更早的标志物。我们的研究引入了一种非侵入性方式，可以实现皮肤微血管结构和功能的可视化和量化，弥补技术差距，并为疾病对 MiVED 的影响提供新的见解。这项研究可能为 fRSOM 用作早期检测、诊断或治疗诊断标记物铺平道路。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02113-4",
        "title": "Professor John Rarity",
        "link": "https://doi.org/10.1038/s41377-025-02113-4",
        "published": "2026-01-03",
        "author": "Yining Zhang",
        "summary": "From demonstrating the ﬁ rst “ path entanglement ” experiments in the 1980s to enabling secure quantum communication links stretching from mountaintops to space, Professor John G. Rarity has been a central ﬁ gure in translating quantum mechanics from a subject of philosophical debate to a driver of real-world technology.",
        "journal": "Light: Science & Applications",
        "title_cn": "约翰·瑞瑞教授",
        "abstract_cn": "从 20 世纪 80 年代展示第一个“路径纠缠”实验到实现从山顶延伸到太空的安全量子通信链路，John G. Rarity 教授一直是将量子力学从哲学辩论主题转变为现实世界技术驱动力的核心人物。"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02123-2",
        "title": "Demonstrating completeness in optical neural computing",
        "link": "https://doi.org/10.1038/s41377-025-02123-2",
        "published": "2026-01-03",
        "author": "Krzysztof Tyszka",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>A silicon photonic deep optical neural network integrating convolutional and fully connected layers with on-chip optoelectronic nonlinear activations operates with partially coherent light to achieve high-speed, energy-efficient, end-to-end inference. This demonstration establishes a functional and scalable platform for evaluating complete optical neural processing, representing another step toward specialised, ultrafast photonic architectures beyond electronics.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "展示光学神经计算的完整性",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>硅光子深度光学神经网络将卷积层和全连接层与片上光电非线性激活相集成，使用部分相干光进行操作，以实现高速、节能、端到端推理。该演示建立了一个功能性且可扩展的平台，用于评估完整的光学神经处理，代表着朝着超越电子学的专业化超快光子架构又迈出了一步。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02108-1",
        "title": "Dynamically reconfigurable topological routing in nonlinear photonic systems",
        "link": "https://doi.org/10.1038/s41377-025-02108-1",
        "published": "2026-01-03",
        "author": "Stephan Wong, Simon Betzold, Sven Höfling, Alexander Cerjan",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>The propagation path of topologically protected states is bound to the interface between regions with different topology, and as such, the functionality of linear photonic devices leveraging these states is fixed during fabrication. Here, we propose a mechanism for dynamic control over a driven dissipative system’s local topology, yielding reconfigurable topological interfaces and thus tunable paths for protected routing. We illustrate our approach in non-resonantly pumped polariton lattices, where the nonlinear interaction between the polaritons and the exciton reservoir due to non-resonant pumping can yield picosecond-scale changes in the propagation paths of the chiral edge states. To analytically confirm the numerically observed topological dynamics, we generalize the spectral localizer framework to non-linear non-Hermitian Chern materials and apply this framework to a continuous model of the polariton system based on a driven-dissipative Gross-Pitaevskii equation. In doing so, we show that the local changes in the polariton lattice’s topology are captured by a local Chern marker. Looking forward, we anticipate such reconfigurable topological routing will enable the realization of novel classes of topological photonic devices.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "非线性光子系统中的动态可重构拓扑路由",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>拓扑保护态的传播路径绑定到具有不同拓扑的区域之间的界面，因此，利用这些状态的线性光子器件的功能在制造过程中是固定的。在这里，我们提出了一种对驱动耗散系统的本地拓扑进行动态控制的机制，产生可重新配置的拓扑接口，从而产生受保护路由的可调路径。我们在非共振泵浦极化子晶格中说明了我们的方法，其中由于非共振泵浦而导致的极化子和激子库之间的非线性相互作用可以在手性边缘态的传播路径中产生皮秒级的变化。为了分析证实数值观察到的拓扑动力学，我们将光谱定位器框架推广到非线性非厄米陈材料，并将该框架应用于基于驱动耗散 Gross-Pitaevskii 方程的极化子系统的连续模型。在此过程中，我们表明极化子晶格拓扑的局部变化是由局部陈标记捕获的。展望未来，我们预计这种可重新配置的拓扑路由将能够实现新型拓扑光子器件。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02136-x",
        "title": "High-efficiency broadband active metasurfaces via reversible metal electrodeposition",
        "link": "https://doi.org/10.1038/s41377-025-02136-x",
        "published": "2026-01-03",
        "author": "Qizhang Li, Sachin Prashant Kulkarni, Chenxi Sui, Ting-Hsuan Chen, Gangbin Yan, Ronghui Wu, Wen Chen, Pei-Jan Hung, Xubing Wu, Tadej Emersic, Koray Aydin, Po-Chun Hsu",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Realizing active metasurfaces with substantial tunability is important for many applications but remains challenging due to difficulties in dynamically tuning light-matter interactions at subwavelength scales. Here, we introduce reversible metal electrodeposition as a versatile approach for enabling active metasurfaces with exceptional tunability across a broad bandwidth. As a proof of concept, we demonstrate a dynamic beam-steering device by performing reversible copper (Cu) electrodeposition on a reflective gradient metasurface composed of metal-insulator-metal resonators. By applying different voltages, the Cu atoms can be uniformly and reversibly electrodeposited and stripped around the resonators, effectively controlling the gap-surface plasmon resonances and steering the reflected light. This process experimentally achieved &gt;90% diffraction efficiencies and &gt;60% reflection efficiencies in both specular and anomalous modes, even after thousands of cycles. Moreover, these high efficiencies can be extended from the visible to the near- and mid-infrared regimes, demonstrating the broad versatility of this approach in enabling various active optical and thermal devices with different working wavelengths and bandwidths.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "通过可逆金属电沉积实现高效宽带活性超表面",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>实现具有显着可调性的活性超表面对于许多应用来说很重要，但由于在亚波长尺度上动态调整光与物质相互作用的困难，仍然具有挑战性。在这里，我们引入可逆金属电沉积作为一种通用方法，使活性超表面在宽带宽内具有出色的可调性。作为概念证明，我们通过在由金属-绝缘体-金属谐振器组成的反射梯度超表面上进行可逆铜（Cu）电沉积来演示动态光束控制装置。通过施加不同的电压，铜原子可以在谐振器周围均匀、可逆地电沉积和剥离，有效地控制间隙表面等离子体共振并控制反射光。该过程在实验上实现了在镜面和反常模式下的＞90％的衍射效率和＞60％的反射效率，甚至在数千次循环之后也是如此。此外，这些高效率可以从可见光扩展到近红外和中红外区域，这证明了这种方法在实现具有不同工作波长和带宽的各种有源光学和热学器件方面具有广泛的多功能性。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02150-z",
        "title": "Programmable Bell state generation in an integrated thin film lithium niobate circuit",
        "link": "https://doi.org/10.1038/s41377-025-02150-z",
        "published": "2026-01-03",
        "author": "Andreas Maeder, Robert J. Chapman, Alessandra Sabatti, Giovanni Finco, Jost Kellner, Rachel Grange",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Entanglement is central to quantum technologies such as cryptography, sensing, and computing. Photon pairs generated via nonlinear optical processes are excellent for preparing entangled states due to their long coherence times and compatibility with fiber optic networks. Steady progress in nanofabrication has positioned lithium niobate-on-insulator (LNOI) as a leading platform for monolithic integration of photon pair sources into optical circuits, leveraging its strong second-order nonlinearity. Here, we present a reconfigurable photonic integrated circuit on LNOI, which combines two on-chip photon pair sources with programmable interferometers, enabling the generation of entangled states. The photon pair sources achieve a source brightness of 26 MHz nm\n                    <jats:sup>−1</jats:sup>\n                    mW\n                    <jats:sup>−1</jats:sup>\n                    while maintaining a coincidence-to-accidental ratio above 100. We successfully interfere the two sources with 99.0 ± 0.7% visibility, demonstrating the indistinguishability required for producing entanglement on-chip. We show the preparation of any of the maximally entangled Bell states with fidelity above 90% verified by quantum state tomography. These results establish LNOI as a compelling, scalable platform to explore integrated quantum photonic technologies enabled by high-brightness sources of entangled quantum states.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "集成薄膜铌酸锂电路中的可编程贝尔态生成",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    纠缠是密码学、传感和计算等量子技术的核心。通过非线性光学过程产生的光子对由于相干时间长且与光纤网络兼容，非常适合制备纠缠态。纳米加工的稳步进展使绝缘体上铌酸锂（LNOI）成为利用其强大的二阶非线性将光子对源单片集成到光电路中的领先平台。在这里，我们提出了一种基于 LNOI 的可重构光子集成电路，它将两个片上光子对源与可编程干涉仪结合在一起，从而能够生成纠缠态。光子对源的源亮度达到 26 MHz nm\n                    <jats:sup>−1</jats:sup>\n                    毫瓦\n                    <jats:sup>−1</jats:sup>\n                    同时将巧合与意外的比率保持在 100 以上。我们成功地以 99.0 ± 0.7% 的可见度干扰了两个源，证明了在片上产生纠缠所需的不可区分性。我们展示了任何最大纠缠贝尔态的制备方法，通过量子态断层扫描验证保真度高于 90%。这些结果使 LNOI 成为一个引人注目的可扩展平台，用于探索由高亮度纠缠量子态源实现的集成量子光子技术。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02058-8",
        "title": "Hybrid tungsten oxyselenide/graphene electrodes for near-lossless 2D semiconductor phase modulators",
        "link": "https://doi.org/10.1038/s41377-025-02058-8",
        "published": "2026-01-03",
        "author": "Shi Guo, Sung-Gyu Lee, Xiangxin Gong, Lalit Singh, Rui Yu, Ahmad Sholehin Bin Juperi, Seoungbum Lim, Yuhui Yang, Jinpeng Huo, Jeremy Leong, Ce Liang, Hyojin Seung, Yangchen He, Daniel Rhodes, Min Sup Choi, Takashi Taniguchi, Kenji Watanabe, Wonkeun Chang, Beng Kang Tay, Luigi Ranno, Juejun Hu, Qingyun Wu, Lay Kee Ang, Jia Xu Brian Sia, Sang Hoon Chae",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Optical phase modulators are critical components in integrated photonics, but conventional designs suffer from a trade-off between modulation efficiency and optical loss. Two-dimensional materials like graphene offer strong electro-optic effects, yet their high optical absorption at telecom wavelengths leads to significant insertion losses. Although monolayer transition metal dichalcogenides (TMDs) provide exceptional telecom-band transparency for low-loss electro-refractive response, their practical implementation in phase modulators requires top electrodes to enable vertical electric field tuning, which typically introduces parasitic absorption. Here, we address this challenge by developing hybrid tungsten oxyselenide/graphene (TOS/Gr) electrodes that minimize optical loss while enabling efficient phase modulation in TMD-based devices. The UV-ozone-converted TOS (from WSe\n                    <jats:sub>2</jats:sub>\n                    ) acts as a heavy p-type dopant for graphene, making the graphene transparent in the NIR region while enhancing its conductivity. Our complete device integrates a hybrid TOS/graphene transparent electrode with a hexagonal boron nitride dielectric spacer and monolayer WS\n                    <jats:sub>2</jats:sub>\n                    electro-optic material on a SiN microring platform. This achieves a high modulation efficiency of 0.202 V·cm while maintaining an exceptionally low extinction ratio change of just 0.08 dB, demonstrating superior performance compared to modulators employing conventional electrodes. Our breakthrough in near-lossless phase modulation opens new possibilities for energy-efficient optical communications, photonic computing, and fault-tolerant quantum networks.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于近无损二维半导体相位调制器的混合硒化钨/石墨烯电极",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    光相位调制器是集成光子学中的关键组件，但传统设计面临着调制效率和光损耗之间的权衡。石墨烯等二维材料具有很强的电光效应，但它们在电信波长下的高光吸收会导致显着的插入损耗。尽管单层过渡金属二硫化物 (TMD) 为低损耗电折射响应提供了出色的电信频段透明度，但它们在相位调制器中的实际实现需要顶部电极来实现垂直电场调谐，这通常会引入寄生吸收。在这里，我们通过开发混合硒化钨/石墨烯 (TOS/Gr) 电极来应对这一挑战，该电极可以最大限度地减少光学损耗，同时在基于 TMD 的设备中实现高效的相位调制。紫外线臭氧转换的 TOS（来自 WSe\n                    <贾茨：子>2</贾茨：子>\n                    ）作为石墨烯的重p型掺杂剂，使石墨烯在近红外区域透明，同时增强其导电性。我们的完整器件集成了混合 TOS/石墨烯透明电极、六方氮化硼电介质间隔物和单层 WS\n                    <贾茨：子>2</贾茨：子>\n                    SiN 微环平台上的电光材料。这实现了 0.202V·cm 的高调制效率，同时保持了仅 0.08dB 的极低消光比变化，与采用传统电极的调制器相比，表现出了卓越的性能。我们在近无损相位调制方面的突破为节能光通信、光子计算和容错量子网络开辟了新的可能性。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02158-5",
        "title": "Longitudinally engineered metasurfaces for 3D vectorial holography",
        "link": "https://doi.org/10.1038/s41377-025-02158-5",
        "published": "2026-01-03",
        "author": "Le Tan, Pengcheng Huo, Peicheng Lin, Yongze Ren, Haocun Qi, Lizhi Fang, Yilin Wang, Junfei Ou, Yanqing Lu, Ting Xu",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>The ability to precisely generate and manipulate three-dimensional (3D) vectorial optical fields is crucial for advancing applications in volumetric displays, secure data encoding, and optical information processing. However, conventional holographic techniques generally lack the capability to simultaneously control both light intensity and polarization within a volumetric region, thereby limiting the full realization of complex 3D vectorial light fields. Here, we present a metasurface-based platform for 3D vectorial holography that enables independent and programmable control over axial intensity and polarization profiles within structured beam arrays. By decomposing complex volumetric holographic targets into a dense array of non-diffracting beams—each governed by a tailored longitudinal response function—we achieve broadband, high-fidelity reconstruction of vectorial light fields encoded in both spatial intensity and polarization domains. Moreover, we demonstrate a vectorial encryption scheme that exploits the combined axial intensity and polarization degrees of freedom to realize secure, key-based optical information encoding. This approach provides a compact, integrable, and scalable solution for 3D vectorial holographic projection and volumetric vector beam shaping, offering a versatile platform for high-capacity optical storage, secure communication, and emerging quantum photonic technologies.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于 3D 矢量全息术的纵向工程超表面",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>精确生成和操纵三维 (3D) 矢量光场的能力对于推进体积显示、安全数据编码和光学信息处理中的应用至关重要。然而，传统的全息技术通常缺乏在体积区域内同时控制光强度和偏振的能力，从而限制了复杂3D矢量光场的完全实现。在这里，我们提出了一个基于超表面的 3D 矢量全息平台，可以对结构化光束阵列内的轴向强度和偏振分布进行独立且可编程的控制。通过将复杂的体积全息目标分解为密集的非衍射光束阵列（每个光束都由定制的纵向响应函数控制），我们实现了在空间强度和偏振域中编码的矢量光场的宽带、高保真重建。此外，我们演示了一种矢量加密方案，该方案利用组合的轴向强度和偏振自由度来实现安全的、基于密钥的光学信息编码。这种方法为 3D 矢量全息投影和体积矢量光束整形提供了紧凑、可集成和可扩展的解决方案，为大容量光存储、安全通信和新兴量子光子技术提供了多功能平台。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02157-6",
        "title": "Dynamic tuning of Bloch modes in anisotropic phonon polaritonic crystals",
        "link": "https://doi.org/10.1038/s41377-025-02157-6",
        "published": "2026-01-03",
        "author": "Junbo Xu, Ke Yu, Xiang Ni, Enrico M. Renzi, Lei Zhou, Yanzhen Yin, Zhou Zhou, Zhichen Zhao, Tao He, Di Huang, Kyoung-Duck Park, Zhanshan Wang, Andrea Alù, Tao Jiang",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Phonon polaritons, arising from the coupling of photons with lattice vibrations, enable light confinement on deeply subwavelength scales. Phonon polaritonic crystals (PoCs), leveraging these inherently low-dissipation excitations, have further shown exceptional potential for nanoscale light manipulation through engineered Bloch modes. Yet, their static nature has so far hindered dynamic modulation, thus limiting their adaptability for real-time applications. Here, we demonstrate in situ electrostatic control of low-loss anisotropic phonon-polaritonic Bloch modes in α-MoO\n                    <jats:sub>3</jats:sub>\n                    patterned into a periodic hole array with a graphene gate. Through theoretical calculation and real-space nano-imaging, we show that electrostatic gating dynamically modulates key characteristics of Bloch modes in hybrid α-MoO\n                    <jats:sub>3</jats:sub>\n                    /graphene PoCs. Critically, gating reshapes the PoC band structure, spectrally aligning high-density-of-states flat-band regions with the excitation laser frequency, thereby selectively amplifying Bloch mode resonances. We further achieve on-demand switching over far-field leakage of Bloch modes by electrostatically steering these flat bands across the light cone. Our work establishes a platform for adaptive nanostructured phonon polaritonic devices. This advancement not only facilitates directional control of low-loss anisotropic phonon-polaritonic Bloch modes, but also paves the way for their practical application in nanophotonics.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "各向异性声子极化晶体中布洛赫模式的动态调谐",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    声子极化激元是由光子与晶格振动耦合产生的，可以将光限制在深亚波长尺度上。声子极化晶体 (PoC) 利用这些固有的低耗散激发，进一步显示出通过工程布洛赫模式进行纳米级光操纵的非凡潜力。然而，迄今为止，它们的静态特性阻碍了动态调制，从而限制了它们对实时应用的适应性。在这里，我们演示了 α-MoO2 中低损耗各向异性声子极化布洛赫模式的原位静电控制\n                    <贾茨：子>3</贾茨：子>\n                    用石墨烯门将其图案化为周期性孔阵列。通过理论计算和实空间纳米成像，我们表明静电门控动态调制混合α-MoO中布洛赫模式的关键特性\n                    <贾茨：子>3</贾茨：子>\n                    /石墨烯 PoC。至关重要的是，选通重塑了 PoC 能带结构，将高态密度平带区域与激发激光频率进行光谱对准，从而选择性地放大布洛赫模式谐振。我们通过静电引导这些平带穿过光锥，进一步实现了布洛赫模式远场泄漏的按需切换。我们的工作为自适应纳米结构声子极化器件建立了一个平台。这一进展不仅促进了低损耗各向异性声子极化布洛赫模式的定向控制，而且为其在纳米光子学中的实际应用铺平了道路。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02115-2",
        "title": "A framework for spontaneous Brillouin noise: unveiling fundamental limits in Brillouin metrology",
        "link": "https://doi.org/10.1038/s41377-025-02115-2",
        "published": "2026-01-03",
        "author": "Simeng Jin, Shuai Yao, Zhisheng Yang, Zixuan Du, Xiaobin Hong, Marcelo A. Soto, Jingjing Xie, Long Zhang, Fan Yang, Jian Wu",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Spontaneous Brillouin scattering (SpBS) enables non-contact probing of mechanical and thermodynamic material properties, underpinning transformative technologies such as distributed optical fiber sensing and high-resolution microscopy. Achieving ultimate precision in these systems demands a fundamental understanding of noise limits. Yet, an intrinsic SpBS noise phenomenon proposed over three decades ago has remained largely unexplored, particularly in metrological contexts. Here, we revisit the physical mechanism and stochastic nature of this long-overlooked noise source, developing a comprehensive analytical framework, validated through dedicated experiments. Crucially, we propose, for the first time, that SpBS noise constitutes a universal and fundamental limit capable of surpassing conventional constraints (e.g., the shot-noise limit) in spontaneous Brillouin metrological systems, such as imaging, microscopy and sensing. We experimentally demonstrate the SpBS-noise-limited regime in Brillouin imaging and sensing scenarios. This framework establishes a critical foundation for understanding and optimizing the performance of current and future Brillouin-based technologies across a broad range of applications.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "自发布里渊噪声的框架：揭示布里渊计量的基本极限",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>自发布里渊散射 (SpBS) 能够对机械和热力学材料特性进行非接触式探测，支撑分布式光纤传感和高分辨率显微镜等变革性技术。要在这些系统中实现终极精度，需要对噪声限制有基本的了解。然而，三十多年前提出的内在 SpBS 噪声现象在很大程度上仍未得到探索，特别是在计量领域。在这里，我们重新审视这种长期被忽视的噪声源的物理机制和随机性质，开发了一个全面的分析框架，并通过专门的实验进行了验证。至关重要的是，我们首次提出，SpBS 噪声构成了一种普遍且基本的限制，能够超越自发布里渊计量系统（例如成像、显微镜和传感）中的传统约束（例如散粒噪声限制）。我们通过实验证明了布里渊成像和传感场景中的 SpBS 噪声限制机制。该框架为理解和优化当前和未来基于布里渊的技术在广泛应用中的性能奠定了重要基础。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02110-7",
        "title": "Seeing without touching: weak-disturbance imaging and characterization of ultra-confined optical near fields",
        "link": "https://doi.org/10.1038/s41377-025-02110-7",
        "published": "2026-01-03",
        "author": "Bowen Wang, Qian Chen, Chao Zuo",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>A recent study employing high-spatial-resolution photoemission electron microscopy (PEEM) achieved, for the first time, weak-disturbance imaging of the ultra-confined nanoslit mode in a coupled nanowire pair (CNP), revealing its quasi-three-dimensional field distribution.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "无需触摸即可看到：超受限光学近场的弱干扰成像和表征",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>最近一项采用高空间分辨率光电子显微镜（PEEM）的研究首次实现了耦合纳米线对（CNP）中超约束纳米狭缝模式的弱干扰成像，揭示了其准三维场分布。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02141-0",
        "title": "Compressing and expanding optical matrix-vector multipliers for enabling optical image encoder-decoders and generators",
        "link": "https://doi.org/10.1038/s41377-025-02141-0",
        "published": "2026-01-03",
        "author": "Adrian Stern",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Both compressing and expanding optical matrix-vector multipliers are necessary for the full optical realization of neural networks. An expanding multiplier scheme is proposed, which, together with common compressing multipliers, is employed to demonstrate image processor networks such as autoencoders and image generators.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "压缩和扩展光学矩阵矢量乘法器以实现光学图像编码器-解码器和生成器",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>压缩和扩展光学矩阵矢量乘法器对于神经网络的完整光学实现都是必要的。提出了一种扩展乘法器方案，该方案与常见的压缩乘法器一起用于演示图像处理器网络，例如自动编码器和图像生成器。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02111-6",
        "title": "Prof. Siying Peng: caterpillars to butterflies, chasing light in photonics",
        "link": "https://doi.org/10.1038/s41377-025-02111-6",
        "published": "2026-01-04",
        "author": "Ji Wang",
        "summary": "<jats:title>Editorial</jats:title>\n                  <jats:p>“To eyelids in the Sepulchre—/ How dumb the Dancer lies—/ While Color’s Revelations break—/ And blaze—the Butterflies!” A renowned American poet, Emily Dickinson’s poem vividly mirrors the journey of women’s growth: No matter how many hardships they encounter in their development or constraints they face, they will eventually break free from their “cocoons” and transform into colorful butterflies radiating “light”. In this issue of “Light People”, Professor Siying Peng is invited to share how the optical properties of butterfly wings have inspired her metamorphosis in the field of photonics.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "彭思颖教授：从毛毛虫到蝴蝶，在光子学中追逐光",
        "abstract_cn": "<jats:title>社论</jats:title>\n                  <jats:p>“致坟墓中的眼睑——/舞者的谎言多么愚蠢——/当色彩的启示破裂时——/并点燃——蝴蝶！”美国著名诗人艾米莉·狄金森的诗生动地反映了女性的成长历程：无论她们的发展遭遇多少磨难、多少束缚，她们最终都会挣脱“茧”，化作绽放“光芒”的彩蝶。本期《光人》邀请彭思颖教授分享蝴蝶翅膀的光学特性如何启发她在光子学领域的蜕变。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02084-6",
        "title": "Decoupling metasurface parameters for independent Stokes polarization control via generalized lattice",
        "link": "https://doi.org/10.1038/s41377-025-02084-6",
        "published": "2026-01-04",
        "author": "Zhi Cheng, Zhou Zhou, Zhuo Wang, Yue Wang, Changyuan Yu",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>The ability to achieve comprehensive control over all Stokes parameters, including both the state of polarization (SoP) and the degree of polarization (DoP), is fundamental to advancements in quantum optics, imaging, and optical communications. While metasurfaces have demonstrated remarkable capabilities in polarization manipulation, existing designs typically rely on locally periodic unit cells and deterministic phase profiles, limiting their flexibility in controlling both SoP and DoP simultaneously. Here, we introduce the generalized lattice approach for metasurface design, which enables the decoupling of structural parameters from the full-Stokes polarization response. Our approach introduces a spatially global but structurally disordered arrangement, constructed on a generalized lattice framework. This framework enables the flexible placement of an arbitrary number and type of meta-atoms within a generalized lattice, where the relative quantity ratios among different meta-atoms serve as a new design degree of freedom. This decoupling enables the azimuthal and elevation angles of the SoP on the Poincaré sphere to be governed by the in-plane rotation and size of individual meta-atoms, while the DoP is controlled independently via the quantity ratio. This establishes a direct and analytically tractable mapping between metasurface geometry and polarization space, offering new physical insights into metasurface-based polarization control. A computationally efficient algorithm optimizes the metasurface arrangement, achieving a polarization similarity (evaluated by Stokes Euclidean Distance) of 0.93 in theory and 0.90 in experiment. Our findings demonstrate that the generalized lattice approach provides an effective and versatile route to full-Stokes polarization control with greater flexibility than conventional metasurface designs.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "通过广义晶格解耦超表面参数以实现独立斯托克斯偏振控制",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>实现对所有斯托克斯参数（包括偏振态 (SoP) 和偏振度 (DoP)）的全面控制的能力是量子光学、成像和光通信进步的基础。虽然超表面在偏振操纵方面表现出了卓越的能力，但现有的设计通常依赖于局部周期性晶胞和确定性相位分布，限制了它们同时控制 SoP 和 DoP 的灵活性。在这里，我们介绍了用于超表面设计的广义晶格方法，该方法能够将结构参数与全斯托克斯偏振响应解耦。我们的方法引入了一种空间全局但结构无序的排列，构建在广义晶格框架上。该框架使得能够在广义晶格内灵活放置任意数量和类型的元原子，其中不同元原子之间的相对数量比作为新的设计自由度。这种解耦使得庞加莱球上的 SoP 的方位角和仰角能够由各个超原子的面内旋转和尺寸来控制，而 DoP 通过数量比来独立控制。这在超表面几何形状和偏振空间之间建立了直接且易于分析处理的映射，为基于超表面的偏振控制提供了新的物理见解。计算效率高的算法优化了超表面排列，理论上实现了 0.93 的偏振相似性（通过斯托克斯欧几里得距离评估），实验中达到 0.90。我们的研究结果表明，广义晶格方法提供了一种有效且通用的全斯托克斯偏振控制途径，比传统的超表面设计具有更大的灵活性。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02071-x",
        "title": "Harnessing optical bound states in the continuum for ultrafast, reconfigurable, long-range photonic networks",
        "link": "https://doi.org/10.1038/s41377-025-02071-x",
        "published": "2026-01-04",
        "author": "Jiantao Ma, Ying Yu, Jin Liu",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Bound states in the continuum (BICs) provide a route to strong, long-range photonic coupling with dynamic tunability. Recent advances demonstrate that BIC metasurfaces enable reconfigurable two-dimensional coupling between arbitrarily positioned resonators, with the added capability of ultrafast all-optical control.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "利用连续体中的光学束缚态来实现超快、可重构、远程光子网络",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>连续体束缚态 (BIC) 提供了实现具有动态可调性的强远程光子耦合的途径。最近的进展表明，BIC 超表面能够在任意位置的谐振器之间实现可重构的二维耦合，并具有超快全光控制的附加功能。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02120-5",
        "title": "Light management in monolithic all-perovskite tandem solar cells",
        "link": "https://doi.org/10.1038/s41377-025-02120-5",
        "published": "2026-01-04",
        "author": "Chenshuaiyu Liu, Han Gao, Wennan Ou, Hairen Tan, Renxing Lin",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>All-perovskite tandem solar cells represent a promising strategy for breaking the Shockley-Queisser limits inherent in single-junction solar cells. Reasonable light management and optical design are necessary for all-perovskite tandem solar cells to improve power conversion efficiency. In this review, the recent progresses in light management for monolithic all-perovskite tandem solar cells are summarized comprehensively. The current-matching conditions, optical challenges, and potential development trajectories for all-perovskite tandem solar cells are investigated. It includes key optical losses, enhancements and strategies for light trapping and light utilization. Ultimately, forward-looking perspectives on future developments are presented. This review aims to offer valuable insights and practical suggestions for improving power conversion efficiency of all-perovskite tandem solar cells from light management techniques.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "单片全钙钛矿串联太阳能电池的光管理",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>全钙钛矿串联太阳能电池代表了一种打破单结太阳能电池固有的肖克利-奎瑟极限的有前途的策略。全钙钛矿串联太阳能电池需要合理的光管理和光学设计来提高功率转换效率。本文全面总结了单片全钙钛矿串联太阳能电池光管理的最新进展。研究了全钙钛矿串联太阳能电池的电流匹配条件、光学挑战和潜在发展轨迹。它包括关键的光学损耗、增强功能以​​及光捕获和光利用的策略。最后，对未来发展提出了前瞻性的看法。本综述旨在为通过光管理技术提高全钙钛矿串联太阳能电池的功率转换效率提供有价值的见解和实用建议。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02137-w",
        "title": "Ideal optical antimatter using passive lossy materials under complex frequency excitation",
        "link": "https://doi.org/10.1038/s41377-025-02137-w",
        "published": "2026-01-04",
        "author": "Olivia Y. Long, Peter B. Catrysse, Seunghoon Han, Shanhui Fan",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>The original concept of left-handed material has inspired the possibility of optical antimatter, where the effect of light propagation through a medium can be completely canceled by its complementary medium. Despite recent progress in the development of negative-index metamaterials, losses continue to be a significant barrier to realizing optical antimatter. In this work, we show that passive, lossy materials can be used to realize optical antimatter when illuminated by light at a complex frequency. We further establish that one can engineer arbitrary complex-valued permittivity and permeability in such materials. Strikingly, we show that materials with a positive index at real frequencies can act as negative-index materials under complex frequency excitation. Using our approach, we numerically demonstrate the optical antimatter functionality, as well as double focusing by an ideal perfect lens and superscattering. Our work demonstrates the power of temporally structured light in unlocking the promising opportunities of complementary media, which have until now been inhibited by material loss.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "在复杂频率激励下使用无源有损材料的理想光学反物质",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>左手材料的最初概念激发了光学反物质的可能性，其中光通过介质传播的效应可以被其互补介质完全抵消。尽管负折射率超材料的开发最近取得了进展，但损耗仍然是实现光学反物质的重大障碍。在这项工作中，我们展示了当被复杂频率的光照射时，无源有损材料可用于实现光学反物质。我们进一步证明，人们可以设计此类材料中任意复值的介电常数和磁导率。引人注目的是，我们表明，在实际频率下具有正折射率的材料可以在复杂频率激励下充当负折射率材料。使用我们的方法，我们以数字方式演示了光学反物质功能，以及理想完美透镜和超级散射的双重聚焦。我们的工作展示了时间结构光在释放互补介质的有希望的机会方面的力量，而迄今为止，这些机会一直受到材料损失的抑制。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02105-4",
        "title": "Compact THz absorption spectroscopy using a LiNbO3 slot waveguide",
        "link": "https://doi.org/10.1038/s41377-025-02105-4",
        "published": "2026-01-04",
        "author": "Eric R. Sung, Keith A. Nelson",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>THz spectroscopy is a powerful tool for studying a variety of samples, ranging from large biomolecules to solid-state materials. In cases where experimental space is limited or sample volumes are small, THz waveguides have been used to enable compact THz spectroscopy. The THz polaritonics platform is a waveguide-based approach that uses a thin lithium niobate slab to allow direct visualization of THz fields as they interact with structures integrated into the waveguide. Although there have been many successful studies using the platform for integrated photonics, the platform’s utility as a spectroscopic tool has been largely unexploited. Here, we use a slot waveguide integrated into the thin lithium niobate slab to measure the absorption spectrum of a sample inserted into the slot. The slot waveguide localizes the THz electric field within a low-index slot where a sample is placed. The THz fields propagate through the slot and are monitored as they interact with the sample. Perturbation theory is then used to extract the absorption spectrum and bulk refractive index of the sample with good sensitivity. These results show much promise for enabling compact linear and nonlinear THz spectroscopy using thin lithium niobate waveguides.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "使用 LiNbO3 槽波导的紧凑型太赫兹吸收光谱",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>太赫兹光谱是研究各种样品（从大生物分子到固态材料）的强大工具。在实验空间有限或样品体积较小的情况下，太赫兹波导可用于实现紧凑的太赫兹光谱。太赫兹极化激元平台是一种基于波导的方法，它使用薄铌酸锂板来直接可视化太赫兹场，因为它们与集成到波导中的结构相互作用。尽管已经有许多使用该平台进行集成光子学的成功研究，但该平台作为光谱工具的实用性基本上尚未得到开发。在这里，我们使用集成到薄铌酸锂板中的槽波导来测量插入槽中的样品的吸收光谱。槽波导将太赫兹电场定位在放置样品的低折射率槽内。太赫兹场通过槽传播，并在它们与样品相互作用时受到监测。然后利用微扰理论以良好的灵敏度提取样品的吸收光谱和体折射率。这些结果显示了使用薄铌酸锂波导实现紧凑线性和非线性太赫兹光谱的巨大希望。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02056-w",
        "title": "Optical frequency comb integration in radio telescopes: advancing signal generation and phase calibration",
        "link": "https://doi.org/10.1038/s41377-025-02056-w",
        "published": "2026-01-04",
        "author": "Minji Hyun, Changmin Ahn, Junyong Choi, Jihoon Baek, Woosong Jeong, Do-Heung Je, Do-Young Byun, Jan Wagner, Myoung-Sun Heo, Taehyun Jung, Jungwon Kim",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Very long baseline interferometry (VLBI) enables high-angular-resolution observations in astronomy and geodesy by synthesizing a virtual telescope with baselines spanning hundreds to thousands of kilometres. Achieving high instrumental phase stability in VLBI relies on the generation of high-quality, atomic-referenced RF local oscillator (LO) and RF-comb signals for the effective downconversion of celestial RF signals and precise phase calibration, respectively. As observing frequencies move into higher ranges with wider bandwidths, conventional electronic methods face significant challenges in maintaining the quality of these signals. Here, we demonstrate that an optical frequency comb (OFC) can be used as a versatile tool to generate and distribute low-noise and atomic-referenced RF-comb and RF-LO signals in the VLBI telescope. Hydrogen maser-stabilized optical pulses are transmitted over a timing-stabilized fibre link from the observatory building to the VLBI receiver system at the telescope, where photodetection converts them into the required RF signals. In VLBI test observation, we successfully detected VLBI fringes and extracted the RF-combs characteristics in a format suitable for VLBI instrumental phase calibration. These results highlight the high potential of OFC-based technology for enhancing next-generation broadband VLBI measurements, advancing astrophysical research and facilitating intercontinental clock comparison.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "射电望远镜中的光学频率梳集成：推进信​​号生成和相位校准",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>超长基线干涉测量 (VLBI) 通过合成基线跨越数百至数千公里的虚拟望远镜，实现天文学和大地测量中的高角分辨率观测。在 VLBI 中实现高仪器相位稳定性依赖于生成高质量的原子参考射频本地振荡器 (LO) 和射频梳信号，分别用于天体射频信号的有效下变频和精确的相位校准。随着观测频率进入更高的范围和更宽的带宽，传统的电子方法在维持这些信号的质量方面面临着巨大的挑战。在这里，我们证明光学频率梳（OFC）可以用作一种多功能工具，在 VLBI 望远镜中生成和分发低噪声和原子参考 RF 梳和 RF-LO 信号。氢脉塞稳定的光脉冲通过定时稳定的光纤链路从天文台大楼传输到望远镜的 VLBI 接收系统，在那里光电探测将它们转换成所需的射频信号。在VLBI测试观测中，我们成功检测到了VLBI条纹，并以适合VLBI仪器相位校准的格式提取了射频梳特征。这些结果凸显了基于 OFC 的技术在增强下一代宽带 VLBI 测量、推进天体物理研究和促进洲际时钟比较方面的巨大潜力。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02069-5",
        "title": "Non-Hermitian quantum walks uncover dynamical quantum phase transitions under self-normal and biorthogonal bases",
        "link": "https://doi.org/10.1038/s41377-025-02069-5",
        "published": "2026-01-04",
        "author": "Guangzhen Li, Luqi Yuan",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>The differences in critical times and critical momenta between self-normal and biorthogonal dynamical quantum phase transitions are revealed. The theoretical analysis is experimentally validated through multiple quench processes using a one-dimensional discrete-time non-Hermitian quantum walks.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "非厄米量子行走揭示了自法线和双正交基下的动态量子相变",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>揭示了自法向和双正交动态量子相变之间临界时间和临界动量的差异。理论分析通过使用一维离散时间非厄米量子行走的多个淬灭过程进行了实验验证。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02117-0",
        "title": "Label-free mid-infrared dichroism-sensitive photoacoustic microscopy for histostructural analysis of engineered heart tissues",
        "link": "https://doi.org/10.1038/s41377-025-02117-0",
        "published": "2026-01-04",
        "author": "Eunwoo Park, Dong Gyu Hwang, Hwanyong Choi, Donggyu Kim, Joongho Ahn, Yong-Jae Lee, Tae Joong Eom, Jinah Jang, Chulhong Kim",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Many biological tissues, such as cardiac muscle, tendons, and the cornea, exhibit highly organized microstructural alignment that is critical for mechanical and physiological functions. Disruptions in this structural organization are commonly associated with pathological conditions such as fibrosis, infarction, and cancer. However, conventional histological imaging techniques rely on immunofluorescence or histochemical staining, and they evaluate tissue alignment via non-physical 2D gradient-based calculation, which is labor-intensive, antibody-dependent, and prone to variability. Here, we demonstrate label-free mid-infrared dichroism-sensitive photoacoustic microscopy (MIR-DS-PAM), an analytical imaging system for cardiac tissue assessments. By combining molecular specificity with polarization sensitivity, this method selectively visualizes protein-rich engineered heart tissue (EHT) and quantifies the extracellular matrix (ECM) alignment without any labeling. The extracted dichroism-sensitive parameters, such as the degree of dichroism and the orientation angle, enable histostructural evaluation of tissue integrity and reveal diagnostic cues in fibrotic EHT. This technique offers a label-free analytical tool for fibrosis research and tissue engineering applications.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于工程心脏组织组织结构分析的无标记中红外二色性敏感光声显微镜",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>许多生物组织，例如心肌、肌腱和角膜，表现出高度组织化的微观结构排列，这对于机械和生理功能至关重要。这种结构组织的破坏通常与纤维化、梗塞和癌症等病理状况有关。然而，传统的组织学成像技术依赖于免疫荧光或组织化学染色，并且通过非物理的基于二维梯度的计算来评估组织排列，这是劳动密集型的、抗体依赖性的，并且容易出现变异。在这里，我们展示了无标记中红外二色性敏感光声显微镜（MIR-DS-PAM），这是一种用于心脏组织评估的分析成像系统。通过将分子特异性与偏振敏感性相结合，该方法选择性地可视化富含蛋白质的工程心脏组织 (EHT) 并量化细胞外基质 (ECM) 排列，而无需任何标记。提取的二色性敏感参数，例如二色性程度和取向角，能够对组织完整性进行组织结构评估，并揭示纤维化 EHT 的诊断线索。该技术为纤维化研究和组织工程应用提供了一种无标记分析工具。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02049-9",
        "title": "Random optical parametric oscillator fibre sensor",
        "link": "https://doi.org/10.1038/s41377-025-02049-9",
        "published": "2026-01-04",
        "author": "Pedro Tovar, Jean Pierre von der Weid, Yuan Wang, Liang Chen, Xiaoyi Bao",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Fibre laser-sensors have emerged as a promising solution for long-distance sensing, offering high SNR and fine spatial resolution. However, their adoption is constrained by fundamental limitations: they typically require a fixed mirror at the sensing location or access to both fibre ends for electronic selection of the sensing location. This work introduces a random optical parametric oscillator (R-OPO) fibre sensor that addresses these challenges. Similar to a laser-sensor but exploiting modulation instability and continuous weak reflections, the R-OPO sensor enables long-distance access ( &gt; 25 km) sensing by arbitrarily addressing 1 m-long fibre sections over a long sensing range ( &gt; 1 km). It supports both backward and forward sensing, but unlike most forward sensors, the sensing location information is readily available at both fibre ends. Most importantly, it eliminates the need for a fixed mirror at the sensing location, offering electronically tunable sensing locations. The proposed detection scheme enables straightforward quantitative measurement of dynamic perturbations, requiring only a single fast Fourier transform, thus enabling real-time monitoring. Temperature and strain noise-limited sensitivities of 10.73\n                    <jats:inline-formula>\n                      <jats:alternatives>\n                        <jats:tex-math>$${\\mu }^{o}C/\\sqrt{Hz}$$</jats:tex-math>\n                        <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\">\n                          <mml:mrow>\n                            <mml:msup>\n                              <mml:mrow>\n                                <mml:mi>μ</mml:mi>\n                              </mml:mrow>\n                              <mml:mrow>\n                                <mml:mi>o</mml:mi>\n                              </mml:mrow>\n                            </mml:msup>\n                            <mml:mi>C</mml:mi>\n                            <mml:mo>/</mml:mo>\n                            <mml:msqrt>\n                              <mml:mrow>\n                                <mml:mi>H</mml:mi>\n                                <mml:mi>z</mml:mi>\n                              </mml:mrow>\n                            </mml:msqrt>\n                          </mml:mrow>\n                        </mml:math>\n                      </jats:alternatives>\n                    </jats:inline-formula>\n                    and 80.6\n                    <jats:inline-formula>\n                      <jats:alternatives>\n                        <jats:tex-math>$$p\\varepsilon /\\sqrt{Hz}$$</jats:tex-math>\n                        <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\">\n                          <mml:mrow>\n                            <mml:mi>p</mml:mi>\n                            <mml:mi>ε</mml:mi>\n                            <mml:mo>/</mml:mo>\n                            <mml:msqrt>\n                              <mml:mrow>\n                                <mml:mi>H</mml:mi>\n                                <mml:mi>z</mml:mi>\n                              </mml:mrow>\n                            </mml:msqrt>\n                          </mml:mrow>\n                        </mml:math>\n                      </jats:alternatives>\n                    </jats:inline-formula>\n                    were obtained. Taking advantage of four-wave-mixing by-products inherent to R-OPOs, the sensitivity to external perturbations could be enhanced by a factor of two compared to conventional Rayleigh-based sensors. A simple frequency-unwrapping algorithm is proposed to extend the dynamic measurement range, and the continuous monitoring of a 2 °C temperature increase was accurately measured. This first demonstration of a R-OPO fibre sensor establishes the foundations for parametric fibre sensors.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "随机光参量振荡器光纤传感器",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    光纤激光传感器已成为一种有前景的长距离传感解决方案，具有高信噪比和精细的空间分辨率。然而，它们的采用受到基本限制的限制：它们通常需要在传感位置安装固定镜子或访问光纤两端以电子方式选择传感位置。这项工作引入了一种随机光参量振荡器 (R-OPO) 光纤传感器来解决这些挑战。与激光传感器类似，但利用调制不稳定性和连续弱反射，R-OPO 传感器通过在长传感范围 (> 1 km) 内任意寻址 1 m 长的光纤部分来实现长距离访问 (> 25 km) 传感。它支持向后和向前传感，但与大多数前向传感器不同，传感位置信息在光纤两端都很容易获得。最重要的是，它不需要在传感位置安装固定镜子，从而提供电子可调的传感位置。所提出的检测方案能够直接定量测量动态扰动，仅需要单个快速傅里叶变换，从而实现实时监测。温度和应变噪声限制灵敏度为 10.73\n                    <jats:内联公式>\n                      <贾茨：替代品>\n                        <jats:tex-math>$${\\mu }^{o}C/\\sqrt{Hz}$$</jats:tex-math>\n                        <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\">\n                          <mml:mrow>\n                            <mml:msup>\n                              <mml:mrow>\n                                <mml:mi>μ</mml:mi>\n                              </mml:mrow>\n                              <mml:mrow>\n                                <mml:mi>o</mml:mi>\n                              </mml:mrow>\n                            </mml：msup>\n                            <mml:mi>C</mml:mi>\n                            <mml：月>/</mml：月>\n                            <mml:msqrt>\n                              <mml:mrow>\n                                <mml:mi>H</mml:mi>\n                                <mml:mi>z</mml:mi>\n                              </mml:mrow>\n                            </mml：msqrt>\n                          </mml:mrow>\n                        </mml：数学>\n                      </jats：替代品>\n                    </jats:内联公式>\n                    和80.6\n                    <jats:内联公式>\n                      <贾茨：替代品>\n                        <jats:tex-math>$$p\\varepsilon /\\sqrt{Hz}$$</jats:tex-math>\n                        <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\">\n                          <mml:mrow>\n                            <mml:mi>p</mml:mi>\n                            <mml:mi>ε</mml:mi>\n                            <mml：月>/</mml：月>\n                            <mml:msqrt>\n                              <mml:mrow>\n                                <mml:mi>H</mml:mi>\n                                <mml:mi>z</mml:mi>\n                              </mml:mrow>\n                            </mml：msqrt>\n                          </mml:mrow>\n                        </mml：数学>\n                      </jats：替代品>\n                    </jats:内联公式>\n                    获得。利用 R-OPO 固有的四波混合副产品，与传统的基于瑞利的传感器相比，对外部扰动的灵敏度可以提高两倍。提出了一种简单的频率展开算法来扩展动态测量范围，并且对2°C温度升高的连续监测进行了精确测量。 R-OPO 光纤传感器的首次演示为参数光纤传感器奠定了基础。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02128-x",
        "title": "Near infrared light controlled gene editing",
        "link": "https://doi.org/10.1038/s41377-025-02128-x",
        "published": "2026-01-05",
        "author": "Mikhail Y. Berezin",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>A novel NIR light-activated CRISPR-dCas9/Cas9 system achieves precise and rapid gene regulation in living organism using a chemically cleavable rapamycin dimer. Unlike previous light-driven systems, this approach offers deeper tissue penetration, low toxicity, fast response, and minimal background activity. This platform opens new directions for highly efficient, targeted, noninvasive, and spatially confined gene editing for a great number of preclinical and clinically translatable applications.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "近红外光控制的基因编辑",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>一种新型近红外光激活 CRISPR-dCas9/Cas9 系统利用可化学裂解的雷帕霉素二聚体在活体中实现精确、快速的基因调控。与以前的光驱动系统不同，这种方法具有更深的组织穿透性、低毒性、快速响应和最小的背景活性。该平台为大量临床前和临床可转化应用的高效、靶向、非侵入性和空间受限的基因编辑开辟了新的方向。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02090-8",
        "title": "Intrapulse multimodal four-wave sum mixing in the visible range from high contrast index grating with PMMA layer",
        "link": "https://doi.org/10.1038/s41377-025-02090-8",
        "published": "2026-01-05",
        "author": "Paolo Franceschini, Andrea Tognazzi, Evgenii Menshikov, Leonid Y. Beliaev, Radu Malureanu, Osamu Takayama, Ivano Alessandri, Alfonso Carmelo Cino, Domenico de Ceglia, Andrei V. Lavrinenko, Costantino De Angelis",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Nonlinear metasurfaces have emerged as powerful platforms for enhancing and controlling light-matter interactions at the nanoscale, enabling versatile and compact design of devices for frequency conversion processes. In this work, we report on the experimental observation and theoretical analysis of intrapulse four-wave sum mixing (FWSM) in a high-index contrast grating (HCG) supporting quasi-bound states in the continuum (q-BIC). By engineering a one-dimensional silicon-based HCG with an additional poly(methyl methacrylate) (PMMA) cladding layer, we achieve the simultaneous excitation of a q-BIC and a guided-mode resonance (GMR), enabling nonlinear coupling between the two modes. Broadband femtosecond excitation reveals multiple distinct spectral peaks in the visible range, attributed to FWSM processes involving different combinations of q-BIC and GMR frequencies. Fourier microscopy measurements further confirm the redistribution of the generated nonlinear signals among diffraction orders. Our results demonstrate a new approach to tailoring nonlinear frequency mixing through metasurfaces, leveraging the interaction of multiple non-local resonances, thus opening new pathways for tunable frequency conversion, all-optical signal processing, and nonlinear photonic devices.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "具有 PMMA 层的高对比度指数光栅在可见光范围内进行脉冲内多模态四波和混频",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>非线性超表面已成为增强和控制纳米尺度光与物质相互作用的强大平台，从而实现了用于频率转换过程的设备的多功能和紧凑设计。在这项工作中，我们报告了支持连续体准束缚态（q-BIC）的高折射率对比光栅（HCG）中脉冲内四波和混频（FWSM）的实验观察和理论分析。通过设计带有附加聚甲基丙烯酸甲酯 (PMMA) 包层的一维硅基 HCG，我们实现了 q-BIC 和导模谐振 (GMR) 的同时激发，从而实现了两种模式之间的非线性耦合。宽带飞秒激发揭示了可见光范围内多个不同的光谱峰，这归因于涉及 q-BIC 和 GMR 频率的不同组合的 FWSM 过程。傅立叶显微镜测量进一步证实了所生成的非线性信号在衍射级之间的重新分布。我们的结果展示了一种通过超表面定制非线性混频的新方法，利用多个非局部共振的相互作用，从而为可调谐频率转换、全光信号处理和非线性光子器件开辟了新的途径。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02149-6",
        "title": "Optoretinography reveals rapid rod photoreceptor movement upon rhodopsin activation",
        "link": "https://doi.org/10.1038/s41377-025-02149-6",
        "published": "2026-01-07",
        "author": "Huakun Li, Connor E. Weiss, Vimal Prabhu Pandiyan, Davide Nanni, Teng Liu, Pei Wen Kung, Bingyao Tan, Veluchamy Amutha Barathi, Leopold Schmetterer, Ramkumar Sabesan, Tong Ling",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Rod photoreceptors are essential for vision under dim light conditions and are highly vulnerable in retinal degenerative diseases. Here, we demonstrate that both human and rodent rods undergo a minute and rapid contraction of their outer segments upon photoisomerization, the first step of phototransduction. The contraction is explained as an electromechanical manifestation of the rod early receptor potential generated in the disk membranes, which is challenging to access in electrophysiology. The in vivo optical imaging of light-evoked electrical activity in rodent rods was facilitated by an ultrahigh-resolution point-scan optical coherence tomography (OCT) system, combined with an unsupervised learning approach to separate the light-evoked response of the rod outer segment tips from the retinal pigment epithelium-Bruch’s membrane complex. In humans, an adaptive optics line-scan OCT facilitated high-speed recordings in rods. The non-invasive in vivo optical imaging of rhodopsin activation extends the diagnostic capability of optoretinography, and may facilitate personalized, objective assessment of rod dysfunction and visual cycle impairment in inherited and age-related macular degeneration.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "视视网膜成像显示视紫红质激活后视杆光感受器快速运动",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>视杆细胞对于弱光条件下的视力至关重要，并且在视网膜退行性疾病中非常脆弱。在这里，我们证明人类和啮齿动物的视杆细胞在光异构化（光转导的第一步）时其外节都会经历微小而快速的收缩。这种收缩被解释为椎间盘膜中产生的杆早期受体电位的机电表现，这在电生理学中很难理解。超高分辨率点扫描光学相干断层扫描（OCT）系统促进了啮齿动物视杆细胞光诱发电活动的体内光学成像，并结合无监督学习方法将视杆细胞外节尖端的光诱发反应与视网膜色素上皮-布鲁赫膜复合物分开。在人类中，自适应光学线扫描 OCT 促进了视杆细胞的高速记录。视紫红质激活的非侵入性体内光学成像扩展了视视网膜成像的诊断能力，并可能有助于对遗传性和年龄相关性黄斑变性中视杆细胞功能障碍和视觉周期损伤的个性化、客观评估。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02130-3",
        "title": "Colossal infrared nonlinear optical anisotropy in a 2D charge-transfer Mott insulator",
        "link": "https://doi.org/10.1038/s41377-025-02130-3",
        "published": "2026-01-08",
        "author": "Ruihuan Duan, Song Zhu, Xiaodong Xu, Yao Wu, Sicheng Zhou, Xuan Mao, Zhen Xu, Wenduo Chen, Xiaodan Lyu, Youqiang Huang, Yi Zhang, Fakun Wang, Lishu Wu, Ya Deng, Manzhang Xu, Yanchao He, Jiayu Shi, Wenting Zhao, Guangtong Liu, Weibo Gao, Zhipei Sun, Xingji Li, Qi Jie Wang, Zheng Liu",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Mott insulators are a unique class of materials whose insulating state originates from strong electron-electron correlations: the interactions localize charge carriers, and the resulting on-site Coulomb repulsion opens a charge gap, fundamentally different from conventional insulators, making these systems an exceptional platform for exploring exotic physical phenomena. Significantly, the interplay between strong correlations and charge transfer not only stabilizes the antiferromagnetic ground state but also endows the material with enriched properties, particularly in optics. Herein, we demonstrate a 2D antiferromagnetic charge-transfer Mott insulator, Vanadium Oxychloride (VOCl), which shows giant third-harmonic generation (THG) anisotropy (\n                    <jats:italic>ρ</jats:italic>\n                    <jats:sub>THG</jats:sub>\n                     = \n                    <jats:italic>I</jats:italic>\n                    <jats:sub>x</jats:sub>\n                    /\n                    <jats:italic>I</jats:italic>\n                    <jats:sub>y</jats:sub>\n                    , where\n                    <jats:italic>I</jats:italic>\n                    <jats:sub>x</jats:sub>\n                    and\n                    <jats:italic>I</jats:italic>\n                    <jats:sub>y</jats:sub>\n                    represent the THG intensities corresponding to the excitation polarization parallel to crystal’s\n                    <jats:italic>x</jats:italic>\n                    - and\n                    <jats:italic>y</jats:italic>\n                    -axes), with\n                    <jats:italic>ρ</jats:italic>\n                    <jats:sub>THG</jats:sub>\n                    reaching up to 187 at 1280 nm excitation wavelength. Notably, it is the highest THG anisotropic ratio within the van der Waals materials family. The nonlinear anisotropy is further modulated across a broadband infrared (IR) excitation wavelength range from 2028 to 1280 nm, during which\n                    <jats:italic>ρ</jats:italic>\n                    <jats:sub>THG</jats:sub>\n                    rises from 2.6 to 187, corresponding to a 72-fold enhancement relative to its value at 2028 nm. Additionally, VOCl demonstrates layer-independent third-order susceptibilities (χ\n                    <jats:sup>(3)</jats:sup>\n                     ~ 10\n                    <jats:sup>-19</jats:sup>\n                    m\n                    <jats:sup>2</jats:sup>\n                    /V\n                    <jats:sup>2</jats:sup>\n                    ) and band structures attributed to its extremely weak interlayer electronic coupling. Moreover, the colossal THG anisotropic ratio in 2D VOCl can be ascribed to the synergistic effect of the correlated charge-transfer Mott insulator behavior and intrinsic\n                    <jats:italic>C</jats:italic>\n                    <jats:sub>3</jats:sub>\n                    symmetry breaking, as supported by theoretical calculations. The colossal nonlinear optical anisotropy in 2D VOCl positions it as an excellent candidate for nanophotonic and optoelectronic applications, enabling next-generation nanodevices based on 2D correlated Mott insulators.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "二维电荷转移莫特绝缘体中巨大的红外非线性光学各向异性",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    莫特绝缘体是一类独特的材料，其绝缘状态源自强电子-电子相关性：相互作用使载流子局域化，由此产生的现场库仑斥力打开电荷间隙，与传统绝缘体根本不同，使这些系统成为探索奇异物理现象的特殊平台。值得注意的是，强相关性和电荷转移之间的相互作用不仅稳定了反铁磁基态，而且赋予了材料丰富的特性，特别是在光学方面。在这里，我们展示了一种二维反铁磁电荷转移莫特绝缘体，即氯氧化钒（VOCl），它表现出巨大的三次谐波产生（THG）各向异性（\n                    <jats:斜体>ρ</jats:斜体>\n                    <jats:sub>THG</jats:sub>\n                     = \n                    <贾茨：斜体>我</贾茨：斜体>\n                    <jats:sub>x</jats:sub>\n                    /\n                    <贾茨：斜体>我</贾茨：斜体>\n                    <jats:sub>y</jats:sub>\n                    , 其中\n                    <贾茨：斜体>我</贾茨：斜体>\n                    <jats:sub>x</jats:sub>\n                    和\n                    <贾茨：斜体>我</贾茨：斜体>\n                    <jats:sub>y</jats:sub>\n                    代表与晶体平行的激发偏振对应的 THG 强度\n                    <jats:斜体>x</jats:斜体>\n                    - 和\n                    <jats:斜体>y</jats:斜体>\n                    -轴），与\n                    <jats:斜体>ρ</jats:斜体>\n                    <jats:sub>THG</jats:sub>\n                    在1280nm激发波长处达到187。值得注意的是，它是范德华材料系列中最高的 THG 各向异性比。非线性各向异性在 2028 至 1280 nm 的宽带红外 (IR) 激发波长范围内进一步调制，在此期间\n                    <jats:斜体>ρ</jats:斜体>\n                    <jats:sub>THG</jats:sub>\n                    从 2.6 上升到 187，相当于相对于 2028nm 处的值增强了 72 倍。此外，VOCl 表现出与层无关的三阶磁化率 (χ\n                    <贾茨：sup>（3）</贾茨：sup>\n                     ~ 10\n                    <贾茨：sup>-19</贾茨：sup>\n                    米\n                    <贾茨：sup>2</贾茨：sup>\n                    /V\n                    <贾茨：sup>2</贾茨：sup>\n                    ）和能带结构归因于其极弱的层间电子耦合。此外，2D VOCl 中巨大的 THG 各向异性比可归因于相关电荷转移莫特绝缘体行为和本征的协同效应\n                    <jats:斜体>C</jats:斜体>\n                    <贾茨：子>3</贾茨：子>\n                    对称性破缺，得到理论计算的支持。 2D VOCl 中巨大的非线性光学各向异性使其成为纳米光子和光电应用的绝佳候选者，从而实现基于 2D 相关莫特绝缘体的下一代纳米器件。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02156-7",
        "title": "Superradiant terahertz free-electron laser driven by electron microbunch trains",
        "link": "https://doi.org/10.1038/s41377-025-02156-7",
        "published": "2026-01-08",
        "author": "Yifan Liang, Tong Li, Jitao Sun, Zhuoyuan Liu, Jiayue Yang, Xiaofan Wang, Yong Yu, Qili Tian, Zhigang He, Hongfei Wang, Li Zeng, Huaiqian Yi, Hao Sun, Yingjie Dai, Xiujie Deng, Guorong Wu, Weiqing Zhang, Xueming Yang, Chuanxiang Tang, Lixin Yan",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Superradiance, an enhanced radiation phenomenon stemming from the phase synchronization of emitters, features a radiation intensity proportional to the number of emitters squared. The pursuit of superradiance from free electrons has long been a goal for generating intense radiation across a broad spectrum, from terahertz (THz) to the X-ray regime. However, achieving superradiance in the THz spectral range has been hindered by the lack of effective microbunching techniques. Here, we demonstrate an ultra-widely tunable superradiant THz free-electron laser (FEL) driven by high-peak-current electron microbunch trains. The emission efficiency is substantially improved as the ultra-short electron microbunches emit in phase and engage in strong interactions with the generated THz waves within the undulator. We further demonstrate that the implementation of a tapered undulator configuration leads to a two-fold enhancement in emission intensity compared to the non-tapered case, elevating the pulse energy of the narrow-band THz radiation to the millijoule level in a one-meter-long undulator. This experimental breakthrough represents a critical step toward realizing a compact, high-power, narrow-band THz source capable of fully bridging the ‘THz gap’ and will unlock numerous opportunities across a wide range of scientific disciplines.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "电子微束串驱动的超辐射太赫兹自由电子激光器",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>超辐射是一种源自发射器相位同步的增强辐射现象，其特点是辐射强度与发射器数量的平方成正比。长期以来，追求自由电子的超辐射一直是产生从太赫兹 (THz) 到 X 射线范围的广谱强辐射的目标。然而，由于缺乏有效的微聚束技术，在太赫兹光谱范围内实现超辐射一直受到阻碍。在这里，我们展示了一种由高峰值电流电子微束串驱动的超宽可调超辐射太赫兹自由电子激光器（FEL）。由于超短电子微束同相发射并与波荡器内生成的太赫兹波发生强烈相互作用，发射效率得到显着提高。我们进一步证明，与非锥形情况相比，锥形波荡器配置的实施导致发射强度提高两倍，将一米长波荡器中窄带太赫兹辐射的脉冲能量提升至毫焦耳水平。这一实验突破代表着朝着实现紧凑、高功率、窄带太赫兹源迈出的关键一步，该源能够完全弥合“太赫兹差距”，并将在广泛的科学学科中释放大量机会。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02050-2",
        "title": "Integrated, ultrafast all-optical polariton transistors with sub-wavelength grating microcavities",
        "link": "https://doi.org/10.1038/s41377-025-02050-2",
        "published": "2026-01-12",
        "author": "Pietro Tassan, Darius Urbonas, Bartos Chmielak, Jens Bolten, Thorsten Wahlbrink, Max C. Lemme, Michael Forster, Ullrich Scherf, Rainer F. Mahrt, Thilo Stöferle",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    All-optical logic has the potential to overcome the operation speed barrier that has persisted in electronic circuits for two decades. However, the development of scalable architectures has been prevented so far by the lack of materials with sufficiently strong nonlinear interactions needed to realize compact and efficient ultrafast all-optical switches with optical gain. Microcavities with embedded organic material in the strong light-matter interaction regime have recently enabled all-optical transistors operating at room temperature with picosecond switching times. However, the vertical cavity geometry, which is predominantly used in polaritonics, is not suitable for complex circuits with on-chip coupled transistors. Here, by leveraging state-of-the-art silicon photonics technology, we have achieved exciton-polariton condensation at ambient conditions in fully integrated high-index contrast sub-wavelength grating microcavities filled with a π-conjugated polymer as optically active material. We demonstrate ultrafast all-optical transistor action by coupling two resonators and utilizing seeded polariton condensation. With a device area as small as 2 × 2 µm\n                    <jats:sup>2</jats:sup>\n                    , we realize picosecond switching and amplification up to 60x, with extinction ratio up to 8:1. This compact ultrafast transistor device with in-plane integration is a key component for a scalable platform for all-optical logic circuits that could operate two orders of magnitude faster than electronic counterparts.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "具有亚波长光栅微腔的集成超快全光极化子晶体管",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    全光逻辑有潜力克服电子电路中二十年来一直存在的运算速度障碍。然而，迄今为止，由于缺乏实现具有光增益的紧凑高效超快全光开关所需的具有足够强非线性相互作用的材料，可扩展架构的发展一直受到阻碍。最近，在强光-物质相互作用状态下嵌入有机材料的微腔使得全光晶体管能够在室温下以皮秒开关时间运行。然而，主要用于极化子学的垂直腔几何结构并不适合具有片上耦合晶体管的复杂电路。在这里，通过利用最先进的硅光子技术，我们在环境条件下在完全集成的高折射率对比度亚波长光栅微腔中实现了激子-极化子凝聚，微腔填充有作为光学活性材料的π共轭聚合物。我们通过耦合两个谐振器并利用种子极化子凝聚来演示超快全光晶体管动作。器件面积小至2 × 2 μm\n                    <贾茨：sup>2</贾茨：sup>\n                    ，我们实现了高达 60 倍的皮秒切换和放大，消光比高达 8:1。这种具有面内集成的紧凑型超快晶体管器件是全光逻辑电路可扩展平台的关键组件，其运行速度比电子同类器件快两个数量级。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02131-2",
        "title": "Self-powered mechanoluminescent elastomer for solar-blind ultraviolet emission",
        "link": "https://doi.org/10.1038/s41377-025-02131-2",
        "published": "2026-01-12",
        "author": "Xulong Lv, Tianyi Duan, Shaofan Fang, Zhaofeng Wang, Dongxun Chen, Lipeng Huang, Huanyu Liu, Zheming Liu, Chao Liu, Xiao-Jun Wang, Yanjie Liang",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Flexible mechanoluminescence (ML) elastomers show significant potential for next-generation wearable electronics, artificial skin, advanced sensing, and human-machine interaction. However, their broader application has been hindered by challenges such as restricted emission wavelengths, inadequate repeatability, insufficient cyclic stability, and poor self-recovery. Here, we report an innovative and high-performance solar-blind ultraviolet ML elastomer by combining commercial polydimethylsiloxane (PDMS) and newly fabricated Sr\n                    <jats:sub>3</jats:sub>\n                    (BO\n                    <jats:sub>3</jats:sub>\n                    )\n                    <jats:sub>2</jats:sub>\n                    :Pr\n                    <jats:sup>3+</jats:sup>\n                    phosphors, capable of generating intense ultraviolet-C (UVC) ML peaked at 272 nm under mechanical stimulation. The composite elastomer exhibits exceptional repeatability and cyclic stability, maintaining detectable UVC emission over 10,000 continuous stretching cycles (power intensity at the 1st cycle is ~6.2 mW m\n                    <jats:sup>−2</jats:sup>\n                    ). It also demonstrates rapid and efficient self-recovery behavior, restoring 43.2% of its initial intensity within 1 s and 90.2% after 24 h. Combined experimental and theoretical analyses reveal that interfacial triboelectrification, involving electron transfer from the phosphor to the PDMS matrix, leads to the observed UVC ML emission. Leveraging the solar-blind nature and high photon energy of UVC light, we further demonstrate the feasibility of self-powered photonics applications. This work not only offers novel insights into the design of advanced UVC ML systems but also provides “power-free” solutions for important applications where UVC photons are essential, such as outdoor optical tagging and microbial sterilization.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于日盲紫外线发射的自供电机械发光弹性体",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    柔性机械发光 (ML) 弹性体在下一代可穿戴电子产品、人造皮肤、先进传感和人机交互方面显示出巨大潜力。然而，其更广泛的应用受到发射波长受限、重复性不足、循环稳定性不足和自恢复性差等挑战的阻碍。在这里，我们报告了一种创新的高性能日盲紫外线 ML 弹性体，该弹性体结合了商用聚二甲基硅氧烷 (PDMS) 和新制造的 Sr\n                    <贾茨：子>3</贾茨：子>\n                    （博\n                    <贾茨：子>3</贾茨：子>\n                    ）\n                    <贾茨：子>2</贾茨：子>\n                    :Pr\n                    <贾茨：sup>3+</贾茨：sup>\n                    荧光粉，能够在机械刺激下产生强烈的紫外线 C (UVC) ML，峰值波长为 272 nm。该复合弹性体表现出卓越的重复性和循环稳定性，在 10,000 次连续拉伸循环中保持可检测的 UVC 发射（第一个循环的功率强度约为 6.2 mW m\n                    <jats:sup>−2</jats:sup>\n                    ）。它还表现出快速有效的自我恢复行为，1秒内恢复初始强度的43.2%，24小时后恢复90.2%。实验和理论分析相结合表明，界面摩擦起电（涉及从荧光粉到 PDMS 基质的电子转移）导致观察到的 UVC ML 发射。利用UVC光的日盲特性和高光子能量，我们进一步证明了自供电光子学应用的可行性。这项工作不仅为先进的 UVC ML 系统的设计提供了新颖的见解，而且还为 UVC 光子必不可少的重要应用提供了“无电”解决方案，例如户外光学标签和微生物灭菌。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02146-9",
        "title": "On-chip nonlocal metasurface for color router: conquering efficiency-loss from spatial-multiplexing",
        "link": "https://doi.org/10.1038/s41377-025-02146-9",
        "published": "2026-01-12",
        "author": "Yangyang Shi, Shuai Wan, Zejing Wang, Runlong Rao, Zhongyang Li",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Metasurfaces integrated onto guided-wave photonic systems have been investigated for enabling advanced functionalities such as point-by-point optical extraction and manipulation of amplitude, phase, and polarization. However, achieving full control over the spectrum (i.e., wavelength/frequency) of on-chip light remains a challenge, limiting their widespread application in integrated photonics. Here, we propose and experimentally demonstrate an on-chip metasurface color router by leveraging symmetry-broken quasi-bound states in the continuum (q-BICs) mode. By precisely engineering the on-chip meta-diatom pairs with controlled scaling and asymmetry, we simultaneously achieve modulation of both extraction intensity and narrowband spectral extraction of the out-coupled lightwave. As a proof of concept, we realize several on-chip multiplexed color routers through spatial mapping and cascading of distinct q-BIC-assisted meta-diatom pixels, capable of selectively guiding and routing primary wavelengths into free space from different spatial positions along the waveguide. Crucially, due to the on-chip optical propagation scheme, these color routers, enabled by nonlocal metasurfaces, exhibit spatial multiplexing but with a significant improvement in the energy utilization efficiency (EUE) compared with conventional designs. We envision that such on-chip q-BIC-assisted metasurface color routers, with their potential for miniaturized integration, could open new avenues for advanced applications in multiplexed information routing, intelligent integrated photonic systems, and next-generation wearable display technologies.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于彩色路由器的片上非局部超表面：克服空间复用带来的效率损失",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>集成到导波光子系统上的超表面已经被研究用于实现先进的功能，例如逐点光学提取以及幅度、相位和偏振的操纵。然而，实现对片上光的光谱（即波长/频率）的完全控制仍然是一个挑战，限制了它们在集成光子学中的广泛应用。在这里，我们通过利用连续体（q-BIC）模式中对称破缺的准束缚态，提出并实验演示了一种片上超表面颜色路由器。通过精确设计具有受控缩放和不对称性的片上元硅藻对，我们同时实现了输出耦合光波的提取强度和窄带光谱提取的调制。作为概念证明，我们通过空间映射和不同 q-BIC 辅助元硅藻像素的级联实现了多个片上多路复用颜色路由器，能够选择性地将主波长从波导的不同空间位置引导和路由到自由空间。至关重要的是，由于采用片上光学传播方案，这些由非局部超表面实现的彩色路由器表现出空间复用，但与传统设计相比，能量利用效率（EUE）显着提高。我们设想，这种片上 q-BIC 辅助超表面彩色路由器具有小型化集成的潜力，可以为多路复用信息路由、智能集成光子系统和下一代可穿戴显示技术的高级应用开辟新途径。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02170-9",
        "title": "Gradient-graphene-enabled directional photothermal regulation for self-aligned laser transfer printing",
        "link": "https://doi.org/10.1038/s41377-025-02170-9",
        "published": "2026-01-12",
        "author": "Mengxin Gai, Jing Bian, Furong Chen, Lei Liu, Yu Luo, Yuxing Ma, Xincheng Huang, Hong Xiao, YongAn Huang",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Laser-assisted transfer printing has gained attention for integrating microdevices on unusual substrates. However, conventional technologies exhibit limited fault tolerance during laser-matter interactions, reducing transfer accuracy due to unavoidable irradiation deviations. We report a self-aligned laser transfer (SALT) that enables high-precision, programmable assembly of microchips without precise laser-to-die alignment. A thermal conductivity gradient carbon (TCGC), with an upper graphene layer and lower amorphous carbon layer, is embedded in the stamp via excimer laser self-limited carbonization of polyimide. The TCGC converts asymmetric light input into uniform heat output under non-uniform/misaligned infrared laser irradiation, whereas the upper graphene layer absorbs heat from the lower amorphous carbon and rapidly conducts heat laterally, ensuring uniform heat distribution of the underlying adhesive layer. This guarantees synchronous chip release at all adhesive sites, mitigating transfer deviations. Additionally, periodically arranged, grayscale-controlled TCGC can be fabricated by modulating excimer laser parameters during carbonization, thereby enabling selective microchip release without pre-planned scanning paths. SALT achieves excellent size compatibility ( &lt; 100 micrometers) and high tolerance for irradiation deviations (transfer accuracy &lt;5 micrometers). Demonstrations of RGB micro-LED display highlight its self-aligned and batch-selective capabilities.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于自对准激光转移印刷的梯度石墨烯定向光热调节",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>激光辅助转移印刷因在不寻常的基材上集成微型设备而受到关注。然而，传统技术在激光与物质相互作用期间表现出有限的容错能力，由于不可避免的照射偏差而降低了传输精度。我们报告了一种自对准激光转移 (SALT)，它可以实现高精度、可编程的微芯片组装，而无需精确的激光与芯片对准。导热梯度碳（TCGC）具有上层石墨烯层和下层无定形碳层，通过准分子激光自限性碳化聚酰亚胺嵌入到印模中。 TCGC在非均匀/未对准的红外激光照射下将不对称的光输入转换为均匀的热输出，而上层石墨烯层吸收下层非晶碳的热量并快速横向传导热量，确保下面的粘合层的热量分布均匀。这保证了所有粘合部位的芯片同步释放，从而减少了转移偏差。此外，可以通过在碳化过程中调制准分子激光参数来制造周期性排列的灰度控制的TCGC，从而无需预先计划的扫描路径即可选择性地释放微芯片。 SALT 实现了出色的尺寸兼容性（ < 100 微米）和对照射偏差的高容忍度（转移精度<5 微米）。 RGB micro-LED 显示屏的演示突出了其自对准和批量选择功能。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02145-w",
        "title": "Multi-dimensional camouflage against VIS-NIR hyperspectral, MIR intensity, and MIR polarization imaging",
        "link": "https://doi.org/10.1038/s41377-025-02145-w",
        "published": "2026-01-12",
        "author": "Rui Qin, Huanzheng Zhu, Rongxuan Zhu, Pintu Ghosh, Min Qiu, Qiang Li",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Camouflage is essential in modern security and military operations, playing a critical role in evading detection and enhancing the survivability of equipment. However, most existing camouflage devices operate in a single dimension, rendering them inadequate against emerging multi-dimensional detection techniques, including visible to near-infrared (VIS-NIR) hyperspectral imaging and mid-infrared (MIR) polarization imaging. In this work, we propose a multi-dimensional camouflage strategy that realizes simultaneous VIS-NIR spectrum camouflage, MIR intensity, and polarization camouflage by a hierarchical structure. The multi-dimensional camouflage device exhibits an emissivity of 0.7, a low degree of linear polarization (&lt; 1.5%) at large observation angles in MIR range, and high spectral similarity (&gt;96.9%) in the VIS-NIR range. Moreover, it deceives hyperspectral classification in vegetative background and blends into its environment under MIR intensity and polarization imaging. This work introduces a novel paradigm for multi-dimensional camouflage techniques and opens up new avenues for electromagnetic waves manipulation.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "针对 VIS-NIR 高光谱、MIR 强度和 MIR 偏振成像的多维伪装",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>伪装在现代安全和军事行动中至关重要，在逃避检测和提高设备的生存能力方面发挥着关键作用。然而，大多数现有的伪装装置在单一维度上运行，使其不足以应对新兴的多维探测技术，包括可见光到近红外（VIS-NIR）高光谱成像和中红外（MIR）偏振成像。在这项工作中，我们提出了一种多维伪装策略，通过分层结构同时实现可见光-近红外光谱伪装、中红外强度和偏振伪装。该多维伪装装置表现出0.7的发射率、在MIR范围内的大观察角度下的低线性偏振度(＜1.5％)以及在VIS-NIR范围内的高光谱相似性(＞96.9％)。此外，它欺骗植物背景中的高光谱分类，并在中红外强度和偏振成像下融入其环境。这项工作引入了多维伪装技术的新范例，并为电磁波操纵开辟了新途径。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02167-4",
        "title": "Mid-infrared InAs/InP quantum-dot lasers",
        "link": "https://doi.org/10.1038/s41377-025-02167-4",
        "published": "2026-01-12",
        "author": "Yangqian Wang, Hui Jia, Jae-Seong Park, Haotian Zeng, Igor P. Marko, Matthew Bentley, Khalil El Hajraoui, Shangfeng Liu, Bo Yang, Calum Dear, Mengxun Bai, Huiwen Deng, Chong Chen, Jiajing Yuan, Jun Li, Kongming Liu, Dominic A. Duffy, Zhao Yan, Zihao Wang, Stephen J. Sweeney, Qiandong Zhuang, Quentin M. Ramasse, Siming Chen, Mingchu Tang, Qiang Li, Alwyn Seeds, Huiyun Liu",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Mid-infrared semiconductor lasers operating in the 2.0–5.0 μm spectral range play an important role for various applications, including trace-gas detection, biomedical analysis, and free-space optical communication. InP-based quantum-well (QW) and quantum-dash (Qdash) lasers are promising alternatives to conventional GaSb-based QW lasers because of their lower cost and mature fabrication infrastructure. However, they suffer from high threshold current density (\n                    <jats:italic>J</jats:italic>\n                    <jats:sub>th</jats:sub>\n                    ) and limited operation temperatures. InAs/InP quantum-dot (QD) lasers theoretically offer lower\n                    <jats:italic>J</jats:italic>\n                    <jats:sub>th</jats:sub>\n                    owing to their three-dimensional carrier confinement. Nevertheless, achieving high-density, uniform InAs/InP QDs with sufficient gain for lasing over 2 μm remains a major challenge. Here, we report the first demonstration of mid-infrared InAs/InP QD lasers emitting beyond 2 μm. Five-stack InAs/In\n                    <jats:sub>0.532</jats:sub>\n                    Ga\n                    <jats:sub>0.468</jats:sub>\n                    As/InP QDs grown by molecular-beam epitaxy exhibit room-temperature photoluminescence at 2.04 μm. Edge-emitting lasers achieve lasing at 2.018 μm with a low\n                    <jats:italic>J</jats:italic>\n                    <jats:sub>th</jats:sub>\n                    of 589 A cm\n                    <jats:sup>−2</jats:sup>\n                    and a maximum operation temperature of 50 °C. Notably, the\n                    <jats:italic>J</jats:italic>\n                    <jats:sub>th</jats:sub>\n                    per layer (118 A cm\n                    <jats:sup>−2</jats:sup>\n                    ) is the lowest ever reported for room-temperature InP-based mid-infrared lasers, outperforming QW/Qdash counterparts. These results pave the way for a new class of low-cost, high-performance mid-infrared light sources using InAs/InP QDs, marking a notable step forward in the development of mid-infrared semiconductor lasers.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "中红外 InAs/InP 量子点激光器",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    在 2.0–5.0μm 光谱范围内工作的中红外半导体激光器在各种应用中发挥着重要作用，包括痕量气体检测、生物医学分析和自由空间光通信。 InP 基量子阱 (QW) 和量子冲刺 (Qdash) 激光器因其成本较低且制造基础设施成熟而成为传统 GaSb 基 QW 激光器的有前途的替代品。然而，它们面临着高阈值电流密度（\n                    <贾茨：斜体>J</贾茨：斜体>\n                    <jats:sub>第</jats:sub>\n                    ）和有限的工作温度。 InAs/InP 量子点 (QD) 激光器理论上可提供更低的\n                    <贾茨：斜体>J</贾茨：斜体>\n                    <jats:sub>第</jats:sub>\n                    由于它们的三维载流子限制。然而，实现高密度、均匀的 InAs/InP QD 并具有足够的增益以产生超过 2μm 的激光仍然是一个重大挑战。在这里，我们报告了发射超过 2μm 波长的中红外 InAs/InP QD 激光器的首次演示。五叠层 InAs/In\n                    <贾茨：子>0.532</贾茨：子>\n                    嘎\n                    <贾茨：子>0.468</贾茨：子>\n                    通过分子束外延生长的 As/InP QD 在 2.04μm 处表现出室温光致发光。边发射激光器可实现 2.018 μm 的激光发射，且具有低\n                    <贾茨：斜体>J</贾茨：斜体>\n                    <jats:sub>第</jats:sub>\n                    589 A cm\n                    <jats:sup>−2</jats:sup>\n                    最高工作温度为 50°C。值得注意的是，\n                    <贾茨：斜体>J</贾茨：斜体>\n                    <jats:sub>第</jats:sub>\n                    每层（118 A cm\n                    <jats:sup>−2</jats:sup>\n                    ）是室温 InP 基中红外激光器有史以来报道的最低值，优于 QW/Qdash 同类激光器。这些结果为使用 InAs/InP QD 的新型低成本、高性能中红外光源铺平了道路，标志着中红外半导体激光器的发展向前迈出了显着的一步。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02160-x",
        "title": "Phase-multiplied interferometry via cavity dynamics for resolution-enhanced coherent ranging",
        "link": "https://doi.org/10.1038/s41377-025-02160-x",
        "published": "2026-01-12",
        "author": "Yifan Wang, Jinsong Liu, Chenxiao Lin, Xin Xu, Yu Wang, Xinhang Yang, Binbin Xie, Jibo Han, Tengfei Wu, Xuling Lin, Liangcai Cao, Hongbo Sun, Yidong Tan",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Coherent light detection and ranging (LiDAR) has become an indispensable tool in autonomous systems, offering exceptional precision and ambient-light immunity. Recently, applications spanning from scientific research to advanced manufacturing have increasingly required resolution that exceeds current capabilities, which faces a fundamental trade-off between improved performance and system complexity. In this study, we overcome the intrinsic limitation and present a cavity dynamics-enabled approach that actively enhances the ranging resolution through phase multiplication. By injecting target-scattered light into the optical resonator, the operating frequency of the laser undergoes periodic modulation, generating interference harmonics that multiply the phase sensitivity. Experimentally, we observe the excitation of up to the 13th-order harmonic and effective phase multiplication without physical modulation extensions, which enables more than 10 times resolution enhancement for ranging. Owing to the intrinsic phase correlation between the fundamental wave and harmonic waves, the phase noise is effectively controlled, resulting in high-precision ranging with a standard deviation on the order of tens of micrometers. The system concurrently leverages laser feedback sensitivity, achieving significant signal-to-noise ratio (SNR) improvement. With its enhanced resolution, low photon consumption, and low-cost implementation, this technology demonstrates new capabilities that promise to enable a wide range of applications.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "通过腔动力学进行相位倍增干涉测量，以实现分辨率增强的相干测距",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>相干光探测和测距 (LiDAR) 已成为自主系统中不可或缺的工具，提供卓越的精度和环境光抗扰度。最近，从科学研究到先进制造的应用越来越需要超出当前能力的分辨率，这面临着改进的性能和系统复杂性之间的根本权衡。在这项研究中，我们克服了固有的限制，并提出了一种支持腔动力学的方法，该方法通过相位倍增主动增强测距分辨率。通过将目标散射光注入光学谐振腔，激光器的工作频率经历周期性调制，产生使相位灵敏度成倍增加的干涉谐波。通过实验，我们在没有物理调制扩展的情况下观察到高达 13 阶谐波的激励和有效相位倍增，这使得测距分辨率增强了 10 倍以上。由于基波和谐波之间固有的相位相关性，相位噪声得到有效控制，实现了标准偏差数十微米量级的高精度测距。该系统同时利用激光反馈灵敏度，显着提高信噪比 (SNR)。凭借其增强的分辨率、低光子消耗和低成本实施，该技术展示了有望实现广泛应用的新功能。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02067-7",
        "title": "Meta-device for sensing subwavelength lateral displacement",
        "link": "https://doi.org/10.1038/s41377-025-02067-7",
        "published": "2026-01-12",
        "author": "Shufan Chen, Yubin Fan, Hao Li, Xiaodong Qiu, Ben Wang, Lijian Zhang, Shumin Xiao, Din Ping Tsai",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Accurate transverse displacement measurement is essential for precise mask-to-wafer positioning in lithography. While lateral displacement metrology has achieved nanometer-level precision, the limitations imposed by coherent state and grating challenge in-situ measurement speed and precision. Here, we introduce a two-photon state transverse displacement measurement method utilizing a polarization gradient metasurface by employing two-photon state interference. Compared with the classical method, our new method can experimentally reduce the number of detected photons to around 3% with equivalent precision. These attributes make the two-photon state polarization gradient metasurface approach highly suitable for integration with semiconductor lithography processes and show its promise in realizing equivalent measurement precision within notably shorter acquisition durations, providing a robust solution for next-generation transverse displacement measurement requirements.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于传感亚波长横向位移的元装置",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>准确的横向位移测量对于光刻中掩模到晶圆的精确定位至关重要。虽然横向位移计量已达到纳米级精度，但相干态和光栅带来的限制对原位测量速度和精度提出了挑战。在这里，我们介绍了一种利用双光子态干涉的偏振梯度超表面的双光子态横向位移测量方法。与经典方法相比，我们的新方法可以在实验上将检测到的光子数量减少到 3% 左右，同时精度相当。这些属性使得双光子态偏振梯度超表面方法非常适合与半导体光刻工艺集成，并显示出其在显着更短的采集持续时间内实现等效测量精度的前景，为下一代横向位移测量需求提供稳健的解决方案。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02168-3",
        "title": "Absolute thermometry based on Brillouin scattering in gases",
        "link": "https://doi.org/10.1038/s41377-025-02168-3",
        "published": "2026-01-12",
        "author": "Yuting Yang, Marcelo A. Soto, Luc Thévenaz",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>We propose a novel thermometric technique for measuring absolute temperature in gas media based on Brillouin scattering. The method retrieves the temperature from the acoustic velocity of the gas, inferred through the spectral shift experienced by a scattered laser beam during the Brillouin acousto-optic interaction. This approach is inherently contactless, enabling remote sensing applications with high precision. It also exhibits enhanced sensitivity in the cryogenic range and is fully compatible with distributed measurements along recent hollow-core single-mode fibres. This study establishes the theoretical foundations of the technique and provides experimental validation across a range of temperature and pressure conditions. The influence of the gas species on the Brillouin response is analysed, enabling the selection of the optimal gas medium for specific applications. Illustrative distributed measurements demonstrate the strong potential of this technique for cryogenic sensing, where favourable scaling of several parameters leads to significantly improved temperature sensitivity. These results open new avenues for high-accuracy, remote, and minimally invasive thermometric measurements across a wide temperature range, including extreme cryogenic environments.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "基于气体布里渊散射的绝对测温",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>我们提出了一种基于布里渊散射测量气体介质中绝对温度的新型测温技术。该方法从气体的声速中检索温度，这是通过布里渊声光相互作用期间散射激光束经历的光谱偏移推断的。这种方法本质上是非接触式的，可以实现高精度的遥感应用。它还在低温范围内表现出增强的灵敏度，并且与最新空心单模光纤的分布式测量完全兼容。这项研究奠定了该技术的理论基础，并在一系列温度和压力条件下提供了实验验证。分析了气体种类对布里渊响应的影响，从而能够为特定应用选择最佳气体介质。说明性分布式测量证明了该技术在低温传感方面的巨大潜力，其中多个参数的有利缩放可显着提高温度灵敏度。这些结果为在宽温度范围（包括极端低温环境）内进行高精度、远程和微创测温测量开辟了新途径。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02163-8",
        "title": "Deciphering light transformation in chiral metasurface in real space and time by ultrafast electron microscopy",
        "link": "https://doi.org/10.1038/s41377-025-02163-8",
        "published": "2026-01-14",
        "author": "Ling Tong, Fei Xie, Xiaochen Gao, Yuxuan Chen, Shaozheng Ji, Bin Zhang, Jing Li, Jiangteng Guo, Fang Liu, Cuntao Gao, Min Feng, Wei Wu, Shibin Deng, Yiming Pan, Yunquan Liu, Jingjun Xu, Mengxin Ren, Xuewen Fu",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Optical activity in chiral structures, i.e., circular dichroism (CD), has led to significant advances in nanoscale optical manipulation, including chiral metasurfaces, helicoid crystals, and chiral macromolecules. Although the local geometric design of chiral structures fundamentally governs their optical responses, the microscopic origin of CD remains unresolved due to the inability to probe optical chirality generation and local geometry effects with sufficient spatiotemporal resolution. Here, we unveil the light transformation process in a Γ-shaped chiral metasurface by combining far-field ellipticity measurements with direct near-field imaging at nanometer-femtosecond scale using photon-induced near-field electron microscopy (PINEM). By decomposing the near-field distributions into local symmetric and asymmetric components, we define a near-field ellipticity that quantitatively follows the wavelength-dependent far-field ellipticity. Finite-element simulations reveal that an electric dipole at the top-right corner of the Γ-shaped meta-atom dominates the ellipticity, which increases as the dipole contribution grows with wavelength. Crucially, time-resolved PINEM reveals that asymmetric near-fields dissipate faster than the symmetric counterparts by tens to hundreds of femtoseconds, indicating chiral-geometry-dependent energy dissipation pathways. This work provides microscopic insight into light transformation in chiral structures and lays the foundation for advanced chiral photonic device design.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "通过超快电子显微镜解读真实时空中手性超表面的光变换",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>手性结构（即圆二色性（CD））的光学活性导致了纳米级光学操纵的重大进展，包括手性超表面、螺旋晶体和手性大分子。尽管手性结构的局部几何设计从根本上控制其光学响应，但由于无法以足够的时空分辨率探测光学手性的产生和局部几何效应，CD的微观起源仍未解决。在这里，我们通过将远场椭圆率测量与使用光子诱导近场电子显微镜（PINEM）在纳米飞秒尺度上的直接近场成像相结合，揭示了 Γ 形手性超表面中的光变换过程。通过将近场分布分解为局部对称和不对称分量，我们定义了一个近场椭圆率，该近场椭圆率定量地遵循与波长相关的远场椭圆率。有限元模拟表明，位于 Γ 形元原子右上角的电偶极子在椭圆率中占主导地位，并且随着偶极子贡献随波长的增加而增加。至关重要的是，时间分辨的 PINEM 揭示了不对称近场的消散速度比对称近场快数十到数百飞秒，这表明了手性几何依赖的能量耗散途径。这项工作提供了对手性结构中光转换的微观见解，并为先进的手性光子器件设计奠定了基础。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02094-4",
        "title": "Integrated-photonics-based systems for polarization-gradient cooling of trapped ions",
        "link": "https://doi.org/10.1038/s41377-025-02094-4",
        "published": "2026-01-15",
        "author": "Sabrina M. Corsetti, Ashton Hattori, Ethan R. Clements, Felix W. Knollmann, Milica Notaros, Reuel Swint, Tal Sneh, Patrick T. Callahan, Gavin N. West, Dave Kharas, Thomas Mahony, Colin D. Bruzewicz, Cheryl Sorace-Agaskar, Robert McConnell, Isaac L. Chuang, John Chiaverini, Jelena Notaros",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Trapped ions are a promising modality for quantum systems, with demonstrated utility as the basis for quantum processors and optical clocks. However, traditional trapped-ion systems are implemented using complex free-space optical configurations, whose large size and susceptibility to vibrations and drift inhibit scaling to large numbers of qubits. In recent years, integrated-photonics-based systems have been demonstrated as an avenue to address the challenge of scaling trapped-ion systems while maintaining high fidelities. While these previous demonstrations have implemented both Doppler and resolved-sideband cooling of trapped ions, these cooling techniques are fundamentally limited in efficiency. In contrast, polarization-gradient cooling can enable faster and more power-efficient cooling and, therefore, improved computational efficiencies in trapped-ion systems. While free-space implementations of polarization-gradient cooling have demonstrated advantages over other cooling mechanisms, polarization-gradient cooling has never previously been implemented using integrated photonics. In this paper, we design and experimentally demonstrate key polarization-diverse integrated-photonics devices and utilize them to implement a variety of integrated-photonics-based polarization-gradient-cooling systems, culminating in the first experimental demonstration of polarization-gradient cooling of a trapped ion by an integrated-photonics-based system. By demonstrating polarization-gradient cooling using an integrated-photonics-based system and, in general, opening up the field of polarization-diverse integrated-photonics-based devices and systems for trapped ions, this work facilitates new capabilities for integrated-photonics-based trapped-ion platforms.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "用于捕获离子偏振梯度冷却的基于集成光子学的系统",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>捕获离子是量子系统的一种有前途的模式，已被证明可作为量子处理器和光学时钟的基础。然而，传统的俘获离子系统是使用复杂的自由空间光学配置来实现的，其大尺寸以及对振动和漂移的敏感性抑制了大规模量子位的扩展。近年来，基于集成光子学的系统已被证明是解决缩放俘获离子系统挑战同时保持高保真度的一种途径。虽然之前的演示已经实现了捕获离子的多普勒冷却和解析边带冷却，但这些冷却技术从根本上限制了效率。相比之下，偏振梯度冷却可以实现更快、更节能的冷却，从而提高俘获离子系统的计算效率。虽然偏振梯度冷却的自由空间实现已显示出优于其他冷却机制的优势，但偏振梯度冷却以前从未使用集成光子学来实现。在本文中，我们设计并实验演示了关键的偏振分集集成光子器件，并利用它们来实现各种基于集成光子学的偏振梯度冷却系统，最终首次通过基于集成光子学的系统对捕获离子进行偏振梯度冷却的实验演示。通过使用基于集成光子学的系统演示偏振梯度冷却，并且总体上开辟了用于捕获离子的偏振多样化集成光子学设备和系统领域，这项工作促进了基于集成光子学的捕获离子平台的新功能。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02099-z",
        "title": "Plan meta-objective for sub-micron quantitative phase imaging",
        "link": "https://doi.org/10.1038/s41377-025-02099-z",
        "published": "2026-01-20",
        "author": "Junyi Wang, Jiacheng Sun, Jian Li, Chunyu Huang, Jitao Ji, Wenjing Shen, Zhizhang Wang, Junxiao Zhou, Chen Chen, Shining Zhu, Tao Li",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Quantitative phase imaging (QPI) provides valuable objective insights for investigating transparent samples, yet miniaturizing QPI systems without compromising performance remains a critical challenge for applications requiring compactness and portability. Here, by introducing partially coherent illumination modulation, together with a plan meta-objective (PMO) design, we present a compact QPI system with sub-micron resolution. The PMO is a monolithically integrated doublet metalens with its dispersion enabling focal shifts at two wavelengths, obviating the need for mechanical translations during image acquisition for phase retrieval. The PMO is also optimized to correct for monochromatic aberrations, delivering an object-side field of view equivalent to ~90% of the lens aperture with minimal distortion and aberrations. The spatial coherence of the illumination is controlled to enhance imaging resolution. By co-designing illumination and imaging systems, we demonstrate QPI achieving a half-pitch lateral resolution of 488 nm with a phase accuracy of 0.06λ. Our approach enables high-quality QPI analysis of diverse phase objects, including unstained biospecimens, laying the foundation for the development of compact, stable, and practical QPI platforms.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "规划亚微米定量相位成像元物镜",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>定量相位成像 (QPI) 为研究透明样品提供了宝贵的客观见解，但在不影响性能的情况下小型化 QPI 系统对于需要紧凑性和便携性的应用来说仍然是一个关键挑战。在这里，通过引入部分相干照明调制以及平面元物镜 (PMO) 设计，我们提出了一种具有亚微米分辨率的紧凑型 QPI 系统。 PMO 是一种单片集成的双合态超透镜，其色散可实现两个波长的焦移，从而无需在图像采集期间进行机械平移以进行相位恢复。 PMO 还经过优化，可校正单色像差，提供相当于镜头孔径约 90% 的物方视场，同时将畸变和像差降至最低。控制照明的空间相干性以提高成像分辨率。通过共同设计照明和成像系统，我们证明了 QPI 实现了 488nm 的半节距横向分辨率和 0.06λ 的相位精度。我们的方法能够对包括未染色的生物样本在内的不同相物体进行高质量的QPI分析，为开发紧凑、稳定、实用的QPI平台奠定了基础。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02142-z",
        "title": "mJ-level 7-octave ultraflat white laser encompassing 200–25,000 nm",
        "link": "https://doi.org/10.1038/s41377-025-02142-z",
        "published": "2026-01-20",
        "author": "Lihong Hong, Renyu Feng, Yuanyuan Liu, Junming Liu, Junyu Qian, Yujie Peng, Yuxin Leng, Ruxin Li, Zhi-Yuan Li",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    An intense ultrafast pulse white laser with continuous and ultraflat spectral coverage from deep-ultraviolet (DUV) to far-infrared (FIR) can open up a new arena of full-spectrum laser spectroscopy with applications to a wide variety of basic science and technology areas. Here, we present the creation of an intense white laser with 200–25,000 nm bandwidth @17 dB and ~1 mJ pulse energy by exploiting the synergic action of a high-efficiency nonlinear up-conversion module and down-conversion module upon an intense mid-infrared (MIR) seed pulse laser. The MIR seed pulse laser of 3.62 mJ pulse energy is achieved by sending an optical-parametric chirped pulse amplification pulse laser of 7.12 mJ pulse energy and 3.9 µm central wavelength through a krypton gas-filled hollow-core fiber. The up-conversion nonlinear module is a deliberately designed chirped-periodic poling lithium niobate (CPPLN) nonlinear crystal supporting simultaneous broadband second-order nonlinear 2nd–12th harmonic generation upon the seed laser to generate the shortest DUV wavelength down to 200 nm with a nearly 40% conversion efficiency. The down-conversion nonlinear module is composed of a bare LN crystal offering third-order nonlinear spectral broadening effect and a cascaded AgGaSe\n                    <jats:sub>2</jats:sub>\n                    nonlinear crystal offering high-efficiency intra-pulse difference-frequency generation, and generates a 2000–25,000 nm MIR-FIR laser with an overall conversion efficiency of 18%. The intense 7-octave ultraflat DUV-FIR white laser would offer an unprecedented power to simultaneously probe and monitor the electronic transition, molecular vibration, and lattice oscillation in a wide variety of physical, chemical, and biological substances and processes.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "mJ 级 7 倍频程超平白激光，波长范围 200–25,000 nm",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    强超快脉冲白光激光器具有从深紫外（DUV）到远红外（FIR）连续、超平坦的光谱覆盖范围，可以开辟全光谱激光光谱学的新领域，应用于各种基础科学和技术领域。在这里，我们展示了通过利用高效非线性上转换模块和下转换模块在强中红外（MIR）种子脉冲激光器上的协同作用，创建了具有200–25,000nm带宽@17dB和〜1mJ脉冲能量的强白激光。脉冲能量为3.62 mJ的中红外种子脉冲激光器是通过充氪气体的空心光纤发送脉冲能量为7.12 mJ、中心波长为3.9 µm的光参量啁啾脉冲放大脉冲激光器来实现的。上转换非线性模块是一种精心设计的啁啾周期极化铌酸锂 (CPPLN) 非线性晶体，支持在种子激光器上同时产生宽带二阶非线性 2 至 12 次谐波，以产生低至 200nm 的最短 DUV 波长，转换效率接近 40%。下变频非线性模块由提供三阶非线性光谱展宽效应的裸LN晶体和级联的AgGaSe组成\n                    <贾茨：子>2</贾茨：子>\n                    非线性晶体提供高效脉冲内差频生成，并生成 2000–25,000 nm MIR-FIR 激光，总转换效率为 18%。强烈的 7 倍频程超平坦 DUV-FIR 白光激光器将提供前所未有的功率，以同时探测和监测各种物理、化学和生物物质和过程中的电子跃迁、分子振动和晶格振荡。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02127-y",
        "title": "A near-infrared Sn-Pb perovskite imager with monolithic integration",
        "link": "https://doi.org/10.1038/s41377-025-02127-y",
        "published": "2026-01-20",
        "author": "Ciyu Ge, Chengjie Deng, Jiaxing Zhu, Yongcheng Zhu, Qi Xu, Borui Jiang, Long Chen, Yuxuan Liu, Boxiang Song, Ping Fu, Chao Chen, Liang Gao, Jiang Tang",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Solution-processed Sn-Pb perovskites have emerged as promising candidates for near-infrared (NIR) photodetectors due to their low-cost, tunable bandgap and scalable fabrication. However, Sn\n                    <jats:sup>2+</jats:sup>\n                    oxidation creates Sn vacancies and undesirable p-type doping, resulting in high dark current and limited detectivity, which hinder the practical deployment of Sn-Pb perovskite photodetectors. Herein, we propose a Sn(SCN)\n                    <jats:sub>2</jats:sub>\n                    inorganic molecular surface passivation strategy to suppress Sn\n                    <jats:sup>2+</jats:sup>\n                    oxidation, significantly reduce surface defect density and enhance the optoelectronic properties (a dark current density of 10 nA cm\n                    <jats:sup>−2</jats:sup>\n                    at a bias of −0.1 V and a high specific detectivity of ~1.6 × 10\n                    <jats:sup>13</jats:sup>\n                    Jones). Leveraging this approach, we report the monolithically integrated Sn-Pb perovskite NIR imager with a complementary metal-oxide-semiconductor readout circuit. The imager, featuring a 640 × 512 pixel array with a 15 μm pixel pitch, achieves an external quantum efficiency of 76% at 940 nm and a modulation transfer function of 206.5 LW/PH at 50%. Furthermore, the Sn-Pb perovskite imager demonstrates advanced material recognition capabilities, including liquid identification, underscoring its potential in chemical sensing, biomedical imaging and industrial inspection.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "具有单片集成功能的近红外 Sn-Pb 钙钛矿成像仪",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    溶液处理的锡铅钙钛矿因其低成本、可调谐带隙和可扩展的制造而成为近红外（NIR）光电探测器的有前途的候选者。然而，锡\n                    <贾茨：sup>2+</贾茨：sup>\n                    氧化会产生 Sn 空位和不良的 p 型掺杂，导致高暗电流和有限的探测灵敏度，这阻碍了 Sn-Pb 钙钛矿光电探测器的实际部署。在此，我们提出了 Sn(SCN)\n                    <贾茨：子>2</贾茨：子>\n                    抑制Sn的无机分子表面钝化策略\n                    <贾茨：sup>2+</贾茨：sup>\n                    氧化，显着降低表面缺陷密度并增强光电性能（暗电流密度为10 nA cm\n                    <jats:sup>−2</jats:sup>\n                    偏压为-0.1 V，高比探测率约为1.6 × 10\n                    <贾茨：sup>13</贾茨：sup>\n                    琼斯）。利用这种方法，我们报告了带有互补金属氧化物半导体读出电路的单片集成锡铅钙钛矿近红外成像仪。该成像仪采用640 × 512像素阵列，像素间距为15μm，在940nm处实现了76%的外量子效率，在50%时实现了206.5 LW/PH的调制传递函数。此外，Sn-Pb钙钛矿成像仪展示了先进的材料识别能力，包括液体识别，突显了其在化学传感、生物医学成像和工业检测方面的潜力。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02178-1",
        "title": "A versatile coherent Ising computing platform",
        "link": "https://doi.org/10.1038/s41377-025-02178-1",
        "published": "2026-01-20",
        "author": "Hai Wei, Chengjun Ai, Putuo Guo, Bingjie Jia, Lixin Yuan, Hanquan Song, Shaobo Chen, Chongyu Cao, Jie Wu, Chao Ju, Yin Ma, Jintao Fan, Minglie Hu, Chuan Wang, Kai Wen",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Coherent Ising machines (CIMs) have emerged as a hybrid form of quantum computing devices designed to solve NP-complete problems, offering an exciting opportunity for discovering optimal solutions. Despite challenges such as susceptibility to noise-induced local minima, we achieved notable advantages in improving the computational accuracy and stability of CIMs. We conducted a successful experimental demonstration of CIM via femtosecond laser pumping that integrates optimization strategies across optical and structural dimensions, resulting in significant performance enhancements. The results are particularly promising. An average success rate of 55% was achieved to identify optimal solutions within a Möbius Ladder graph comprising 100 vertices. Compared with other alternatives, the femtosecond pulse results in significantly higher peak power, leading to more pronounced quantum effects and lower pump power in optical fiber-based CIMs. In addition, we have maintained an impressive success rate for a continuous period of 8 hours, emphasizing the practical applicability of CIMs in real-world scenarios. Furthermore, our research extends to the application of these principles in practical applications such as molecular docking and credit scoring. The results presented substantiate the theoretical promise of CIMs, paving the way for their integration into large-scale practical applications.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "多功能相干伊辛计算平台",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>相干伊辛机 (CIM) 已经作为量子计算设备的混合形式出现，旨在解决 NP 完全问题，为发现最佳解决方案提供了令人兴奋的机会。尽管存在诸如对噪声引起的局部最小值敏感等挑战，我们在提高 CIM 的计算精度和稳定性方面取得了显着的优势。我们通过飞秒激光泵浦成功地进行了 CIM 实验演示，该泵浦集成了光学和结构维度上的优化策略，从而显着提高了性能。结果特别有希望。在包含 100 个顶点的莫比乌斯梯图中确定最佳解决方案的平均成功率为 55%。与其他替代方案相比，飞秒脉冲可产生明显更高的峰值功率，从而在基于光纤的 CIM 中产生更明显的量子效应和更低的泵浦功率。此外，我们在连续 8 小时内保持了令人印象深刻的成功率，强调了 CIM 在现实场景中的实际适用性。此外，我们的研究还扩展到这些原理在分子对接和信用评分等实际应用中的应用。所得出的结果证实了 CIM 的理论前景，为将其集成到大规模实际应用中铺平了道路。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02172-7",
        "title": "TRIXS: a multilayer grating solution towards highly efficient resonant inelastic tender X-ray scattering",
        "link": "https://doi.org/10.1038/s41377-025-02172-7",
        "published": "2026-01-21",
        "author": "Ke-Jin Zhou, Qiushi Huang, Mirian Garcia-Fernandez, Yeqi Zhuang, Stefano Agrestini, Shengyou Wen, Thomas Rice, Sahil Tippireddy, Jaewon Choi, Andrew Walters, Igor V. Kozhevnikov, Zhe Zhang, Runze Qi, Zhong Zhang, Hongchang Wang, Zhanshan Wang",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    Resonant inelastic X-ray scattering (RIXS) is a photon-in/photon-out spectroscopic technique which has become increasingly important for the condensed matter physics community. The development of the RIXS instrumentation in soft X-ray and hard X-ray range facilitated the research in 3\n                    <jats:italic>d</jats:italic>\n                    and 5\n                    <jats:italic>d</jats:italic>\n                    transition metal (TM)-based materials, respectively. However, the tender X-ray (2000–3000 eV) RIXS covering most of 4\n                    <jats:italic>d</jats:italic>\n                    TM-based materials severely falls behind due to the lack of high-performance energy dispersive optics. Here, we demonstrate the design and fabrication of a laterally graded multilayer grating (MLG) optics for the establishment of the tender RIXS at the I21 RIXS beamline in Diamond Light Source. The successful implementation of the MLG boosts the photon flux by more than an order of magnitude at the Sulfur\n                    <jats:italic>K</jats:italic>\n                    -edge (2475 eV) and the Ru\n                    <jats:italic>L</jats:italic>\n                    <jats:sub>\n                      <jats:italic>3</jats:italic>\n                    </jats:sub>\n                    -edge (2838 eV) in comparison to the solution of a single-layer coated grating (SLG). More importantly, MLG retains the high energy resolution of the SLG design (~10,000) and works continuously across the full range of 2000–3000 eV. It renders the I21 beamline as the very first RIXS facility in the world that covers both soft and tender X-rays (280–3000 eV) using a grating-based spectrometer for a wide range of science applications.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "TRIXS：一种多层光栅解决方案，可实现高效共振非弹性 X 射线散射",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    共振非弹性 X 射线散射 (RIXS) 是一种光子输入/光子输出光谱技术，对于凝聚态物理界变得越来越重要。 RIXS 软 X 射线和硬 X 射线范围仪器的开发促进了 3 方面的研究\n                    <jats:斜体>d</jats:斜体>\n                    和 5\n                    <jats:斜体>d</jats:斜体>\n                    分别是过渡金属（TM）基材料。然而，温柔的 X 射线 (2000–3000 eV) RIXS 覆盖了 4 的大部分。\n                    <jats:斜体>d</jats:斜体>\n                    由于缺乏高性能的能量色散光学器件，TM基材料严重落后。在这里，我们演示了横向渐变多层光栅 (MLG) 光学器件的设计和制造，用于在钻石光源的 I21 RIXS 光束线上建立招标 RIXS。 MLG 的成功实施将硫磺处的光子通量提高了一个数量级以上\n                    <贾茨：斜体>K</贾茨：斜体>\n                    -edge (2475 eV) 和 Ru\n                    <贾茨：斜体>L</贾茨：斜体>\n                    <贾茨：子>\n                      <贾茨：斜体>3</贾茨：斜体>\n                    </贾茨：子>\n                    与单层涂层光栅（SLG）的解决方案相比，边缘（2838 eV）。更重要的是，MLG保留了SLG设计的高能量分辨率（~10,000），并在2000–3000 eV的整个范围内连续工作。它使 I21 光束线成为世界上第一个 RIXS 设施，使用基于光栅的光谱仪覆盖软 X 射线和温柔 X 射线 (280–3000 eV)，适用于广泛的科学应用。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02182-5",
        "title": "High-efficiency femtosecond laser fabrication of graphene-hybrid planar micro-supercapacitors with micro/nanostructured electrodes",
        "link": "https://doi.org/10.1038/s41377-025-02182-5",
        "published": "2026-01-21",
        "author": "Yuyuan Zhang, Tingting Zou, Haobo Jiang, Xiuyan Fu, Wei Xin, Yiyang Meng, Xilin Li, Jun-Ming Cao, Lin Yang, Yuanzheng Li, Weizhen Liu, Dongdong Han, Xing-Long Wu, Jianjun Yang, Haiyang Xu, Yichun Liu",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    The integration of surface-regular micro/nanostructured electrodes within a limited footprint area is promising to enhance the electrochemical performance of planar micro-supercapacitors (P-MSCs), while developing simple yet efficient manufacturing methods for such electrodes remains a challenge. Here, we propose a universal strategy combining femtosecond laser plasma lithography with spatial light modulation (SLM-FPL), fabricating well-ordered sub-wavelength micro/nanostructured electrodes of interdigital P-MSCs (SEP-MSCs) on graphene oxide (GO) films. Achieving 500/50 µm finger widths/spacings and 680 nm internal grating periods, this method enables device densities &gt;25 units inch\n                    <jats:sup>−2</jats:sup>\n                    with processing efficiency orders of magnitude higher than conventional laser direct writing. Further performance optimizations via wettability modification, electric field engineering, and hybrid composites (GO-MXene/COF) yield outstanding specific capacitance (~41.4 F cm\n                    <jats:sup>−3</jats:sup>\n                    ) and cycling stability (93% retention over 5000 cycles), supporting applications in flexible sensors and compact power supplies. This SLM-FPL technology shows strong potential for high-performance, spatially efficient SEP-MSCs in next-generation integrated systems.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "具有微/纳米结构电极的石墨烯混合平面微型超级电容器的高效飞秒激光制造",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    在有限的占地面积内集成表面规则微/纳米结构电极有望提高平面微型超级电容器（P-MSC）的电化学性能，但为此类电极开发简单而高效的制造方法仍然是一个挑战。在这里，我们提出了一种将飞秒激光等离子体光刻与空间光调制（SLM-FPL）相结合的通用策略，在氧化石墨烯（GO）薄膜上制造有序的亚波长微/纳米结构叉指P-MSC（SEP-MSC）电极。该方法实现 500/50μm 指宽/间距和 680nm 内部光栅周期，使器件密度大于 25 单位英寸\n                    <jats:sup>−2</jats:sup>\n                    加工效率比传统激光直写高出几个数量级。通过润湿性改性、电场工程和混合复合材料 (GO-MXene/COF) 进一步优化性能，产生出色的比电容 (~41.4 F cm\n                    <jats:sup>−3</jats:sup>\n                    ）和循环稳定性（5000 次循环后保持率为 93%），支持灵活传感器和紧凑型电源中的应用。这种 SLM-FPL 技术在下一代集成系统中显示出高性能、空间高效的 SEP-MSC 的巨大潜力。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02109-0",
        "title": "Experimental demonstration of spatiotemporal analog computation in ultrafast optics",
        "link": "https://doi.org/10.1038/s41377-025-02109-0",
        "published": "2026-01-22",
        "author": "Junyi Huang, Dong Zhao, Jixuan Shi, Hongliang Zhang, Hengyi Wang, Fang-Wen Sun, Qiwen Zhan, Shiyao Zhu, Kun Huang, Zhichao Ruan",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>It is intractable to perform information processing and computation on single ultrafast optical pulses, within picoseconds or even femtoseconds. Here, we experimentally demonstrate an optical spatiotemporal differentiator, a mirror-symmetry-breaking dielectric metagrating, which performs analog computations of both spatial and temporal differentiations on single ultrafast optical wavepackets. The spatiotemporal differentiator is designed with a transfer function with linear dependence on spatial wavevector and temporal frequency and fabricated by using a double-exposure E-beam lithography process. We achieve the first-order spatiotemporal differentiation with experimental resolutions of approximately 14 μm (in space) and 260 fs (in time). Furthermore, we report a parabolic relationship between the transverse velocity of a front-tilted photonic wavepacket and the normalized intensity of its first-order spatiotemporal-differentiation wavepacket. This relationship allows direct measurement of the transverse velocity using only the normalized intensity, fundamentally simplifying velocity detection. These capabilities of optical spatiotemporal computation endow emerging space-time optics with fundamental computation blocks.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "超快光学时空模拟计算的实验演示",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>在皮秒甚至飞秒内对单个超快光脉冲进行信息处理和计算是很困难的。在这里，我们通过实验演示了一种光学时空微分器，一种打破镜像对称的介电元光栅，它可以对单个超快光波包的空间和时间微分进行模拟计算。时空微分器的设计具有与空间波矢量和时间频率线性相关的传递函数，并通过使用双曝光电子束光刻工艺制造。我们以大约 14 μm（空间）和 260fs（时间）的实验分辨率实现了一阶时空微分。此外，我们报告了前倾光子波包的横向速度与其一阶时空微分波包的归一化强度之间的抛物线关系。这种关系允许仅使用归一化强度直接测量横向速度，从根本上简化了速度检测。光学时空计算的这些能力赋予新兴的时空光学基本的计算模块。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-026-02190-z",
        "title": "Detection and imaging of chemicals and hidden explosives using terahertz time-domain spectroscopy and deep learning",
        "link": "https://doi.org/10.1038/s41377-026-02190-z",
        "published": "2026-01-22",
        "author": "Xinghe Jiang, Yuhang Li, Yuzhu Li, Che-Yung Shen, Aydogan Ozcan, Mona Jarrahi",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Detecting concealed chemicals and explosives remains a critical challenge in global security. Terahertz time-domain spectroscopy (THz-TDS) offers a promising non-invasive and stand-off detection technique owing to its ability to penetrate optically opaque materials without causing ionization damage. While many chemicals exhibit distinct spectral features in the terahertz range, conventional terahertz-based detection methods often struggle in real-world environments, where variations in sample geometry, thickness, and packaging can lead to inconsistent spectral responses. In this study, we present a chemical imaging system that integrates THz-TDS with deep learning to enable accurate pixel-level identification and classification of different explosives. Operating in reflection mode and enhanced with plasmonic nanoantenna arrays, our THz-TDS system achieves a peak dynamic range of 96 dB and a detection bandwidth of 4.5 THz, supporting practical, stand-off operation. By analyzing individual time-domain pulses with deep neural networks, the system exhibits strong resilience to environmental variations and sample inconsistencies. Blind testing across eight chemicals—including pharmaceutical excipients and explosive compounds—resulted in an average classification accuracy of 99.42% at the pixel level. Notably, the system maintained an average accuracy of 88.83% when detecting explosives concealed under opaque paper coverings, demonstrating its robust generalization capability. These results highlight the potential of combining advanced terahertz spectroscopy with neural networks for highly sensitive and specific chemical and explosive detection in diverse and operationally relevant scenarios.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "使用太赫兹时域光谱和深度学习对化学品和隐藏爆炸物进行检测和成像",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>检测隐藏的化学品和爆炸物仍然是全球安全的一项严峻挑战。太赫兹时域光谱（THz-TDS）提供了一种有前途的非侵入性和远距离检测技术，因为它能够穿透光学不透明材料而不造成电离损伤。虽然许多化学品在太赫兹范围内表现出独特的光谱特征，但传统的基于太赫兹的检测方法通常在现实环境中举步维艰，其中样品几何形状、厚度和包装的变化可能导致光谱响应不一致。在这项研究中，我们提出了一种化学成像系统，它将 THz-TDS 与深度学习相结合，能够对不同爆炸物进行精确的像素级识别和分类。我们的 THz-TDS 系统在反射模式下运行，并通过等离子体纳米天线阵列进行增强，可实现 96dB 的峰值动态范围和 4.5THz 的检测带宽，支持实际的隔离操作。通过使用深度神经网络分析单个时域脉冲，该系统对环境变化和样本不一致表现出强大的适应能力。对八种化学品（包括药用辅料和爆炸性化合物）进行盲测，像素级平均分类准确度达到 99.42%。值得注意的是，该系统在检测隐藏在不透明纸质覆盖物下的爆炸物时，平均准确率保持在 88.83%，展示了其强大的泛化能力。这些结果凸显了将先进的太赫兹光谱与神经网络相结合的潜力，可在多种和操作相关的场景中进行高灵敏度和特定的化学和爆炸物检测。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02102-7",
        "title": "Generation of vectorial generalized vortex array with metasurfaces",
        "link": "https://doi.org/10.1038/s41377-025-02102-7",
        "published": "2026-01-22",
        "author": "Qingsong Yao, Zile Li, Guoxing Zheng",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>The ability to create complex three-dimensional structures of light is extremely challenging. Now, a technique combining Dammann optimization with metasurfaces has been developed, enabling control over all parameters, including polarization, phase, angular momentum, and spatial modes. The generation of three-dimensional generalized vortex beams can open new horizons for their applications in photonics.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "具有超表面的矢量广义涡阵列的生成",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>创建复杂的三维光结构的能力极具挑战性。现在，一种将达曼优化与超表面相结合的技术已经开发出来，可以控制所有参数，包括偏振、相位、角动量和空间模式。三维广义涡旋光束的产生可以为其在光子学中的应用开辟新的视野。</jats:p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02057-9",
        "title": "Soft X-ray imaging with coherence tomography in the water window spectral range using high-harmonic generation",
        "link": "https://doi.org/10.1038/s41377-025-02057-9",
        "published": "2026-01-22",
        "author": "Julius Reinhard, Felix Wiesner, Martin Hennecke, Themistoklis Sidiropoulos, Sophia Kaleta, Julian Späthe, Johann Jakob Abel, Martin Wünsche, Gabriele Schmidl, Jonathan Plentz, Uwe Hübner, Katharina Freiberg, Jonathan Apell, Stephanie Lippmann, Matthias Schnürer, Stefan Eisebitt, Gerhard G. Paulus, Silvio Fuchs",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>\n                    High-harmonic generation (HHG) is used as a source for various imaging applications in the extreme ultraviolet spectral range. It offers spatially coherent radiation and unique elemental contrast with the potential for attosecond time resolution. The unfavorable efficiency scaling to higher photon energies prevented the imaging application in the soft X-ray range so far. In this work we demonstrate the feasibility of using harmonics for imaging in the water window spectral region (284 eV to 532 eV). We achieve nondestructive depth profile imaging in a heterostructure by utilizing a broadband and noise-resistant technique called soft X-ray Coherence Tomography (SXCT) at a high-flux lab-scale HHG source. SXCT is derived from Optical Coherence Tomography, a Fourier based technique that can use the full bandwidth of the source to reach an axial resolution of 12 nm in this demonstration. The employed source covers the entire water window, with a photon flux exceeding 10\n                    <jats:sup>6</jats:sup>\n                    photons/eV/s at a photon energy of 500 eV. We show local cross sections of a sample consisting of Aluminium oxide and Platinum layers of varying thickness on a Zinc oxide substrate. We validate the findings with scanning and transmission electron microscopy after preparation with focused ion beam milling.\n                  </jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "使用高次谐波发生在水窗光谱范围内进行相干断层扫描的软 X 射线成像",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <贾茨：p>\n                    高次谐波发生 (HHG) 用作极紫外光谱范围内各种成像应用的光源。它提供空间相干辐射和独特的元素对比度，并具有阿秒时间分辨率的潜力。迄今为止，向更高光子能量扩展的不利效率阻碍了软 X 射线范围内的成像应用。在这项工作中，我们证明了使用谐波在水窗光谱区域（284 eV 至 532 eV）成像的可行性。我们通过在高通量实验室规模 HHG 源上利用称为软 X 射线相干断层扫描 (SXCT) 的宽带和抗噪声技术，在异质结构中实现无损深度剖面成像。 SXCT 源自光学相干断层扫描，这是一种基于傅立叶的技术，在本演示中可以使用光源的整个带宽来达到 12 nm 的轴向分辨率。采用的光源覆盖整个水窗，光子通量超过10\n                    <贾茨：sup>6</贾茨：sup>\n                    光子能量为 500 eV 时的光子/eV/s。我们展示了氧化锌基底上由不同厚度的氧化铝和铂层组成的样品的局部横截面。在使用聚焦离子束铣削制备后，我们通过扫描和透射电子显微镜验证了结果。\n                  </贾茨：p>"
    },
    {
        "id": "https://doi.org/10.1038/s41377-025-02169-2",
        "title": "Dispersion engineering by rotational symmetry breaking in an optical microcavity",
        "link": "https://doi.org/10.1038/s41377-025-02169-2",
        "published": "2026-01-22",
        "author": "Jian-Zheng Ren, Li-Jie Li, Rui-Qi Zhang, Zhi-Yan Wang, Qi-Tao Cao, Yun-Feng Xiao",
        "summary": "<jats:title>Abstract</jats:title>\n                  <jats:p>Dispersion engineering is pivotal for nonlinear optics, yet it often faces challenges posed by material and structural limitations. Here, we establish rotational symmetry breaking as the guiding principle for dispersion engineering in optical microcavities. Through boundary deformation, multi-branch global dispersion emerges in island modes, and local dispersion is controlled via resonance-assisted tunneling between quasi-whispering gallery modes. Enabled by the global dispersion, the optical parametric oscillation is predicted in blue-violet light spectrum with high efficiency (&gt;55%) and large frequency separation (&gt;180 THz). Using the local dispersion engineering, the doubly-resonant enhancement of second-harmonic generation is regulated by the resonance-assisted tunneling.</jats:p>",
        "journal": "Light: Science & Applications",
        "title_cn": "光学微腔中旋转对称破缺的色散工程",
        "abstract_cn": "<jats:title>摘要</jats:title>\n                  <jats:p>色散工程对于非线性光学至关重要，但它经常面临材料和结构限制带来的挑战。在这里，我们将旋转对称破缺确立为光学微腔色散工程的指导原则。通过边界变形，在岛模式中出现多分支全局色散，并且通过准回音壁模式之间的共振辅助隧道控制局部色散。通过全局色散，可以预测蓝紫光光谱中的光学参量振荡具有高效率（> 55％）和大频率间隔（> 180 THz）。利用局部色散工程，通过谐振辅助隧道调节二次谐波产生的双谐振增强。</jats:p>"
    },
    {
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://onlinelibrary.wiley.com/doi/10.1002/lpor.202502562?af=R"
            }
        ],
        "link": "https://doi.org/10.1002/lpor.202502562",
        "published": "Thu, 22 Jan 2026 22:40:46 -0800",
        "published_parsed": [
            2026,
            1,
            23,
            6,
            40,
            46,
            4,
            23,
            0
        ],
        "updated": "2026-01-22T10:40:46-08:00",
        "updated_parsed": [
            2026,
            1,
            22,
            18,
            40,
            46,
            3,
            22,
            0
        ],
        "source": {
            "href": "https://onlinelibrary.wiley.com/journal/18638899?af=R",
            "title": "Wiley: Laser & Photonics Reviews: Table of Contents"
        },
        "prism_coverdate": "",
        "prism_coverdisplaydate": "",
        "id": "https://doi.org/10.1002/lpor.202502562",
        "guidislink": false,
        "title": "Omnidirectional‐Incidence On‐Chip Meta‐Optics Enabling Massive 3D Holographic Storage",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Omnidirectional‐Incidence On‐Chip Meta‐Optics Enabling Massive 3D Holographic Storage"
        },
        "summary": "[New Paper] Abstract not indexed yet. Please visit the official website.",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "Laser &amp;Photonics Reviews, EarlyView."
        },
        "content": [
            {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "An omnidirectional‐incidence on‐chip metasurface is demonstrated for massive 3D meta‐holographic storage. By leveraging angular‐independent detour phase modulation together with the conjugate relation of optical responses under opposite on‐chip illuminations, we break the conjugate constraint and extend the azimuthal multiplexing to 360° angular space. Eventually, up to 32‐channel multiplane 3D meta‐holograms are successfully reconstructed by sequentially switching the azimuthal angles.\n\n\n\n\n\n\n\n\nABSTRACT\nWith the ever‐increasing demand for high‐capacity and chip‐integrated information storage, on‐chip metasurface‐enabled optical holography offers a promising solution by manipulating various optical parameters. However, the incident azimuthal angle, an essential optical degree of freedom (DoF), remains underexplored and limited due to the lack of arbitrary direction‐decoupled and effective phase‐encoding mechanisms, constraining both the multiplexing capacity and channel scalability. Here, we propose and experimentally demonstrate an omnidirectional‐incidence on‐chip metasurface for massive 3D meta‐holographic storage. Specifically, by leveraging angular‐independent detour phase modulation together with the conjugate relation of optical responses under opposite on‐chip illuminations, we break the conjugate constraint and extend the azimuthal multiplexing to 360° angular space, achieving full utilization of arbitrary angular DoF. As a proof of concept, up to 32‐channel multiplane 3D meta‐holograms are successfully reconstructed by sequentially switching the azimuthal angles to 0°, 45°, 90°, 135°, 180°, 225°, 270°, and 315°, thereby surpassing typical azimuthal coding strategies. Moreover, our arbitrary azimuthal encoding for massive information storage relies solely on the displacements of identical meta‐atoms, simplifying design complexity and improving the fabrication robustness. We envision that the proposed omnidirectional azimuthal‐multiplexed on‐chip metasurfaces represent a powerful platform for high‐density optical information storage, high‐fidelity 3D displays, and secure optical encryption."
            },
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<img alt=\"Omnidirectional-Incidence On-Chip Meta-Optics Enabling Massive 3D Holographic Storage\" src=\"https://onlinelibrary.wiley.com/cms/asset/6bb64f1d-0045-4b03-9937-d1aa9701bd3d/lpor70922-gra-0001-m.png\" />\n<p>An omnidirectional-incidence on-chip metasurface is demonstrated for massive 3D meta-holographic storage. By leveraging angular-independent detour phase modulation together with the conjugate relation of optical responses under opposite on-chip illuminations, we break the conjugate constraint and extend the azimuthal multiplexing to 360° angular space. Eventually, up to 32-channel multiplane 3D meta-holograms are successfully reconstructed by sequentially switching the azimuthal angles.\n\n</p>\n<br />\n<h2>ABSTRACT</h2>\n<p>With the ever-increasing demand for high-capacity and chip-integrated information storage, on-chip metasurface-enabled optical holography offers a promising solution by manipulating various optical parameters. However, the incident azimuthal angle, an essential optical degree of freedom (DoF), remains underexplored and limited due to the lack of arbitrary direction-decoupled and effective phase-encoding mechanisms, constraining both the multiplexing capacity and channel scalability. Here, we propose and experimentally demonstrate an omnidirectional-incidence on-chip metasurface for massive 3D meta-holographic storage. Specifically, by leveraging angular-independent detour phase modulation together with the conjugate relation of optical responses under opposite on-chip illuminations, we break the conjugate constraint and extend the azimuthal multiplexing to 360° angular space, achieving full utilization of arbitrary angular DoF. As a proof of concept, up to 32-channel multiplane 3D meta-holograms are successfully reconstructed by sequentially switching the azimuthal angles to 0°, 45°, 90°, 135°, 180°, 225°, 270°, and 315°, thereby surpassing typical azimuthal coding strategies. Moreover, our arbitrary azimuthal encoding for massive information storage relies solely on the displacements of identical meta-atoms, simplifying design complexity and improving the fabrication robustness. We envision that the proposed omnidirectional azimuthal-multiplexed on-chip metasurfaces represent a powerful platform for high-density optical information storage, high-fidelity 3D displays, and secure optical encryption.</p>"
            }
        ],
        "authors": [
            {
                "name": "Cheng Yi, \nChao Xu, \nShuai Wan, \nZejing Wang, \nZirui Zhao, \nXinglong Li, \nRunlong Rao, \nWei Dai, \nZhike He, \nZhongyang Li, \nYangyang Shi"
            }
        ],
        "author": "Cheng Yi, \nChao Xu, \nShuai Wan, \nZejing Wang, \nZirui Zhao, \nXinglong Li, \nRunlong Rao, \nWei Dai, \nZhike He, \nZhongyang Li, \nYangyang Shi",
        "author_detail": {
            "name": "Cheng Yi, \nChao Xu, \nShuai Wan, \nZejing Wang, \nZirui Zhao, \nXinglong Li, \nRunlong Rao, \nWei Dai, \nZhike He, \nZhongyang Li, \nYangyang Shi"
        },
        "tags": [
            {
                "term": "RESEARCH ARTICLE",
                "scheme": null,
                "label": null
            }
        ],
        "dc_identifier": "10.1002/lpor.202502562",
        "prism_publicationname": "Laser & Photonics Reviews",
        "prism_doi": "10.1002/lpor.202502562",
        "prism_url": "https://onlinelibrary.wiley.com/doi/10.1002/lpor.202502562?af=R",
        "prism_section": "RESEARCH ARTICLE",
        "journal": "Laser & Photonics Reviews",
        "title_cn": "全向入射片上元光学器件支持海量 3D 全息存储",
        "abstract_cn": "【摘要未收录】新文章暂无数据库记录，请点击链接直达官网。"
    },
    {
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://onlinelibrary.wiley.com/doi/10.1002/lpor.202503063?af=R"
            }
        ],
        "link": "https://doi.org/10.1002/lpor.202503063",
        "published": "Thu, 22 Jan 2026 22:42:28 -0800",
        "published_parsed": [
            2026,
            1,
            23,
            6,
            42,
            28,
            4,
            23,
            0
        ],
        "updated": "2026-01-22T10:42:28-08:00",
        "updated_parsed": [
            2026,
            1,
            22,
            18,
            42,
            28,
            3,
            22,
            0
        ],
        "source": {
            "href": "https://onlinelibrary.wiley.com/journal/18638899?af=R",
            "title": "Wiley: Laser & Photonics Reviews: Table of Contents"
        },
        "prism_coverdate": "",
        "prism_coverdisplaydate": "",
        "id": "https://doi.org/10.1002/lpor.202503063",
        "guidislink": false,
        "title": "Copper(I) Clusters With Different Nuclear Structures Featuring Thermally Activated Delayed Fluorescence for Highly Efficient X‐Ray Scintillator",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Copper(I) Clusters With Different Nuclear Structures Featuring Thermally Activated Delayed Fluorescence for Highly Efficient X‐Ray Scintillator"
        },
        "summary": "[New Paper] Abstract not indexed yet. Please visit the official website.",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "Laser &amp;Photonics Reviews, EarlyView."
        },
        "content": [
            {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "This study addresses the low triplet exciton utilization in X‐ray scintillators by designing Cu(I) clusters with distinct core structures and coordination environments. A mononuclear copper(I) cluster coordinated with triphenylphosphine (PPh3) exhibits high structural rigidity, enabling a small ΔEST, efficient radiative internal conversion (RISC), suppressed non‐radiative losses, nearly 100% photoluminescence, and outstanding X‐ray scintillation performance.\n\n\n\n\n\n\n\n\nABSTRACT\nCu(I) clusters are molecular aggregates consisting of several Cu centers consolidated by organic ligands. They typically exhibit significant metal‐to‐ligand charge transfer (MLCT) characteristics, enabling thermally activated delayed fluorescence (TADF) emission, making them promising candidates for next‐generation X‐ray scintillators. However, the low triplet exciton utilization rate is a critical obstacle to their further practical application. To address this challenge and establish key structure‐property relationships, we designed a series of Cu(I) clusters featuring a diversity of nuclear structures (the number and arrangement of Cu) and coordination environments. Our investigation reveals that the PPh3‐coordinated mononuclear clusters (CuI(PPh3)2Py) exhibit high structural rigidity, suppressing excited‐state distortion and thereby forming a narrow singlet‐triplet energy gap (ΔEST = 0.09 eV). This enables efficient reverse intersystem crossing (RISC), maximizing triplet exciton utilization. Moreover, the mononuclear structure maximally suppresses non‐radiative relaxation pathways, achieving near‐unity photoluminescence quantum yields (99.5%). The scintillator films exhibit imaging quality comparable to that of commercial BGO, achieving a spatial resolution of 17.5 lp/mm. Furthermore, high‐definition imaging of low‐brightness images through digital image processing algorithms was realized. This work establishes key structure‐property relationships in Cu(I) clusters, paving the way for the rational design of advanced X‐ray scintillators."
            },
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<img alt=\"Copper(I) Clusters With Different Nuclear Structures Featuring Thermally Activated Delayed Fluorescence for Highly Efficient X-Ray Scintillator\" src=\"https://onlinelibrary.wiley.com/cms/asset/9308a460-51cf-41c2-8f22-e646d6f91d8c/lpor70927-gra-0001-m.png\" />\n<p>This study addresses the low triplet exciton utilization in X-ray scintillators by designing Cu(I) clusters with distinct core structures and coordination environments. A mononuclear copper(I) cluster coordinated with triphenylphosphine (PPh<sub>3</sub>) exhibits high structural rigidity, enabling a small Δ<i>E</i>\n<sub>ST</sub>, efficient radiative internal conversion (RISC), suppressed non-radiative losses, nearly 100% photoluminescence, and outstanding X-ray scintillation performance.\n\n</p>\n<br />\n<h2>ABSTRACT</h2>\n<p>Cu(I) clusters are molecular aggregates consisting of several Cu centers consolidated by organic ligands. They typically exhibit significant metal-to-ligand charge transfer (MLCT) characteristics, enabling thermally activated delayed fluorescence (TADF) emission, making them promising candidates for next-generation X-ray scintillators. However, the low triplet exciton utilization rate is a critical obstacle to their further practical application. To address this challenge and establish key structure-property relationships, we designed a series of Cu(I) clusters featuring a diversity of nuclear structures (the number and arrangement of Cu) and coordination environments. Our investigation reveals that the PPh<sub>3</sub>-coordinated mononuclear clusters (CuI(PPh<sub>3</sub>)<sub>2</sub>Py) exhibit high structural rigidity, suppressing excited-state distortion and thereby forming a narrow singlet-triplet energy gap (Δ<i>E</i>\n<sub>ST</sub> = 0.09 eV). This enables efficient reverse intersystem crossing (RISC), maximizing triplet exciton utilization. Moreover, the mononuclear structure maximally suppresses non-radiative relaxation pathways, achieving near-unity photoluminescence quantum yields (99.5%). The scintillator films exhibit imaging quality comparable to that of commercial BGO, achieving a spatial resolution of 17.5 lp/mm. Furthermore, high-definition imaging of low-brightness images through digital image processing algorithms was realized. This work establishes key structure-property relationships in Cu(I) clusters, paving the way for the rational design of advanced X-ray scintillators.</p>"
            }
        ],
        "authors": [
            {
                "name": "Youkui Xu, \nFeifei Chai, \nChang Shi, \nBaoyi An, \nZhenHua Li, \nGuoqiang Peng, \nYutian Lei, \nHaiyu Ren, \nHaoran Deng, \nZhiwen Jin, \nQian Wang"
            }
        ],
        "author": "Youkui Xu, \nFeifei Chai, \nChang Shi, \nBaoyi An, \nZhenHua Li, \nGuoqiang Peng, \nYutian Lei, \nHaiyu Ren, \nHaoran Deng, \nZhiwen Jin, \nQian Wang",
        "author_detail": {
            "name": "Youkui Xu, \nFeifei Chai, \nChang Shi, \nBaoyi An, \nZhenHua Li, \nGuoqiang Peng, \nYutian Lei, \nHaiyu Ren, \nHaoran Deng, \nZhiwen Jin, \nQian Wang"
        },
        "tags": [
            {
                "term": "RESEARCH ARTICLE",
                "scheme": null,
                "label": null
            }
        ],
        "dc_identifier": "10.1002/lpor.202503063",
        "prism_publicationname": "Laser & Photonics Reviews",
        "prism_doi": "10.1002/lpor.202503063",
        "prism_url": "https://onlinelibrary.wiley.com/doi/10.1002/lpor.202503063?af=R",
        "prism_section": "RESEARCH ARTICLE",
        "journal": "Laser & Photonics Reviews",
        "title_cn": "具有不同核结构的铜（I）簇具有热激活延迟荧光，用于高效 X 射线闪烁体",
        "abstract_cn": "【摘要未收录】新文章暂无数据库记录，请点击链接直达官网。"
    },
    {
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://onlinelibrary.wiley.com/doi/10.1002/lpor.202502531?af=R"
            }
        ],
        "link": "https://doi.org/10.1002/lpor.202502531",
        "published": "Thu, 22 Jan 2026 22:46:38 -0800",
        "published_parsed": [
            2026,
            1,
            23,
            6,
            46,
            38,
            4,
            23,
            0
        ],
        "updated": "2026-01-22T10:46:38-08:00",
        "updated_parsed": [
            2026,
            1,
            22,
            18,
            46,
            38,
            3,
            22,
            0
        ],
        "source": {
            "href": "https://onlinelibrary.wiley.com/journal/18638899?af=R",
            "title": "Wiley: Laser & Photonics Reviews: Table of Contents"
        },
        "prism_coverdate": "",
        "prism_coverdisplaydate": "",
        "id": "https://doi.org/10.1002/lpor.202502531",
        "guidislink": false,
        "title": "Optical Stark Effect of Enhanced Charged Biexciton Interactions in Monolayer Semiconductors",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Optical Stark Effect of Enhanced Charged Biexciton Interactions in Monolayer Semiconductors"
        },
        "summary": "[New Paper] Abstract not indexed yet. Please visit the official website.",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "Laser &amp;Photonics Reviews, EarlyView."
        },
        "content": [
            {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "The optical Stark effect (OSE) probes excitonic nonlinearities in monolayer WS2, revealing a ∼6 meV transient shift of the charged biexciton (CB). Valley‐resolved measurements representing a value slightly above a quintupling (7.2‐fold) of the nonlinear interaction strength relative to neutral exciton, an enhancement directly validated by a detuning‐squared scaling law and attributed to CB's expanded radius.\n\n\n\n\n\n\n\n\nABSTRACT\nThe intrinsically weak exciton‐exciton interactions in monolayer transition metal dichalcogenides (TMDs) limit optical nonlinearities crucial for switching. While valley‐selective manipulation offers pathways for enhanced intra‐ or inter‐valley excitonic coupling, however, the weak interaction strength remains a bottleneck, primarily constrained by the small spatial extent of neutral excitons (X, ∼1 nm radius). To overcome this limitation, we exploit the charged biexciton (CB), a five‐body complex with a significantly expanded radius (∼5 nm). This known extent facilitates greater excitonic wavefunction overlap, thereby enhancing Coulomb repulsion and exchange interactions beyond the capabilities of X. For quantification, we employ valley‐resolved pump‐probe spectroscopy combined with optical Stark effect (OSE) modulation in monolayer WS2. Results reveal that CB exhibits a transient shift of ∼6 meV under given pump fluence and detuning parameters, representing a value slightly above a quintupling (7.2‐fold) of the nonlinear interaction strength relative to X. This finding highlights CB's large‐scale capacity for nonlinear amplification, positioning it as a candidate for advancing high‐efficiency optical applications."
            },
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<img alt=\"Optical Stark Effect of Enhanced Charged Biexciton Interactions in Monolayer Semiconductors\" src=\"https://onlinelibrary.wiley.com/cms/asset/566ec6fd-6587-404f-905b-da34b944f609/lpor70885-gra-0001-m.png\" />\n<p>The optical Stark effect (OSE) probes excitonic nonlinearities in monolayer WS<sub>2</sub>, revealing a ∼6 meV transient shift of the charged biexciton (CB). Valley-resolved measurements representing a value slightly above a quintupling (7.2-fold) of the nonlinear interaction strength relative to neutral exciton, an enhancement directly validated by a detuning-squared scaling law and attributed to CB's expanded radius.\n\n</p>\n<br />\n<h2>ABSTRACT</h2>\n<p>The intrinsically weak exciton-exciton interactions in monolayer transition metal dichalcogenides (TMDs) limit optical nonlinearities crucial for switching. While valley-selective manipulation offers pathways for enhanced intra- or inter-valley excitonic coupling, however, the weak interaction strength remains a bottleneck, primarily constrained by the small spatial extent of neutral excitons (X, ∼1 nm radius). To overcome this limitation, we exploit the charged biexciton (CB), a five-body complex with a significantly expanded radius (∼5 nm). This known extent facilitates greater excitonic wavefunction overlap, thereby enhancing Coulomb repulsion and exchange interactions beyond the capabilities of X. For quantification, we employ valley-resolved pump-probe spectroscopy combined with optical Stark effect (OSE) modulation in monolayer WS<sub>2</sub>. Results reveal that CB exhibits a transient shift of ∼6 meV under given pump fluence and detuning parameters, representing a value slightly above a quintupling (7.2-fold) of the nonlinear interaction strength relative to X. This finding highlights CB's large-scale capacity for nonlinear amplification, positioning it as a candidate for advancing high-efficiency optical applications.</p>"
            }
        ],
        "authors": [
            {
                "name": "Qirui Liu, \nKe Wei, \nYuxiang Tang, \nYingqian Ye, \nTian Jiang"
            }
        ],
        "author": "Qirui Liu, \nKe Wei, \nYuxiang Tang, \nYingqian Ye, \nTian Jiang",
        "author_detail": {
            "name": "Qirui Liu, \nKe Wei, \nYuxiang Tang, \nYingqian Ye, \nTian Jiang"
        },
        "tags": [
            {
                "term": "RESEARCH ARTICLE",
                "scheme": null,
                "label": null
            }
        ],
        "dc_identifier": "10.1002/lpor.202502531",
        "prism_publicationname": "Laser & Photonics Reviews",
        "prism_doi": "10.1002/lpor.202502531",
        "prism_url": "https://onlinelibrary.wiley.com/doi/10.1002/lpor.202502531?af=R",
        "prism_section": "RESEARCH ARTICLE",
        "journal": "Laser & Photonics Reviews",
        "title_cn": "单层半导体中增强的带电双激子相互作用的光学斯塔克效应",
        "abstract_cn": "【摘要未收录】新文章暂无数据库记录，请点击链接直达官网。"
    },
    {
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://onlinelibrary.wiley.com/doi/10.1002/lpor.202503254?af=R"
            }
        ],
        "link": "https://doi.org/10.1002/lpor.202503254",
        "published": "Thu, 22 Jan 2026 22:48:00 -0800",
        "published_parsed": [
            2026,
            1,
            23,
            6,
            48,
            0,
            4,
            23,
            0
        ],
        "updated": "2026-01-22T10:48:00-08:00",
        "updated_parsed": [
            2026,
            1,
            22,
            18,
            48,
            0,
            3,
            22,
            0
        ],
        "source": {
            "href": "https://onlinelibrary.wiley.com/journal/18638899?af=R",
            "title": "Wiley: Laser & Photonics Reviews: Table of Contents"
        },
        "prism_coverdate": "",
        "prism_coverdisplaydate": "",
        "id": "https://doi.org/10.1002/lpor.202503254",
        "guidislink": false,
        "title": "Direct Water Thermal Exchange for Laser‐Driven Lighting: Achieving Miniature Super‐Bright Green Light Source for Underwater Illumination and Broadcast Communication",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Direct Water Thermal Exchange for Laser‐Driven Lighting: Achieving Miniature Super‐Bright Green Light Source for Underwater Illumination and Broadcast Communication"
        },
        "summary": "[New Paper] Abstract not indexed yet. Please visit the official website.",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "Laser &amp;Photonics Reviews, EarlyView."
        },
        "content": [
            {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "This study overcomes heat dissipation limits in underwater laser‐driven lighting by enabling direct thermal exchange with water. The developed sandwich waterproof color converter maintains high luminous intensity in harsh conditions and achieves illumination that is 14 times brighter without saturation. This enables a miniaturized, super‐bright green light source for underwater illumination and broadcast communication.\n\n\n\n\n\n\n\n\nABSTRACT\nUnderwater laser‐driven lighting is limited by the poor heat dissipation of color converters, which causes luminance saturation and prevents miniaturization. This study presents a direct water thermal exchange method, allowing both the color converter and laser diode to dissipate heat directly into the surrounding water. A water‐contact green‐emitting Y3(Al,Ga)5O12:Ce3+ (YAGG:Ce3+) phosphor‐in‐glass (PiG) with a sandwich waterproof structure (SW‐PiG) was thus developed as the color converter, maintaining 89% of its luminous intensity even after 40 days of immersion in 80°C seawater. The SW‐PiG achieved an underwater illuminance of 2.5 × 105 lux at 15 cm under blue laser excitation, which is 14 times higher than that of a conventional heatsink‐based setup (1.8 × 104 lux). Notably, no luminescence saturation was observed even at 25 W laser excitation, while the conventional setup suffered thermal rupture at just 3.5 W. Finally, a miniature, super‐bright green light source was demonstrated, highlighting its potential to improve personal diving safety and enable wide‐area (60° divergence angle, >40 meters) underwater point‐to‐multipoint broadcast communication across diverse applications."
            },
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<img alt=\"Direct Water Thermal Exchange for Laser-Driven Lighting: Achieving Miniature Super-Bright Green Light Source for Underwater Illumination and Broadcast Communication\" src=\"https://onlinelibrary.wiley.com/cms/asset/fa7c4c79-a5e0-4b65-8a30-7209daf1120b/lpor70924-gra-0001-m.png\" />\n<p>This study overcomes heat dissipation limits in underwater laser-driven lighting by enabling direct thermal exchange with water. The developed sandwich waterproof color converter maintains high luminous intensity in harsh conditions and achieves illumination that is 14 times brighter without saturation. This enables a miniaturized, super-bright green light source for underwater illumination and broadcast communication.\n\n</p>\n<br />\n<h2>ABSTRACT</h2>\n<p>Underwater laser-driven lighting is limited by the poor heat dissipation of color converters, which causes luminance saturation and prevents miniaturization. This study presents a direct water thermal exchange method, allowing both the color converter and laser diode to dissipate heat directly into the surrounding water. A water-contact green-emitting Y<sub>3</sub>(Al,Ga)<sub>5</sub>O<sub>12</sub>:Ce<sup>3+</sup> (YAGG:Ce<sup>3+</sup>) phosphor-in-glass (PiG) with a sandwich waterproof structure (SW-PiG) was thus developed as the color converter, maintaining 89% of its luminous intensity even after 40 days of immersion in 80°C seawater. The SW-PiG achieved an underwater illuminance of 2.5 × 10<sup>5</sup> lux at 15 cm under blue laser excitation, which is 14 times higher than that of a conventional heatsink-based setup (1.8 × 10<sup>4</sup> lux). Notably, no luminescence saturation was observed even at 25 W laser excitation, while the conventional setup suffered thermal rupture at just 3.5 W. Finally, a miniature, super-bright green light source was demonstrated, highlighting its potential to improve personal diving safety and enable wide-area (60° divergence angle, &gt;40 meters) underwater point-to-multipoint broadcast communication across diverse applications.</p>"
            }
        ],
        "authors": [
            {
                "name": "Yu‐Yan Wang, \nJia‐Ying Zhao, \nYue Zhai, \nYu‐Bin Kang, \nJuan Kang, \nQiang‐Qiang Zhu, \nLe Wang"
            }
        ],
        "author": "Yu‐Yan Wang, \nJia‐Ying Zhao, \nYue Zhai, \nYu‐Bin Kang, \nJuan Kang, \nQiang‐Qiang Zhu, \nLe Wang",
        "author_detail": {
            "name": "Yu‐Yan Wang, \nJia‐Ying Zhao, \nYue Zhai, \nYu‐Bin Kang, \nJuan Kang, \nQiang‐Qiang Zhu, \nLe Wang"
        },
        "tags": [
            {
                "term": "RESEARCH ARTICLE",
                "scheme": null,
                "label": null
            }
        ],
        "dc_identifier": "10.1002/lpor.202503254",
        "prism_publicationname": "Laser & Photonics Reviews",
        "prism_doi": "10.1002/lpor.202503254",
        "prism_url": "https://onlinelibrary.wiley.com/doi/10.1002/lpor.202503254?af=R",
        "prism_section": "RESEARCH ARTICLE",
        "journal": "Laser & Photonics Reviews",
        "title_cn": "用于激光驱动照明的直接水热交换：实现用于水下照明和广播通信的微型超亮绿色光源",
        "abstract_cn": "【摘要未收录】新文章暂无数据库记录，请点击链接直达官网。"
    },
    {
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://onlinelibrary.wiley.com/doi/10.1002/lpor.202502639?af=R"
            }
        ],
        "link": "https://doi.org/10.1002/lpor.202502639",
        "published": "Thu, 22 Jan 2026 22:51:51 -0800",
        "published_parsed": [
            2026,
            1,
            23,
            6,
            51,
            51,
            4,
            23,
            0
        ],
        "updated": "2026-01-22T10:51:51-08:00",
        "updated_parsed": [
            2026,
            1,
            22,
            18,
            51,
            51,
            3,
            22,
            0
        ],
        "source": {
            "href": "https://onlinelibrary.wiley.com/journal/18638899?af=R",
            "title": "Wiley: Laser & Photonics Reviews: Table of Contents"
        },
        "prism_coverdate": "",
        "prism_coverdisplaydate": "",
        "id": "https://doi.org/10.1002/lpor.202502639",
        "guidislink": false,
        "title": "Planarized Sidewall‐Integrated Metafibers for Enhanced Evanescent Field Interaction via Long‐Range Resonant Near‐Field Coupling",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Planarized Sidewall‐Integrated Metafibers for Enhanced Evanescent Field Interaction via Long‐Range Resonant Near‐Field Coupling"
        },
        "summary": "[New Paper] Abstract not indexed yet. Please visit the official website.",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "Laser &amp;Photonics Reviews, EarlyView."
        },
        "content": [
            {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "A novel metafiber paradigm, which integrates metasurfaces on planarized fiber sidewalls, is proposed to fully harness the evanescent field mechanism. To this aim, a fiber‐substrate planarization strategy is developed to enable the in situ fabrication of a cm‐scale‐long plasmonic metasurface on side‐polished fibers. As a proof of concept, ultralow‐threshold mode‐locking is demonstrated by utilizing the metafiber as a high‐performance saturable absorber.\n\n\n\n\n\n\n\n\nABSTRACT\nMetafibers, optical fibers integrated with metasurfaces, have recently emerged as a transformative platform for miniaturized fiber‐optic components with advanced functionalities. However, existing metafibers are largely limited to fiber tip integration, where metasurfaces interact dominantly with localized guided modes, thus failing to exploit the inherent potential of fiber sidewalls for long‐range evanescent field interaction. Here, we propose a novel metafiber paradigm—integrating metasurfaces on planarized fiber sidewalls—to fully harness the evanescent field mechanism. To this end, we develop a robust in situ fabrication method via a fiber‐substrate planarization strategy, enabling direct, large‐area, and high‐fidelity metasurface patterning on side‐polished fibers (SPFs). Numerical simulations reveal that long‐range resonant near‐field coupling drives cumulative amplification of the evanescent field within the metasurface layer, leading to significant enhancement of both linear and nonlinear optical responses. As a proof of concept, we present a nonlinear metafiber by integrating a 1‐cm‐long gold nanorod‐based metasurface onto an SPF, demonstrating a high‐performance saturable absorber (SA). This metafiber SA enables all‐fiber ultrafast lasers across all soliton regimes with ultralow mode‐locking thresholds. This work establishes a universal methodology for planarized sidewall‐integrated metafibers, reshaping the landscape of metafibers, and provides a versatile lab‐on‐fiber platform for enhanced linear and nonlinear optics."
            },
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<img alt=\"Planarized Sidewall-Integrated Metafibers for Enhanced Evanescent Field Interaction via Long-Range Resonant Near-Field Coupling\" src=\"https://onlinelibrary.wiley.com/cms/asset/60a57db1-0f66-4974-aaf9-01dbb1e4a36d/lpor70929-gra-0001-m.png\" />\n<p>A novel metafiber paradigm, which integrates metasurfaces on planarized fiber sidewalls, is proposed to fully harness the evanescent field mechanism. To this aim, a fiber-substrate planarization strategy is developed to enable the in situ fabrication of a cm-scale-long plasmonic metasurface on side-polished fibers. As a proof of concept, ultralow-threshold mode-locking is demonstrated by utilizing the metafiber as a high-performance saturable absorber.\n\n</p>\n<br />\n<h2>ABSTRACT</h2>\n<p>Metafibers, optical fibers integrated with metasurfaces, have recently emerged as a transformative platform for miniaturized fiber-optic components with advanced functionalities. However, existing metafibers are largely limited to fiber tip integration, where metasurfaces interact dominantly with localized guided modes, thus failing to exploit the inherent potential of fiber sidewalls for long-range evanescent field interaction. Here, we propose a novel metafiber paradigm—integrating metasurfaces on planarized fiber sidewalls—to fully harness the evanescent field mechanism. To this end, we develop a robust in situ fabrication method via a fiber-substrate planarization strategy, enabling direct, large-area, and high-fidelity metasurface patterning on side-polished fibers (SPFs). Numerical simulations reveal that long-range resonant near-field coupling drives cumulative amplification of the evanescent field within the metasurface layer, leading to significant enhancement of both linear and nonlinear optical responses. As a proof of concept, we present a nonlinear metafiber by integrating a 1-cm-long gold nanorod-based metasurface onto an SPF, demonstrating a high-performance saturable absorber (SA). This metafiber SA enables all-fiber ultrafast lasers across all soliton regimes with ultralow mode-locking thresholds. This work establishes a universal methodology for planarized sidewall-integrated metafibers, reshaping the landscape of metafibers, and provides a versatile lab-on-fiber platform for enhanced linear and nonlinear optics.</p>"
            }
        ],
        "authors": [
            {
                "name": "Chao Zeng, \nDing Luo, \nXiaotong Zhang, \nBoqiang Zhang, \nJincheng Hu, \nRuixue Si, \nChenxu Liu, \nChenyang Zhao, \nXin Xie, \nYueqing Du, \nXuetao Gan, \nJianlin Zhao, \nYanxiao Sun, \nDong Mao"
            }
        ],
        "author": "Chao Zeng, \nDing Luo, \nXiaotong Zhang, \nBoqiang Zhang, \nJincheng Hu, \nRuixue Si, \nChenxu Liu, \nChenyang Zhao, \nXin Xie, \nYueqing Du, \nXuetao Gan, \nJianlin Zhao, \nYanxiao Sun, \nDong Mao",
        "author_detail": {
            "name": "Chao Zeng, \nDing Luo, \nXiaotong Zhang, \nBoqiang Zhang, \nJincheng Hu, \nRuixue Si, \nChenxu Liu, \nChenyang Zhao, \nXin Xie, \nYueqing Du, \nXuetao Gan, \nJianlin Zhao, \nYanxiao Sun, \nDong Mao"
        },
        "tags": [
            {
                "term": "RESEARCH ARTICLE",
                "scheme": null,
                "label": null
            }
        ],
        "dc_identifier": "10.1002/lpor.202502639",
        "prism_publicationname": "Laser & Photonics Reviews",
        "prism_doi": "10.1002/lpor.202502639",
        "prism_url": "https://onlinelibrary.wiley.com/doi/10.1002/lpor.202502639?af=R",
        "prism_section": "RESEARCH ARTICLE",
        "journal": "Laser & Photonics Reviews",
        "title_cn": "平面化侧壁集成超纤维通过长程谐振近场耦合增强瞬逝场相互作用",
        "abstract_cn": "【摘要未收录】新文章暂无数据库记录，请点击链接直达官网。"
    },
    {
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://onlinelibrary.wiley.com/doi/10.1002/lpor.202501886?af=R"
            }
        ],
        "link": "https://doi.org/10.1002/lpor.202501886",
        "published": "Thu, 22 Jan 2026 22:52:58 -0800",
        "published_parsed": [
            2026,
            1,
            23,
            6,
            52,
            58,
            4,
            23,
            0
        ],
        "updated": "2026-01-22T10:52:58-08:00",
        "updated_parsed": [
            2026,
            1,
            22,
            18,
            52,
            58,
            3,
            22,
            0
        ],
        "source": {
            "href": "https://onlinelibrary.wiley.com/journal/18638899?af=R",
            "title": "Wiley: Laser & Photonics Reviews: Table of Contents"
        },
        "prism_coverdate": "",
        "prism_coverdisplaydate": "",
        "id": "https://doi.org/10.1002/lpor.202501886",
        "guidislink": false,
        "title": "Broadband III‐V/Lithium Niobate Actively Mode‐Locked Lasers",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Broadband III‐V/Lithium Niobate Actively Mode‐Locked Lasers"
        },
        "summary": "[New Paper] Abstract not indexed yet. Please visit the official website.",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "Laser &amp;Photonics Reviews, EarlyView."
        },
        "content": [
            {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "We demonstrate two integrated III‐V/lithium niobate actively mode‐locked lasers that achieve a broadband spectrum with a 10‐dB bandwidth of 19.1 nm and an enhanced off‐chip output power of 26 mW. Theoretical modeling reveals that inhomogeneous gain facilitates stretched‐state pulse formation, enabling broadband comb generation. These results establish a viable approach for realizing compact, broadband, and tunable frequency comb sources for integrated photonic applications.\n\n\n\n\n\n\n\n\nABSTRACT\nChip‐scale optical frequency combs (OFCs) enable integrated solutions for various applications among optical communications, LiDAR, spectroscopy, and radio frequency signal generation. Among integrated OFC platforms, III‐V semiconductor mode‐locked lasers provide gigahertz repetition rates but often suffer from limited power and tunability due to narrow driving current ranges. Hybrid integration with thin‐film lithium niobate (TFLN) has been explored to address these limitations, but previous III‐V/TFLN mode‐locked lasers exhibited narrow spectral widths, constrained by gain bandwidth and cavity dispersion. This work demonstrates broadband III‐V/TFLN integrated actively mode‐locked lasers at the telecom band, leveraging a broadband multiple‐quantum‐well reflective semiconductor optical amplifier (RSOA). A mode‐locked laser with a high‐reflectivity TFLN mirror generates a 45‐nm‐span spectrum with a 10‐dB bandwidth of 19.1 nm and a beat‐note contrast exceeding 60 dB, while another laser with a low‐reflectivity RSOA output facet achieves an off‐chip output power of 26 mW with a 10‐dB bandwidth of 11.4 nm. Numerical simulations based on the Haus's master equation and the generalized nonlinear Schrödinger equation confirm the role of slight inhomogeneous gain in supporting stretched‐state pulse solutions and overcoming dispersion‐limited spectral narrowing. This work demonstrates outstanding spectral performance and provides a promising route toward broadband, high‐power OFC sources for integrated photonic applications."
            },
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<img alt=\"Broadband III-V/Lithium Niobate Actively Mode-Locked Lasers\" src=\"https://onlinelibrary.wiley.com/cms/asset/d79fa873-3528-42cf-8e48-d1027caf0fa7/lpor70907-gra-0001-m.png\" />\n<p>We demonstrate two integrated III-V/lithium niobate actively mode-locked lasers that achieve a broadband spectrum with a 10-dB bandwidth of 19.1 nm and an enhanced off-chip output power of 26 mW. Theoretical modeling reveals that inhomogeneous gain facilitates stretched-state pulse formation, enabling broadband comb generation. These results establish a viable approach for realizing compact, broadband, and tunable frequency comb sources for integrated photonic applications.\n\n</p>\n<br />\n<h2>ABSTRACT</h2>\n<p>Chip-scale optical frequency combs (OFCs) enable integrated solutions for various applications among optical communications, LiDAR, spectroscopy, and radio frequency signal generation. Among integrated OFC platforms, III-V semiconductor mode-locked lasers provide gigahertz repetition rates but often suffer from limited power and tunability due to narrow driving current ranges. Hybrid integration with thin-film lithium niobate (TFLN) has been explored to address these limitations, but previous III-V/TFLN mode-locked lasers exhibited narrow spectral widths, constrained by gain bandwidth and cavity dispersion. This work demonstrates broadband III-V/TFLN integrated actively mode-locked lasers at the telecom band, leveraging a broadband multiple-quantum-well reflective semiconductor optical amplifier (RSOA). A mode-locked laser with a high-reflectivity TFLN mirror generates a 45-nm-span spectrum with a 10-dB bandwidth of 19.1 nm and a beat-note contrast exceeding 60 dB, while another laser with a low-reflectivity RSOA output facet achieves an off-chip output power of 26 mW with a 10-dB bandwidth of 11.4 nm. Numerical simulations based on the Haus's master equation and the generalized nonlinear Schrödinger equation confirm the role of slight inhomogeneous gain in supporting stretched-state pulse solutions and overcoming dispersion-limited spectral narrowing. This work demonstrates outstanding spectral performance and provides a promising route toward broadband, high-power OFC sources for integrated photonic applications.</p>"
            }
        ],
        "authors": [
            {
                "name": "Xujia Zhang, \nYuyao Guo, \nXiaotian Xue, \nTianyi Li, \nZekun Cui, \nHao Li, \nXianfeng Chen, \nYuanlin Zheng, \nJianping Chen, \nKan Wu"
            }
        ],
        "author": "Xujia Zhang, \nYuyao Guo, \nXiaotian Xue, \nTianyi Li, \nZekun Cui, \nHao Li, \nXianfeng Chen, \nYuanlin Zheng, \nJianping Chen, \nKan Wu",
        "author_detail": {
            "name": "Xujia Zhang, \nYuyao Guo, \nXiaotian Xue, \nTianyi Li, \nZekun Cui, \nHao Li, \nXianfeng Chen, \nYuanlin Zheng, \nJianping Chen, \nKan Wu"
        },
        "tags": [
            {
                "term": "RESEARCH ARTICLE",
                "scheme": null,
                "label": null
            }
        ],
        "dc_identifier": "10.1002/lpor.202501886",
        "prism_publicationname": "Laser & Photonics Reviews",
        "prism_doi": "10.1002/lpor.202501886",
        "prism_url": "https://onlinelibrary.wiley.com/doi/10.1002/lpor.202501886?af=R",
        "prism_section": "RESEARCH ARTICLE",
        "journal": "Laser & Photonics Reviews",
        "title_cn": "宽带 III-V/铌酸锂主动锁模激光器",
        "abstract_cn": "【摘要未收录】新文章暂无数据库记录，请点击链接直达官网。"
    },
    {
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://onlinelibrary.wiley.com/doi/10.1002/lpor.202502914?af=R"
            }
        ],
        "link": "https://doi.org/10.1002/lpor.202502914",
        "published": "Thu, 22 Jan 2026 23:02:54 -0800",
        "published_parsed": [
            2026,
            1,
            23,
            7,
            2,
            54,
            4,
            23,
            0
        ],
        "updated": "2026-01-22T11:02:54-08:00",
        "updated_parsed": [
            2026,
            1,
            22,
            19,
            2,
            54,
            3,
            22,
            0
        ],
        "source": {
            "href": "https://onlinelibrary.wiley.com/journal/18638899?af=R",
            "title": "Wiley: Laser & Photonics Reviews: Table of Contents"
        },
        "prism_coverdate": "",
        "prism_coverdisplaydate": "",
        "id": "https://doi.org/10.1002/lpor.202502914",
        "guidislink": false,
        "title": "Ultrafast Laser Two‐Photon Lithography for Metasurface Engineering: Advances in Fabrication and Photonic Applications",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Ultrafast Laser Two‐Photon Lithography for Metasurface Engineering: Advances in Fabrication and Photonic Applications"
        },
        "summary": "[New Paper] Abstract not indexed yet. Please visit the official website.",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "Laser &amp;Photonics Reviews, EarlyView."
        },
        "content": [
            {
                "type": "text/plain",
                "language": null,
                "base": "",
                "value": "Ultrafast laser two‐photon lithography (TPL) has revolutionized the fabrication of metasurfaces, enabling precise 3D structures with sub‐diffraction‐limited resolution. This review explores the integration of TPL with metasurface engineering, highlighting breakthroughs in photonic devices such as diffractive optics, imaging systems, and quantum optics. Challenges in material properties, process optimization, and scalability are discussed, along with potential solutions and future directions for advancing TPL in photonics.\n\n\n\n\n\n\n\n\nABSTRACT\nUltrafast laser two‐photon lithography (TPL) has revolutionized micro/nanofabrication, enabling the creation of intricate 3D structures with sub‐diffraction‐limited resolution. The integration of TPL with metasurface engineering has unlocked new frontiers in photonic device design, offering unprecedented control over light‐matter interactions at the nanoscale. This review delves into the cutting‐edge advancements in TPL as applied to the fabrication of metasurfaces, which are thin, artificially structured materials with unique optical properties. We explore TPL's unparalleled precision of TPL, which allows the creation of complex metasurface geometries, facilitating breakthroughs in diverse applications, including high‐efficiency diffractive optics, next‐generation imaging systems, quantum optics, and dynamic tunable photonic devices. Key challenges, such as material limitations, process optimization, and scalability, are discussed along with promising solutions and future directions for overcoming these barriers. Furthermore, the potential of TPL to drive innovation in areas such as optical sensing, energy harvesting, and quantum information processing is critically analyzed. Through this comprehensive review, we highlight the transformative role of ultrafast laser two‐photon lithography in advancing metasurface technologies, positioning it as a cornerstone of the future of photonics."
            },
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "<img alt=\"Ultrafast Laser Two-Photon Lithography for Metasurface Engineering: Advances in Fabrication and Photonic Applications\" src=\"https://onlinelibrary.wiley.com/cms/asset/e9055262-74be-441d-90d0-1ca3e75608ab/lpor70874-gra-0001-m.png\" />\n<p>Ultrafast laser two-photon lithography (TPL) has revolutionized the fabrication of metasurfaces, enabling precise 3D structures with sub-diffraction-limited resolution. This review explores the integration of TPL with metasurface engineering, highlighting breakthroughs in photonic devices such as diffractive optics, imaging systems, and quantum optics. Challenges in material properties, process optimization, and scalability are discussed, along with potential solutions and future directions for advancing TPL in photonics.\n\n</p>\n<br />\n<h2>ABSTRACT</h2>\n<p>Ultrafast laser two-photon lithography (TPL) has revolutionized micro/nanofabrication, enabling the creation of intricate 3D structures with sub-diffraction-limited resolution. The integration of TPL with metasurface engineering has unlocked new frontiers in photonic device design, offering unprecedented control over light-matter interactions at the nanoscale. This review delves into the cutting-edge advancements in TPL as applied to the fabrication of metasurfaces, which are thin, artificially structured materials with unique optical properties. We explore TPL's unparalleled precision of TPL, which allows the creation of complex metasurface geometries, facilitating breakthroughs in diverse applications, including high-efficiency diffractive optics, next-generation imaging systems, quantum optics, and dynamic tunable photonic devices. Key challenges, such as material limitations, process optimization, and scalability, are discussed along with promising solutions and future directions for overcoming these barriers. Furthermore, the potential of TPL to drive innovation in areas such as optical sensing, energy harvesting, and quantum information processing is critically analyzed. Through this comprehensive review, we highlight the transformative role of ultrafast laser two-photon lithography in advancing metasurface technologies, positioning it as a cornerstone of the future of photonics.</p>"
            }
        ],
        "authors": [
            {
                "name": "Mohamed Hassan Eisa, \nAli Zia, \nZainuriah Hassan, \nSadaf Saeed"
            }
        ],
        "author": "Mohamed Hassan Eisa, \nAli Zia, \nZainuriah Hassan, \nSadaf Saeed",
        "author_detail": {
            "name": "Mohamed Hassan Eisa, \nAli Zia, \nZainuriah Hassan, \nSadaf Saeed"
        },
        "tags": [
            {
                "term": "REVIEW",
                "scheme": null,
                "label": null
            }
        ],
        "dc_identifier": "10.1002/lpor.202502914",
        "prism_publicationname": "Laser & Photonics Reviews",
        "prism_doi": "10.1002/lpor.202502914",
        "prism_url": "https://onlinelibrary.wiley.com/doi/10.1002/lpor.202502914?af=R",
        "prism_section": "REVIEW",
        "journal": "Laser & Photonics Reviews",
        "title_cn": "用于超表面工程的超快激光双光子光刻：制造和光子应用的进展",
        "abstract_cn": "【摘要未收录】新文章暂无数据库记录，请点击链接直达官网。"
    },
    {
        "title": "Evolution of fractional vortices through intensity autocorrelation of scattered speckle patterns",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Evolution of fractional vortices through intensity autocorrelation of scattered speckle patterns"
        },
        "summary": "[New Paper] Abstract not indexed yet. Please visit the official website.",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "<p>Publication date: June 2026</p><p><b>Source:</b> Optics and Lasers in Engineering, Volume 201</p><p>Author(s): MD. Haider Ansari, Velagala Ganesh, Sakshi Choudhary, Ravi Kumar, Shashi Prabhakar, Salla Gangi Reddy</p>"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.sciencedirect.com/science/article/pii/S0143816626000370?dgcid=rss_sd_all"
            }
        ],
        "link": "https://www.sciencedirect.com/science/article/pii/S0143816626000370",
        "id": "https://www.sciencedirect.com/science/article/pii/S0143816626000370",
        "guidislink": false,
        "journal": "Optics and Lasers in Engineering",
        "title_cn": "通过散射散斑图案的强度自相关来演化分数涡旋",
        "abstract_cn": "【摘要未收录】新文章暂无数据库记录，请点击链接直达官网。"
    },
    {
        "title": "Space-frequency analysis-based Fourier single-pixel 3D imaging",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Space-frequency analysis-based Fourier single-pixel 3D imaging"
        },
        "summary": "[New Paper] Abstract not indexed yet. Please visit the official website.",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "<p>Publication date: June 2026</p><p><b>Source:</b> Optics and Lasers in Engineering, Volume 201</p><p>Author(s): Le Hu, Xinyue Ma, Junyang Li, Ke Hu, Chenxing Wang</p>"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.sciencedirect.com/science/article/pii/S0143816626000400?dgcid=rss_sd_all"
            }
        ],
        "link": "https://www.sciencedirect.com/science/article/pii/S0143816626000400",
        "id": "https://www.sciencedirect.com/science/article/pii/S0143816626000400",
        "guidislink": false,
        "journal": "Optics and Lasers in Engineering",
        "title_cn": "基于空频分析的傅里叶单像素3D成像",
        "abstract_cn": "【摘要未收录】新文章暂无数据库记录，请点击链接直达官网。"
    },
    {
        "id": "https://doi.org/10.29026/oea.2025.250226",
        "title": "In-situ and ex-situ twisted bilayer liquid crystal computing platform for reconfigurable image processing",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "In-situ and ex-situ twisted bilayer liquid crystal computing platform for reconfigurable image processing"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.oejournal.org/oea/article/doi/10.29026/oea.2025.250226"
            }
        ],
        "link": "https://doi.org/10.29026/oea.2025.250226",
        "summary": "<p>All-optical image processing has been viewed as a promising technique for its high computation speed and low power consumption. However, current methods are often restricted to few functionalities and low reconfigurabilities, which cannot meet the growing demand for device integration and scenario adaptation in next-generation vision regimes. Here, we propose and experimentally demonstrate a bilayer liquid crystal computing platform for reconfigurable image processing. Under different in-situ/ex-situ twisted/untwisted conditions of the layers, our approach allows for eight kinds of image processing functions, including one/two-channel bright field imaging, one/two-channel vortex filtering, horizontally/vertically one-dimensional edge detection, vertex detection, and photonic spin Hall effect-based resolution adjustable edge detection. A unified theoretical framework for this scheme is established on the transfer function theory, which coincides well with the experimental results. The proposed method offers an easily-switchable multi-functional solution to optical image processing by introducing mechanical degrees of freedom, which may enable emerging applications in computer vision, autonomous driving, and biomedical microscopy.</p>",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "&lt;br/&gt;&lt;p&gt;&amp;lt;p&amp;lt;All-optical image processing has been viewed as a promising technique for its high computation speed and low power consumption. However, current methods are often restricted to few functionalities and low reconfigurabilities, which cannot meet the growing demand for device integration and scenario adaptation in next-generation vision regimes. Here, we propose and experimentally demonstrate a bilayer liquid crystal computing platform for reconfigurable image processing. Under different in-situ/ex-situ twisted/untwisted conditions of the layers, our approach allows for eight kinds of image processing functions, including one/two-channel bright field imaging, one/two-channel vortex filtering, horizontally/vertically one-dimensional edge detection, vertex detection, and photonic spin Hall effect-based resolution adjustable edge detection. A unified theoretical framework for this scheme is established on the transfer function theory, which coincides well with the experimental results. The proposed method offers an easily-switchable multi-functional solution to optical image processing by introducing mechanical degrees of freedom, which may enable emerging applications in computer vision, autonomous driving, and biomedical microscopy.&amp;lt;/p&amp;lt;&lt;/p&gt;\n\t\t\t&lt;br/&gt;Opto-Electronic Advances. 2025 8(12): 250226. Published 2025-12-25"
        },
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "&lt;br/&gt;&lt;p&gt;&amp;lt;p&amp;lt;All-optical image processing has been viewed as a promising technique for its high computation speed and low power consumption. However, current methods are often restricted to few functionalities and low reconfigurabilities, which cannot meet the growing demand for device integration and scenario adaptation in next-generation vision regimes. Here, we propose and experimentally demonstrate a bilayer liquid crystal computing platform for reconfigurable image processing. Under different in-situ/ex-situ twisted/untwisted conditions of the layers, our approach allows for eight kinds of image processing functions, including one/two-channel bright field imaging, one/two-channel vortex filtering, horizontally/vertically one-dimensional edge detection, vertex detection, and photonic spin Hall effect-based resolution adjustable edge detection. A unified theoretical framework for this scheme is established on the transfer function theory, which coincides well with the experimental results. The proposed method offers an easily-switchable multi-functional solution to optical image processing by introducing mechanical degrees of freedom, which may enable emerging applications in computer vision, autonomous driving, and biomedical microscopy.&amp;lt;/p&amp;lt;&lt;/p&gt;\n\t\t\t&lt;br/&gt;Opto-Electronic Advances. 2025 8(12): 250226. Published 2025-12-25"
            }
        ],
        "authors": [
            {}
        ],
        "author": "Kang Zeng, Yougang Ke, Zhangming Hong, Linzhou Zeng, Xinxing Zhou",
        "updated": "2025-12-25",
        "updated_parsed": [
            2025,
            12,
            25,
            0,
            0,
            0,
            3,
            359,
            0
        ],
        "rights": "Personal use only, all commercial or other reuse prohibited",
        "rights_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Personal use only, all commercial or other reuse prohibited"
        },
        "dc_source": "Opto-Electronic Advances. 2025 8(12): 250226.",
        "dc_type": "article",
        "dc_identifier": "doi:10.29026/oea.2025.250226",
        "prism_doi": "10.29026/oea.2025.250226",
        "prism_publicationname": "Opto-Electronic Advances",
        "prism_volume": "8",
        "prism_number": "12",
        "prism_publicationdate": "2025-12-25",
        "prism_url": "https://www.oejournal.org/oea/article/doi/10.29026/oea.2025.250226",
        "prism_startingpage": "250226",
        "journal": "Opto-Electronic Advances",
        "title_cn": "用于可重构图像处理的原位和异位扭曲双层液晶计算平台",
        "abstract_cn": "<p>全光学图像处理因其高计算速度和低功耗而被视为一种有前途的技术。然而，当前的方法通常仅限于功能较少和可重构性较低，无法满足下一代视觉体系中对设备集成和场景适应不断增长的需求。在这里，我们提出并实验演示了一种用于可重构图像处理的双层液晶计算平台。在层的不同原位/异位扭曲/非扭曲条件下，我们的方法允许八种图像处理功能，包括一/两通道明场成像、一/两通道涡旋滤波、水平/垂直一维边缘检测、顶点检测和基于光子自旋霍尔效应的分辨率可调边缘检测。该方案基于传递函数理论建立了统一的理论框架，与实验结果吻合较好。该方法通过引入机械自由度，为光学图像处理提供了一种易于切换的多功能解决方案，这可能会在计算机视觉、自动驾驶和生物医学显微镜方面实现新兴应用。</p>"
    },
    {
        "id": "https://doi.org/10.29026/oea.2025.250144",
        "title": "Filament based ionizing radiation sensing",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Filament based ionizing radiation sensing"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.oejournal.org/oea/article/doi/10.29026/oea.2025.250144"
            }
        ],
        "link": "https://doi.org/10.29026/oea.2025.250144",
        "summary": "<p>Accidental exposure to overdose ionizing radiation will inevitably lead to severe biological damage, thus detecting and localizing radiation is essential. Traditional measurement techniques are generally restricted to the detection range of few centimeters, posing a great risk to operators. The prospect in remote sensing makes femtosecond laser filament technology a great candidate for constructively addressing this challenge. Here we propose a novel filament-based ionizing radiation sensing method, and clarify the interaction mechanism between filaments and ionizing radiation from systematic experiment to microscopic theory. Specifically, it is demonstrated that the energetic electrons produced by <italic>α</italic> radiation in air can be effectively accelerated within the filament, serving as seed electrons, which will enhance nitrogen fluorescence. The extended nitrogen fluorescence lifetime of ~1 ns is also observed. Lastly, the combined microscopic model was elaborately established to quantitatively explain the modulation of nitrogen fluorescence emission from filament by ionizing radiation. These findings provide insights into the intricate interaction among ultra-strong light field, plasma and energetic particle beam, potentially suggesting a promising novel avenue for remote sensing of ionizing radiation.</p>",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "&lt;br/&gt;&lt;p&gt;&amp;lt;p&amp;lt;Accidental exposure to overdose ionizing radiation will inevitably lead to severe biological damage, thus detecting and localizing radiation is essential. Traditional measurement techniques are generally restricted to the detection range of few centimeters, posing a great risk to operators. The prospect in remote sensing makes femtosecond laser filament technology a great candidate for constructively addressing this challenge. Here we propose a novel filament-based ionizing radiation sensing method, and clarify the interaction mechanism between filaments and ionizing radiation from systematic experiment to microscopic theory. Specifically, it is demonstrated that the energetic electrons produced by &amp;lt;italic&amp;lt;α&amp;lt;/italic&amp;lt; radiation in air can be effectively accelerated within the filament, serving as seed electrons, which will enhance nitrogen fluorescence. The extended nitrogen fluorescence lifetime of ~1 ns is also observed. Lastly, the combined microscopic model was elaborately established to quantitatively explain the modulation of nitrogen fluorescence emission from filament by ionizing radiation. These findings provide insights into the intricate interaction among ultra-strong light field, plasma and energetic particle beam, potentially suggesting a promising novel avenue for remote sensing of ionizing radiation.&amp;lt;/p&amp;lt;&lt;/p&gt;\n\t\t\t&lt;br/&gt;Opto-Electronic Advances. 2025 8(12): 250144. Published 2025-10-30"
        },
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "&lt;br/&gt;&lt;p&gt;&amp;lt;p&amp;lt;Accidental exposure to overdose ionizing radiation will inevitably lead to severe biological damage, thus detecting and localizing radiation is essential. Traditional measurement techniques are generally restricted to the detection range of few centimeters, posing a great risk to operators. The prospect in remote sensing makes femtosecond laser filament technology a great candidate for constructively addressing this challenge. Here we propose a novel filament-based ionizing radiation sensing method, and clarify the interaction mechanism between filaments and ionizing radiation from systematic experiment to microscopic theory. Specifically, it is demonstrated that the energetic electrons produced by &amp;lt;italic&amp;lt;α&amp;lt;/italic&amp;lt; radiation in air can be effectively accelerated within the filament, serving as seed electrons, which will enhance nitrogen fluorescence. The extended nitrogen fluorescence lifetime of ~1 ns is also observed. Lastly, the combined microscopic model was elaborately established to quantitatively explain the modulation of nitrogen fluorescence emission from filament by ionizing radiation. These findings provide insights into the intricate interaction among ultra-strong light field, plasma and energetic particle beam, potentially suggesting a promising novel avenue for remote sensing of ionizing radiation.&amp;lt;/p&amp;lt;&lt;/p&gt;\n\t\t\t&lt;br/&gt;Opto-Electronic Advances. 2025 8(12): 250144. Published 2025-10-30"
            }
        ],
        "authors": [
            {}
        ],
        "author": "Pengfei Qi, Haiyi Liu, Jiewei Guo, Nan Zhang, Lu Sun, Shishi Tao, Binpeng Shang, Lie Lin, Weiwei Liu",
        "updated": "2025-10-30",
        "updated_parsed": [
            2025,
            10,
            30,
            0,
            0,
            0,
            3,
            303,
            0
        ],
        "rights": "Personal use only, all commercial or other reuse prohibited",
        "rights_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Personal use only, all commercial or other reuse prohibited"
        },
        "dc_source": "Opto-Electronic Advances. 2025 8(12): 250144.",
        "dc_type": "article",
        "dc_identifier": "doi:10.29026/oea.2025.250144",
        "prism_doi": "10.29026/oea.2025.250144",
        "prism_publicationname": "Opto-Electronic Advances",
        "prism_volume": "8",
        "prism_number": "12",
        "prism_publicationdate": "2025-10-30",
        "prism_url": "https://www.oejournal.org/oea/article/doi/10.29026/oea.2025.250144",
        "prism_startingpage": "250144",
        "journal": "Opto-Electronic Advances",
        "title_cn": "基于灯丝的电离辐射传感",
        "abstract_cn": "<p>意外暴露于过量的电离辐射将不可避免地导致严重的生物损伤，因此检测和定位辐射至关重要。传统的测量技术一般仅限于几厘米的检测范围，给操作人员带来很大的风险。遥感的前景使飞秒激光灯丝技术成为建设性应对这一挑战的绝佳候选者。在这里，我们提出了一种新型的基于灯丝的电离辐射传感方法，并从系统实验到微观理论阐明了灯丝与电离辐射之间的相互作用机制。具体来说，证明空气中α辐射产生的高能电子可以在灯丝内有效加速，作为种子电子，从而增强氮荧光。还观察到氮荧光寿命延长了约 1 ns。最后，精心建立了组合微观模型，定量解释了电离辐射对灯丝氮荧光发射的调制。这些发现为超强光场、等离子体和高能粒子束之间复杂的相互作用提供了见解，可能为电离辐射遥感提供了一种有前景的新途径。</p>"
    },
    {
        "id": "https://doi.org/10.29026/oea.2025.250159",
        "title": "Spatiotemporal multiplexed photonic reservoir computing: parallel prediction for the high-dimensional dynamics of complex semiconductor laser network",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Spatiotemporal multiplexed photonic reservoir computing: parallel prediction for the high-dimensional dynamics of complex semiconductor laser network"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.oejournal.org/oea/article/doi/10.29026/oea.2025.250159"
            }
        ],
        "link": "https://doi.org/10.29026/oea.2025.250159",
        "summary": "<p>Accurately forecasting the high-dimensional chaotic dynamics of semiconductor laser (SL) networks is essential in photonics research. In this study, we propose a spatiotemporal multiplexed photonic reservoir computing (STM-PRC) architecture, specifically designed for parallel prediction of the high-dimensional chaotic dynamics in complex SL networks. This is accomplished by decomposing the prediction task into multiple simplified reservoirs, leveraging the intrinsic topological characteristics of the network. Additionally, we introduce a dimensionality reduction technique for high-dimensional chaotic datasets, which exploits the symmetrical properties of the network topology and cluster synchronization patterns derived from complex network theory. This approach further simplifies the prediction process and enhances the computational efficiency of the parallel STM-PRC system. The feasibility and effectiveness of the proposed framework are demonstrated through numerical simulations and corroborated by experimental validation. Our results expand the application potential of SL networks in all-optical communication systems and suggest new directions for optical information processing.</p>",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "&lt;br/&gt;&lt;p&gt;&amp;lt;p&amp;lt;Accurately forecasting the high-dimensional chaotic dynamics of semiconductor laser (SL) networks is essential in photonics research. In this study, we propose a spatiotemporal multiplexed photonic reservoir computing (STM-PRC) architecture, specifically designed for parallel prediction of the high-dimensional chaotic dynamics in complex SL networks. This is accomplished by decomposing the prediction task into multiple simplified reservoirs, leveraging the intrinsic topological characteristics of the network. Additionally, we introduce a dimensionality reduction technique for high-dimensional chaotic datasets, which exploits the symmetrical properties of the network topology and cluster synchronization patterns derived from complex network theory. This approach further simplifies the prediction process and enhances the computational efficiency of the parallel STM-PRC system. The feasibility and effectiveness of the proposed framework are demonstrated through numerical simulations and corroborated by experimental validation. Our results expand the application potential of SL networks in all-optical communication systems and suggest new directions for optical information processing.&amp;lt;/p&amp;lt;&lt;/p&gt;\n\t\t\t&lt;br/&gt;Opto-Electronic Advances. 2025 8(12): 250159. Published 2025-11-14"
        },
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "&lt;br/&gt;&lt;p&gt;&amp;lt;p&amp;lt;Accurately forecasting the high-dimensional chaotic dynamics of semiconductor laser (SL) networks is essential in photonics research. In this study, we propose a spatiotemporal multiplexed photonic reservoir computing (STM-PRC) architecture, specifically designed for parallel prediction of the high-dimensional chaotic dynamics in complex SL networks. This is accomplished by decomposing the prediction task into multiple simplified reservoirs, leveraging the intrinsic topological characteristics of the network. Additionally, we introduce a dimensionality reduction technique for high-dimensional chaotic datasets, which exploits the symmetrical properties of the network topology and cluster synchronization patterns derived from complex network theory. This approach further simplifies the prediction process and enhances the computational efficiency of the parallel STM-PRC system. The feasibility and effectiveness of the proposed framework are demonstrated through numerical simulations and corroborated by experimental validation. Our results expand the application potential of SL networks in all-optical communication systems and suggest new directions for optical information processing.&amp;lt;/p&amp;lt;&lt;/p&gt;\n\t\t\t&lt;br/&gt;Opto-Electronic Advances. 2025 8(12): 250159. Published 2025-11-14"
            }
        ],
        "authors": [
            {}
        ],
        "author": "Tong Yang, Li-Yue Zhang, Song-Sui Li, Wei Pan, Xi-Hua Zou, Lian-Shan Yan",
        "updated": "2025-11-14",
        "updated_parsed": [
            2025,
            11,
            14,
            0,
            0,
            0,
            4,
            318,
            0
        ],
        "rights": "Personal use only, all commercial or other reuse prohibited",
        "rights_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Personal use only, all commercial or other reuse prohibited"
        },
        "dc_source": "Opto-Electronic Advances. 2025 8(12): 250159.",
        "dc_type": "article",
        "dc_identifier": "doi:10.29026/oea.2025.250159",
        "prism_doi": "10.29026/oea.2025.250159",
        "prism_publicationname": "Opto-Electronic Advances",
        "prism_volume": "8",
        "prism_number": "12",
        "prism_publicationdate": "2025-11-14",
        "prism_url": "https://www.oejournal.org/oea/article/doi/10.29026/oea.2025.250159",
        "prism_startingpage": "250159",
        "journal": "Opto-Electronic Advances",
        "title_cn": "时空复用光子库计算：复杂半导体激光网络高维动力学的并行预测",
        "abstract_cn": "<p>准确预测半导体激光（SL）网络的高维混沌动力学对于光子学研究至关重要。在这项研究中，我们提出了一种时空复用光子库计算（STM-PRC）架构，专门用于复杂SL网络中高维混沌动力学的并行预测。这是通过利用网络的固有拓扑特征将预测任务分解为多个简化的储层来实现的。此外，我们引入了一种用于高维混沌数据集的降维技术，该技术利用了从复杂网络理论导出的网络拓扑和集群同步模式的对称特性。该方法进一步简化了预测过程并提高了并行STM-PRC系统的计算效率。通过数值模拟证明了所提出框架的可行性和有效性，并通过实验验证得到了证实。我们的研究成果拓展了SL网络在全光通信系统中的应用潜力，并为光信息处理提出了新的方向。</p>"
    },
    {
        "id": "https://doi.org/10.29026/oea.2025.250168",
        "title": "Highly textured single-crystal-like perovskite films for large-area, high-performance photodiodes",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Highly textured single-crystal-like perovskite films for large-area, high-performance photodiodes"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.oejournal.org/oea/article/doi/10.29026/oea.2025.250168"
            }
        ],
        "link": "https://doi.org/10.29026/oea.2025.250168",
        "summary": "<p>Organometallic perovskite single crystals have been considered one of the most promising candidates for photodetection applications, owing to their grain-boundary-free structure and improved optoelectronic properties. However, several challenges still remain for the application of perovskite single crystals in photodetectors, in particular the thickness and area controls and poor compatibility with substrates. Herein, we report a straightforward fabrication process for realizing large-area (up to 100 cm<sup>2</sup>) and highly textured single-crystal-like MAPbBr<sub>3</sub> films by combining inverse-temperature crystallization with a hot-pressing process. Thanks to the following hot-pressing treatment, the obtained perovskites can be effectively integrated onto the FTO substrates without falling, facilitating electrical connections and device integration. The obtained MAPbBr<sub>3</sub> exhibits a low trap density of 1.4 × 10<sup>11</sup> cm<sup>−3</sup> and a high mobility of 217 cm<sup>2</sup>·V<sup>−1</sup>·s<sup>−1</sup> (with a high mobility-lifetime product of up to 5.4 × 10<sup>−4</sup> cm<sup>2</sup>·V<sup>-1</sup>). The resulting photodiodes exhibit the self-powered capability and show a maximum responsivity approaching 944 mA·W<sup>−1</sup>, a champion detectivity exceeding 10<sup>11</sup> Jones, and a fast photoresponse of 45 ms, together with excellent stability. This study constitutes a demonstration of highly textured, large-area perovskite photodiodes integrated sturdily onto FTO substrates and paves the way for various practical applications, such as optical imaging technology.</p>",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "&lt;br/&gt;&lt;p&gt;&amp;lt;p&amp;lt;Organometallic perovskite single crystals have been considered one of the most promising candidates for photodetection applications, owing to their grain-boundary-free structure and improved optoelectronic properties. However, several challenges still remain for the application of perovskite single crystals in photodetectors, in particular the thickness and area controls and poor compatibility with substrates. Herein, we report a straightforward fabrication process for realizing large-area (up to 100 cm&amp;lt;sup&amp;lt;2&amp;lt;/sup&amp;lt;) and highly textured single-crystal-like MAPbBr&amp;lt;sub&amp;lt;3&amp;lt;/sub&amp;lt; films by combining inverse-temperature crystallization with a hot-pressing process. Thanks to the following hot-pressing treatment, the obtained perovskites can be effectively integrated onto the FTO substrates without falling, facilitating electrical connections and device integration. The obtained MAPbBr&amp;lt;sub&amp;lt;3&amp;lt;/sub&amp;lt; exhibits a low trap density of 1.4 × 10&amp;lt;sup&amp;lt;11&amp;lt;/sup&amp;lt; cm&amp;lt;sup&amp;lt;−3&amp;lt;/sup&amp;lt; and a high mobility of 217 cm&amp;lt;sup&amp;lt;2&amp;lt;/sup&amp;lt;·V&amp;lt;sup&amp;lt;−1&amp;lt;/sup&amp;lt;·s&amp;lt;sup&amp;lt;−1&amp;lt;/sup&amp;lt; (with a high mobility-lifetime product of up to 5.4 × 10&amp;lt;sup&amp;lt;−4&amp;lt;/sup&amp;lt; cm&amp;lt;sup&amp;lt;2&amp;lt;/sup&amp;lt;·V&amp;lt;sup&amp;lt;-1&amp;lt;/sup&amp;lt;). The resulting photodiodes exhibit the self-powered capability and show a maximum responsivity approaching 944 mA·W&amp;lt;sup&amp;lt;−1&amp;lt;/sup&amp;lt;, a champion detectivity exceeding 10&amp;lt;sup&amp;lt;11&amp;lt;/sup&amp;lt; Jones, and a fast photoresponse of 45 ms, together with excellent stability. This study constitutes a demonstration of highly textured, large-area perovskite photodiodes integrated sturdily onto FTO substrates and paves the way for various practical applications, such as optical imaging technology.&amp;lt;/p&amp;lt;&lt;/p&gt;\n\t\t\t&lt;br/&gt;Opto-Electronic Advances. 2025 8(12): 250168. Published 2025-12-19"
        },
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "&lt;br/&gt;&lt;p&gt;&amp;lt;p&amp;lt;Organometallic perovskite single crystals have been considered one of the most promising candidates for photodetection applications, owing to their grain-boundary-free structure and improved optoelectronic properties. However, several challenges still remain for the application of perovskite single crystals in photodetectors, in particular the thickness and area controls and poor compatibility with substrates. Herein, we report a straightforward fabrication process for realizing large-area (up to 100 cm&amp;lt;sup&amp;lt;2&amp;lt;/sup&amp;lt;) and highly textured single-crystal-like MAPbBr&amp;lt;sub&amp;lt;3&amp;lt;/sub&amp;lt; films by combining inverse-temperature crystallization with a hot-pressing process. Thanks to the following hot-pressing treatment, the obtained perovskites can be effectively integrated onto the FTO substrates without falling, facilitating electrical connections and device integration. The obtained MAPbBr&amp;lt;sub&amp;lt;3&amp;lt;/sub&amp;lt; exhibits a low trap density of 1.4 × 10&amp;lt;sup&amp;lt;11&amp;lt;/sup&amp;lt; cm&amp;lt;sup&amp;lt;−3&amp;lt;/sup&amp;lt; and a high mobility of 217 cm&amp;lt;sup&amp;lt;2&amp;lt;/sup&amp;lt;·V&amp;lt;sup&amp;lt;−1&amp;lt;/sup&amp;lt;·s&amp;lt;sup&amp;lt;−1&amp;lt;/sup&amp;lt; (with a high mobility-lifetime product of up to 5.4 × 10&amp;lt;sup&amp;lt;−4&amp;lt;/sup&amp;lt; cm&amp;lt;sup&amp;lt;2&amp;lt;/sup&amp;lt;·V&amp;lt;sup&amp;lt;-1&amp;lt;/sup&amp;lt;). The resulting photodiodes exhibit the self-powered capability and show a maximum responsivity approaching 944 mA·W&amp;lt;sup&amp;lt;−1&amp;lt;/sup&amp;lt;, a champion detectivity exceeding 10&amp;lt;sup&amp;lt;11&amp;lt;/sup&amp;lt; Jones, and a fast photoresponse of 45 ms, together with excellent stability. This study constitutes a demonstration of highly textured, large-area perovskite photodiodes integrated sturdily onto FTO substrates and paves the way for various practical applications, such as optical imaging technology.&amp;lt;/p&amp;lt;&lt;/p&gt;\n\t\t\t&lt;br/&gt;Opto-Electronic Advances. 2025 8(12): 250168. Published 2025-12-19"
            }
        ],
        "authors": [
            {}
        ],
        "author": "Runkai Liu, Feng Li, Rongkun Zheng",
        "updated": "2025-12-19",
        "updated_parsed": [
            2025,
            12,
            19,
            0,
            0,
            0,
            4,
            353,
            0
        ],
        "rights": "Personal use only, all commercial or other reuse prohibited",
        "rights_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Personal use only, all commercial or other reuse prohibited"
        },
        "dc_source": "Opto-Electronic Advances. 2025 8(12): 250168.",
        "dc_type": "article",
        "dc_identifier": "doi:10.29026/oea.2025.250168",
        "prism_doi": "10.29026/oea.2025.250168",
        "prism_publicationname": "Opto-Electronic Advances",
        "prism_volume": "8",
        "prism_number": "12",
        "prism_publicationdate": "2025-12-19",
        "prism_url": "https://www.oejournal.org/oea/article/doi/10.29026/oea.2025.250168",
        "prism_startingpage": "250168",
        "journal": "Opto-Electronic Advances",
        "title_cn": "用于大面积、高性能光电二极管的高织构类单晶钙钛矿薄膜",
        "abstract_cn": "<p>有机金属钙钛矿单晶因其无晶界结构和改进的光电性能而被认为是光电检测应用中最有前途的候选者之一。然而，钙钛矿单晶在光电探测器中的应用仍然存在一些挑战，特别是厚度和面积控制以及与基底的兼容性差。在此，我们报告了一种通过将逆温结晶与热压工艺相结合来实现大面积（高达 100 cm<sup>2</sup>）和高度织构的单晶类 MAPbBr<sub>3</sub> 薄膜的简单制造工艺。通过后续的热压处理，获得的钙钛矿可以有效地集成到FTO基板上而不会掉落，有利于电气连接和器件集成。所得的MAPbBr<sub>3</sub>表现出1.4 × 10<sup>11</sup> cm<sup>−3</sup>的低陷阱密度和217 cm<sup>2</sup>·V<sup>-1</sup>·s<sup>-1</sup>的高迁移率（高迁移率寿命乘积高达5.4 × 10<sup>−4</sup> 厘米<sup>2</sup>·V<sup>-1</sup>）。由此产生的光电二极管具有自供电能力，最大响应度接近 944 mA·W<sup>-1</sup>，冠军探测率超过 10<sup>11</sup> Jones，并且具有 45 ms 的快速光响应以及出色的稳定性。这项研究展示了将高纹理、大面积的钙钛矿光电二极管牢固地集成到 FTO 基板上，并为光学成像技术等各种实际应用铺平了道路。</p>"
    },
    {
        "id": "https://doi.org/10.29026/oea.2025.250148",
        "title": "Robust performance of PTQ10:DTY6 in halogen-free photovoltaics across deposition techniques and configurations for industrial scale-up",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Robust performance of PTQ10:DTY6 in halogen-free photovoltaics across deposition techniques and configurations for industrial scale-up"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.oejournal.org/oea/article/doi/10.29026/oea.2025.250148"
            }
        ],
        "link": "https://doi.org/10.29026/oea.2025.250148",
        "summary": "<p>With performance improvements, organic photovoltaics (OPVs) are an increasingly competitive technology for renewable energy. However, most high-performance OPVs are small-area devices processed from toxic halogenated solvents via spin-coating, posing a challenge for mass production. We study a low-cost polymer donor (PTQ10) and a non-fullerene acceptor (DTY6) in a halogen-free solvent using industrially relevant blade coating. The non-inverted architecture performed best, achieving 12% efficiency, with the blade-coating deposition surpassing spin-coating. Active layers processed from the two coating techniques exhibited similar exciton quenching, likely due to the same measured nanodomain size and purity. However, blade-coated devices exhibited a higher charge carrier lifetime correlated with increased acceptor pi-stacking despite decreased donor pi-stacking. This suggests that optimizing crystallinity in blade-coated devices could result in even higher performance. Additionally, high performance in upscaled blade-coated devices (1 cm<sup>2</sup>) processed in air with a green solvent demonstrated the industrial potential of this system<bold>.</bold></p>",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "&lt;br/&gt;&lt;p&gt;&amp;lt;p&amp;lt;With performance improvements, organic photovoltaics (OPVs) are an increasingly competitive technology for renewable energy. However, most high-performance OPVs are small-area devices processed from toxic halogenated solvents via spin-coating, posing a challenge for mass production. We study a low-cost polymer donor (PTQ10) and a non-fullerene acceptor (DTY6) in a halogen-free solvent using industrially relevant blade coating. The non-inverted architecture performed best, achieving 12% efficiency, with the blade-coating deposition surpassing spin-coating. Active layers processed from the two coating techniques exhibited similar exciton quenching, likely due to the same measured nanodomain size and purity. However, blade-coated devices exhibited a higher charge carrier lifetime correlated with increased acceptor pi-stacking despite decreased donor pi-stacking. This suggests that optimizing crystallinity in blade-coated devices could result in even higher performance. Additionally, high performance in upscaled blade-coated devices (1 cm&amp;lt;sup&amp;lt;2&amp;lt;/sup&amp;lt;) processed in air with a green solvent demonstrated the industrial potential of this system&amp;lt;bold&amp;lt;.&amp;lt;/bold&amp;lt;&amp;lt;/p&amp;lt;&lt;/p&gt;\n\t\t\t&lt;br/&gt;Opto-Electronic Advances. 2025 8(12): 250148. Published 2025-12-18"
        },
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "&lt;br/&gt;&lt;p&gt;&amp;lt;p&amp;lt;With performance improvements, organic photovoltaics (OPVs) are an increasingly competitive technology for renewable energy. However, most high-performance OPVs are small-area devices processed from toxic halogenated solvents via spin-coating, posing a challenge for mass production. We study a low-cost polymer donor (PTQ10) and a non-fullerene acceptor (DTY6) in a halogen-free solvent using industrially relevant blade coating. The non-inverted architecture performed best, achieving 12% efficiency, with the blade-coating deposition surpassing spin-coating. Active layers processed from the two coating techniques exhibited similar exciton quenching, likely due to the same measured nanodomain size and purity. However, blade-coated devices exhibited a higher charge carrier lifetime correlated with increased acceptor pi-stacking despite decreased donor pi-stacking. This suggests that optimizing crystallinity in blade-coated devices could result in even higher performance. Additionally, high performance in upscaled blade-coated devices (1 cm&amp;lt;sup&amp;lt;2&amp;lt;/sup&amp;lt;) processed in air with a green solvent demonstrated the industrial potential of this system&amp;lt;bold&amp;lt;.&amp;lt;/bold&amp;lt;&amp;lt;/p&amp;lt;&lt;/p&gt;\n\t\t\t&lt;br/&gt;Opto-Electronic Advances. 2025 8(12): 250148. Published 2025-12-18"
            }
        ],
        "authors": [
            {}
        ],
        "author": "Atiq Ur Rahman, Tanner M. Melody, Sydney Pfleiger, Acacia Patterson, Andrea Reale, Brian A. Collins",
        "updated": "2025-12-18",
        "updated_parsed": [
            2025,
            12,
            18,
            0,
            0,
            0,
            3,
            352,
            0
        ],
        "rights": "Personal use only, all commercial or other reuse prohibited",
        "rights_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Personal use only, all commercial or other reuse prohibited"
        },
        "dc_source": "Opto-Electronic Advances. 2025 8(12): 250148.",
        "dc_type": "article",
        "dc_identifier": "doi:10.29026/oea.2025.250148",
        "prism_doi": "10.29026/oea.2025.250148",
        "prism_publicationname": "Opto-Electronic Advances",
        "prism_volume": "8",
        "prism_number": "12",
        "prism_publicationdate": "2025-12-18",
        "prism_url": "https://www.oejournal.org/oea/article/doi/10.29026/oea.2025.250148",
        "prism_startingpage": "250148",
        "journal": "Opto-Electronic Advances",
        "title_cn": "PTQ10:DTY6 在无卤光伏发电中通过沉积技术和配置实现工业规模化的稳健性能",
        "abstract_cn": "<p>随着性能的提高，有机光伏 (OPV) 成为可再生能源领域竞争力日益增强的技术。然而，大多数高性能有机光伏器件都是采用有毒卤化溶剂通过旋涂加工而成的小面积器件，这对大规模生产提出了挑战。我们使用工业相关的刮刀涂层在无卤溶剂中研究低成本聚合物供体 (PTQ10) 和非富勒烯受体 (DTY6)。非倒置架构表现最好，达到 12% 的效率，刮刀涂层沉积超过了旋涂。采用两种涂层技术处理的活性层表现出相似的激子猝灭，这可能是由于测量的纳米域尺寸和纯度相同。然而，尽管施主 pi 堆积减少，但刀片涂层器件表现出更高的载流子寿命，这与受主 pi 堆积增加相关。这表明优化刀片涂层器件的结晶度可能会带来更高的性能。此外，使用绿色溶剂在空气中处理的大型刀片涂层设备 (1 cm<sup>2</sup>) 的高性能证明了该系统的工业潜力<bold>。</bold></p>"
    },
    {
        "id": "https://doi.org/10.29026/oea.2025.250256",
        "title": "Surpassing the diffraction limit in long-range laser engineering via cross-scale vectorial optical field manipulation: perspectives and outlooks",
        "title_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Surpassing the diffraction limit in long-range laser engineering via cross-scale vectorial optical field manipulation: perspectives and outlooks"
        },
        "links": [
            {
                "rel": "alternate",
                "type": "text/html",
                "href": "https://www.oejournal.org/oea/article/doi/10.29026/oea.2025.250256"
            }
        ],
        "link": "https://doi.org/10.29026/oea.2025.250256",
        "summary": "<p>We present a vectorial optical field (VOF) framework that surpasses the diffraction limit in both long-range imaging and energy delivery. By jointly engineering spatial and temporal dimensions, reflective Fourier ptychography is extended to 3.2 km with 0.37× the classical diffraction limit, while a single-photon LiDAR tomography system achieves centimeter-scale, sub-diffraction imaging at 3.3 km using superconducting nanowire single-photon detectors. These advances demonstrate super-resolution, turbulence-resilient imaging over kilometer-range distances. Beyond super-resolution optical, high power VOFs are able to counteract thermal blooming during atmospheric laser propagation, enhancing on-target power density by a factor larger than 2. Together, these results may outline a cross-scale paradigm that links high-power vector-field structuring, single-photon detection, and adaptive control—offering a pathway toward next-generation optical systems that integrate imaging, sensing, communication and directed energy within a common physical framework.</p>",
        "summary_detail": {
            "type": "text/html",
            "language": null,
            "base": "",
            "value": "&lt;br/&gt;&lt;p&gt;&amp;lt;p&amp;lt;We present a vectorial optical field (VOF) framework that surpasses the diffraction limit in both long-range imaging and energy delivery. By jointly engineering spatial and temporal dimensions, reflective Fourier ptychography is extended to 3.2 km with 0.37× the classical diffraction limit, while a single-photon LiDAR tomography system achieves centimeter-scale, sub-diffraction imaging at 3.3 km using superconducting nanowire single-photon detectors. These advances demonstrate super-resolution, turbulence-resilient imaging over kilometer-range distances. Beyond super-resolution optical, high power VOFs are able to counteract thermal blooming during atmospheric laser propagation, enhancing on-target power density by a factor larger than 2. Together, these results may outline a cross-scale paradigm that links high-power vector-field structuring, single-photon detection, and adaptive control—offering a pathway toward next-generation optical systems that integrate imaging, sensing, communication and directed energy within a common physical framework.&amp;lt;/p&amp;lt;&lt;/p&gt;\n\t\t\t&lt;br/&gt;Opto-Electronic Advances. 2025 8(12): 250256. Published 2025-12-25"
        },
        "content": [
            {
                "type": "text/html",
                "language": null,
                "base": "",
                "value": "&lt;br/&gt;&lt;p&gt;&amp;lt;p&amp;lt;We present a vectorial optical field (VOF) framework that surpasses the diffraction limit in both long-range imaging and energy delivery. By jointly engineering spatial and temporal dimensions, reflective Fourier ptychography is extended to 3.2 km with 0.37× the classical diffraction limit, while a single-photon LiDAR tomography system achieves centimeter-scale, sub-diffraction imaging at 3.3 km using superconducting nanowire single-photon detectors. These advances demonstrate super-resolution, turbulence-resilient imaging over kilometer-range distances. Beyond super-resolution optical, high power VOFs are able to counteract thermal blooming during atmospheric laser propagation, enhancing on-target power density by a factor larger than 2. Together, these results may outline a cross-scale paradigm that links high-power vector-field structuring, single-photon detection, and adaptive control—offering a pathway toward next-generation optical systems that integrate imaging, sensing, communication and directed energy within a common physical framework.&amp;lt;/p&amp;lt;&lt;/p&gt;\n\t\t\t&lt;br/&gt;Opto-Electronic Advances. 2025 8(12): 250256. Published 2025-12-25"
            }
        ],
        "authors": [
            {}
        ],
        "author": "Yinghui Guo, Mingbo Pu, Yang Li, Mingfeng Xu, Xiangang Luo",
        "updated": "2025-12-25",
        "updated_parsed": [
            2025,
            12,
            25,
            0,
            0,
            0,
            3,
            359,
            0
        ],
        "rights": "Personal use only, all commercial or other reuse prohibited",
        "rights_detail": {
            "type": "text/plain",
            "language": null,
            "base": "",
            "value": "Personal use only, all commercial or other reuse prohibited"
        },
        "dc_source": "Opto-Electronic Advances. 2025 8(12): 250256.",
        "dc_type": "article",
        "dc_identifier": "doi:10.29026/oea.2025.250256",
        "prism_doi": "10.29026/oea.2025.250256",
        "prism_publicationname": "Opto-Electronic Advances",
        "prism_volume": "8",
        "prism_number": "12",
        "prism_publicationdate": "2025-12-25",
        "prism_url": "https://www.oejournal.org/oea/article/doi/10.29026/oea.2025.250256",
        "prism_startingpage": "250256",
        "journal": "Opto-Electronic Advances",
        "title_cn": "通过跨尺度矢量光场操纵超越远程激光工程中的衍射极限：观点和展望",
        "abstract_cn": "<p>我们提出了一种矢量光场 (VOF) 框架，该框架在远程成像和能量传输方面都超越了衍射极限。通过联合设计空间和时间维度，反射式傅立叶叠层成像技术可扩展至 3.2 公里，具有 0.37 倍经典衍射极限，而单光子 LiDAR 断层扫描系统则使用超导纳米线单光子探测器在 3.3 公里处实现厘米级亚衍射成像。这些进步展示了在公里范围内的超分辨率、抗湍流成像。除了超分辨率光学之外，高功率 VOF 还能够抵消大气激光传播过程中的热晕，将目标功率密度提高超过 2 倍。总之，这些结果可能概述了一种将高功率矢量场结构、单光子检测和自适应控制联系起来的跨尺度范式，为下一代光学系统提供了一条途径，该系统将成像、传感、通信和定向能集成在一个共同的物理框架内。</p>"
    }
]